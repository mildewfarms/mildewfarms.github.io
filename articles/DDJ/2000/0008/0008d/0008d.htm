<html>
<head>
<title>Aug00: Augural Image Zooming</title>
</head>

<body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000">
<!--Copyright &#169; Dr. Dobb's Journal-->

<h1>Augural Image Zooming</h1>

<p><i>Dr. Dobb's Journal</i> August 2000</p>
<h2>Enlarge digital images rapidly and crisply</h2>

<h3>By Wm. Douglas Withers</h3>

<I>
Els is a member of the Department of Mathematics at the U.S. Naval Academy and a research scientist with Pegasus Imaging. He can be contacted at wdw@usna.edu.</I>

<hr>

<p><A NAME="rf1"></a><A HREF="0008df1.htm">Figure 1</A> is an image represented as a 192X300 matrix of pixels, each with a specified color value. <A NAME="rf2"></a><A HREF="0008df2.htm">Figure 2</A> is a smaller image, represented as a 96X150 matrix of pixels, thus containing only one-fourth the quantity of data of <A NAME="rf1"></a><A HREF="0008df1.htm">Figure 1</A>. <A NAME="rf3"></a><A HREF="0008df3.htm">Figure 3</A> is the same 96X150 image as <A NAME="rf2"></a><A HREF="0008df2.htm">Figure 2</A>, but covering the same area as <A NAME="rf1"></a><A HREF="0008df1.htm">Figure 1</A>, so that each pixel has four times the area of the pixels in <A NAME="rf1"></a><A HREF="0008df1.htm">Figure 1</A>. Even though <A NAME="rf3"></a><A HREF="0008df3.htm">Figure 3</A> is coarser than <A NAME="rf1"></a><A HREF="0008df1.htm">Figure 1</A> (that is, of lower resolution rather than smaller), it is obvious that they represent the same scene. </p>
<p><A NAME="rf3"></a><A HREF="0008df3.htm">Figure 3</A> was derived from <A NAME="rf1"></a><A HREF="0008df1.htm">Figure 1</A>. Each coarse pixel of <A NAME="rf3"></a><A HREF="0008df3.htm">Figure 3</A> corresponds to a 2X2 group of four fine pixels from <A NAME="rf1"></a><A HREF="0008df1.htm">Figure 1</A>; and the color value (having three components red, green, and blue) of the coarse pixel is the average of the color values of the four fine pixels. The coarse image, <A NAME="rf3"></a><A HREF="0008df3.htm">Figure 3</A>, created by shrinking the fine image, <A NAME="rf1"></a><A HREF="0008df1.htm">Figure 1</A>, is identical up to rounding error with an image of the same resolution created directly from the given scene. </p>
<DDJADVERTISEMENT INLINE>

<p>The derivation of a finer image from a coarser one is referred to as "image zooming." Unlike shrinking, zooming in an exact sense is theoretically impossible, because many different finer images correspond to a single coarser image. So in zooming an image, you don't expect to reproduce the finer image exactly -- rather you seek to choose the most plausible of all the possible finer images corresponding to the coarser. </p>

<p>Image zooming has a variety of applications. Multitudes of images travel daily over the Internet. Due to the limited capacity of the transmission channel relative to the quantity of data in an image, transmission of a single image often requires seconds or minutes. This delay can be alleviated by sending images in a progressive format: a low-resolution version of the image to begin with, followed by additional data providing a gradual increase in resolution. The recipient can then get an early impression of an image and interrupt the transmission if desired. Skillful zooming improves the appearance of the image while it has been only partially transmitted. You might zoom an image to move it from one device to another with higher resolution. A computer monitor may display an image at a resolution of 72 pixels per inch, while a printer may provide resolution of 300 pixels per inch. Printing an image displayed on the monitor entails either printing the image at a smaller size or increasing the resolution.</p>

<p>In the U.S., digital television (DTV) is coming into real use. The new format provides resolution more than double the old NTSC. However, much programming has been recorded on NTSC-compatible media, such as VHS videotape. Viewing such media on a high-resolution television entails either using only a small portion of the screen or zooming the video signal.</p>

<p>Various image-zooming approaches are already in use. The most primitive, but also one of the most popular, is resampling or pixel replication. Resampling consists of simply repeating the pixel values of the image as necessary to achieve the desired size. <A NAME="rf3"></a><A HREF="0008df3.htm">Figure 3</A> could be zoomed by resampling to the same resolution as <A NAME="rf1"></a><A HREF="0008df1.htm">Figure 1</A>, but with no change whatsoever in appearance. The resampling method is fast, but leaves much to be desired in quality. <A NAME="rf3"></a><A HREF="0008df3.htm">Figure 3</A> shows objectionable features (jaggies) along sharp edges, such as the edge of the model's dress, or the edges between her right shoulder or right cheek and the background. Smooth areas such as the dimple in her throat or the right side of her forehead show less prominent artifacts.</p>

<p><A NAME="rf4"></a><A HREF="0008df4.htm">Figure 4</A> is a slightly more sophisticated approach, produced by linearly interpolating to determine the new pixel values. This eliminates most of the objectionable features seen in smooth regions of <A NAME="rf3"></a><A HREF="0008df3.htm">Figure 3</A>. Moreover, jaggies on sharp edges are much alleviated. However, edges and other regions of detail show blurring.</p>

<p>In this article, I present a fundamentally new method for zooming images, which I call the "augural method." My goal in developing the augural method was to zoom images with a minimum of computation, while keeping smooth regions smooth and sharp edges sharp. The method described here serves to double the scale of an image; the same principles have been applied to zoom an image to any desired size. </p>



<h3>Principles of the Augural Method</h3>


<p>For starters, I assume that the coarse image to be zoomed is a digital photograph of a real scene; for example, <A NAME="rf1"></a><A HREF="0008df1.htm">Figure 1</A> depicts a woman wearing a black dress in the depicted environment. The transition from real scene to digital image may have comprised several steps involving cameras and scanners; but I assume that the ultimate effect is equivalent to laying a rectangular grid in front of the scene and filling each grid cell with the average color value of the corresponding region of the scene. Each grid cell then becomes one pixel of the image. A finer image of the same scene can be created simply by using a grid with smaller rectangles. </p>


<p>The augural method is thus inappropriate for certain types of images: synthesized images containing features such as aliased edges, which would not appear in a digital photograph of a real scene; or dithered images, where the pixel values no longer represent average color values of the corresponding grid cells. The method is applicable, however, to synthetic images (such as ray-traced images) created using an underlying ideal model.</p>

<p><A NAME="rf5"></a><A HREF="0008df5.htm">Figure 5</A> is a magnified portion of an ideal scene, together with pixelizations at various resolutions. Region <i>I </i>shows the ideal scene. Region <i>F </i>shows a fine pixelization, while Region <i>CR </i>shows a coarse pixelization at half the resolution of Region <i>F, </i>each pixel in Region <i>CR </i>covering the same area as four pixels in Region <i>F. </i>Region <i>C </i>represents an intermediate stage whose pixels cover the same area as just two pixels from Region <i>F. </i>In Regions <i>F, C, </i>and <i>CR, </i>each pixel value equals the average value of the underlying ideal image over the corresponding rectangle. But each pixel value in Region <i>C </i>can also be calculated as the average of the corresponding pair of pixel values from Region <i>F. </i>Similarly, each pixel value in Region <i>CR </i>equals the average of the corresponding pair of pixel values in Region <i>C.</i></p>

<p>The goal of zooming is to derive a good approximation to the fine pixelization in Region <i>F </i>from a coarse pixelization like that in Region <i>CR. </i>I chose to consider the simpler problem of producing the intermediate pixelization in Region <i>C. </i>Essentially, the same process can then be applied to the intermediate pixelization (with a 90 degree change in orientation) to produce the fine pixelization.</p>

<p>The essence of the augural method is to start with a coarse pixelization, hypothesize a model for the underlying ideal structure in each neighborhood of the real scene, analyze the coarse pixel values to refine the details of the model, and use this model to calculate the corresponding pixel values in the fine image. Deriving a model for the underlying image structure is a deep, subtle problem without a complete solution. The augural method, by compromises and makeshifts, makes a crude judgment that nonetheless proves quite useful.</p>

<p>Images are two dimensional. The first compromise of the augural method is to operate in only one dimension at a time. The resolution of the image is doubled in two steps; first the vertical resolution is doubled (Region <i>CR </i>to Region <i>C</i>), and then the horizontal (Region <i>C </i>to Region<i> F</i>). Moreover, when doubling the vertical (or horizontal) resolution, each column (or row) of the image is considered in isolation, and doubled in resolution. (The underlying image-structure model, however, is considered in two dimensions.) Thus, each coarse pixel corresponds to a pair of fine pixels. The following discussion is couched in terms of doubling the length of a row; but doubling a column is essentially the same except for orientation.</p>

<p>I describe the method as applied to 8-bit gray-scale images, each pixel value a number in the range 0 to 255. Color images can be zoomed quite satisfactorily by zooming the red, green, and blue color planes separately. Other levels of precision can be handled by straightforward modifications. </p>

<p>I denote the coarse pixel values in a row from left to right by <i>C</i>[0], <i>C</i>[1],..., <i>C</i>[<i>w</i>-1], where <i>w</i> is the width of the coarse row. I must calculate estimated fine pixel values <i>F</i>[0],<i>F</i>[1],...,<i>F</i>[2<i>w</i>-1] (twice as many fine pixels as coarse pixels in a row). The coarse pixel with value <i>C</i>[<i>n</i>] covers the same region of the image as the two fine pixels with values <i>F</i>[2<i>n</i>] and <i>F</i>[2<i>n</i>+1]. As already noted, <i>C</i>[<i>n</i>] equals the average of <i>F</i>[2<i>n</i>] and <i>F</i>[2<i>n</i>+1]: <i>C</i>[<i>n</i>]=(<i>F</i>[2<i>n</i>]+<i>F</i>[2<i>n</i>+ 1])/2.</p>

<p>Let <i>D</i>[<i>n</i>]=<i>F</i>[2<i>n</i>+1]-<i>F</i>[2<i>n</i>]; then <i>F</i>[2<i>n</i>] and <i>F</i>[2<i>n</i>+1] can be calculated from <i>C</i>[<i>n</i>] and <i>D</i>[<i>n</i>]: <i>F</i>[2<i>n</i>]=<i>C</i>[<i>n</i>]-<i>D</i>[<i>n</i>]/2, <i>F</i>[2<i>n</i>+1]= <i>C</i>[<i>n</i>]+<i>D</i>[<i>n</i>]/2.</p>

<p>The problem now is how to determine the value of <i>D</i>[<i>n</i>] corresponding to a particular <i>C</i>[<i>n</i>]. Splitting the coarse pixel with value <i>C</i>[<i>n</i>] (henceforth called the "home" pixel) entails predicting <i>D[n] </i>and then using it to find <i>F</i>[2<i>n</i>] and <i>F</i>[2<i>n</i>+1].<i> </i>I proceed across the row from left to right, so when splitting the home pixel with value <i>C</i>[<i>n</i>], not only are all coarse pixel values of the row available, but also available are the fine pixel values from <i>F</i>[0] to <i>F</i>[2<i>n</i>-1]. To predict the value of <i>D</i>[<i>n</i>], I utilize the three values <i>F</i>[2<i>n</i>-1], <i>C</i>[<i>n</i>], and <i>C</i>[<i>n</i>+1] (and eventually <i>F</i>[2<i>n</i>-2]).</p>

<p>I imposed some abstract mathematical conditions upon the zooming process. The first condition is variation preservation. The variation of the row is the total amount of fluctuation up and down as one travels across the row. The variation of the original coarse row is <i>V</i><sub>coarse</sub>= |<i>C</i>[1]-<i>C</i>[0]|+|<i>C</i>[2]-<i>C</i>[1]|+...+|<i>C</i>[<i>w</i>-1]- <i>C</i>[<i>w</i>-2]|; the variation of the calculated fine row is <i>V</i><sub>fine</sub>=|<i>F</i>[1]-<i>F</i>[0]|+|<i>F</i>[2]-<i>F</i>[1]|+ ...+|<i>F</i>[2<i>w</i>-]-<i>F</i>[2<i>w</i>-2]|. </p>

<p>It is always true that <i>V</i><sub>fine</sub><img src="gteq.gif"><i>V</i><sub>coarse</sub>; variation preservation is the additional condition that <i>V</i><sub>fine</sub><img src="lteq12.gif"><i>V</i><sub>coarse</sub>. I imposed this condition as a preventative against zooming artifacts: the introduction of detail into areas such as smooth regions, where the eye expects none. This seems visually more disturbing than the absence of detail where expected. Sophisticated zooming tools such as fractals or wavelets sometimes generate such artifacts, which as a rule entail a variation increase. Variation preservation also eliminates the possibility of pixel-value overflow or underflow.</p>

<p>You can show that variation is preserved if for each <i>D</i>[<i>n</i>] the 
  resulting <i>F</i>[2<i>n</i>] and <i>F</i>[2<i>n</i>+1] satisfy: |<i>F</i>[2<i>n</i>]-<i>F</i>[2<i>n</i>-1]|+|<i>F</i>[2<i>n</i>+1]- 
  <i>F</i>[2<i>n</i>]|+|<i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>+1]||<img src="lteq12.gif" width="6" height="7" align="baseline"><i>C</i>[<i>n</i>]-<i>F</i>[2<i>n</i>-1]|+|<i>C</i>[<i>n</i>+1]-<i>C</i>[<i>n</i>]|.</p>

<p>The second condition is that the zooming process be invariant when all pixel values are modified by addition of or multiplication by a constant. The rationale is that adding a constant to all pixel values has an effect akin to twiddling the brightness knob on the computer monitor, and multiplying all pixel values by a constant is like twiddling the contrast knob. Both transformations change the colors of objects in the image without affecting structural features. So, if you define a new set <i>C<sub>T</sub></i> of coarse pixel values by the transformation <i>C<sub>T</sub></i>[<i>n</i>]=<i>pC</i>[<i>n</i>]+<i>q</i>, the corresponding fine pixel values <i>F<sub>T</sub></i> obtained by zooming <i>C<sub>T</sub></i> should be related to the original fine pixel values <i>F</i> by: <i>F<sub>T</sub></i>[<i>n</i>]=<i>pF</i>[<i>n</i>]+<i>q</i>. The transformed fine-pixel differences <i>D<sub>T</sub></i> then satisfy: <i>D<sub>T</sub></i>[<i>n</i>]=<i>F<sub>T</sub></i>[2<i>n</i>+1]-<i>F<sub>T</sub></i>[2<i>n</i>](<i>pF</i>[2<i>n</i>+1]+<i>q</i>)- (<i>pF</i>[2<i>n</i>]+<i>q</i>)=<i>pD</i>[<i>n</i>].</p>

<p>This condition lets me set <i>p</i> and <i>q</i> to any convenient values for the purpose of splitting the home pixel with value <i>C</i>[<i>n</i>]; I can use standard settings for "brightness" and "contrast" of the image, which will simplify my task. I choose to let: <i>p</i>=1/(<i>C</i>[<i>n</i>+1]- <i>F</i>[2<i>n</i>-1]) and <i>q</i>=-<i>F</i>[2<i>n</i>1]/(<i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>-1]), the case <i>C</i>[<i>n</i>+1]=<i>F</i>[2<i>n</i>-1] being moot because variation preservation then requires that <i>D</i>[<i>n</i>]=0. Then: <i>F<sub>T</sub></i>[2<i>n</i>-1]=0, <i>C<sub>T</sub></i>[<i>n</i>]=(<i>C</i>[<i>n</i>]- <i>F</i>[2<i>n</i>-1])/(<i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>-1]), <i>C<sub>T</sub></i>[<i>n</i>+1]=1. The fine-pixel difference <i>D</i>[<i>n</i>] can be calculated as: <i>D</i>[<i>n</i>] =<i>D<sub>T</sub></i>[<i>n</i>]/<i>p</i>=(<i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>-1])<i>D<sub>T</sub></i>[<i>n</i>].</p>

<p>The prediction of <i>D</i>[<i>n</i>] from the values of <i>F</i>[2<i>n</i>-1], <i>C</i>[<i>n</i>], and <i>C</i>[<i>n</i>+1] now reduces to a single input variable, the "augury": <i>A</i>= <i>C<sub>T</sub></i>[<i>n</i>]=(<i>C</i>[<i>n</i>]-<i>F</i>[2<i>n</i>-1])/(<i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>-1]), and a single output variable, the "declivity": D=<i>D<sub>T</sub></i>[<i>n</i>]=<i>D</i>[<i>n</i>]/(<i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>-1]). </p>

<p>The declivity will be calculated as a certain function <i>G</i>, the "geminator," of the augury: D=<i>G</i>(<i>A</i>).</p>



<h3>Premises and  Consequences of Geminators</h3>


<p>A geminator arises from an assumption (which I call a "scenario") concerning the type of structure found in the image. <A NAME="rf6"></a><A HREF="0008df6.htm">Figure 6</A> is part of an image with certain features of particular interest highlighted. Each highlighted region represents two coarse pixels (having values <i>C</i>[<i>n</i>] and <i>C</i>[<i>n</i>+1]) with an adjacent fine pixel (having value <i>F</i>[2<i>n</i>-1]). The middle (home) pixel with value <i>C</i>[<i>n</i>] is to be split into two fine pixels with values <i>F</i>[2<i>n</i>] and <i>F</i>[2<i>n</i>+1]. Recall that the only information available is the average value over the rectangular region that is each pixel, as in <A NAME="rf7"></a><A HREF="0008df7.htm">Figure 7</A>. </p>


<p>The image may contain structures quite complex at the given resolution level (such as the yellow region in <A NAME="rf6"></a><A HREF="0008df6.htm">Figure 6</A>). Faithfully zooming these regions is most likely impossible, and I did not try. Rather, I chose to consider simple features such as smooth areas (red) and sharp, straight edges at various orientations to the pixel grid (red, green, and blue). These features are simple enough to be feasible of analysis, occur frequently in most images, and are visually important.</p>

<p>Consider first the blue-shaded region in <A NAME="rf6"></a><A HREF="0008df6.htm">Figure 6</A>, an example of a sharp, straight edge passing through the home pixel perpendicular, or almost so, to the pixel row. I call this the "perpendicular-edge" scenario. In this scenario, the declivity can be calculated as a function of the position of the edge within the home pixel. The augury can also be calculated as a function of this position; in fact, the augury equals the distance between the edge and the left boundary of the home pixel. Thus, the declivity can be calculated as a function of the augury, yielding the geminator for the perpendicular-edge scenario.</p>

<p>The result is the function <i>G<sub>P</sub></i>(<i>A</i>)=2<i>A</i> for 0<img src="lteq12.gif"><i>A</i><img src="lteq12.gif">0.5; <i>G<sub>P</sub></i>(<i>A</i>)=2-2<i>A</i> for 0.5<img src="lteq12.gif"><i>A</i><img src="lteq12.gif">1. <A NAME="rf8"></a><A HREF="0008df8.htm">Figure 8</A> is the graph of <i>G<sub>P</sub></i> (in blue), and also its peak value, which occurs when the perpendicular edge exactly bisects the home pixel. </p>

<p>Values of <i>A</i> less than 0 or greater than 1 do not occur in the perpendicular case; however, for such values of <i>A</i>, variation preservation requires that <i>G<sub>P</sub></i>(<i>A</i>)=0. In fact, the variation-preservation condition translates into a straightforward condition on the geminator <i>G</i> for any scenario: 0<img src="lteq12.gif"><i>G</i>(<i>A</i>)<img src="lteq12.gif"> <i>G<sub>P</sub></i>(<i>A</i>); in other words, the graph of <i>G</i> is constrained to lie within the variation- preserving zone shown as light gray in <A NAME="rf8"></a><A HREF="0008df8.htm">Figure 8</A>. This zone takes the single value 0 for values of <i>A</i> less than 0 or greater than 1.</p>

<p><A NAME="rf10"></a><A HREF="0008df10.htm">Figure 10</A> is the result of zooming using <i>G<sub>P</sub></i>. For comparison, <A NAME="rf9"></a><A HREF="0008df9.htm">Figure 9</A> shows zooming by resampling. Repeated zooming exaggerates the special characteristics of a given zoomer. I therefore zoomed a small portion of the image (bounded by the blue rectangle) twice to facilitate detailed comparison. </p>

<p><A NAME="rf10"></a><A HREF="0008df10.htm">Figure 10</A> cannot be considered a success, though it does have some interesting features. Vertical and horizontal edges indeed retain sharpness. Smooth areas break up into patches of constant color. And diagonal edges acquire a stair-step appearance. Repeated zooming accentuates all of these effects. The failure of this zoomer, derived from a sharp-edge scenario, to handle smooth areas properly is unsurprising. However, its performance on diagonal edges is disappointing.</p>

<p>Consider next a smooth area of the image (such as the model's cheek, red in <A NAME="rf6"></a><A HREF="0008df6.htm">Figure 6</A>), which I call the "smooth" scenario. You can calculate the geminator in the smooth scenario to be <i>G<sub>S</sub></i>(<i>A</i>)=(<i>A</i>+1)/5, constrained to stay within the variation-preserving zone (red in <A NAME="rf8"></a><A HREF="0008df8.htm">Figure 8</A>). <A NAME="rf8"></a><A HREF="0008df8.htm">Figure 8</A> also indicates the special case of a fixed rate of brightness change, with resulting augury <i>A</i>=3/7 and resulting declivity D=2/7. </p>

<p>The "gentle-edge" scenario supposes a sharp, straight edge just slightly inclined to the pixel row (also red in <A NAME="rf6"></a><A HREF="0008df6.htm">Figure 6</A>). Though visually wholly unlike the smooth scenario, this scenario yields exactly the same geminator <i>G<sub>S</sub></i>.</p>

<p><A NAME="rf11"></a><A HREF="0008df11.htm">Figure 11</A> is the result of zooming using <i>G<sub>S</sub></i>. Exactly as expected, it performs well in smooth areas, but on edges shows blurring similar to linear interpolation.</p>

<p>Because neither the perpendicular-edge scenario nor the smooth scenario yielded satisfactory results on diagonal edges, I next investigated the "diagonal-edge" scenario, wherein a sharp edge runs diagonally through the home pixel (green in <A NAME="rf6"></a><A HREF="0008df6.htm">Figure 6</A>). For the first time I needed to take aspect ratio into account: Splitting a square pixel into two narrow rectangular halves requires a different geminator from splitting a narrow rectangular pixel into two square halves. In both cases, I determined the geminator by calculating augury and declivity from the areas of various trapezoids and triangles, and then solving for the declivity in terms of the augury.</p>

<p>The case of splitting a narrow rectangular pixel yields the geminator <i>G<sub>D</sub></i>(<i>A</i>)=4<i>A</i> -4<i>A</i><sup>2</sup>-0.25 for 0.25<img src="lteq12.gif"><i>A</i><img src="lteq12.gif">0.75, <i>G<sub>D</sub></i>(<i>A</i>)=<i>G<sub>P</sub></i>(<i>A</i>) elsewhere. The case of splitting a square pixel into two narrow rectangular halves yields a different geminator <i>H<sub>D</sub></i>. I omit here the formula for <i>H<sub>D</sub></i> because of its complexity, but <A NAME="rf8"></a><A HREF="0008df8.htm">Figure 8</A> shows the graphs of both <i>G<sub>D</sub></i> and <i>H<sub>D</sub></i>. <A NAME="rf8"></a><A HREF="0008df8.htm">Figure 8</A> indicates also the peak values for <i>G<sub>D</sub></i> and <i>H<sub>D</sub></i> (both occurring when the diagonal edge bisects the home pixel), as well as other critical values for both functions.</p>

<p><A NAME="rf12"></a><A HREF="0008df12.htm">Figure 12</A> is the result of zooming using <i>G<sub>D</sub></i> and <i>H<sub>D</sub></i>. This zoomer not only performs well on diagonal edges, but by good fortune also yields acceptable results on perpendicular edges (unlike <i>G<sub>P</sub></i>, which performed strangely on diagonal edges). In smooth areas, <i>G<sub>D</sub></i> and <i>H<sub>D</sub></i> yield a faceted appearance similar to <i>G<sub>P</sub></i>.</p>

<p>Clearly what is needed is a zoomer that combines the performance of <i>G<sub>D</sub></i> and <i>H<sub>D</sub> </i>on edges and the performance of <i>G<sub>S</sub></i> on smooth areas. The elements <i>F</i>[2<i>n</i>-1], <i>C</i>[<i>n</i>], and <i>C</i>[<i>n</i>+1] of the augury, are simply not sufficient information to distinguish between the smooth and diagonal-edge scenarios. I thus resorted to using the value of <i>F</i>[2<i>n</i>-2] to decide between these two scenarios when splitting a given pixel.</p>

<p>The diagonal-edge scenario supposes that a sharp edge is traveling diagonally across the home pixel. In such a case, <i>D</i>[<i>n</i>-1] (the difference <i>F</i>[2<i>n</i>-1]-<i>F</i>[2<i>n</i>-2]) should be close to zero compared to the difference <i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>-1]. On the other hand, in the smooth scenario, the difference <i>F</i>[2<i>n</i>-1]-<i>F</i>[2<i>n</i>-2] should be about 2/7 of the difference <i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>-1].</p>

<p>The criterion I used is this: the diagonal-edge geminator G<sub>D</sub> or <i>H</i><sub>D</sub> is used if: |<i>D</i>[<i>n</i>- 1]|&lt;0.05|<i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>-1]|; the smooth geminator <i>G<sub>S</sub></i> is used otherwise.</p>

<p><A NAME="rf13"></a><A HREF="0008df13.htm">Figure 13</A> is the result of zooming using a <i>G<sub>D</sub></i> and <i>H<sub>D</sub></i> in combination with <i>G<sub>S</sub></i>. This combination zoomer keeps smooth areas smooth and sharp edges sharp.</p>



<h3>Zooming with Integer Arithmetic</h3>


<p>Most image formats specify pixel values as integers, and for better speed and wider applicability I wanted a zooming algorithm that operates entirely in integer arithmetic. To this end, I made several adaptations to the hitherto-described method. </p>


<p>First, recall: <i>C</i>[<i>n</i>]=(<i>F</i>[2<i>n</i>]+<i>F</i>[2<i>n</i>+1])/2, <i>D</i>[<i>n</i>]=<i>F</i>[2<i>n</i>+1] -<i>F</i>[2<i>n</i>]. In integer arithmetic, division by 2 in the calculation of <i>C</i>[<i>n</i>] entails losing the lowest precision bit. However, you can still recover <i>F</i>[2<i>n</i>] and <i>F</i>[2<i>n</i>+1] from <i>C</i>[<i>n</i>] and <i>D</i>[<i>n</i>] by: <i>F</i>[2<i>n</i>]=<i>C</i>[<i>n</i>]- (<i>D</i>[<i>n</i>]&gt;&gt;1), <i>F</i>[2<i>n</i>+1]=<i>C</i>[<i>n</i>]+((<i>D</i>[<i>n</i>]+1)&gt;&gt;1). Here, I shift right by one bit rather than divide by two so that the result is rounded down rather than towards zero.</p>

<p>One advantage of distilling the three values <i>F</i>[2<i>n</i>-1], <i>C</i>[<i>n</i>], and <i>C</i>[<i>n</i>+1] down to the single value <i>A</i> is that you can use a lookup table to evaluate the geminator, a function of a single variable, whereas a lookup table with three input variables might be completely infeasible. Thus, the computational complexity of the geminator is of no concern.</p>

<p>However, consider the range of possible values of the augury: <i>A</i>=(<i>C</i>[<i>n</i>]-<i>F</i>[2<i>n</i>-1])/ (<i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>-1]). With pixel values ranging from 0 to 255, the augury <i>A</i> ranges in magnitude from 1/255 to 255, even excluding zero and infinite values. To reduce lookup table size needed, I manipulated augury and declivity on a logarithmic scale. This also eliminates multiplication and division operations from the algorithm.</p>

<p>In integer arithmetic, the augury is represented by the variable <i>LgA</i>, calculated as: <i>LgA</i>=<i>Lg</i>(<i>C</i>[<i>n</i>]-<i>F</i>[2<i>n</i>-1])-<i>LgE</i>, where <i>LgE</i>=<i>Lg</i>(<i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>-1]). The function <i>Lg()</i> is a modified logarithm, calculated by means of a lookup table. Modifications are necessary for three purposes: to handle zero arguments, handle negative arguments, and represent the output as an <i>unsigned char</i>. </p>

<p>To handle zero arguments, I exploited the truncation error in calculating <i>C</i>[<i>n</i>] (or <i>C</i>[<i>n</i>+1]) as an average of two fine pixel values. This error causes the value to be underrepresented by 0.5 about half the time, underrepresented by 0.25 on average. The argument to <i>Lg()</i>, being always a difference between a coarse and a fine pixel value, is also underrepresented by 0.25 on average. To compensate for this, <i>Lg()</i> adds 0.25 before taking the logarithm, thus eliminating the occasion for taking the logarithm of 0.</p>

<p>To handle negative arguments, I adopted the convention of representing the logarithm of a positive number by the logarithm rounded to the nearest even integer and representing the logarithm of a negative number by the logarithm of the absolute value, rounded to the nearest odd integer -- exploiting the fact that the parity of a difference of integers is even if and only if the two arguments have the same parity, just as the sign of a quotient of real numbers is positive if and only if the two arguments have the same sign.</p>

<p>Finally, I normalized the function <i>Lg()</i> by subtracting a constant so that <i>Lg</i>(0)=0, and hence all values of <i>Lg()</i> are nonnegative. This constant cancels out when the two outputs from <i>Lg()</i> are subtracted in the calculation of <i>LgA</i>.</p>

<p>Thus, the actual formula for <i>Lg</i>(<i>t</i>) is: <i>Lg</i>(<i>t</i>)=log<sub><i>B</i></sub>|<i>t</i>+0.25|-log<sub><i>B</i></sub> 0.25, rounded to the nearest odd integer for negative <i>t</i> and rounded to the nearest even integer otherwise. Larger values for the logarithmic base <i>B</i> yield more compact look-up tables at the expense of precision of calculation. I recommend the value <i>B</i>=1.027653151, which allows <i>Lg</i> and the other lookup tables to be byte valued, while keeping as much precision as possible, so that <i>Lg</i>(255)=254 and <i>Lg</i>(-255)=253.</p>

<p>The declivity <i>D</i> is represented on a logarithmic scale by the variable <i>LgDelta</i>, related to <i>D</i> by the formula: <i>LgDelta</i>=log<sub><i>B</i></sub> <i>D</i>-log<sub><i>B</i></sub> 0.25, rounded to the nearest even integer for positive values of <i>D</i> and to the nearest odd integer for negative values. The fine-pixel differences <i>D</i>[<i>n</i>] and <i>D</i>[<i>n</i>-1] are represented on a logarithmic scale by the variable <i>LgD</i>, related to <i>D</i>[<i>n</i>] (or <i>D</i>[<i>n</i>-1] as occasion demands) by: <i>LgD</i>=log<sub><i>B</i></sub> <i>D</i>[<i>n</i>]-log<sub><i>B</i></sub> 0.25-log<sub><i>B</i></sub> 0.05, likewise rounded to an even or odd integer according to the sign of <i>D</i>[<i>n</i>]. These various versions of the logarithmic scale allow <i>LgD</i> to be calculated as: <i>LgD</i>=<i>LgDelta</i>+<i>LgE</i>, while the criterion |<i>D</i>[<i>n</i>-1]|&lt;0.05|<i>C</i>[<i>n</i>+1]-<i>F</i>[2<i>n</i>-1]| for choosing the diagonal-edge versus the smooth scenario translates into simply: <i>LgD</i>&lt;<i>LgE</i>.</p>

<p>The actual fine-pixel difference <i>D</i>[<i>n</i>] must be recovered from the logarithmic <i>LgD</i> in order to calculate the fine pixel values; this is done by the modified exponential function <i>Xp()</i> (also calculated by lookup table), given by: <i>Xp(LgD)</i>= (<sup>+</sup>_(0.25)(0.05)<i>B<sup>LgD</sup></i>, rounded to the nearest integer, negatively valued for odd <i>LgD</i>, and positively valued otherwise.</p>

<p>Finally, the geminators <i>G<sub>D</sub></i>, <i>H<sub>D</sub></i>, and <i>G<sub>S</sub></i> must be adapted to the appropriate logarithmic scale on both input and output. The logarithmic equivalents are functions <i>LgG_D()</i>, <i>LgH_D()</i>, and <i>LgG_S()</i> (all calculated by lookup tables). <i>LgG_D()</i> is related to <i>G<sub>D</sub></i> by the formula: <i>LgG_D</i>(<i>LgA</i>) =log<sub><i>B</i></sub>(<i>G<sub>D</sub></i>(<i>B<sup>LgA</sup></i>)/0.05); with corresponding relations for <i>LgH_D</i> and <i>LgG_S</i>. Zero values for the geminator are represented on the logarithmic scale by a value small enough that the eventual value of <i>D</i>[<i>n</i>] is guaranteed to be zero.</p>

<p>In summary, a single coarse pixel with value <i>C</i>[<i>n</i>] is split into two fine pixels with values <i>F</i>[2<i>n</i>] and <i>F</i>[2<i>n</i>+1] by the following sequence of steps. <i>LgD</i> holds the value that remains after splitting the previous pixel.</p>

<blockquote><p>
<i>LgE=Lg(C[n+</i>1<i>]-F[2n-</i>1<i>]);</i></p><p>

<i>
</i>LgA=Lg(C[n]-F[2<i>n-</i>1<i>]);</i></p><i>

<p>LgDelta=LgD&lt;LgE?LgGH_D(LgA):LgG_S(LgA);</p></i>

<p>LgD=LgDelta+LgE;</p>

<p>D[n]=Xp(LgD);</p>

<p>F[2<i>n]=C[n]-(D[n]&gt;&gt;</i>1<i>);</i></p><p>

<i>
</i>F[2<i>n+</i>1<i>]=C[n]+((D[n]+</i>1<i>)&gt;&gt;</i>1<i>);</i></p>

</blockquote><p><i></i>Here <i>LgGH_D</i> represents either <i>LgG_D</i> for horizontal zooming or <i>LgH_D</i> for vertical zooming. All functions are calculated by lookup tables. The algorithm design completely eliminates the need for range checking on lookup table input.</p>




<h3>Sample Code </h3>


<p>I've implemented the augural method described here in ZOOMTEST, a sample program (available electronically; see "Resource Center," page 5). The program consists of files: IMAGE.H, BMP.H, ZOOM.H, ZOOM.CPP, BMP.CPP, and ZOOMTEST.CPP. This is intended as an example program rather than a finished software product, so issues such as error checking and interfacing have been kept as sparse and unobtrusive as possible. The source code is distributed under the terms of the GNU public license.</p>


<p>ZOOMTEST has the usage syntax: <i>ZOOMTEST &lt;infile&gt; &lt;outfile&gt;.</i> Input and output files are 24-bit BMP format. </p>

<p>The 24-bit color format is handled by zooming the red, green, and blue color planes separately. The edges of the image (where <i>F</i>[2<i>n</i>-1] or <i>C</i>[<i>n</i>+1] would fall beyond the edge of the image) are handled by effectively setting <i>F</i>[2<i>n</i>-1] or <i>C</i>[<i>n</i>+1] to <i>C</i>[<i>n</i>] as necessary.</p>

<p>The augural method requires only a few rows of the image held in memory at any given time. The design of the example program exploits this. I defined an abstract base class <i>Image</i> (in IMAGE.H). The basic idea of an <i>Image</i> is that it writes a specified number of image rows to a specified location in memory on demand. Classes derived from Image are <i>BmpFile</i> (defined in BMP.H and BMP.CPP), which allows rows to be read from a 24-bit BMP file; and <i>HZoom</i> and <i>VZoom</i> (both defined in ZOOM.H and ZOOM.CPP), which double the horizontal and vertical resolution of an image, respectively.</p>

<p>ZOOMTEST.CPP provides a simple command-line interface. It opens a BMP file, zooms it vertically and then horizontally, and then writes the resulting image to a new BMP file. (<i>VZoom</i> should precede <i>HZoom</i>, because their geminators differ. <i>HZoom</i> followed by <i>VZoom</i> will produce inferior results.)</p>

<p>The core of the zooming process is embodied in the procedure <i>SplitPxl()</i> found in ZOOM.CPP. This procedure actually splits a red, green, or blue pixel component.</p>



<h3>Enhancements</h3>


<p>The principles outlined here can be further developed. More detailed calculations allow the resolution to be increased by an arbitrary factor, rather than simply doubled. A more sophisticated analysis of image structure using two-dimensional information yields more precise and complete location of edges for better image quality. A commercial version of the augural zoomer includes these enhancements, and also incorporates Intel machine code for greater speed. (For more information, send e-mail to sarmstrong @ jpg.com.)</p>


<p></p>



<p><b>DDJ</b></p>
</body>
</html>
