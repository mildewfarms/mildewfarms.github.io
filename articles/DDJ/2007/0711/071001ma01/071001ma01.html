<html>
<head>
<title>Distributed Computing: Windows and Linux</title>
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/Layout.css" type="text/css">
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/FontStyles.css" type="text/css">
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/newarticle.css" type="text/css">
<script src="../../../../forms/popwindow.js"></script>
</head>

<body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000">
<!--Copyright &#169; Dr. Dobb's Journal-->
<p><i>Dr. Dobb's Journal</i> November 2007</p>

<h1>Distributed Computing: Windows and Linux</h1>
<h2>A cluster for analyzing  hundreds of gigabytes of data</h2>


<h3>By Mohamed Abo El-Fotouh and Klaus Diepold</h3>


<I>Mohamed is a Ph.D. student at Munich University of Technology. 
Klaus is  the head of the Institute for Data Processing at Munich University of Technology. They can be  contacted at mohamed@tum.de and kldi@tum.de, respectively.</I>

<hr>




<p>In this article, we discuss a distributed system in which a single Windows machine controls a Linux cluster. We implemented this system as a part of an investigation into the security of block ciphers. In particular, we were analyzing block ciphers as to their suitability to act as random number generators. To this end, we used the NIST statistical suite for testing the randomness of specific data sets (<a href="http://csrc.nist.gov/rng">csrc.nist.gov/rng</a>). For each data set, we performed 188 different statistical tests, measuring the percentage of the tests each cipher passes. The two main parameters we were changing were the keys and plaintext. To generate and analyze the data, we built "System1" under Windows on a single machine. This system was easily able to process megabytes of generated data for our analysis. </p>

<p>Before long, however, the number and size of the data sets increased dramatically (as we decided to study the randomness of block cipher modes of operation), and System1 could no longer analyze data in a timely and reasonable manner. Consequently, we then built "System2," a Linux-based cluster that works in parallel on several machines to analyze hundreds of gigabytes of data; see Figure 1.</p>



<div>
    
<div class="smallcap">&#91;Click image to view at full size&#93;</div>
<!-- http://i.cmpnet.com/ddj/images/article/2007/07/ -->    
<img class="illowide" src="071001ma01_f1.gif" onclick = "popimage(this,'www.ddj.com - Distributed Computing: Windows and Linux - Figure 1')">

<div class="caption">
Figure 1: Overview of the Windows/Linux distributed system.
</div>
</div>










<h3>System1 and System2</h3>

<p>The Windows-based System1 consists of the following programs:</p>

<ul>
    <li>The Generator, which generates statistical data sets, written in Visual C++.</li>
  <li>The NIST statistical suite, which processes the data sets generated with the Generator, written in C.</li>
  <li>The Extractor, which extracts and summarizes the results generated from the NIST statistical suite, written in Visual Basic 6.</li>
</ul>

<p>For its part, System2 works as follows:</p>

<ul>
    <li>Data sets are generated with the Generator on the Windows machine.</li>
  <li>These data sets are then transferred to a shared hard-disk partition on the Linux cluster.</li>
  <li>The NIST statistical suite processes the data sets on the Linux cluster.</li>
  <li>The results are then transferred back to the Windows machine.</li>
  <li>Finally, the data are extracted and summarized by the Extractor on the Windows machine.</li>
</ul>

<p>Our biggest challenge here was how to get System2 programs to communicate with each other, and how to automate the system as much as possible. To accomplish this, we had to modify the current programs and write new ones. In a nutshell, we decided to divide System2 into three parts:</p>

<ul>
    <li>Data sets generation and transmission to the Linux cluster. </li>
  <li>Processing data on the Linux cluster.  </li>
  <li>Transmitting results to the Windows machine for analysis. </li>
  </ul>

<p>Once we generated the data using the Generator, our next problem was how to transfer it to the Linux cluster. We tried several techniques, including generating all data sets, then transferring them via the Samba client. But the problem here is that we had to wait until all the data is generated (which could take a couple of days), then start the Samba client from a Linux emulator under Windows (cgywin). Clearly, this didn't suit our needs.</p>

<p>In another attempt, during generation of the data sets, we started WinSCP using the command, "Keep the remote directory up to date," and changed the priority of the WinSCP to a higher priority than that of the Generator, to transfer the data once it is created. The problem with this approach was that we ran out of space on the Windows machine, as all the generated data sets are stored on the Windows machine.</p>

<p>Finally, we modified the Generator by adding the function <i>MoveData()</i> (Listing One), which calls a WinSCP script (Listing Two) to copy the data sets from the Windows machine to the Linux cluster. It then deletes these data sets from the Windows machine (to free up space for more generated data sets). <i>MoveData()</i> is then called after each group of data sets is generated.</p>

	

<pre class="code">

void MoveData()
{
system("F:\\WinSCP3\\WinSCP3 /console /script=c:\\move.txt");
system("del c:\\test\\* /q");
}

</pre>
<div class="caption">
   Listing One
</div>	
	

<pre class="code">

# Automatically answer all prompts negatively not to 
# stall the script on error
#     option batch on
# Disable overwrite confirmations that 
# conflict with the previous
#     option confirm off
# Connect a stored connection called mido 
# (where the password was saved)
#     open mido
# Change remote directory
#    cd /users/disk2/et/midono1/test
# Force binary mode transfer (It is very 
# important for us to transfer the data in binary
# format) 
#    option transfer binary
# Upload the file to current working directory
put c:\test\*
# Disconnect
close
# Exit WinSCP
exit

</pre>
<div class="caption">
   Listing Two
</div>	










<h3>Controlling the Cluster</h3>

<p>With the NIST statistical suite, input is designed to be interactive. We modified this to accept all the parameters from the command line (some parameters were also hard-coded). We then added these parameters:</p>

<ul>
    <li><i>Start</i>. The index of the first processed file.</li>
  <li><i>End</i>. The index of the last processed file.</li>
  <li><i>Exp</i>. The index of the current experiment.</li>
  <li><i>Other</i>. Other parameters that are experiment specific. </li>
</ul>

<p>All the intermediate files (a couple of dozens for each file) are suffixed with the file index and experiment index. After processing each file, that file is deleted with all the intermediate files to free space on the Linux cluster. Only the final result file is kept. </p>

<p>At this point, the question was how to start the NIST statistical suite on each processor of the Linux cluster. We had several options:</p>

<ul>
    <li>Connect to each machine using PUTTY and run the command line. However, this approach required a lot of user interaction, so it was discarded.</li>
  <li>Connect to all the machines using SSH and start a program that executes scripts&#151;which is what we opted to do.</li>
</ul>

<p>We wrote the Cluster program (Listing Three) to invoke the Scheduler program (Listing Four) on each node of the Linux cluster. The Scheduler executes script files prepared by the script generator program. This is done using the <i>fork()</i> function to create a child process for each connection. The connections to the Linux nodes using SSH are set to use automatic login and the Cluster program is run on the cgywin emulator on the windows machine.</p>

	

<pre class="code">

#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/types.h&gt; 
#include &lt;unistd.h&gt; 
int main()
{
int i,pid;
char cmd[100];
static int N=1;
for( i=start;i&lt;end;i++) {
pid=fork();
sprintf(cmd,"ssh username@node%d.cluster.com ./script/scheduler ",i);
system(cmd);
exit(0);
if(pid==-1)
printf("error on node %d\n",i);}
return 1;
}

</pre>
<div class="caption">
   Listing Three
</div>	
	
	

<pre class="code" style="height:250">

#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;
int CPU_sleep()
{
int i=0,j=0,k=0,sum=0;
for(i=0;i&lt;100;i++)
for(j=0;j&lt;100;j++)
for(k=0;k&lt;10;k++)
sum=sum+j*j*k;
return sum;
}

void main()
{

char * file="/home/script/max.txt";
char* filebase="/home/script/";
char filename[200];
char cmd[200];
char tempo[200];
FILE* W;
FILE* F=fopen(file,"r");
int N=0;
int X,max;
int S,E;
fscanf(F,"%d",&amp;max);


fclose(F);
while(N&lt;max)
{
N++;
sprintf(filename,"%s%d.do",filebase,N);
CPU_sleep();
W=fopen(filename,"r");
if(W==NULL)
{
   FILE* ch=fopen(filename,"w");
   fclose(ch); // we reserve the file
   sprintf(cmd,"/home/script/%d.sh",N);
   system(cmd);
   ch=fopen(filename,"w");
   fprintf(ch,"DONE");//now the file is marked to be done
   fclose(ch);
}
else
{
   fclose(W);// by pass
}
F=fopen(file,"r");
fscanf(F,"%d",&amp;max);  //read the maximum again, 
                      //  to be able to increase it
fclose(F);
CPU_sleep();
}
}

</pre>
<div class="caption">
   Listing Four
</div>	
	


<p>The script generator program generates scripts to be executed by the Linux schedule. A script processes each job and the number of the scripts is stored in a max.txt file. The script files are generated in the form <i>#.sh</i>, where # is the number of the script. These files are then transferred to the directory "script" on the Linux cluster and their access mode is changed to be executable using the <i>chmod +x *.sh </i>command executed from a PUTTY terminal.</p>

<p>The Scheduler program first opens the max.txt file to get the maximum number of scripts. It then enters the loop where it sequentially checks all the status files with the form <i>"#.do."</i> When it finds a nonexisting status file, then it directly assigns it to itself by creating it and executes the corresponding script file. After finishing the script file, it rewrites the status file with the string "DONE" in it, then searches for the next status file until the maximum is reached. It then stops. </p>

<p>The <i>max</i> is read in each loop (as sometimes we increased it) as we introduce new experiments (with new files).</p>

<p>Only one job is assigned per script. If one node stops working due to any reasons, only one file will not be processed, and can be processed later.</p>

<p>The generated scripts look like the script in Listing Five. After the Cluster program finishes, we check the status files. If any are of size 0, the corresponding file is not executed due to a node failure. We then execute this script (manually or by deleting this status file(s) and calling the Cluster program). If the Windows machine is restarted for some reason, we restart the Cluster program. In the worse case, two scripts execute at the same time on each node. Because the Linux cluster is not dedicated to our processes, we use the lowest priority of execution using the nice<i> -n 19 </i>command, which lets others use the Linux nodes.</p>
	

<pre class="code">

cd
cd  test
nice -n 19 ./nist  1  1  2481  1  128 &gt; /dev/null

</pre>
<div class="caption">
   Listing Five
</div>	
	
	
	


<p>Once the status files are four bytes in size (the word DONE is written in them), we transfer the result files back to the Windows machine using WinSCP, then run the unmodified Extractor program.</p>



</body>
</html>