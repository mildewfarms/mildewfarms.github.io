<html><head><title>Aug03: Extreme Parsing</title></head><body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000"><!--Copyright &#169; Dr. Dobb's Journal--><h1>Extreme Parsing</h1><p><i>Dr. Dobb's Journal</i> August 2003</p><h2>Applying XP techniques to parser development</h2><h3>By Kyle F. Downey</h3><I>Kyle is a J2EE architect who works as a project leader at HBO, and also as an independent consultant and software developer. He can be contacted at kdowney@amberarcher.com.</I><hr><p>A project I was working on required an IDL parser with extensions. However, writing a parser from scratch wasn't an option&#151;IDL is too complex and I didn't have time. Because I had previously used SableCC (http://www.sablecc.org/), an open-source compiler-compiler for Java, to write a simple parser for the WHERE clause part of the SQL grammar, I took another look at it and realized it has a grammar for basic IDL. Upon further examination, however, its license turned out to be too restrictive, so I decided to write the parser from scratch after all&#151;but use SableCC to generate the lexer and parser.</p><p>The Common Object Request Broker Architecture (CORBA) 3.0 specification is daunting, weighing in at over 1000 pages. Granted, a mere 74 pages define IDL syntax and semantics, but the information is still dense and detailed. Consequently, when sitting down to build the parser, I settled on a plan of attack that had a lot in common with Kent Beck's Extreme Programming (XP) core principles (http://www.xprogramming.com/).</p><DDJADVERTISEMENT INLINE><h3>XP Core Principles</h3><p>Four of the 12 core XP principles Beck describes in <i>Extreme Programming Explained: Embrace Change </i>(Addison-Wesley, 1999; ISBN 0201616416) particularly apply to parser development:</p><ul>  <li>Simple design. At the end of the process, you want a grammar that represents the full specification and nothing more. Any excess makes the parser slower, may introduce bugs, and makes it harder to understand and extend the grammar. Thus, this XP principle forces you to implement the minimum, following Einstein's advice to make your solutions "as simple as possible&#151;but no simpler."  <li>Test-driven development. Standards bodies sometimes produce suites of compliance tests. You could say that a compliant parser for a Standard is done when it passes those tests. Whether you have a suite to work from or you build one from examples in the spec (as I did), the key to test-driven development for parsers is to add only the new grammar elements needed to pass the current test. For IDL, you might start with:<blockquote><p>module M {</p><p> interface foo { };</p><p>};</p></blockquote><P>which is valid and requires only two keywords and a grammar for what makes a valid identifier. The important part is that you structure each step as an automated unit test. This lets you re-run all tests every time you add new grammar elements. If you do it right, it becomes natural to rerun the whole compliance set every time you make a change, helping you to catch changes (that introduce ambiguities or invalidate other parts of the grammar) early on. </P><P>Parsers benefit from this even more than well-factored, object-oriented code because the grammar specification is not encapsulated. You can easily reorder the token definitions and have keywords recognized as identifiers instead. Additions can (and often do) break seemingly unrelated parts of the grammar.</P>  <li>Design improvement. Grammar elements are not encapsulated, but they can be subdivided, so more complex productions build on smaller productions and tokens. Making sure your grammar is clear and reuses simpler productions cleanly is equivalent to refactoring implementation code. Just as with object-oriented refactoring, the goal is to improve (and if possible simplify) the design without changing the functionality. Again, your suite of unit tests provides indispensable tools: After you make changes that shouldn't impact the parser, you can immediately rerun to make sure it really didn't!  <li>Continuous integration. Incremental, test-driven development and redesign require frequent builds. To ease this, you'll want to ensure that parser/lexer generation and code compilation are automated. SableCC includes an Ant task, so that, with a few lines of XML, you can incorporate the compiler-compiler phase as part of the build.</ul><h3>Introducing SableCC</h3></blockquote><p>Tools such as lex and yacc have been in programmers' parser-development toolchests for a long time. These tools read grammar and generate the lexer and parser code&#151;in C, in the case of lex and yacc. Every major language has at least one compiler-compiler. For instance, Java has ports of lex and yacc, plus more object-oriented, Java-friendly tools such as PCCTS/antlr, JavaCC (Jack, originally from Sun, now from Metamata), and SableCC, among others.</p><p>SableCC is nice because it generates Visitor-pattern-based tree-walking classes that make it easy to build code generators, pretty printers, and whatever other tools you create on top of your grammar. Your <i>visitor</i> class gets callbacks for entry into and exit out of each production, and it's passed a <i>Node</i> object with all the details you need.</p><p>SableCC's syntax is easy to learn and close to Extended Backus-Naur Format (EBNF), the standard grammar notation used in major specifications. For instance, the EBNF production for IDL interfaces from the CORBA spec in <A NAME="re1"><A HREF="0308ce1.htm">Example 1</A>(a) is rendered in SableCC as <A NAME="re1"><A HREF="0308ce1.htm">Example 1</A>(b).</p><h3>Continuous Building and Testing</h3><p>To satisfy the continuous integration and test-driven development principles, you need a one-touch build script. Since SableCC comes with an Ant task, you can integrate the creation of the lexer/parser source code as part of your build. <A NAME="rl1"><A HREF="#l1">Listing One</A> is a complete Ant build script. The first highlighted section shows how to dynamically load a <i>Task</i> extension into Ant, and assign it to a new XML tag, in this case, <i>&lt;sablecc&gt;</i>. The second highlighted section shows how to use this tag to build the grammar.</p><p>In this script, the generated Java source code goes to its own directory and is compiled separately from the unit test and other supporting code. Usually, you will not want to check this code into your source-code control system, so this helps to keep it distinct and makes it easy to clean up (just remove the build directory).</p><p>The next step is to set up a suite of automated unit tests. The base class I created for all parsing unit tests lets me load a test input file and feed it to my generated parser; see <A NAME="rl2"><A HREF="#l2">Listing Two</A>. The import package base (com.amberarcher.corba.idl) varies depending on your declared <i>Package</i> for the parser, but the names of the generated classes (<i>Start, Parser,</i> and so on) are identical. Like many compiler-compilers, there is no supporting library for SableCC.</p><p>Most of the code just sets up the input stream that is fed into the lexer. For convenience, this particular base class loads all test files relative to src/share/test-fixtures/idl, so the filename is also built up. The heart of the code is:</p><blockquote><p>Parser p = new Parser(new Lexer(in));</p><p>return p.parse();</p></blockquote><p>The returned node, <i>Start</i>, corresponds to the first production in your grammar. The derived test class calls <i>parse</i> and passes the name of the example file to test. I followed a convention in which the filename is mapped to the section of the CORBA spec and includes some basic information about what is being tested. <A NAME="rl3"><A HREF="#l3">Listing Three</A> shows how to use this base class to execute a single test, illustrating a critical requirement for automated unit testing&#151;the test must decide for itself whether it passed. You should not have to eyeball the results. In this case, the IDL in <A NAME="re2"><A HREF="0308ce2.htm">Example 2</A> should fail, at least according to the spec. In the test, I try to catch a <i>ParseException</i> (if there is one) and assert either that it failed or that it failed in the place I expected it to fail for the reason it was supposed to fail.</p><p>Using IntelliJ IDEA (http://www.intellij.com/idea/), you can run the Ant script and the unit tests inside the IDE. <A NAME="rf1"><A HREF="0308cf1.htm">Figure 1</A> shows a successful test run with multiple test cases executing.</p><h3>Extreme MiniIDL with SableCC</h3><p>My goal was to write a SableCC grammar that can handle a fragment of IDL that represents just a handful of tokens and productions from the CORBA 3.0 specification; see <A NAME="rl4"><A HREF="#l4">Listing Four</A>. CORBA is a mature distributed object technology, and IDL is its language-neutral Interface Definition Language. Given the IDL, you can take an IDL compiler and generate network stubs and skeletons that can connect to the remote object&#151;even if your client is in Perl and the server is in C++ or is a Java EJB. IDL isn't just for network servers, though. Microsoft uses a variation on IDL to define COM components, and Mozilla's XPIDL and the Linux Gnome component object model (Bonobo) also use IDL for component interfaces. The XML Document Object Model (DOM) is also defined in terms of IDL. So having an extensible IDL parser around to generate documentation and write a stub compiler is useful.</p><p>Here, I handle a subset of IDL&#151;just enough to declare interfaces (with inheritance), attributes, and modules (a name-scoping mechanism similar to Java packages or C++ namespaces), plus comments. Amazingly, this can be done with under 50 lines of Sablecc grammar, resulting in hundreds of lines of generated Java code.</p><p>I start by defining the package, along with a few helpers. In <A NAME="re3"><A HREF="0308ce3.htm">Example 3</A>, the first line defines which package the generate code goes into. The <i>all</i> set is every possible Unicode character, because SableCC inherits Java's Unicode text-handling support. From there, I define a few useful subsets using SableCC's range operator. For instance, <i>lowercase</i> is defined to be all the lowercase ASCII characters from a to z. Integers can be used to represent ASCII character codes; for example,<i> tab = 9;</i> defines some helpful whitespace characters (tab, carriage return, line feed). The <i>eol </i>definition uses SableCC's <i>or</i> operator ("|") and concatenation to represent that an end-of-line is a carriage-return/linefeed, carriage return, or linefeed.</p><p>From here you can define derived helpers; see <A NAME="re4"><A HREF="0308ce4.htm">Example 4</A>. Note how "+" and "-" work as you expect they would in defining character ranges; for instance, <i>not_eol </i>is all character excluding (minus) carriage return and line feed, just as <i>not_star</i> is <i>not_eol</i> excluding "*" or<i> eol</i>. </p><p>These last three helpers are for matching comment tokens. To match an interface declaration and make sure it works, you have to add tokens&#151;atomic pieces of the grammar (see <A NAME="re5"><A HREF="0308ce5.htm">Example 5</A>). Token definition is like helper definition: <i>name = value.</i> Valid right-side values are literal values (like "interface"), helpers, and combinations of the two. Globbing operators can be used, too; for instance,<i> (' ' | tab | eol)+ </i>indicates that whitespace can be one or more of the three possible values given. The "<i>?</i>" indicates 0 or 1; "*" indicates 0 or more, just as in DOS file globs and regular expressions. Because productions have to be defined in terms of tokens, you have to declare some tokens for symbols like "<i>{</i>" and "<i>;.</i>"</p><p>With tokens defined, you can also specify some to ignore:</p><blockquote><p>Ignored Tokens</p><p>    white_space</p></blockquote><p>At this point, you can string tokens together into valid sentences in the grammar. The first one is the <i>Start</i> node, and each one in turn can be defined in terms of the others, and even recursively; see <A NAME="re6"><A HREF="0308ce6.htm">Example 6</A>.</p><p>Production definition translates to token definition, with one exception: If you use the same name for a production as for a token, you need to qualify it with a "<i>P</i>." and "<i>T</i>." prefix. In <A NAME="re6"><A HREF="0308ce6.htm">Example 6</A>, <i>interface</i> has this ambiguity and needs to be qualified.</p><p>Productions can have branches, but you need to label them like this:</p><blockquote><p>interface = {interface_dcl} interface_dcl |</p><p>  {forward_dcl} forward_dcl;</p></blockquote><p>The labels in the curly braces become the accessors (<i>getXXX()</i>) in the generated Java code. So now you can load up the test:</p><blockquote><p>interface foo { };</p><p>interface B { };</p><p>interface Fee_Foo_Fum { };</p></blockquote><p>and it should parse correctly. You build out from here, adding forward declarations, attribute declarations, and inheritance, and writing tests for each extension. With the base helpers and tokens, the rest is straightforward. <A NAME="rl5"><A HREF="#l5">Listing Five</A> is the full grammar.</p><h3>Conclusion</h3><p>Outside of a computer-science classroom, no one gets points for writing a parser and lexer from scratch. However, using a compiler-compiler&#151;whatever your language of choice&#151;is a good expression of Larry Wall's "laziness" virtue of programmers. If you also have the "hubris" virtue, though, and want to tackle a big grammar by yourself, you're advised to build it piecewise using the extreme development methods I present here: Develop a production; build, test, and add; and keep doing it until you've covered the whole grammar.</p><p></p><p><b>DDJ</b></p><H4><A NAME="l1">Listing One</H4><pre>&lt;?xml version="1.0"?&gt;&lt;project name="comc" default="compile" basedir="."&gt;    &lt;!-- allow for local override of site settings --&gt;    &lt;property file="${user.home}/.ant.properties"/&gt;    &lt;property name="build.dir" value="${basedir}/build"/&gt;    &lt;property name="build.classes.dir" value="${build.dir}/classes"/&gt;    &lt;property name="build.gen-src.dir" value="${build.dir}/gen-src"/&gt;    &lt;property name="src.dir" value="src/share/classes"/&gt;    &lt;property name="grammar.dir" value="src/share/grammars"/&gt;    &lt;path id="build_classpath"&gt;        &lt;pathelement path="${basedir}/lib/junit.jar"/&gt;    &lt;/path&gt;   &lt;path id="tools_classpath"&gt;       &lt;pathelement path="${basedir}/build-tools/sablecc-anttask.jar"/&gt;       &lt;pathelement path="${basedir}/build-tools/sablecc.jar"/&gt;   &lt;/path&gt;    &lt;taskdef name="sablecc" classname="org.sablecc.ant.taskdef.Sablecc"        classpathref="tools_classpath"/&gt;    &lt;target name="generate_idl_parser"&gt;        &lt;mkdir dir="${build.classes.dir}"/&gt;        &lt;mkdir dir="${build.gen-src.dir}"/&gt;        &lt;sablecc src="${grammar.dir}" includes="idl.sablecc"             outputdirectory="${build.gen-src.dir}"/&gt;         &lt;javac srcdir="${build.gen-src.dir}"            destdir="${build.classes.dir}"&gt;            &lt;include name="**/*.java"/&gt;        &lt;/javac&gt;        &lt;copy todir="${build.classes.dir}"&gt;            &lt;fileset dir="${build.gen-src.dir}"&gt;                &lt;include name="**/lexer.dat" /&gt;                &lt;include name="**/parser.dat" /&gt;            &lt;/fileset&gt;        &lt;/copy&gt;    &lt;/target&gt;    &lt;target name="compile"&gt;        &lt;mkdir dir="${build.classes.dir}"/&gt;        &lt;javac srcdir="${src.dir}" classpathref="build_classpath"            destdir="${build.classes.dir}"&gt;            &lt;include name="**/*.java"/&gt;        &lt;/javac&gt;        &lt;copy todir="${build.classes.dir}"&gt;            &lt;fileset dir="${build.gen-src.dir}"&gt;                &lt;include name="**/lexer.dat" /&gt;                &lt;include name="**/parser.dat" /&gt;            &lt;/fileset&gt;        &lt;/copy&gt;    &lt;/target&gt;    &lt;target name="clean"&gt;        &lt;delete dir="${build.dir}"/&gt;    &lt;/target&gt;&lt;/project&gt;</pre><P><A HREF="#rl1">Back to Article</A></P><H4><A NAME="l2">Listing Two</H4><pre>package com.amberarcher.corba.idl.testing;import java.io.FileReader;import java.io.PushbackReader;import java.io.File;import junit.framework.TestCase;import com.amberarcher.corba.idl.node.Start;import com.amberarcher.corba.idl.parser.Parser;import com.amberarcher.corba.idl.lexer.Lexer;public class AbstractTestCase extends TestCase {    public AbstractTestCase(String methodName) {        super(methodName);    }    protected Start parse(String testCaseFileBaseName) throws Exception {        FileReader fin = new FileReader("src" + File.separator +                "share" + File.separator + "test-fixtures" +                 File.separator + "idl" +                File.separator + testCaseFileBaseName);        PushbackReader in = new PushbackReader(fin);        Parser p = new Parser(new Lexer(in));        return p.parse();    }}</pre><P><A HREF="#rl2">Back to Article</A></P><H4><A NAME="l3">Listing Three</H4><pre>public class StandardIdlParsingUnitTests extends AbstractTestCase {    public StandardIdlParsingUnitTests(String methodName) {        super(methodName);    }    public void testUnescapedIdentifierFails() throws Exception {        String msg = null;        boolean failed = false;        try {            parse("example-3.2.3.1-esc-identifiers-1.idl");        } catch (ParserException e) {            msg = e.getMessage();            failed = true;        }        assertTrue(failed);        assertEquals("[3,27] expecting: identifier, escaped identifier", msg);    }}</pre><P><A HREF="#rl3">Back to Article</A></P><H4><A NAME="l4">Listing Four</H4><pre>module M {    interface base;              /* forward declaration */    interface base { };    interface thing : base {        attribute boolean foo;   // creates get_foo(), set_foo()    };};</pre><P><A HREF="#rl4">Back to Article</A></P><H4><A NAME="l5">Listing Five</H4><pre>Package com.amberarcher.corba.idl;Helpers    all = [0 .. 0xFFFF];    lowercase = ['a' .. 'z'];    uppercase = ['A' .. 'Z'];    digit = ['0' .. '9'];    tab = 9;    cr = 13;    lf = 10;    eol = cr lf | cr | lf;    identifier_prefix = lowercase | uppercase ;    identifier_char =  identifier_prefix | digit | '_';    not_eol = [all - [cr + lf]];    not_star = [not_eol - '*'] | eol;    not_star_not_slash = [not_eol - ['*' + '/']] | eol;Tokens    // different types of comments    traditional_comment = '/*' not_star+ '*'+(not_star_not_slash not_star* '*'+)* '/';    end_of_line_comment = '//' not_eol* eol?;    attribute = 'attribute';    boolean = 'boolean';    interface = 'interface';    module = 'module';    identifier = identifier_prefix identifier_char*;    escaped_identifier = '_' identifier_prefix identifier_char*;    white_space = (' ' | tab | eol)+;    start_scope = '{';    end_scope = '}';    end_decl = ';';    inherit_op = ':';    scoping_op = '::';    interface_sep = ',';Ignored Tokens    white_space,    traditional_comment,    end_of_line_comment;Productions    specification = definition+;    definition = {interface} P.interface |        {module} P.module;    module = T.module P.identifier start_scope definition+ end_scopeend_decl;    interface = {interface_dcl} interface_dcl |        {forward_dcl} forward_dcl;    interface_dcl =        interface_header start_scope interface_body end_scope end_decl;    forward_dcl = T.interface P.identifier end_decl;    interface_header = T.interface P.identifierinterface_inheritance_spec?;    interface_body = exports*;    interface_inheritance_spec = inherit_op interface_nameinterface_inheritance_spec_tail*;    interface_inheritance_spec_tail = interface_sep interface_name;    interface_name = scoped_name;    exports = attr_dcl;    attr_dcl = attribute type_declaration P.identifier end_decl;    type_declaration = boolean;    scoped_name = {identifier} P.identifier |            {relative_identifier} scoping_op P.identifier |            {global_identifier} scoped_name scoping_op P.identifier;    identifier = {id} T.identifier | {esc_id} escaped_identifier;</pre><P><A HREF="#rl5">Back to Article</A></P></body></html>