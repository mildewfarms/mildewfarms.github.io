<html><head><title>Sep03: Programming Paradigms</title></head><body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000"><!--Copyright &#169; Dr. Dobb's Journal--><h1>Summer Reading</h1><p><i>Dr. Dobb's Journal</i> September 2003</p><h3>By Michael Swaine</h3><I>Michael is editor-at-large for DDJ. He can be contacted at mike@swaine.com.</I><hr><p>More of my friends took vacations this summer than ever before; some of them have been on vacation since 2001. Magazine tradition holds that you are supposed to lug a suitcase full of light reading along on your summer vacation, and that it is the duty of magazine columnists to help you pack that case. So be it.</p><p>A steady stream of books flows across my desk, from which babbling brook I can readily scoop up a sample. It won't be a representative sample&#151;<i>Enhancing Enterprise Security via Goal-Directed Customer-Centric Client-Server Agile UML Business Rule Pattern Implementation Strategies in Perl: Second Edition, for Java Programmers</i>&#151;that more or less captures the general drift of the stream. My job is to shield you from the swill of the mill.</p><DDJADVERTISEMENT INLINE><p>Nor would a sample of my latest Amazon purchases (political memoir by HRC, evolutionary opus by SJG, guilty juvenile pleasure from JKR) be appropriate fodder for the<i> Dr. Dobb's</i> feedbag (extra points for those who know the secret appropriateness of the feedbag metaphor). I've filched from the flow five recent works in three categories&#151;philosophy, history, and law&#151;all with a distinct technical slant. I know what kind of vacation (some of) you take.</p><p>But first, a word about what Apple's been up to. (Executive Summary: They haven't been on vacation.)</p><h3>The World's Fastest Personal Computer</h3><p>That headline should really be in quotes. It was to be expected that Steve Jobs's claim that Apple's new G5 Macintoshes are "the world's fastest personal computers" would be challenged. But even if exaggerated, the claim directs attention to a legitimate phenomenon: The MegaHertz gap has essentially been closed.</p><p>But for those who do not track the Mac, that paragraph may need some contexting. Here's a quick recap of what Steve announced in his keynote at this year's Apple's Worldwide Developer's Conference, with more details and analysis to come next month.</p><ul>  <li>A line of new Macs based on IBM's 64-bit PowerPC 970 CPU, which Apple calls the G5. Maxing out at 2 GHz today, they'll hit 3 MHz in a year; benchmarks show impressive speed for Apple's G5 machines compared to AMD- and Intel-powered machines. Details: 1-GHz frontside bus (per processor), 8-GB maximum RAM, AGP 8X Pro graphics, 133-MHz 64-bit PCI-X. Superdrive is not an option; it's included in every Power Mac G5. The machines feature a new aluminum case whose tidy interior is divided into four sections cooled by nine computer-controlled fans. Starting at $2000, these are Apple's high end. New portables and low-end machines are likely later in the year, when the buzz from these machines starts to die down.  <li>A new version of the Mac OS X operating system that, among other things, fixes some of the nagging usability problems that OS X has had since its launch. A feature called "Expose" lets me quit nagging my partner Nancy about her untidy habit of cluttering up her screen with so many open windows that I can't tell what's going on when she asks me some system administrator question. Expose appears to do a superb job of managing windows.  <li>File dialogs in OS X have been a disappointment to many for years. I don't know if everyone will love what Apple has done with file dialogs in the new release, but for me, the initial impression is: Problem solved.  <li>	   I still don't know what the logic of the brushed metal interface is. Apple is now providing some help for those who want to create brushed-metal apps and may have an explanation for which apps should be brushed metal and which should not, but I haven't seen any explanation for why Apple wants to have two different looks in the first place. Anyway, the Finder is now a brushed-metal app, for better or worse.  <li>A new version of the iChat application that supports video conferencing, and a $149 camera to push the aforementioned video conferencing. That's how Apple is positioning its iSight camera; to a meeting hater like me, iSight looks more like a nifty webcam.  <li>A new application development environment "as easy to interact with as iTunes." Hmmm. Should Metrowerks be worried? More on this next month.</ul><p>Exactly <i>why</i> these announcements were made at WWDC rather than at one of the usual end-user shows, apart from the fact that the most likely of those end-user shows kept threatening to blink out of existence and had three different names in one month, is the Venue Question, and we'll leave it to the true fanatics.</p><p>And then there is the matter of Microsoft. We're long past that strange five-year Coopetition Agreement era and well into the All Bets Are Off era. It is unquestionably meaningful that Microsoft has axed the Mac version of its IE browser and that Apple at WWDC officially crowned its own Safari the default Mac browser, but exactly what do these developments mean? The hatching of Safari and the cracking of IE are a Chicken and Egg puzzle complicated by the fact that IE is also on its way out as a separate product for Windows. Does the IE/Safari thing, or even more confrontationally, the PowerPoint/Keynote thing, signal anything about the future of Microsoft Office or the prospects for Open Office on the Mac platform? Would knowing the reason behind Microsoft's acquisition of Virtual PC provide any insight into the future of Office for Mac? Probably, but posing a harder question does not qualify as an answer.</p><p>More next month. More answers? Or just more questions? Some of both, I suspect. On to the books.</p><h3>Computationalism</h3><p>The term "Computationalism" in the title of Matthias Scheutz's <i>Computationalism: New Directions </i>(MIT Press, 2002, ISBN 0-262-19478-3) refers to the idea of the mind as a computer, loosely speaking, rather than to the idea of the universe as a computer or a computation, as advanced by Ed Fredkin and Stephen Wolfram.</p><p>The idea of the mind as a mechanism probably goes back as far as the first complex machines. It can be stated bluntly&#151;the mind is a machine, the mind is a computer, all mental states are computational states&#151;but despite the simplicity of the statement, it is not always clear what is being claimed. This is partly because the definitions of computer and computation are somewhat fluid. At its loosest, the claim is merely a statement of faith that whatever the mind can do, artificial man-made devices will someday be able to do.</p><p>Computationalism in its various forms has been criticized for not addressing the physical realities with which minds concern themselves. But is this a failure of the mind-as-computation model, or a failure to recognize the true physical nature of computation? The essays in <i>Computationalism</i> all try to go beyond the familiar, tedious arguments about mind versus mechanism, to advance a new generation of&#151;uh, arguments about mind and mechanism.</p><p>This is a dense book of philosophical explorations by philosophers and computer scientists, but it is not inaccessible. I'll see if I can snip out a few juicy scenes and compile a trailer.</p><ul>  <li>To talk about computation, we need to decide what the word means. Is it all about the formal manipulation of symbols, or is it defined adequately by saying that it is the execution of an algorithm, or do you need to bring in mathematical notions like effective computability? Brian Cantwell Smith considers these questions and concludes that computation is not even a coherent subject on its own. Thus, he claims, there will never be a theory of computation. He further confounds his readers by claiming that this is a <i>good</i> thing for those who want to understand computers and computation.  <li>If an information processing system is a mechanism, in a sense described by B. Jack Copeland, then information processing systems that are not equivalent to a Turing Machine are possible. The mind could be such an information processing system. Aaron Sloman also looks outside the Turing Machine paradigm to model the mind.  <li>Stevan Harnad and John Haugeland both take on the difficult problem of what I would (too loosely, I'm sure) call semantics. Somehow, the symbols that are manipulated in a computation must be connected to the real world. Harnad looks at how minds accomplish this: fundamentally by sorting, labeling, and interacting with sensorimotor projections of the world out there, but at least as often by "stealing" the real-world grounding of concepts through the technique of hearsay. Haugeland takes a line through these semantic questions to a conclusion that we can't understand computation without understanding what it means to take responsibility. I'm still puzzling over that, but to give you a sense of the sweep of Haugeland's ideas, in the space of one page he makes this claim about responsibility, gives rough operational definitions of two varieties of responsibility, claims that freedom and love are implicit in his definitions, and concludes that "cognitive science and artificial intelligence cannot succeed in their own essential aims unless and until they can understand and/or implement genuine freedom and the capacity to love."</ul><p>I'm glad he said "and/OR." If cognitive scientists had to both understand AND implement freedom and love, it would be rather difficult. But one or the other, no problem.</p><h3>Historian's Perspective</h3><p>In <i>From Airline Reservations to Sonic the Hedgehog: A History of the Software Industry </i>(MIT Press, 2003, ISBN 0-262-03303-8), Martin Campbell-Kelly takes an historian's perspective on his subject. If you don't understand that, you will have a hard time understanding how he can write about the software industry with scarcely a mention of Java, Linux, or open source.</p><p>This historical approach is markedly different from the way most technology trackers write about the industry. Unlike those of us who are always trying to guess what the impact will be of the latest development, Campbell-Kelly draws a line in the sand at five years and doesn't try to interpret any closer than that.</p><p>I don't fault Campbell-Kelly his approach, but it makes for an unusual read. Also, it might have been smart for him to choose a more timeless and historical title for his book. That cutesy reference to a video-game character is going to seem awfully stale, awfully soon.</p><p>Even granting the reason for the lack of insight into (or even mention of) the most recent developments in the software industry, I have some issues with the coverage.</p><p>Philippe Kahn's and Adam Osborne's innovations in the selling of software don't get a word. Kahn's Borland International gets another insult: Campbell-Kelly says, "Had Microsoft ever produced a Pascal system, it would surely have eclipsed Turbo Pascal." He's entitled to his opinion, but in my opinion, it's a wrong opinion, and it's certainly not history.</p><p>Then there is the oppressively corporate mindset. True, he credits clusters of small companies and the social networks that existed among their employees&#151;as opposed to isolated large hierarchical companies&#151;for the success of Silicon Valley software firms in the early '80s. But he doesn't examine the often rabidly anticorporate nature of those social networks. He recognizes the value of trade associations, but not of computer clubs. He cites government funding for R&amp;D, but doesn't recognize that often (Oracle, Mosaic, Cbasic, Don Lancaster), the government contribution was merely to pay the salary of the programmer so he could moonlight on his own project in every free moment.</p><p>I don't see how you can write about the software industry without looking at the economics of software development, even though looking honestly at the economics of software development often takes you into areas that have nothing to do with industries and markets. But these complaints are in the category of wishing that the author had written a different book. The book Campbell-Kelly actually wrote succeeds admirably in its goals, I'd say.</p><p>I've written about Paul Ceruzzi's<i> A History of Modern Computing </i>(MIT Press, 1998, 2003, ISBN 0-262-53203-4) before. I consider it a good addition to any collection of computer history books and I think I have said as much, but perhaps I should have been kinder: I notice that in the new second edition he still credits <i>Fire in the Valley </i>entirely to my coauthor Paul Freiberger. He tells me he'll fix it in the next printing, but admits he hasn't read the second edition of <i>FitV</i>. Sigh. Never offend historians; they'll write you out of history.</p><p>The second edition of <i>his</i> book appears to differ from the first essentially in the inclusion of a new chapter covering developments from 1995 to 2001. I find no obvious errors in a quick read of this chapter.</p><p>The new chapter, like the rest of Ceruzzi's book, is a less formal history than Campbell-Kelly's, and a better vacation read. You may already know most of what he has to say about Microsoft and Linux, but you might not know, say, that Linus Torvalds was named after Linus Pauling. Ceruzzi considers what this means for the pronunciation of "Linux." Yes, very different from Campbell-Kelly's dry book.</p><p>The third "history" book that I want to mention is <i>The New Media Reader </i>(MIT Press, 2003, ISBN 0-262-23227-8), edited by Noah Wardrip-Fruin and Nick Montfort. I put "history" in quotes because this book is actually a collection of historical documents. All these documents have something to do with the development of new media, aka hypertext&#151;hypermedia. This is a really fantastic assemblage of seminal papers by big thinkers such as Vannevar Bush, Doug Engelbart, Ted Nelson, J.C.R. Licklider, Alan Kaye, Seymour Papert, and Tim Berners-Lee. On top of that, there's a CD with historic video including Engelbart's famous 1968 Mother of All Demos. Plus some executable programs.</p><p>Although Campbell-Kelly's and Ceruzzi's books are worth having if you are interested in the history of this field, <i>The New Media Reader</i>, with its many highly readable and genuinely historic essays, is my if-you-can-only-take-one pick for a computer history vacation suitcase-stuffer.</p><h3>Expert Testimony</h3><p><i>A Guide to Forensic Testimony: The Art and Practice of Presenting Testimony as an Expert Technical Witness, </i>by Fred Chris Smith and Rebecca Gurley Bace (Addison-Wesley, 2003, ISBN 0-201-75279-4) is the book you'll want to have read if you ever get called as an expert witness, an eventuality that grows increasingly likely as the tech field and society at large grow more litigious.</p><p>I'm no lawyer, so I'll have to recuse myself from assessing the legal advice in the book&#151;which will make this a very short review. (I only wish some judges would reciprocate and recuse themselves from technology cases on grounds of technological ignorance.)</p><p>But any legal book that starts out by analyzing the inimitable Mona Lisa Vito's testimony in the general area of automobile technology from the movie <i>My Cousin Vinny </i>gets my attention. I knew that her portrayal of Ms. Vito won Marisa Tomei an Oscar, but I didn't realize that the movie handled certain legal details well enough to serve as a framework for discussing issues that an expert technical witness might run into in court. Like Ms. Vito, you may be subjected to cross examination and <i>voir dire</i> and may have to defend against an imputation of bias. The authors don't recommend that you emulate her exactly, but they do wrap a lot of useful advice around their summary of the final courtroom scene from the movie.</p><p>In the remainder of the book, the authors explain how your demeanor and posture can affect your credibility, explain what to expect in the courtroom, and review various strategies for presenting expert testimony. They convinced me, so either (1) their advice really is good, or (2) they snowed me because they are really good at presenting their expert testimony in a convincing way&#151;in which case, their advice on doing the same is probably good anyway.</p><p>The authors also offer advice on preparing graphical aids for the presentation of evidence. If I were trying to convince a jury that I had read this book carefully, I would compare the map in their Figure 8-2 with the corresponding map in Edward Tufte's classic <i>The Visual Display of Quantitative Information,</i> pointing out that their map is missing that crucial X on Broad Street and, therefore, must be<i> a different version of the map.</i></p><p>I rest my case. </p><p><b>DDJ</b></p></body></html>