<html><head><title>Oct98: Letters</title></head><body bgcolor="FFFFFF"><!--Copyright &#169; Dr. Dobb's Journal--><h1>Letters</h1><hr><h3>MFC Plug-In Components </h3><p>Dear <i>DDJ</i>,</p><p>The article "Plug-In Components for MFC" by Stefan Hoenig (<i>DDJ</i>, August 1998) describes the best GUI architecture using MFC I have seen. Ironically, Stefan has used MFC to bend Windows event handling into something that resembles the Java 1.1 event model. I applaud him. However, the claim that he presents "...a completely new approach for encapsulating window functionality into different objects." is false. In addition to paralleling Java 1.1 event listeners, Stefan's approach is similar to the Taskmaster pattern presented by Robert Martin in the March 1997 issue of <i>C++ Report</i>. I do not doubt that Stefan developed his method independently, since MFC programmers usually refer strictly to Microsoft publications, which emphasize "tips and tricks" and have less to say about architecture and engineering. This may also explain "...why the MFC team had never considered such a solution."</p><p>Joshua Lynch<br>joshualynch@yahoo.com </p><h3>Embedded Compilers</h3><p>Dear <i>DDJ</i>,</p><p>"Embedded Development Compilers," by Don Hair and Cesar Quiroz (<i>DDJ</i>, August 1998), presents a nice overview of what an embedded-systems programmer requires of a compiler. I would like to add one comment about the use of C language bitfields: Avoid them!</p><p>Reason 1: So much of the implementation is left to the choice of the compiler writer so that you cannot rely on repeatable memory alignment/allocation should you need to change compilers (or if you elect to change to a later version of the same compiler). One compiler may heed the <i>unsigned char</i> type applied to a bitfield, the next may ignore it and treat the field as an <i>int</i> (and still be in accordance with standard C).</p><p>Reason 2: A compiler's optimization pass may compress several sequential bit accesses into a single read/modify/write operation, which manipulates all the bits in the same cycle. This is all right for creating bit patterns, but if (as is often the case) the bitfield is memory mapped to hardware registers, the order of bit operations as originally programmed might be crucial to proper hardware operation, and that information is lost. Standard C provides the keyword <i>volatile</i> to help the embedded programmer deal with this, but I advocate masking and other logical operations to make such bit manipulations more reliable and portable.</p><p>Russ Heeschen<br>Russ.Heeschen@respironics.com </p><p>Dear <i>DDJ</i>,</p><p>I just finished reading "Embedded Development Compilers," by Don Hair and Cesar Quiroz (<i>DDJ</i>, August 1998), and found it one of the best articles I ever read. It is simply excellent and well worthy of appearing in a prestigious magazine like <i>DDJ</i>. It is written in a clear and professional way. It describes its subject in just the right amount of detail. It is even written in beautiful English (the "ostensible locals" is a gem). And most of all, it doesn't beat Microtec's drum. Yet at the end the reader must conclude that to get a good embedded compiler one has to go to your kind of professionals (though there is no URL for Microtec/Mentor Graphics). Bravo! !que lindo!</p><p>Antonio Bigazzi<br>AntonioB@Microsoft.com</p><h3>Theorem Proving Update</h3><p>Dear <i>DDJ</i>,</p><p>I found Sergei Savchenko's article "Theorem Proving and Database Querying" (<i>DDJ</i>, August 1998) interesting and informative. I do, however, think a couple of points should be clarified.</p><p>On page 112 Sergei states that existentially quantified variables are eliminated by replacing them with constants. Actually, the process is more complicated than that, and the complications are relevant to other parts of the article. Briefly, after quantifiers have been moved to the front of a logical statement, each existentially quantified variable is replaced by a new function symbol that takes as arguments all the <i>universally</i> quantified variables whose quantifiers occur to the left of the existential quantifier being replaced, and the existential quantifier is removed; these functions are known as "Skolem functions." For example, the statement <i>(A x) (E y) P(x,y)</i> is changed to<i> P(x,f1(x))</i>; I use <i>(A x)</i> for <i>for all x</i> and <i>(E y)</i> for<i> there exists a </i>y<i> such that</i>. This sheds light on the comment in the middle of the first column of the same page about predicate logic using functions with no arguments instead of constants: Since a constant is logically equivalent to an existentially quantified variable whose scope is the entire statement, replacing it with a function of no arguments is just part of quantifier elimination. A more important effect of Skolem functions is that when an interpretation of a logical statement is being built, they can act like pumps blowing up the size of the domain of interpretation: Each time a universal quantifier is instantiated to a new object, the Skolem functions to its right denote yet more new objects. In some cases this can result in an interpretation with an infinite number of objects.</p><p>The second point that needs clarification concerns the discussion on page 112, including the Tim Kientzle's introductory note. I think Sergei's text is more accurate than the note. The reasons require delving into the proof process. Most automated proof procedures, including the resolution process sketched by Sergei, are based on a result proven by Jacques Herbrand in 1930. A logical statement is said to be <i>satisfiable</i> if a consistent interpretation of its variables, constants, predicate symbols, and function symbols can be found with respect to which the statement is true. Herbrand invented a procedure for checking the satisfiability of a sentence that had the following three properties:</p><ul><li>If the statement is not satisfiable, then the procedure terminates in a finite number of steps indicating nonsatisfiability.  <li>If the statement is satisfiable with a finite number of objects, then the procedure terminates in a finite number of steps indicating satisfiability.  <li>If the statement is only satisfiable by an interpretation containing an infinite number of objects, then the procedure does not terminate.</ul><p>Given a hypothesis H (which may be the conjunction of several hypotheses) and a conclusion C, the theorem H-C (using Sergei's notation of "-" for implication) may be proven by applying Herbrand's procedure to the negation of H-C, which is H&amp;~C. There are three possibilities:</p><ul><li>The procedure terminates indicating nonsatisfiability. In this case the theorem is valid; that is, true in all possible interpretations, and, by G&ouml;del's Completeness Theorem for predicate logic, it is provable.  <li>The procedure terminates indicating satisfiability. In this case the theorem is not valid, and the finite interpretation found by Herbrand's procedure provides a counter example.  <li>The procedure does not terminate. In this case the negation of the purported theorem has an infinite interpretation but no finite ones.</ul><p>If, as I believe, Sergei was referring to the third possibility when he said "the search space can be infinite," then he was exactly right. Tim is mistaken in saying that interleaving an attempted proof of P with an attempted proof of ~P would result in one of the two halting. The reason is that it is possible for both ~P and P to have only infinite interpretations. For example, consider the statement <i>(A x) (E y) (A z) P(x, y, z)</i> with its negation <i>(E x) (A y) (E z) ~P(x, y, z)</i>: Using the manual refutation procedure described in <i>Formal Logic: It's Scope and Limits</i> by Robert C. Jeffrey (McGraw-Hill, 1991, ISBN 0-070-32357-7), pp. 113-114, on each it soon became clear that the procedure was in a loop generating more and more objects. By the way, did you notice that both the above statement and its negation have an existential quantifier to the right of a universal quantifier? Remember those existential quantifier pumps?</p><p>Finally, in 1936 Alonzo Church proved that there was no mechanical proof procedure for predicate logic. As Tim indicated, G&ouml;del's Incompleteness Theorem establishes a similar result for "any reasonable system of mathematics," but pure predicate logic is not such a system (and yes, logic students everywhere are eternally grateful to Kurt G&ouml;del for proving both the Completeness Theorem for first-order predicate logic and the Incompleteness Theorem for first-order arithmetic).</p><p>Bill Wood <br>wtwjek@winternet.com</p><p>Dear <i>DDJ</i>,</p><p>The article "Theorem Proving and Database Querying," by Sergei Savchenko ("Algorithm Alley," <i>DDJ</i>, August 1998) confuses logical OR with logical IMPLIES in the description of example clauses on page 111. The clauses <i>a|~b, b|c</i> and <i>a|c</i> are described as if <i>b</i> follows from <i>a</i> and <i>c</i> follows from <i>b</i>, you can conclude that <i>c</i> follows from <i>a</i>. The relationship between OR and IMPLIES is that <i>x-&gt;y</i> is equivalent to <i>~x|y</i>. The correct logical clauses for the English description in the article are <i>~a|b</i>, <i>~b|c</i>, <i>~a|c</i>. The correct English description of the clauses in the article is if <i>~b</i> follows from <i>~a</i>, and <i>c</i> follows from <i>~b</i>, then <i>c</i> follows from <i>~a</i>. </p>Andy Thomas-Cramer<br>artc@tibinc.com  <p><i>Sergei responds</i>: Thanks Andy. It indeed must be <i>~a|b</i>, <i>~b|c</i>, <i>~a|c</i> to correspond to the description. Resolution: <i>a|~b</i> with <i>b|c</i> producing <i>a|c</i> is ok, but it rather means not <i>a</i> implies not <i>b</i> and not <i>b</i> implies <i>c</i> producing not <i>a</i> implies <i>c</i>. I cannot believe I missed it. </p><h3>Windows CE </h3><p>Dear <i>DDJ</i>,</p><p>I thoroughly agree with Al Stevens in his conclusions about Windows CE <i>(DDJ</i>, July 1998). I am no expert on the handheld or auto-PC market, but I have been programming embedded systems for years, and regularly write for <i>Embedded Systems Programming</i> magazine. I attended a WinCE class at the Embedded Systems Conference last April, where MS turned up in force (and were still surprised that there were so many embedded systems programmers there!).</p><p>The level of misunderstanding between the class and the speaker was amazing. The speaker assumed that all WinCE applications could be tested on the PC in CE emulation mode. It never occurred to him that the embedded target might have a motor hanging off of it, and correct control of the motor might be an important part of testing and debugging. There were many similar misunderstandings, and most embedded programmers left very confused. Someone needs to shout very loud that CE is not an alternative to conventional RTOSs (though it may have something to offer to people who want a stripped down Win95).</p><p>Niall Murphy<br>nmurphy@iol.ie</p><p><b>DDJ</b></p><HR><I>Copyright &copy; 1998, Dr. Dobb's Journal</I><BR>
</body></html>