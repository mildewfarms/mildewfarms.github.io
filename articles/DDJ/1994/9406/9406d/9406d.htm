<HTML>
<META NAME="year" CONTENT="1994">
<HEAD>
<TITLE>JUN94: Rethinking  Memory Management</TITLE></HEAD>
<BODY BGCOLOR="#ffffff">
<h1>Rethinking  Memory Management<a name="01b9_0003"></h1><P>
<h2><a name="01b9_0001"><a name="01b9_0000">Portable techniques for high performance</h2><P>
<h3>Arthur D. Applegate</h3><P>
<p><i><a name="01b9_0002"><a name="01b9_0000">Arthur is the author of SmartHeap, the portable memory-management library published by MicroQuill Software Publishing. He can be contacted at applegate@bix.com.</i></p><hr><P>
Applications written in C and (especially) C++ spend much of their execution time allocating and de-allocating memory. Moreover, when applications run in virtual-memory environments, references to objects stored in dynamically allocated memory are the main cause of excessive swapping--a condition that can bring application performance to unacceptable lows.<P>
In this article, I explain why the traditional approaches to dynamic-memory management--<I>malloc</I> and <I>operator new</I>--are inadequate for memory-intensive applications. I suggest alternative techniques that you can use on all platforms to speed up allocation and minimize swapping. Finally, I present an empirical case study that shows how applying these techniques can result in very dramatic improvements in overall application performance.<P>
<h3><a name="01b9_0004">Why Memory Management Matters<a name="01b9_0004"></h3><P>
Today, most applications use a great deal of dynamic memory. Operating systems and hardware platforms make ever-larger address spaces available, and applications are growing in size to take advantage of this available memory.<P>
All modern operating systems now provide virtual memory. While virtual memory has real benefits, its presence can affect application performance more than any other factor--a single memory reference can be 10,000 times slower if it causes a page fault! The rate of page faulting is determined by only two factors: available physical memory and how you manage memory in your application.<P>
Two other features of modern operating systems--multitasking and multithreading--also increase the demands on memory management. Every time there is a context switch, the data your application is referencing may be swapped out to make room for the other thread or process. Unless each thread's data is contained in a very tight working set, every context switch will cause a lot of unnecessary swapping.<P>
The increasing popularity of C++ also magnifies the importance of efficient heap management. By their nature, C++ programs use dynamic memory much more heavily than their C counterparts--often for small, short-lived allocations.<P>
<h3><a name="01b9_0005"><I>malloc</I> Woes<a name="01b9_0005"></h3><P>
The <I>malloc</I> API specified by ANSI is a general-purpose search for an arbitrarily sized free area of memory. (Note that compilers generally implement C++ <I>operator new</I> directly in terms of <I>malloc</I>.) <I>malloc</I> must handle all block sizes and allocation patterns. Since it does not take a parameter to specify a heap, all allocations through <I>malloc</I> must share the same heap.<P>
The traditional implementation of <I>malloc</I> is simply a list of free blocks that is searched linearly until a suitably sized block is found. With a steady-state pattern of allocations and frees of random sizes, the number of free blocks will, on average, be about half the number of blocks in use; for proof, see Donald Knuth's <I>The Art of Computer Programming</I> Volume 1, second edition (Addison-Wesley, 1973). Consequently, the performance of <I>malloc</I> degrades in proportion to the total number of allocation requests.<P>
In virtual-memory environments, most <I>malloc</I> implementations scale pathologically when the total heap size exceeds currently free physical memory. When <I>malloc</I>'s free list does not fit in memory, <I>malloc</I> can thrash, with every call causing page faults. In some implementations, individual calls to <I>malloc</I> can then cause hundreds of page faults, with a single call taking seconds rather than microseconds.<P>
Applications generally reference data items more than once. Therefore, efficiency of references to your own data can be even more important than references by <I>malloc</I> to its own free list. Good locality is the key to fast references to your data in virtual-memory environments.<P>
Because all callers of <I>malloc</I> in a given process share the same heap, individual blocks allocated by <I>malloc</I> tend to be scattered arbitrarily throughout the process's address space. Consequently, a single data structure's elements are strewn across many pages, together with unrelated data--the data has poor locality. The working set required to hold the entire data structure is thus much larger than necessary, since the virtual-memory manager swaps in units of pages. Traversing the data structure therefore causes many expensive page faults. The problem is compounded even further if there are context switches during the data-structure traversal.<P>
Even in non-virtual-memory environments, <I>malloc</I> has another problem: It wastes memory. Because <I>malloc</I> must handle blocks of variable size, it is prone to fragmentation. This, of course, is the condition in which many free blocks too small to be useful are trapped between larger, in-use blocks.<P>
Another instance of memory waste involves granularity and overhead. The size that your program passes to <I>malloc</I> gets rounded up to the nearest granularity multiple--often between 8 and 32 bytes. Overhead consists of the internal header associated with every memory block, which can be as much as 8 or 16 bytes per allocation. Memory waste is significant even if address space is plentiful, because you pay for any increase in working-set size with page faults.<P>
In multithreaded applications, <I>malloc</I> incurs significant extra overhead in serializing access to the heap. Having only one heap also increases contention and prevents processors from being concurrently active in heap operations on multiprocessor platforms.<P>
<h3><a name="01b9_0006">Solutions<a name="01b9_0006"></h3><P>
The single most important improvement on <I>malloc</I> is the provision of multiple heaps, or memory pools. With multiple memory pools, you can partition your program's allocations into groups that correspond to your program's data structures.<P>
Many benefits result from this change. First, allocation speed improves, because heap sizes are smaller. Second, there is much less swapping, because locality is vastly improved, which reduces working-set sizes. Third, there is less fragmentation, because per-pool allocations vary less in size and extent. Fourth, there is faster freeing, because you can free an entire memory pool rather than individually freeing thousands of blocks. Finally, you can concurrently allocate in separate heaps without expensive synchronization in multithreaded applications.<P>
<h3><a name="01b9_0007">Fixed-Size Allocators<a name="01b9_0007"></h3><P>
Another approach is to change the allocator's algorithm. Remember that <I>malloc</I> degrades with heap size, and is roughly O(n) (in physical memory). What we'd really like is an allocator closer to O(c).<P>
Remember that in most applications, especially those written in C++, the allocations are usually quite small. In fact, most allocations are for small, fixed-size class or structure objects. You could allocate these very efficiently by maintaining free lists of blocks of just the right size for each major class or structure. Allocation is then just a matter of popping off the head of the free list, and deallocation is pushing on a new head.<P>
The benefits of this method include: greater speed than with an allocator of variable-size; better scaling, on the order of O(c) rather than O(n); no internal fragmentation, because all free blocks are just the right size; good locality, if implemented correctly; and, finally, potential elimination of overhead and granularity, because there's no need to store the size with each block (since blocks are of fixed size).<P>
<h3><a name="01b9_0008">Overloading <I>operator new</I> in C++<a name="01b9_0008"></h3><P>
In C++, you can overload <I>operator new</I> for individual classes. This allows you to customize memory management on a per-class basis without users of the class even knowing about it (they just call <I>operator new</I> in the usual way).<P>
You can establish a fixed-size allocator for a class, and allocate objects from fixed-size memory pools according to the data structure to which the class object will belong. This elegantly combines the benefits of multiple memory pools and fixed-size allocators.<P>
<h3><a name="01b9_0009">A Linked-List Example<a name="01b9_0009"></h3><P>
I'll illustrate the techniques I've discussed with an example that directly applies to many applications: linked-list manipulation. The sample application randomly inserts and deletes randomly sized strings in five linked lists. It does a full linear traversal of each list and then deletes each list. The list size is an input parameter.<P>
The first implementation (<a href="#01b9_000e">Listing One</A>, page 96) uses the default global operator <I>new</I>. Element insertion demonstrates allocation speed. All list links and values are allocated from the same heap. If you run the program with a size such that total list data exceeds available physical memory, <I>operator new</I> thrashes before insertion is complete.<P>
List traversal demonstrates how poor locality impacts the speed of memory references. If the total size of list data exceeds physical memory, each list search thrashes. This is because the lists' memory is all allocated from the same heap. Each page in the heap contains data from each of the lists, so the total number of pages needed for one list (the working-set size) is five times more than it needs to be.<P>
When the program terminates, the destructors for each list are invoked. The list destructor frees each element, demonstrating deallocation speed.<P>
<h3><a name="01b9_000a">Improving Memory Management<a name="01b9_000a"></h3><P>
A second version of the program is identical except for memory-management calls. This version uses SmartHeap APIs to demonstrate multiple memory pools, a fixed-size allocator, and memory-pool de-allocation.<P>
<a href="#01b9_0010">Listing Two</A> (page 97) shows the changed definitions in the new version. Each <I>List</I> object has its own memory pool, from which <I>Link</I> objects and string values of that list are allocated.<P>
<I>List</I>'s constructor calls <I>MemPoolInitFS</I> to initialize the memory pool with a fixed-size threshold equal to the size of a <I>Link</I>. This allows all <I>Link</I> objects to be allocated with a fixed-size algorithm.<P>
<I>List::Insert</I> allocates a <I>Link</I> from <I>List</I>'s pool and passes the pool to <I>Link</I>'s constructor. Note that the memory pool is passed to <I>operator new</I> with the placement syntax.<P>
<I>Link</I> defines its own operators <I>new</I> and <I>delete</I>. <I>Link::operator new</I> calls <I>MemAllocFS</I>, the SmartHeap fixed-size allocator. <I>Link</I>'s constructor also allocates string values from the owning list's memory pool. This is reasonable, since <I>Link</I> objects and their associated string values tend to be referenced and freed together.<P>
<I>List</I>'s destructor simply calls <I>MemPoolFree</I> to deallocate the entire memory pool. This frees all <I>Link</I>s and all string values. There is no need to free each <I>Link</I> object or string individually. Moreover, the pages in which these objects reside need not even be touched (they might not be resident).<P>
Note that <I>main, List::RandomOp()</I>, and <I>List::Find</I> are not changed at all, yet the times for each of these functions are dramatically different in the two implementations.<P>
<h3><a name="01b9_000b">Performance Results<a name="01b9_000b"></h3><P>
<a href="#01b9_000d">Table 1(a)</A> shows the times, in seconds, printed by both versions of the program when run with a count of 20,000 in Windows 3.1 on a 25-MHz 386 with 4 Mbytes of RAM. <a href="#01b9_000d">Table 1(b)</A> shows the results with a count of 40,000 in Windows NT running on a 33-MHz 486 with 16 Mbytes of RAM. <a href="#01b9_000d">Table 1(c)</A> shows the results with a count of 150,000 in HP-UX 9.0 on an HP 710 with 32 Mbytes of RAM.<P>
In each case, changing only the memory-management calls results in an order of magnitude or greater overall application performance improvement. This example is admittedly somewhat contrived in that the program allocates more data than will fit in available physical memory. However, it illustrates the impact memory management can have on operations that applications commonly and frequently perform. It also serves to alert you to the fact that memory management <I>cannot</I> be ignored if your application is to perform well in a virtual-memory environment.<P>
<h3><a name="01b9_000c">Alternative Implementations<a name="01b9_000c"></h3><P>
The techniques I've discussed are illustrated here with SmartHeap, a commercial memory manager available for most platforms. However, other alternatives are available to you, in some cases.<P>
For example, in Windows 3.x, you can use <I>LocalAlloc</I> to suballocate in <I>GlobalAlloc</I>ed blocks to create multiple heaps. Paul Yao describes this technique in detail in his <I>Windows 3.0 Power Programming Techniques</I> (Bantam Books, 1990). The Win32 API provides a facility for creating multiple heaps; see <I>HeapAlloc</I> in the Win32 API Reference.<P>
For a fixed-sized allocator in C++, a good place to start is Bjarne Stroustrup's <I>The C++ Programming Language</I> (Addison-Wesley, 1991), which includes simple, fixed-size allocator implementations.<P>
If you want to embark on your own implementation of a multiple-pool memory manager, Knuth's <I>The Art of Computer Programming</I>, Volume 1, second edition, is required reading.<P>
<pre></pre><P>
<h4><a name="01b9_000d"><B>Table 1:</B> (a) Windows 3.1 benchmarks (20,000 iterations); (b) Windows NT benchmarks (40,000 iterations); (c) HP-UX benchmarks (150,000 iterations). (Note: All times are in seconds.)<a name="01b9_000d"></h4><P>
<PRE>
          Operation    Program 1    Program 2
     ----------------------------------------
  <b>(a)</b>
          Insertion     963.01        24.17
          Search         26.15        15.92
          Deletion       91.42         2.09
          Overall App  1086.65        45.15

 <b> (b)</b>
          Insertion      22.65         9.12
          Search        175.79         0.50
          Deletion      159.29         0.14
          Overall App   359.76        10.04

  <b>(c)</b>
          Insertion     319.57        19.97
          Search        171.15         2.82
          Deletion      320.04         0.35
          Overall App   813.21        23.15
</pre><P>

<h4><a name="01b9_000e"><a name="01b9_000f"><B>[LISTING ONE]</B></H4>

<PRE>


//--------------------------------------------------------------------
// Memory management exerciser.                   By Arthur Applegate.
// Program 1: Creates, traverses, and destroys linked links, to show
// the effect of memory management on an application's performance.
//--------------------------------------------------------------------

#include &lt;stdio.h&gt;
#include &lt;time.h&gt;
#include &lt;string.h&gt;
#include &lt;stdlib.h&gt;

//--------------------------------------------------------------------------
// class Timer: Instances of this class, when declared as automatic variables,
// record and print the time taken to execute the block in which they are declared.
//--------------------------------------------------------------------------
class Timer
{
private:    const char *m;
            clock_t startTime;
public:     Timer(const char *msg) : m(msg), startTime(clock()) { }
           ~Timer()
            {     printf(&quot;\n%s: %.2f seconds.&quot;, m,
                  (double)(clock()-startTime) / (double)CLOCKS_PER_SEC);
            }
};
//-------------------------------------------------------------------
class Link                          // Link objects are list elements
{            friend class List;
public:      Link (const char *val, Link *p, Link *n);
            ~Link ();
private:     char *value;
             Link *prev;
             Link *next;
};
//-------------------------------------------------------------------
class List                    // List objects are doubly-linked lists
{
public:      List ();
            ~List ();
             const Link *Insert (Link *prev, const char *val);
             void Delete (Link *remove);
             void RandomOp ();
             const Link *Find (const char *val) const;
private:     Link *head;
             Link *tail;
};
//------------------------------------------------------------------
                                            // create a list element
Link::Link (const char *val, Link *p, Link *n)
{
   value = new char[strlen(val)+1];
   strcpy(value, val);
   if ((prev = p) != NULL)      prev-&gt;next = this;

   if ((next = n) != NULL)      next-&gt;prev = this;
}
//-----------------------------------------------------------------
Link::~Link ()                              // destroy a list element
{
   delete value;
   if (prev)      prev-&gt;next = next;
   if (next)      next-&gt;prev = prev;
}
//------------------------------------------------------------------
List::List ()                  // create a new list: clear head, tail
{
   head = tail = NULL;
}
//------------------------------------------------------------------
List::~List ()         // destroy list: delete each Link individually
{
   while (head)
      Delete(head);
}
//-----------------------------------------------------------------
                          // add a new link after specified element
const Link *List::Insert (Link *prev, const char *val)
{
   Link *next = prev ? prev-&gt;next : head;
   Link *l = new Link (val, prev, next);
   if (!prev)      head = l;
   if (!next)      tail = l;
   return l;
}
//-----------------------------------------------------------------
void List::Delete (Link *l)     // remove a link; no-op if link NULL
{
   if (!l) return;
   if (head == l)      head = l-&gt;next;
   if (tail == l)      tail = l-&gt;prev;
   delete l;
}
//-----------------------------------------------------------------
void List::RandomOp ()     // insert (80%) or delete (20%) an element
{
   if (rand() % 5 != 0)
   {
      const maxStr = 64;
      char buf[maxStr+1];

      // generate a string of random length between
      // 1 and 64 bytes, with random fill value
      int len = rand() % maxStr + 1;
      memset(buf, rand() % 128, len);
      buf[len] = '\0';
      Insert(tail, buf);
   }
   else
      Delete(head);

}
//-----------------------------------------------------------------
                       // find the first element with a given value
const Link *List::Find (const char *val) const
{
   for (register Link *l = head;  l;  l = l-&gt;next)
      if (strcmp(l-&gt;value, val) == 0)
         break;
   return l;
}
//-----------------------------------------------------------------
void main(int argc, char *argv[])
{
   if (argc &lt; 2)
   {
      printf(&quot;\nusage: lists &lt;element-count&gt;&quot;);
      return;
   }
   long count = atol(argv[1]);

   Timer t(&quot;Overall Application&quot;);
   List *list1 = new List, *list2 = new List, *list3 = new List,
      *list4 = new List, *list5 = new List;

   // test allocation speed
   // note that to properly benchmark allocations, we need
   // interspersed de-allocations since all allocators will
   // be fast with an empty free-list!
   {
      Timer t(&quot;Insertion&quot;);

      // generate and insert `count' strings of random lengths
      // and contents; occasionally delete to simulate a
      // dynamically shrinking and growing linked list
      while (count--)
      {
         // intersperse each operation so that elements are
         // chaotically distributed in memory if we do not
         // have multiple memory pools
         list1-&gt;RandomOp();
         list2-&gt;RandomOp();
         list3-&gt;RandomOp();
         list4-&gt;RandomOp();
         list5-&gt;RandomOp();
      }
   }
   // test locality: each list will touch five times as many
   // pages if allocations were from a single heap
   {
      Timer t(&quot;Search&quot;);

      list1-&gt;Find(&quot;not present&quot;);
      list2-&gt;Find(&quot;not present&quot;);
      list3-&gt;Find(&quot;not present&quot;);
      list4-&gt;Find(&quot;not present&quot;);
      list5-&gt;Find(&quot;not present&quot;);
   }
   // destructors for lists 1-5: test freeing speed
   {
      Timer t(&quot;Deletion&quot;);

      delete list1;
      delete list2;
      delete list3;
      delete list4;
      delete list5;
   }
}


</PRE>

<h4><a name="01b9_0010"><a name="01b9_0011"><B>[LISTING TWO]</B></H4>

<PRE>


//--------------------------------------------------------------------
// Memory management exerciser, version 2.        By Arthur Applegate.
// This version has changes for improved performance. Only ten lines
// of code needed to be changed from version shown in Listing 1. These
// changes are indicated with &quot;***&quot; in the comment line.
//--------------------------------------------------------------------

#include &lt;smrtheap.hpp&gt;       // *** include SmartHeap C++ header file

//--------------------------------------------------------------------
class Link
{           friend class List;
public:     // *** constructor receives memory pool parameter
            Link (MEM_POOL pool, const char *val, Link *p, Link *n);
           ~Link ();
private:    // *** overload new/delete to use fixed-size algorithm,
            // *** allocating from the owning List's memory pool
            void *operator new(size_t, MEM_POOL pool)
                                        { return MemAllocFS(pool); }
            void operator delete(void *mem)    { MemFreeFS(mem); }
            char *value;
            Link *prev;
            Link *next;
};
//--------------------------------------------------------------------
class List
{
public:     List();
           ~List();
            const Link *Insert(Link *prev, const char *val);
            void Delete(Link *remove);
            void RandomOp();

            const Link *Find(const char *val) const;
private:    Link *head;
            Link *tail;
            MEM_POOL pool;    // *** per-List memory pool data member
};
//--------------------------------------------------------------------
// *** create a list element
Link::Link(MEM_POOL pool, const char *val, Link *p, Link *n)
{
   // *** use placement syntax to allocate string
   // *** from owning List's memory pool
   value = new (pool) char[strlen(val)+1];

   strcpy(value, val);
   if ((prev = p) != NULL)      prev-&gt;next = this;
   if ((next = n) != NULL)      next-&gt;prev = this;
}
//--------------------------------------------------------------------
List::List()                                      // create a new list
{
   // *** initialize memory pool for Link's and strings
   pool = MemPoolInitFS(sizeof(Link), 0, 0);
   head = tail = NULL;
}
//--------------------------------------------------------------------
List::~List()                                        // destroy a list
{
   // *** no need to free individual links or values,
   // *** as freeing the pool frees all Links and string values
   // note that if properly implemented, freeing the memory pool
   // will not even _touch_ the pages that contain the individual
   // blocks -- so there is no swapping regardless of heap size
   MemPoolFree(pool);
}
//--------------------------------------------------------------------
                             // add a new link after specified element
const Link *List::Insert(Link *prev, const char *val)
{
   Link *next = prev ? prev-&gt;next : head;

   // *** use placement syntax to allocate Link
   // *** from current List's memory pool
   Link *l = new (pool) Link(pool, val, prev, next);

   if (!prev)      head = l;
   if (!next)      tail = l;
   return l;
}

</pre><HR><P>Copyright &copy; 1994, <I>Dr. Dobb's Journal</I></P></BODY></HTML>
