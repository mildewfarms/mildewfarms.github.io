<html>
<head>
<title>Sep01: Algorithm Alley</title>
</head>

<body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000">
<!--Copyright &#169; Dr. Dobb's Journal-->

<h1>Simulated Annealing: A Heuristic Optimization Algorithm</h1>
<p><i>Dr. Dobb's Journal</i> September 2001</p>

<h3>By Girish Keshav Palshikar</h3>

<I> Girish is a scientist at the Tata Research Development and Design Centre (TRDDC) 
in Pune, India. His research interests are in AI and mathematical logic. He can 
be contacted at <a href="mailto:girishp@pune.tcs.co.in">girishp@pune.tcs.co.in</a>.</I> 
<hr>

<p>There are many practical problems that need to find a lowest cost solution that minimizes some given cost function. For example, in the famous traveling salesman problem (TSP), given a map connecting <i>N</i> cities through a road network, the task is to find a shortest length tour starting and ending at a given city and where the salesman visits every other city exactly once. The obvious cost here is the total distance traveled in a tour. Of course, there may be additional factors that contribute to evaluating the desirability of a proposed tour; for example, the shortest time to be spent in cold regions. As another example, the placement of components on a circuit board is expected to minimize the total length of the wire used and also the number of crossings. </p>
<p>These so-called "combinatorial optimization" problems have some common characteristics. There is a state-space in which the search for an optimal solution needs to be conducted. Each state (or configuration) in such a state-space is a candidate solution. For example, the state- space for TSP consists of all possible tours in the given graph and the state-space for the circuit placement problem consists of all possible placements of given components in a given <i>M</i>X<i>N</i> grid, subject to connectivity in the circuit diagram. The state-space is often finite, though very large, and is characterized in terms of a small number of parameters where each parameter has a finite domain of possible values. There are domain specific, often symbolic, constraints that exclude certain states as possible solutions. The cost can also include many complex factors and dependencies. To give some idea of the state-space size, consider the problem of placing three components on a 100X50 grid; each component can be placed on a square in this grid and no two components can occupy the same square. One possible state (that is, a placement) is to place the components in squares given by the coordinates (10,10), (15,15), and (20,20). Clearly, the total number of possible placement for three components=5000X4999X998=124925010000&#8776;125 billion; this is the size of the state-space. </p>
<DDJADVERTISEMENT INLINE>

<p>It can be proved that many of these combinatorial optimization problems are intractable; that is, there are no known efficient systematic search algorithms that find the optimal solution for all input instances of the problem. Fortunately, if the optimal solution is too hard to find, a solution that is sufficiently close to it is often acceptable in practice. A common approach is then to define heuristic search algorithms that efficiently find such near optimal solutions most of the time. The heuristics refer to domain-specific knowledge or expertise to control and expedite the search. Among the many heuristic search algorithms, I will outline one rather simple approach (and present a C implementation skeleton for it) called "hill climbing," and use it to introduce some useful terms that describe common limitations of search algorithms. I then present a well-known probabilistic local search technique called "simulated annealing" (SA) that mimics the natural process of the slow cooling of liquids, which leads to a solid that has the lowest energy. Finally, I provide a general C implementation of the SA algorithm and illustrate it by applying it to the problem of producing an aesthetic drawing of a given graph.</p>



<h3>Hill Climbing</h3>


<p>Hill climbing is a greedy nearest neighbor approach to search the state-space to locate a lowest cost solution. It uses domain knowledge in the form of a distance function that returns an estimate of how close a given state is to the global minimum. This function is provided separately by the user for each problem domain; for example, the distance function for the placement problem is different from that for TSP. <A NAME="rl1"></a><A HREF="#l1">Listing One</A> is a C program skeleton of the hill-climbing search algorithm, which is actually for a specific version called the "steepest ascent" hill climbing or "gradient search." The problem-specific definitions of the C structure STATE and the assumed functions need to be provided for using this code. </p>


<p>It is easy to see the limitations of the hill-climbing algorithm for locating the global maximum. Hill climbing often reaches a local minimum &#151; that is, a state that has a lower cost than all its neighbors, but which is not a global minimum. It may also reach a plateau &#151; a state with neighboring states that all have the same cost and hence no next state can be chosen for further exploration. The hill-climbing algorithm can be modified to include simple strategies to deal with these problems; backtracking to some earlier state, taking a jump to some random state (when a plateau is encountered), moving in several directions simultaneously, and so on. Nevertheless, in general, hill climbing has been found to be limited in practical combinatorial optimization problems. Simulated annealing (SA) is another local search algorithm (among a variety of other techniques) that overcomes some of the limitations of hill climbing and often succeeds in efficiently locating good low-cost solutions. (For more information, see "Simulated Annealing," by Michael P. McClauphlin, <i>DDJ</i>, September 1989.)</p>



<h3>Simulated Annealing</h3>


<p>It is well known in physics that when a hot liquid is cooled slowly (annealed) it reaches a crystalline form. The atoms (or molecules) in a crystal are arranged in a regular and ordered configuration; this state has the lowest (potential+kinetic) energy and consequently, highest stability. On the other hand, when the hot liquid is cooled rapidly, the end result is an amorphous solid &#151; this state has a somewhat higher energy. Qualitatively speaking, this happens because when the liquid is cooled slowly, the atoms have time to rearrange themselves until they achieve a state of lowest energy at that temperature &#151; the so-called "thermal equilibrium." In a thermal equilibrium at temperature <i>T</i> (in °<i>K</i>), the system achieves a state of energy <i>E</i> with a probability <i>p(E)</i><IMG SRC="approxeq.gif" ALT="" WIDTH="13" HEIGHT="14" ALIGN="bottom"><i>e</i><i><sup>-E/kT</sup></i> where <i>k</i>=1.3804X10<sup>-16</sup> erg per degree is a constant of nature, called the "Boltzmann" constant. An interesting thing to note about this Boltzmann distribution is that it lets the system be in a higher energy state, even in a thermal equilibrium, although with a small chance. This chance decreases with temperature <i>T</i>, so that the lower the temperature, the higher the chance that the system is in the lowest energy state. </p>


<p>"Optimization by Simulated Annealing," by S. Kirkpatrick et al. (<i>Science</i>, 1983), identified the similarities between the annealing process and a general search for optimal solution in a combinatorial optimization problem. Essentially, the probability, at a temperature <i>T</i>, with which the search algorithm moves from a state <i>s</i>1 of energy <i>E</i>1 to another state <i>s</i>2 of energy <i>E</i>2 is given by <i>e</i><sup>-<i>(E1-E2)/kT</i></sup>. Clearly, whenever <i>E</i>2&lt;<i>E</i>1 the system will definitely move to <i>s</i>2 but when <i>E</i>2&gt;<i>E</i>1, the state change is probabilistic. </p>

<p>For applying search techniques to combinatorial optimization problems, you need to:</p>


<ul>
  <li>Clearly define the information associated with each state. 
  <li>Identify an initial state, which is often generated randomly. 

  <li>Define a function that (often probabilistically) returns a state in the neighborhood of a given state. 

  <li>Define a Boolean function that returns True if the given state is a solution (that is, a minimum cost state) and False, otherwise. 

</ul>


<p>In addition, for applying SA to combinatorial optimization problems, you need to define analogues of temperature and cost. A common approach is to define energy as a function that returns the cost for a given state; the definition of the energy function includes all relevant factors that affect the cost. The Boltzmann constant <i>k</i> is often taken to be 1. The notion of temperature is often purely artificial (does not correspond to any real aspect of the problem) and is often defined to vary from a given maximum value <i>T</i><i><sub>max</sub></i> to a given minimum value <i>T</i><i><sub>min</sub></i>. A number of cooling or annealing strategies are used to systematically drop the temperature from <i>T</i><i><sub>max</sub></i> until it reaches <i>T</i><i><sub>min</sub></i>; the most common is the "geometric annealing schedule," where the next temperature is obtained from the current temperature by the geometric series formula <i>T</i><i><sub>next</sub></i>=<i>g</i>X<i>T</i><i><sub>current</sub></i>, where <i>g</i> is a given constant between 0 and 1. For instance, when <i>T</i><i><sub>max</sub></i>=1000, <i>T</i><i><sub>min</sub></i>=10 and <i>g</i>=0.5, the sequence of temperatures obtained using geometric annealing schedules will be 1000, 500, 250, 125, 62.5, 31.25, 15.625, and 7.8125, which is less than <i>T</i><i><sub>min</sub></i>; at this point the schedule terminates. <A NAME="rf1"></a><A HREF="0109of1.htm">Figure 1</A> is a high-level description of the SA algorithm. The termination condition is often <i>T</i>&lt;<i>T</i><i><sub>min</sub></i>; but additional factors can be included here. Also, since the expression <i>e</i><sup>-<i>(E-E')/kT</i></sup> need not be always between 0 and 1, it has to be scaled appropriately so that comparison with the output of a standard random number can be made. </p>

<p><A NAME="rl2"></a><A HREF="#l2">Listings Two</A> and <A NAME="rl3"></a><A HREF="#l3">Three</A> are a C implementation of the SA algorithm. To apply this C implementation to a specific combinatorial problem, you need to provide some additional problem-specific details. I will illustrate this process by applying this C implementation to a specific problem. </p>



<h3>Aesthetic Graph Drawing Using SA</h3>


<p>A number of practical applications involving combinatorial optimization have used SA. Here I describe an interesting problem of automatically generating an aesthetic drawing of a given graph on an <i>MXN</i> grid (say, on screen), as discussed in "Drawing Graphs Nicely Using Simulated Annealing," by R. Davidson and D. Harel (<i>ACM Transaction Graphics</i>, October 1996). The task here is to take a given graph of <i>n</i> vertices and <i>e</i> edges (representing connectivity between vertices) and place the <i>n</i> vertices on an <i>M</i>X<i>N</i> grid such that when the adjacent vertices are connected by straight line edges, the resulting graph looks aesthetically neat. Of course, there are many criteria for what constitutes an aesthetic drawing of a graph: Vertices are evenly distributed in the grid, not too many are near the center or near the borders, edge lengths are not too small nor too long, edge crossings are minimized, and so on. </p>


<p>Additional C source code needed for applying the SA algorithm to the graph- drawing problem is available electronically (see "Resource Center," page 5). The C structure GRAPH contains the connectivity of the given graph. A state (as stored in the C structure STATE) represents a placement of all the <i>n</i> vertices of a given graph on the <i>M</i>X<i>N</i> grid; that is, a state associates a position, in the form of an x- and a y-coordinate, with each vertex in a given graph. The <i>RandomState</i> function generates a random placement for all the vertices and is used to generate the initial state. The <i>NeighbourState</i> function generates a neighbor state (for the given state) by randomly selecting a vertex and moving it by one square (up, down, right, left, up-right, up-left, down-right, or down-left). </p>

<p>The <i>Energy</i> function computes the cost associated with a given placement of a given graph. Several factors contribute to the calculation of the energy <i>E(s)</i> for a state <i>s</i>; I've implemented only the three, as in the formula for <i>E(s)</i> (<A NAME="rf2"></a><A HREF="0109of2.htm">Figure 2</A>). </p>

<p>In <A NAME="rf2"></a><A HREF="0109of2.htm">Figure 2</A>, <i>n</i> and <i>e</i> are the number of vertices and edges in the given graph, <i>d</i><i><sub>ij</sub></i><i> </i>is the Euclidean distance between vertex <i>i</i> and vertex <i>j</i> (in the given placement), <i>r</i><i><sub>i</sub></i>, <i>l</i><i><sub>i</sub></i>, <i>t</i><i><sub>i</sub></i>, and <i>b</i><i><sub>i</sub></i> are the distances of the <i>i</i>th vertex from the right, left, top, and bottom borders, respectively, <i>d</i><i><sub>k</sub></i> is the length of the <i>k</i>th edge and <IMG SRC="lambda.gif" ALT="" WIDTH="8" HEIGHT="11" ALIGN="bottom"><sub>1</sub>, <IMG SRC="lambda.gif" ALT="" WIDTH="8" HEIGHT="11" ALIGN="bottom"><sub>2</sub>, and <IMG SRC="lambda.gif" ALT="" WIDTH="8" HEIGHT="11" ALIGN="bottom"><sub>3</sub> are the parameters used to control the relative importance of the three factors. Contribution of the first factor increases as the vertices move closer to each other and thus SA will try to prevent vertices from coming too close to each other. Contribution of the second factor to <i>E(s)</i> increases as a vertex moves closer to the borders of the <i>M</i>X<i>N</i> grid and thus SA will try to prevent vertices from coming too close to the borders. Contribution of the third factor to <i>E(s)</i> increases as lengths of edges increase and thus SA will try to prevent edges that are too long. Davidson and Harel suggest more factors that contribute to <i>E(s)</i> and those can be easily added. Increasing <IMG SRC="lambda.gif" ALT="" WIDTH="8" HEIGHT="11" ALIGN="bottom"><sub>1 </sub>relative to other parameters causes SA to prefer pictures with smaller distances between vertices. Increasing <IMG SRC="lambda.gif" ALT="" WIDTH="8" HEIGHT="11" ALIGN="bottom"><sub>2 </sub>relative to <IMG SRC="lambda.gif" ALT="" WIDTH="8" HEIGHT="11" ALIGN="bottom"><sub>1 </sub>causes SA to push the vertices towards the center and decreasing it causes SA to use more drawing space near the borders. Increasing <IMG SRC="lambda.gif" ALT="" WIDTH="8" HEIGHT="11" ALIGN="bottom"><sub>3 </sub>causes SA to prefer shorter edges. When either <i>d</i><i><sub>ij</sub></i>=0 or when either of <i>r</i><i><sub>i</sub></i>, <i>l</i><i><sub>i</sub></i>, <i>t</i><i><sub>i</sub></i>, or <i>b</i><i><sub>i</sub></i> is 0, then you assume that the corresponding energy takes a large value denoted in the program by the constant MAX_ENERGY. </p>

<p>The <i>InitGraph</i> function fills up a global variable with the input graph that is to be placed. The <i>SimAnneal</i> function implements the SA algorithm. <i>T</i><i><sub>max</sub></i> and <i>T</i><i><sub>min</sub></i> are encoded in the constants MAX_TEMP and MIN_TEMP, respectively. </p>

<p>As an example of the application of the SA algorithm, <A NAME="rf3"></a><A HREF="0109of3.htm">Figure 3</A> is a simple graph and its placements as generated by the SA algorithm on a 30X20 grid. Note that the algorithm did not generate a hexagonal placement (possibly because it did not attempt to prevent edge crossings); however, the generated placement does look symmetrical in a different way. By adding more factors to the energy calculations and by selecting appropriate values for the parameters (for <IMG SRC="lambda.gif" ALT="" WIDTH="8" HEIGHT="11" ALIGN="bottom"><sub>1</sub>, <IMG SRC="lambda.gif" ALT="" WIDTH="8" HEIGHT="11" ALIGN="bottom"><sub>2, </sub>and <IMG SRC="lambda.gif" ALT="" WIDTH="8" HEIGHT="11" ALIGN="bottom"><sub>3</sub>), the SA algorithm can be used to generate pleasing placements for more complex graphs; see Davidson and Harel. Even further complex factors that characterize aesthetic drawing of a graph can also be added; for example, for balancing the area occupied by the convex hull of the graph and the remaining blank area. </p>



<h3>Conclusion</h3>


<p>A number of other heuristic algorithms have been invented for combinatorial optimization problems &#151; AO* search, constraint satisfaction, means-end analysis, genetic algorithms, and so on. These algorithms yield acceptable near-optimal solutions for a variety of problems. But there is no known universal algorithm that works efficiently for all problems. We examined a particular probabilistic heuristic optimization algorithm, called "simulated annealing." SA mimics the natural process of slow cooling of liquids that leads to a solid form that has the lowest energy. </p>


<p>A number of possible enhancements have been attempted for SA. The SA algorithm has been parallelized in various ways to obtain speedup benefits on multiprocessor systems. Experimenting with different types of annealing schedules is another possible direction. </p>

<p>SA itself is not always suitable for all combinatorial optimization problems. Empirically it has been observed that for SA to work satisfactorily, the cost function should not contain narrow and steep valleys. The acceptable near minimal solutions should not be within such narrow and steep valleys. The energy (cost) function should change smoothly upon changes in states. It should also be efficiently computable, since it is invoked a large number of times. SA usually finds a near optimal solution, but not the global minimum itself if it has a low probability of being found. Finding suitable temperature schedules and best values of control factors for SA often needs careful experimentation. In spite of these problems, SA is being successfully used in a large number of practical problems, including VLSI chip design and layout, floor planning, flow shop scheduling, channel routing, graph drawing, image processing, coding theory, graph coloring and partitioning, satisfiability, and so on.</p>



<h3>Acknowledgments</h3>


<p>I gratefully acknowledge the support of Professor Mathai Joseph. I also wish to thank Dr. Manasee Palshikar for her patience and strength. </p>


<p></p>



<p><b>DDJ</b></p>
<H4><A NAME="l1"></a>Listing One</H4>


<pre>// max. no. of neighboring states for a given state
#define MAX_NEIGHBOUR   100     

// external functions assumed (specific to each problem domain)
extern double Cost(STATE *pS);  // returns the cost of given state
extern int Solution(STATE *pS);  // 1 if given state is a solution; else 0 
// generate neighbor states of given state; return no. of neighbor states
extern int GetNeighbours(STATE *pS, STATE Next[MAX_NEIGHBOUR]); 

// hopefully find and return the lowest cost state
// STATE is a problem-specific representation of the structure of a state 
// pS0 and pS are pointers to given initial state and low cost state found. 
int HillClimbing(STATE *pS0, STATE *pS)
{
   STATE Next[MAX_NEIGHBOUR];
   int i, n, index;
   double c0, c, c1;

   if ( Solution(pS0) ) // found
   {
       CopyState(pS,pS0);
       return(1);
   }
   CopyState(pS, pS0); // initialize
   c0 = Cost(pS0);     // cost of initial state
   while ( (n = GetNeighbours(pS,Next)) &gt; 0 ) // get neighbours of s
   {
       index = 0; // index (in Next) of lowest cost neighbour
       c = Cost(&amp;Next[0]);
       for(i = 0; i &lt; n; i++) // do for each neighbour state
       {
       if ( Solution(&amp;Next[i]) ) // found
       {
           CopyState(pS,&amp;Next[i]);
           return(1);
       }
       if ( (c1 = Cost(&amp;Next[i])) &lt; c )
       {
           index = i;
           c = c1;
       }
       } // end for 
       if ( c &lt; c0 ) // found a lower cost neighbour
       {
       CopyState(pS, &amp;Next[index]);
       c0 = c;
       }
       else // reached local maximum
       break;
   } // end while
   return(0); // global solution not found; S contains low cost state found 
}
</pre>
<P>
<A HREF="#rl1">Back to Article</A>
</P>
<H4><A NAME="l2"></a>Listing Two </H4>


<pre>/* Module: Simulated Annealing
 * Programmer: Girish Keshav Palshikar
*/
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;

#include "simann.h"
#include "sim_app.h"    // problem-specific information needed by SA

// function prototypes 
int NextTemp(TEMP *pt);       
BOOL Boltzmann(ENERGY e1, ENERGY e2, TEMP t);
BOOL CoolEnough(TEMP t); 

// problem-specific functions assumed
extern BOOL NeighbourState(STATE *pS, STATE *pNew);
extern BOOL IsSolution(STATE *pS); // TRUE if state is an acceptable solution
extern ENERGY Energy(STATE *pS); // compute &amp; return cost/energy of state
extern int CopyState(STATE *pDest, STATE *pSrc);

// s0 is the initial state and t0 is the initial temperature
// Limit is the no. of attempts to explore neighbourhoods at a given temp. 
BOOL SimAnneal(STATE *pInit, TEMP t0, int Limit, STATE *pDest)
{
   STATE s;  // current state
   TEMP t;   // current temp.
   ENERGY e, e_new; // energy of current and new state
   BOOL success = FALSE;
   int i;

   CopyState(&amp;s, pInit);  // make current state = initial state
   e = Energy(&amp;s); // compute current energy
   t = t0;
   CopyState(pDest, pInit);  // copy initial state into pDest
   
   while ( !CoolEnough(t) ) 
   {
       if ( IsSolution(&amp;s) ) // done
       {
       success = TRUE;
       break;
       }
       for ( i = 0, success = FALSE; i &lt; Limit; i++ ) 
       {
       if ( !NeighbourState(&amp;s, pDest) ) // generate new state in pDest
           break;   // no more states in the neighbourhood 
       if ( IsSolution(pDest) ) // done
       {
           success = TRUE;
           break;
       }
       e_new = Energy(pDest);
       printf("temp = %lf i = %d e = %lf e_new = %lf\n", t, i, e, e_new); 
       if ( Boltzmann(e, e_new, t) ) // make pDest new current state?
       {    
           CopyState(&amp;s, pDest);
           e = e_new;
       }
       }  // end for
       NextTemp(&amp;t);  // get the next lower temperature
   } // end while          
   CopyState(pDest, &amp;s); // copy last state into pDest
   return(success);
}
BOOL Boltzmann(ENERGY e1, ENERGY e2, TEMP t)
{
   double x;
   if ( e2 &lt; e1 ) return(TRUE);
   x = exp( (-(e2 - e1)) / t );
   if ( x &lt;= 1.0 &amp;&amp; rand() &lt; x ) return(TRUE);
   if ( rand() &lt; (x - floor(x)) ) // x &gt; 1, so check decimal fraction of x
       return(TRUE); 
   return(FALSE);
}
// implement cooling schedule; return the next lower temp
int NextTemp(TEMP *pt)       
{
    TEMP t1 = (*pt);
    (*pt) = t1 * TEMP_FACTOR;
    return(0);
}
// true if given temp &lt; a fixed threshold; stop condition for SA 
BOOL CoolEnough(TEMP t) 
{ 
   if ( t &lt; MIN_TEMP ) return(TRUE);
   return(FALSE);
}
</pre>
<P>
<A HREF="#rl2">Back to Article</A>
</P>
<H4><A NAME="l3"></a>Listing Three</H4>


<pre>/* Module: Simulated Annealing
 * File: simann.h
 * Programmer: Girish Keshav Palshikar
*/
#ifndef SIMANN_H
#define SIMANN_H

typedef double TEMP;
typedef double ENERGY;
typedef enum { FALSE = 0, TRUE = 1 } BOOL;

#define MAX_TEMP           5000.0
#define MIN_TEMP           1.0
#define BOLTZMANN_CONSTANT 1.0
#define TEMP_FACTOR        0.5

#endif

</pre>
<P>
<A HREF="#rl3">Back to Article</A>
</P>


</body>
</html>
