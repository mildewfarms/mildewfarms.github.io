<html><head><title>Jan01: Algorithm Alley</title></head><body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000"><!--Copyright &#169; Dr. Dobb's Journal--><h1>Reservoir Sampling</h1><p><i>Dr. Dobb's Journal</i> January 2001</p><h3>By Paul F. Hultquist  and William R. Mahoney</h3><I>Paul was a consultant to Technical Support Inc. in Omaha, Nebraska. William is the senior vice president of Technical Support Inc., a part-time computer science faculty member at the University of Nebraska at Omaha, and the owner of a car sporting the only "UNIX" license plate in Nebraska. He can be contacted at bill@techsi.com.</I><hr><p>Suppose your boss asks you to find a random sample of, say, 500 records from a file of customer records. Unfortunately, you may not know the length of the file, in terms of the number of records; or if you do, you may have a qualification such as "include only customers who have spent more than $200 with us this year." There is a good method for drawing exactly <i>N </i>samples randomly from a file of known length, but that is not applicable unless you first run through the file and count the exact number of records in the file. This may not be convenient, especially if there is a qualification on the chosen records. Reservoir sampling, originally developed by Alan Waterman, lets you find precisely the right number <i>N </i>of records without any prior knowledge of the number of records in the file (provided that there are enough). Also, the records are chosen with equal a priori probabilities.</p><p>Reservoir sampling involves the establishment of a reservoir of candidate records. The allotted reservoir space must be several times larger than that of the final sample. (Later, we will show how to estimate the reservoir size.) To begin, we copy the first <i>N </i>(eligible, if there is a qualification) records into the reservoir. An array of length <i>N </i>contains pointers to the <i>N </i>records in the reservoir. </p><DDJADVERTISEMENT INLINE><p>The second stage of the process consists of going through the input file, starting with record <i>N</i>+1, and staging a knock-out tournament with records that are "in" the reservoir. By "in" we mean records that have not been knocked out. Going through the file requires a pointer <i>P </i>that is set initially to record <i>N</i>+1 in the file. For the new record, generate a random integer <i>K </i>on the interval 1<img src="lteq12.gif" width="6" height="7" align=middle><i>K</i><img src="lteq12.gif" width="6" height="7" align=middle><i>P</i>. If <i>K</i><img src="lteq12.gif" width="6" height="7" align=middle><i>N,</i> then copy the record at <i>P </i>in the file to the first available space (past <i>N</i>) in the reservoir, and switch the reservoir pointer from the record at <i>K </i>to the new record. Thus, the record at <i>K </i>is no longer in the reservoir &#151; it has been replaced by the new one. Dead records still occupy reservoir storage space, which makes it grow in size. After the replacement, if it occurs, or if <i>K</i>&gt;<i>N</i>, advance the file pointer <i>P</i> to the next record. </p><p>Continue this process until there are no more records in the file. At the beginning of the tournament, many of the first <i>N </i>records will be evicted, but as the file pointer <i>P </i>grows, the probability of a new file record evicting an old one drops. By the time<i> P</i>=2<i>N,</i> the probability of an eviction drops to one half. We can show that the a priori probability of any of the first <i>N </i>records being chosen for the final cut is <i>N/N<sub>T</sub>, </i>where <i>N<sub>T</sub> </i>is the (unknown beforehand) file length.</p><p>Let <i>N </i>be the desired sample size and <i>N<sub>T</sub> </i>be the unknown file size. Choose a pet record from among the initial <i>N </i>records and follow it to the end of the process. The tournament begins when the file pointer <i>P=N</i>+1. The probability that this record is chosen is <i>N</i>/(<i>N</i>+1); and if it is chosen, the probability that it evicts our pet record is 1/<i>N</i>. Thus, the probability that our pet record is evicted at this point is the product of these probabilities, 1/(<i>N</i>+1). The probability that our chosen record survives is 1-1/(<i>N</i>+1)=(<i>N</i>+1-1)/(<i>N</i>+1)= <i>N</i>/(<i>N</i>+1). Now, for record at <i>P=N</i>+2, the probability that it is chosen is <i>N/</i>(<i>N</i>+2), and the probability that it evicts our pet record, if it is chosen, is 1/<i>N</i>; so the probability of our pet record being evicted is 1/(<i>N</i>+2). The probability of survival at this point is 1-1/(<i>N</i>+2)=(<i>N</i>+2-1)/(<i>N</i>+2)= (<i>N</i>+1)/(<i>N</i>+2). The probability of survival for our pet after two new records being added is:</p><blockquote><img src="0101qq1.gif" width="155" height="51" align="middle"></blockquote><p>If we continue this tiresome process, we find that the survival probability for our pet record is:</p><blockquote><img src="0101qq2.gif" width="320" height="55" align="middle"></blockquote><p>What about the survival probabilities for records chosen after the first <i>N</i>? It is easy to see that the last record is chosen with probability <i>N/N<sub>T</sub>. </i>We can see that the record at the next-to-last position in the file is chosen with probability <i>N</i>/(<i>N<sub>T</i></sub>-1), but it must survive being knocked out by the last record. The probability of the last record being chosen and knocking out the next-to-last one is (<i>N/N<sub>T</i></sub>)(1/<i>N</i>)=1/<i>N<sub>T</i></sub>. The probability of that not happening is 1-1/<i>N<sub>T</i></sub>=(<i>N<sub>T</i></sub> -1)/<i>N<sub>T</i></sub>, which means that the probability that the next-to-last record in the file will be chosen and will survive is:</p><blockquote><img src="0101qq3.gif" width="164" height="53" align="middle"></blockquote><p>This not intended as a rigorous proof, but as a demonstration of how the algorithm works.</p><p>How large does the reservoir grow? That depends on the logarithm of the ratio of the file size <i>N<sub>T</i></sub> to <i>N</i>. We know that, first of all, the reservoir is loaded with <i>N</i> records. Following this, the remaining <i>N<sub>T</i></sub>-<i>N</i> records are chosen to occupy reservoir space with decreasing probabilities &#151; starting with <i>N</i>/(<i>N</i>+1) and steadily decreasing to <i>N/N<sub>T</sub>. </i>(Eliminated records still occupy reservoir space.) It is clear that the statistical expectation of the size <i>S </i>of the reservoir can be calculated as:</p><blockquote><img src="0101qq4.gif" width="90" height="84" align="middle"></blockquote><p>The summation can be slightly overestimated by replacing it with an integral:</p><blockquote><img src="0101qq5.gif" width="191" height="65" align="middle"></blockquote><p>Thus the reservoir size estimate is:</p><blockquote><img src="0101qq6.gif" width="135" height="52" align="middle"></blockquote><p><A NAME="rt1"><A HREF="0101qt1.htm">Table 1</A> gives typical values of <i>S/N</i> for values of <i>N<sub>T</sub>/N</i>.</p><p>The values of <i>S/N</i> given, times the value of <i>N</i>, are the expectations of the mean number of records chosen. Users should allow an extra 25 percent or more for the fact that this is a random process. Likewise, it is also necessary to allow for error in the estimates of <i>N<sub>T</i></sub>.</p><p>One other observation: The source file may very well be alphabetized or sorted on some key or parameter, but the reservoir file will not be. That may not matter for some uses, such as gathering statistics; but for other applications, it may be necessary to copy the active records to a new file and then to sort them properly.  </p><p>Finally, the algorithm as shown will work for gruesome applications such as those involving multiple input files (tapes, multiple disks, and so on). Copying the records to a reservoir in fast memory simplifies the selection and output parts of the process. However, for small files that can be contained in central memory, the reservoir can be replaced by an array of pointers to records in the active reservoir with no copying necessary until output.</p><p><A NAME="rl1"><A HREF="#l1">Listing One</A> demonstrates the reservoir sampling of a large file of records (an executable version is available electronically; see "Resource Center," page 5). In this example, the file is really just an array, and the records are simple integers. The simulated file on disk is handled by the array <i>big_file. </i>It consists of a set of integers selected at random from the range 1..100. The file ranges from 0..BIG_FILE_ SIZE-1. There are several arrays that are allocated dynamically; no error checking is done on these. In a real application, you would want to take care of that. Also, <A NAME="rl1"><A HREF="#l1">Listing One</A> includes some shortcuts that are relevant because we are dealing with integer records. In a real program, these would contain more than just an <i>int</i>, so the shortcuts are omitted.</p><h3>In Passing</h3><p>Sadly, we learned Paul Hultquist passed away just prior to publication of his article. We'd like to extend our heartfelt condolences to his family, friends, and coworkers.</p><p> &#151; The editors</p><p><b>DDJ</b></p><H4><A NAME="l1">Listing One</H4><pre>/* ===========================================================================Demonstration of reservoir sampling.Author:  Bill Mahoney=========================================================================== */#include &lt;iostream.h&gt;#include &lt;time.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;#define  BIG_FILE_SIZE 967  /* Any old number will do */void reservoir_sample( int *big_file, int *sample, int N );int main(){    int *sample, N, i;    int big_file[ BIG_FILE_SIZE ];    srand( (unsigned int) time( (time_t *) NULL ) );    for( i = 0; i &lt; BIG_FILE_SIZE; i++ )        /* We could put in random numbers, or put in numbers that are the */         /* same as the record number. This'll make it simpler for us to   */        /* see which records are in fact selected.                        */#if 0        big_file[ i ] = rand() % 1000;#else        big_file[ i ] = i;#endif    /* For simplicity, assume the user enters a valid number. */    cout &lt;&lt; "How many elements would you like to retrieve? ";    cin &gt;&gt; N;    cout &lt;&lt; "Selecting " &lt;&lt; N &lt;&lt; " elements...";    sample = new int[ N ];    reservoir_sample( big_file, sample, N );    for( i = 0; i &lt; N; i++ )        cout &lt;&lt; sample[ i ] &lt;&lt; ( ( ( i + 1 ) % 5 == 0 ) ? "" : " " );    cout &lt;&lt; "Done!";    delete [] sample;    return( 0 );} /* ===========================================================================reservoir_sampleHere we do the actual guts. Select the first N records from the front of the "file", then selectively knock out candidates and replace them with new ones.Obviously, since we have just an array of int's there is no need for the temporary reservour array at all. We could just keep the index into the array "file" instead of an index into "res", the reservoir. Likewise, we could omit"active" and just use "sample" to hold indices into the array. In an actual application, though, you would need to allocate the reservoir and fill it fromthe disk file; thus the use of the dynamic array "res" - to illustrate this. Same thing with "active". An alternative in a real world application would be to have "res" maintain the file position (i.e. ftell() it) of record on disk.=========================================================================== */void reservoir_sample( int *file, int *sample, int N ){    int end_res, file_record, *res, res_size, *active, i;    /* Here we create a reservoir with sufficient space.  */    /* See the formula in the article for an explanation. */    res_size = (int) ( 1.25 * (double) N *                ( 1.0 + log( (double) BIG_FILE_SIZE / (double) N ) ) );    cout &lt;&lt; "Creating a temporary storage area of " &lt;&lt; res_size &lt;&lt; " elements.";    res = new int[ res_size ];    active = new int[ N ];    /* First off, copy the first N records into the reservoir. */    for( i = 0; i &lt; N; i++ )    {        res[ i ] = file[ i ];        active[ i ] = i;    }     /* end_res is the # of elements in the reservoir, */    /* file_record is the next record in the "file".  */    end_res = file_record = N;    while ( file_record &lt; BIG_FILE_SIZE )    {        /* Position is 0..file_record-1 */        int position = rand() % file_record;        if ( position &lt; N )        {            /* Copy the record into the reservoir */            res[ end_res ] = file[ file_record ];            /* Save the index to this record.     */            active[ position ] = end_res;            end_res++;            if ( end_res &gt;= res_size )               cerr &lt;&lt; "Out of space in the reservoir!";               /* Do some kind of error recovery here. */        }         file_record++;    }     /* Give the caller the desired records. */    for( i = 0; i &lt; N; i++ )        sample[ i ] = res[ active[ i ] ];    delete[] res;    delete [] active;} </pre><P><A HREF="#rl1">Back to Article</A></P></body></html>