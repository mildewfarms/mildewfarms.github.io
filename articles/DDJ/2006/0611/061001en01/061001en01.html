<html>
<head>
<title></title>
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/Layout.css" type="text/css">
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/FontStyles.css" type="text/css">
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/newarticle.css" type="text/css">
<script src="../../../../forms/popwindow.js"></script>
</head>

<body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000">
<!--Copyright &#169; Dr. Dobb's Journal-->
<p><i>Dr. Dobb's Journal</i> November 2006</p>

<h1>Error Checking</h1>
<h2></h2>

<h3>by Ed Nisley</h3>

<I>Ed is an EE, an inactive PE, and author in Poughkeepsie, NY. Contact him at ed .nisley@ieee.org with "Dr Dobbs" in the subject to avoid spam filters.</I>

<hr>




<p>NASA develops robotic spacecraft that perform complex tasks in literally otherworldly conditions, producing hardware and software so dependable that only rare mistakes make headlines. As you saw last month, though, those headlines can arise from simple errors, ones you might make yourself, that somehow slip through verification and testing procedures far more rigorous than anything your projects will ever encounter.</p>

<p>This month I take a closer look at how errors evade detection and give you the opportunity to play code reviewer. Even if your blunders are neither so costly nor public, what you see here may look disturbingly familiar.</p>

<p>As before, direct quotes from the NASA reports are in <i>italics</i>.</p>


<h3>Do What We Mean</h3>

<p>After the Mars Polar Lander (MPL) vanished, the NASA review board identified several potential mission-killer hardware and software errors, of which premature descent engine shutdown was deemed the most likely. Their review isolated that failure to one routine, then determined how it got there.</p>

<p>Each of MPL's three landing pads has a ground-contact probe attached to a Hall-Effect switch. Unlike science-fiction spacecraft, all three pads don't touch down simultaneously, so engine shutdown occurs when the first probe contacts the surface. If that sensor fails, the signal from the second probe triggers the shutdown.</p>

<p><i>It is important to get the engine thrust terminated within 50 milliseconds after touchdown to avoid overturning the lander. </i>The high-level requirements specified a 100-Hz sample rate, automatic rejection of a stuck-on sensor, and two successive "touchdown" readings from any single sensor to signal a valid landing. In addition, <i>the use of the touchdown sensor data shall not begin until 12 [later changed to 40] meters above the surface [...] to protect against premature descent engine thrust termination in the event of failed sensors and possible transients.</i></p>

<p>With those requirements in mind, test your code-debugging skills with the Pythonesque pseudocode I created from flowcharts in the MPL report describing how each of the three sensors work. Example 1(a) tells the monitoring code in Example 2 to begin sampling the contact sensor inputs. Unlike some real-time systems, Example 2 gets called every 10 ms regardless of whether it's enabled or not; this satisfies another requirement to not add sudden CPU loads at critical times.</p>


<div>

<pre class="code">
<b>(a)</b>
def TouchdownMonitorStart() :
 IndicatorHealth = TRUE
 IndicatorState = FALSE
 EventEnabled = FALSE
 TouchdownMonitor = TRUE
 return

<b>(b)</b> 
def TouchdownMonitorEnable() :
 if TouchdownMonitor :
  if LastTouchdownIndicator and CurrentTouchdownIndicator :
   IndicatorHealth = FALSE
  EventEnabled = TRUE
 return
</pre>

<div class="caption">
Example 1: (a) This routine starts the touchdown monitor code, which then samples the input sensors every 10 ms. (b) After this routine returns, the touchdown code is fully activated and can shut off the descent engines.
</div>
</div>




<div>

<pre class="code">
Def TouchdownMonitorExecute() :
 if TouchdownMonitor :
  LastTouchdownIndicator = CurrentTouchdownIndicator
  CurrentIO = ReadIOSensors()
  if IOError() and not EventEnabled :
   CurrentTouchdownIndicator = FALSE
  else:
   CurrentTouchdownIndicator = CurrentIO
  if LastTouchdownIndicator and CurrentTouchdownIndicator :
   IndicatorState = TRUE
  if IndicatorState and IndicatorHealth and EventEnabled :
   DisableThrusters()
   TouchdownMonitor = FALSE
   EventEnabled = FALSE
  return
</pre>

<div class="caption">
Example 2: Does this routine meet its specifications? Does it do so under all conditions?
</div>
</div>


<p>By the way, if global variables give you the heebie-jeebies, you're just not cut out for this line of work.</p>

<p>The Entry, Descent, and Landing (EDL) control program calls the code in Example 1(b) at 40 meters to activate the touchdown monitor by setting <i>EventEnabled</i>. If the sensor has failed stuck-on, it will always read as active and <i>IndicatorHealth</i> will be cleared. There's no check for a stuck-off failure, which will be handled by simply waiting for the next probe to touch the surface.</p>

<p>Example 2 implements a straightforward two-in-a-row filter that ignores spurious single-sample events. When two successive samples indicate touchdown, the code shuts off the descent engines and disables further testing.</p>

<p>Now, for an eighth of a billion dollars, answer this simple question: Will it work? If not, why not and how would you fix it?</p>

<p>Here's a hint. The legs deploy when the lander is a kilometer or two above the surface, well before the EDL code calls <i>TouchdownMonitorEnable()</i> at 40 meters. However, the <i>Start()</i> routine has already set <i>TouchDownMonitor</i> and the <i>Execute()</i> routine has begun sampling the sensors, testing for two successive TRUE inputs from each contact switch.</p>

<p>Examine that code again: Well over 100 Ultra-Large rests on your analytic prowess!</p>

<p>Need another hint? <i>[A] 2001 lander was used for two leg deployment tests ... . The first test resulted in transient times of 12, 26.5, and 7.3 milliseconds ... . The second test resulted in transient times of 16, 12, and 25 milliseconds ...</i> .</p>

<p>Any transient longer than 10 ms after the code begins sampling can cause two successive "valid" samples, at which point <i>Execute()</i> sets <i>IndicatorState</i>. That variable is never turned off, so as soon as the EDL code calls <i>Enable()</i>, the engines shut off.</p>

<p>It took me a protracted pencil-and-paper session to verify the report's conclusions and reject a few false assumptions, but, yup, that's exactly how it works.</p>

<p>The Board found that <i>[t]he touchdown sensing software was not tested with the lander in the flight configuration. Because of this, the software error was not discovered during the verification and validation programs.</i> The initial requirement to ignore sensor transients somehow didn't make it into the software specification used to design the code. The programmers, who weren't aware that switches often produce glitches, simply didn't take that failure mode into account. The system testers, lacking that key spec, did not feel an all-up test would be worth the not-inconsiderable effort and risk.</p>

<p><i>The lack of telemetry during EDL made it impossible to determine if the landing leg deployment transients set the touchdown state to True during the leg deployment.</i></p>

<p>The Board recommended some additional checks-and-balances to prevent a replay of the MPL error. Another incident shows how such procedures play out in real life.</p>






<h3>For Lack of a Bolt</h3>

<p>NASA orbited the first Television Infra-Red Observation Satellite (TIROS) in 1960, followed by increasingly complex satellites through the NOAA-KLM series jointly controlled by the National Oceanic and Atmospheric Administration. The current satellites have a minimum two-year lifetime, which requires a fairly steady stream of replacement birds that, it seems, is a difficult pace to maintain.</p>

<p>Two satellites in the same polar orbit observe each point on the earth every 12 hours, so they're built in pairs. The project manager for the new NOAA-N and N' (also N-Prime) satellite pair convened a risk-management meeting by asking attendees to brainstorm possible failure modes and create procedures to prevent those mishaps. He explicitly ruled out things that simply can't happen, such as dropping a satellite on the floor. The 6 September 2003 phone call describing the situation in Figure 1 came as a nasty surprise.</p>



<div>
    
<div class="smallcap">&#91;Click image to view at full size&#93;</div>
<img class="illowide" src="061001en01_f1.jpg" onclick = "popimage(this,'www.ddj.com - Error Checking - Figure 1')">

<div class="caption">
Figure 1: The NOAA N-Prime satellite slipped off its turnover cart because 24 bolts that should have connected the adapter ring to the cart were missing. Photo from the NASA N-Prime Report. Courtesy of NASA.
</div>
</div>


<p>During much of its assembly, a satellite stands vertically on its base atop a handling cart, but some operations require other alignments. The satellite's structure has enough rigidity to support it horizontally from its base, which terminates in the flight adapter that joins the satellite to its booster and serves as a robust mechanical connection during construction and handling.</p>

<p>The white turnover cart (TOC) in Figure 1 includes a hinged plate that supports the satellite, with a bearing that rotates the satellite around its long axis. Actuators pivot the plate between vertical and horizontal positions. Because Lockheed-Martin Space Systems Company (LMSSC) also builds the Defense Meteorological Satellite Program (DMSP) satellites, which are similar to the NOAA N-series birds, in the same building, the two projects share a common set of TOCs. Even though the satellites both ride Titan-II boosters into orbit, they have different flight adapters and thus require different adapters between their bases and the TOC.</p>


<p>You can feel it coming, can't you?</p>

<p><i>The DMSP Program decided to use this TOC for its activities ... . The reconfiguration was interrupted part way through the process of the TIROS adapter ring removal, in order to install the DMSP adapter ... . This change in plan left the TIROS adapter ring sitting on the TIROS TOC with its 24 attachment bolts removed.</i></p>

<p>The TOC already had a "red tag" due to a damaged floor jack. The Board discovered that <i>[n]o red tag nor any other indication was added to the TIROS TOC to indicate the incomplete configuration. None of this was communicated to the TIROS folks ... , because the over-riding philosophy was that each user was required to verify or ensure the [Ground Support Equipment] configuration was appropriate for its own specific use each time it was used.</i></p>

<p>The TIROS crew repaired the jack, hoisted the satellite with an overhead crane, lowered it on the TOC adapter, then installed and torqued 44 bolts between the satellite's flight adapter and the TOC adapter. <i>During the operation, the Technician Supervisor commented that there were empty bolt holes, a conversation that was overheard by several of the technicians. The team and the RTE [Responsible Test Engineer] in particular dismissed the comment and did not pursue the issue further.</i></p>

<p>A total of 88 bolts secure the satellite's flight adapter to the booster, but because ground handling imposes far less stress than launching, standard practice calls for installing only half the bolts. That left 44 "normally empty" holes in the same area as the 24 missing bolts, obscuring the problem while simplifying the procedure: <i>...members of the crew recognized that, "This was the smoothest this operation has ever gone."</i> </p>

<p>With N-Prime standing atop the TOC, the crew activated the pivot motors and, when the TOC plate reached an angle of 13 degrees, the satellite simply slid off the plate and punched a neat crescent dent in the TOC on its way to the floor. Nobody got hurt, but it could have been much, much worse, as <i>the Nickel-Cadmium batteries were fully charged, the propulsion system was pressurized, and the separation band was tensioned.</i></p>

<p>As you might expect, the Board found <i>[t]here were missed opportunities that could have averted this mishap.</i></p>







<h3>Checks and Balances</h3>

<p>The MPL Report includes several project-level recommendations that seem applicable to nearly any software project.</p>

<p><i>R1) For highly cost- and schedule-constrained projects, it is mandatory that sufficient systems engineering and technical expertise and the use of the institution's processes and infrastructure be applied early in the formulation phase to ensure sound decision making in baseline design selection and risk identification.</i></p>

<p>In other words, when you're expected to work smarter, you must actually think about the project, preferably before you begin. Ignoring potential problems is not a strategy.</p>

<p><i>R2) Do not permit important activities to be implemented by a single individual without appropriate peer interaction; peers working together are the first and best line of defense against errors. Require adequate engineering staffing to ensure that no one individual is single string; that is, make sure that projects are staffed in such a way as to provide appropriate checks and balances.</i></p>

<p>We've found that bouncing your coding ideas off somebody else really is the <i>first and best line of defense against errors</i>. That person must, of course, be competent to recognize errors and omissions, which was part of the problem in both of these mishaps.</p>

<p>While testing cannot ensure the absence of errors, it can demonstrate that the project meets specifications and, with any luck, also show that the specifications don't have any glaring omissions. The tests must match up with reality, rather than with an idealized model: <i>end-to-end validation...through simulation and other analyses was potentially compromised in some areas when the tests employed to develop or validate the constituent models were not of an adequate fidelity level to ensure system robustness.</i></p>

<p>Reading these NASA mishap reports makes perfectly clear the suffocating number of reviews, cross-checks, verifications, and sign-offs required to get anything done. Many of the recommendations boil down to "be more careful" and "check more often," but it seems that, beyond a certain point, humans simply cannot and will not do more checking.</p>

<p>The N-Prime mishap clearly reveals that limiting point. The Report does not include the checklist itself, but the missing steps give some indication of how an intricate procedure can go wrong in real life.</p>

<p><i>L-1) The RTE decided to "assure" the cart configuration through an examination of paperwork from a prior operation rather than through physical and visual verification. The RTE made a second decision error in dismissing a comment by the Technician Supervisor concerning empty bolt holes.</i></p>

<p>L-2) The technicians, with the exception [of the] Technician Supervisor noted above, failed to notice the missing bolts, even though they were working within inches of where the bolts were supposed to be.</p>

<p>L-3a) The PQC [Product Quality Control] and the PA [Product Assurance] signed-off on "assure the configuration" of the TOC procedure step without personally validating the TOC configuration or, in the case of the PA, even being present at the time this step of the procedures was completed during the operation.</p>

<p>L-3b) The safety representative was not present as called for in the procedure. Again, this investigation determines that such a violation is routine.</p>

<p>These elements described above led the MIB to conclude that decision and skill-based errors and routine violations by the NOAA N-PRIME I&amp;T [Integration and Test] team were manifested as a failure to adhere to procedures.</p>







<h3>Last Tab</h3>

<p>Space missions, unlike software projects, can't use iterative design. You simply don't release an incomplete Version 0.1, get user feedback, tweak the design, release Version 0.2, and continue iterating until the code works well enough. Instead, you spend a few hundred million dollars over a decade or so, and get exactly one attempt. Should you overlook something, you must start all over.</p>

<p>Complacency at any point can kill such a project and, I think, accounts for much of ordinary software's error rate. If we all did what we know we should, most of the errors simply wouldn't happen. Be honest: Have you actually analyzed all the possible failure modes for that fancy SOA project?</p>

<p>A simple fault tree for your current project will prove an enlightening activity, if only when it shows how much code you cannot control. Even better, it might reveal ways to improve your own error handling and prevent hostile intrusions.</p>

<p>The more procedures you put in place to prevent errors, however, the more opportunity you'll have to simply ignore those rules in order to get the job done. Has anyone ever factored that into a management decision?</p>

<p>Slides from a NASA Safety Directors Meeting are at <a href="http://ohp.ksc.nasa.gov/conference_info/2006/shconf/pdf/02-01-2006_ChandlerFaith_web.pdf">http://ohp.ksc.nasa.gov/ conference_info/2006/shconf/pdf/02-01-2006_ChandlerFaith_web.pdf</a>. The Mars Polar Lander report is at <a href="http://www.jpl.nasa.gov/marsreports/mpl_report.pdf">www.jpl.nasa.gov/ marsreports/mpl_report.pdf</a> and the N-Prime MIB Report is at <a href="http://www.nasa.gov/pdf/65776main_noaa_np_mishap.pdf">www.nasa.gov/pdf/ 65776main_noaa_np_mishap.pdf</a>.</p>

<p>More on NOAA satellites at <a href="http://noaasis.noaa.gov/NOAASIS/ml/genlsatl.html">http:// noaasis.noaa.gov/NOAASIS/ml/genlsatl .html</a>, with a satellite user guide (!) at <a href="http://www2.ncdc.noaa.gov/docs/klm/index.htm">www2.ncdc.noaa.gov/docs/klm/index.htm</a>.</p>

<p>No combination of keywords turns up the NASA newsletter containing the N-Prime director's summary of the risk-assessment meeting and that fateful phone call, but it's out there somewhere. Memo to self: Always save the links.</p>



</body>
</html>