<html><head><title>February, 2006: Examining &micro;C++</title></head><body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000"><!--Copyright &#169; Dr. Dobb's Journal--><p><i>Dr. Dobb's Journal</i>, February 2006</p><h1>Examining &micro;C++</h1><h2>High-level  object-oriented concurrency for C++</h2><h3>By Peter A. Buhr and  Richard C. Bilson</h3><I>Peter is an associate professor in the School of Computer Science at the University of Waterloo. He can be contacted at pabuhr@uwaterloo.ca. Richard is a research assistant in the School of Computer Science at the University of Waterloo, working in the Programming Languages Group. He can be contacted at rcbilson@ plg.uwaterloo.ca.</I><hr><p>Concurrency is the most complex form of programming, with certain kinds of real-time programming being the most complex forms of concurrency. Often the mechanisms for writing concurrent programs only exacerbate the complexity because they are too low level and/or independent from the language. Currently, concurrency is being thrust upon all programmers indirectly through the push for higher performance in hardware. To maintain Moore's Law, it is becoming necessary to add parallelism at a number of hardware levels&#151;instruction pipeline, multithreading, multicore processors, shared-memory multiprocessors, and distributed clusters. Some successful attempts have been made to implicitly discover concurrency in a sequential program; for instance, by parallelizing loops and access to data structures. While this approach is appealing because of the simple sequential programming model and ability to parallelize legacy code, there is a limit to how much parallelism can be found, and current techniques only work on certain kinds of programs. Therefore, explicit concurrent mechanisms are necessary to achieve maximum concurrency potential. Luckily, approaches to this are complementary, and can appear together in a single programming language.</p><h3>C++ Concurrency</h3><p>Given the need for explicit concurrency, modern programming languages such as Beta, Ada, Modula-3, Java, and C#, among others, provide some direct support for concurrency. Surprisingly, however, C++ has no concurrency support. During C++'s 20-year history, many different concurrency approaches for C++ have been suggested and implemented with only varying degrees of adoption. As a result, there is no de facto standard dominating concurrent programming in C++. (In C, there are two dominant, but incompatible, concurrency libraries&#151;Win32 and pthreads.) In this article, we argue that C++'s lack of concurrency is significantly limiting the language's future. This deficiency has also been recognized by the C++ Standards committee, which is currently examining concurrency extensions. We also outline how high-level object-oriented concurrency can be added to C++ through a freely available concurrent dialect of C++ called "&micro;C++" (http://plg.uwaterloo.ca/ usystem/uC++.html).</p><h3>Concurrent Design Principles</h3><p>There are a number of major design principles for adding concurrency to object-oriented languages, such as: </p><ul>  <li>Object-oriented design is built on the notion of the class. Hence, concurrency should be built on the class notion, allowing it to leverage other class-based language features.</li>  <li>All concurrent systems must provide three fundamental properties: <i>thread</i>, a mechanism to sequentially execute statements, independently of (and possibly concurrently with) other threads; <i>execution context</i>, the state needed to permit independent execution, including a separate stack; and <i>mutual exclusion/synchronization </i>(<i>MES</i>), mechanisms to exclusively access a resource and provide necessary timing relationships among threads. These properties cannot be expressed in an architecture-independent way through existing language constructs. (Even algorithms for MES, such as Dekker's algorithm, do not always work without a sufficient memory model.) Therefore, any concurrency system must provide abstractions to implement these properties.</li>  <li>Because MES causes the most errors for programmers and the greatest difficulty for safe code optimizations, it should be implicit through concurrent language constructs.</li>  <li>If the routine call is the basis for normal object communication, it should also be used for concurrency. Mixing mechanisms, such as routine call with message-passing/channels, is confusing and error prone, and may lose important capabilities such as static type checking.</li></ul><p>Joining the fundamental concurrency properties with the class model is best done by associating thread and execution-context with the class, and MES with member routines. This coupling and the interactions among the concurrency properties generate the programming abstractions in <a name="rt1"></a><a href="0602dt1.html">Table 1</a>.</p><ul>  <li>Case 1 in <a name="rt1"></a><a href="0602dt1.html">Table 1</a> is a standard C++ object. Its member routines do not provide MES, and the caller's thread and stack are used to perform execution. </li>  <li>Case 2 has all the properties of case 1 but only one thread at a time can be executing among the member routines with the MES property, called a "mutex member." Within a mutex member, synchronization with other tasks can be performed. This abstraction is a monitor, which is well understood and appears in many concurrent languages (Java, for instance). </li>  <li>Case 3 is an object that has its own execution context but no MES or thread; the execution context is associated with a distinguished member in the object. This abstraction is a coroutine, which goes back to the roots of C++ in Simula. </li>  <li>Case 4 is like case 3 but deals with concurrent access by adding MES. This abstraction is a coroutine monitor. </li>  <li>Cases 5 and 6 are a thread without a stack, which is meaningless because a thread must have a stack to execute. </li>  <li>Case 7 is an object that has its own thread and execution context but no MES. This case is questionable because explicit locking is now required to handle calls from other threads, which violates design principle 3. </li>  <li>Case 8 is like case 7 but deals with concurrent access by adding MES. This abstraction is a task, which is an active object and appears in many concurrent languages (Ada). Note, the abstractions are derived from fundamental properties and not ad hoc decisions by a language designer, and each has a particular set of problems it can solve well. Simulating one abstraction with the others often results in awkward solutions that are inefficient; therefore, each has a place in a programming language.</li></ul><h3>&micro;C++: Concurrency in C++</h3><p>&micro;C++ was designed using these concurrency design principles and engineered to provide high-level, integrated, lightweight, object-oriented concurrency for C++. By being high level, you can code in a race-free style, which eliminates the need for a complex memory model. By being integrated into the C++ language, the compiler can understand precisely when it can safely perform optimizations. Currently, &micro;C++ is a translator that converts to C++, but its design ultimately assumes it is part of C++.</p><p><a name="rf1"></a><a href="0602df1.html">Figure 1</a> shows the syntax for adding the programming abstractions in <a name="rt1"></a><a href="0602dt1.html">Table 1</a> to C++. There are two new type constructors <i>_Coroutine</i> and <i>_Task</i>, extensions of <i>class</i>, implicitly associating the execution context and thread properties to objects. There are two new type qualifiers, <i>_Mutex</i> and <i>_Nomutex</i>, for qualifying member routines needing the mutual exclusion property and which contain synchronization. There are implicitly inherited members providing context-switch/synchronization, <i>suspend()</i>, <i>resume()</i>, <i>wait()</i>, <i>signal()</i>, <i>signalBlock()</i>, and one new statement&#151;<i>_Accept</i>. Each of these new constructs is explained through examples.</p><h3>Coroutine</h3><p>A coroutine is not a concurrent abstraction, but it appears directly from the combination of fundamental concurrency properties and supports direct implementation of finite-state machines (FSM). In &micro;C++, the execution context (stack) for a coroutine object is associated with its distinguished member <i>main</i>; see <a name="rl1"></a><a href="#l1">Listing One</a>.</p><p>A coroutine type implicitly inherits member routines <i>resume</i> and <i>suspend</i>, which provide control flow among coroutines. Like a class, a coroutine's public members define its interface but also provide the interaction with the coroutine's <i>main</i>; multiple public member routines allow complex, type-safe communication. The <i>resume</i> routine is called from the public members and the <i>suspend</i> routine is called directly or indirectly from the coroutine's <i>main</i>. The first call to <i>resume</i> starts <i>main</i>, which executes on its own stack. Subsequent <i>resume</i>s restart at the last <i>suspend</i> from <i>main</i>. Routine <i>suspend</i> restarts the last <i>resume</i> executed by a public member. A coroutine object becomes a coroutine when <i>main</i> starts (first <i>resume</i>); the coroutine becomes an object again when <i>main</i> ends.</p><p><a name="rl2"></a><a href="#l2">Listing Two</a> is a simple FSM for recognizing phone numbers of the form: (555)<i>opt</i> 123-4567. Characters of the phone number are passed one at a time to the next member, which returns the current status of the parse. Note how the coroutine <i>main</i> retains its execution location and restarts there when it is resumed; for example, when parsing groups of digits, the coroutine suspends in the middle of a <i>for</i> loop and restarts within the particular loop when resumed. The killer application for a coroutine is device drivers, which cause 70-85 percent of failures in Windows/Linux. Many device drivers are FSMs parsing a protocol; for instance:</p><blockquote> ...STX...message...ESC ETX...message...			          ETX 2-byte crc...<br></blockquote><p>Here, a network message begins with the control character <i>STX</i> and ends with an <i>ETX</i>, followed by a 2-byte cyclic redundancy check. Control characters can appear in the message if preceded by an <i>ESC</i>. An Ethernet driver is just a complex version of this simple protocol, and the FSM for the Ethernet protocol can be directly coded as a coroutine. Because FSMs can be complex and occur frequently in important domains, direct support of the coroutine is crucial, independent of concurrency.</p><h3>Monitor</h3><p>A monitor is a concurrency abstraction that encapsulates a shared resource with implicit mutual exclusion and provides for complex synchronization among tasks using the resource; see <a name="rl3"></a><a href="#l3">Listing Three</a>.</p><p>Any member routine can be qualified with the MES qualifiers, <i>_Mutex/_Nomutex</i>, indicating the presence or absence of MES, respectively. Only one thread at a time can be executing among the mutex routines of a monitor object; other threads calling mutex routines of the same object implicitly block. Recursive entry is allowed for the thread currently using the monitor; that is, it may call other mutex members. The MES qualifiers can also qualify a class, which defines the default qualification for the public member routines. Hence, the presence of a single mutex member in a class makes it a monitor. Member variables cannot be MES qualified. The destructor of a monitor is always <i>_Mutex</i>, because the thread terminating a monitor object must wait if another thread is executing in it.</p><p>The mutex property ensures exclusive access to the monitor's data by multiple threads. For simple cases, such as an atomic counter, exclusive access is sufficient and the order of access is unimportant. For complex cases, the order of access can be crucial for correctness; for example, one task may need to communicate information to another task and wait for a reply, or a resource may have strict ordering rules with respect to thread usage. Ordering is controlled by threads synchronizing among themselves within a monitor using condition variables and operations <i>wait()</i>, <i>signal()</i>, <i>signalBlock()</i>, or an <i>_Accept</i> statement on mutex members.</p><p>A condition variable is a place where a task within the monitor can wait for an event to occur by another task using the monitor. <a name="rf2"></a><a href="0602df2.html">Figure 2</a>(a) illustrates the internal parts of a monitor object for synchronization with condition variables. Calling threads wait until no mutex member is active. A condition variable (for example, <i>c</i>) is a queue of waiting threads. The thread active in the monitor object waits on queue <i>c</i> by executing <i>c.wait()</i> (dotted line), which either implicitly restarts the last signalled thread, or if no signalled threads, releases the monitor lock so a new thread may enter. The active thread may execute <i>c.signal()</i> (dashed line) to restart a waiting thread at the front of a condition queue; the signalled thread can only restart after the signaler thread blocks or exits due to the mutual exclusion property, which is accomplished by having the signalled thread wait temporarily on the hidden urgent condition. Alternatively, the active thread may execute <i>c.signalBlock() </i>(solid line), which makes the active thread wait on the urgent queue and immediately starts the signalled thread at the front of the queue. Using these mechanisms, order of access within the monitor can be precisely controlled.</p><p>Tasks within the monitor can wait for an event to occur by a calling task using an accept statement. <a name="rf2"></a><a href="0602df2.html">Figure 2</a>(b) illustrates the internal parts of a monitor object for synchronization with an <i>_Accept</i> statement. <i>_Accept</i> selects which mutex member call to execute next (like Ada's <i>select</i>). <i>_Accept(m1)</i> unblocks the thread on the front of the mutex queue after the accepter is implicitly blocked (like <i>signalBlock</i>). If there is no calling task, the accepter waits (on the hidden urgent queue) until a call to the specified member occurs. When the member call ends, the accepter implicitly restarts after the <i>_Accept</i> statement. <i>_Accept</i> can appear at any level of routine nesting in the monitor. The <i>_Accept</i> statement can check multiple mutex members for calls:</p><blockquote>_Accept( m1, m2,...);<br></blockquote><p>The call on the first nonempty mutex queue is selected (so the order of member names is important); if no calls are pending, the accepter waits until a call occurs. Finally, each selected member can be separated and supplied with a guard:</p><blockquote>_When( conditional-expression ) <br>       _Accept( m1 ) statement<br>else _When( conditional-expression ) <br>       _Accept( m2 ) statement<br> ...<br>else <br>      statement<br></blockquote><p>The guard must be true before a mutex queue is considered; if there is a terminating <i>else</i>, the accepter does not block, rather it polls for callers. The statement after an <i>_Accept</i> is executed by the accepter after the mutex call, allowing it to perform different actions depending on which call occurred. </p><h3>Monitor Examples</h3><p><a name="rl4"></a><a href="#l4">Listing Four</a>(a) shows the classic dating- service problem implemented with condition variables, where two kinds of tasks exchange information based on some criteria. In this case, there are <i>girl</i> and <i>boy</i> tasks exchanging phone numbers if they have matching compatibility codes (values 0-19). A <i>girl</i> task checks if a <i>boy</i> with the same code is waiting. If not, she waits; otherwise, she copies her phone number to the shared variable <i>GirlPhoneNo</i>, and does a <i>signalBlock</i> to immediately restart the waiting <i>boy</i> while she waits on the urgent queue. The waiting <i>boy</i> restarts, copies his phone number to the shared variable <i>BoyPhoneNo</i>, and returns with the<i> girl</i>'s phone number. The waiting <i>girl</i> is then implicitly restarted from the urgent queue after the <i>boy</i> returns, and she now returns with the <i>boy</i>'s phone number. <a name="rl4"></a><a href="#l4">Listing Four</a>(b) shows the classic read/write problem implemented with <i>_Accept</i>, where multiple <i>reader</i> tasks can simultaneously read a resource, but <i>writer</i> tasks must be serialized to write the resource. Tasks access the resource like this:</p><blockquote>ReadersWriter rw;<br>  reader task                 writer task<br>rw.StartRead();           rw.StartWrite();<br>// read resource         // write resource<br>rw.EndRead();           rw.EndWrite();<br></blockquote><p>The variables <i>rcnt</i> and <i>wcnt</i> count the number of simultaneous <i>reader</i> or <i>writer</i> tasks using the resource. <i>EndRead/EndWrite</i> decrement the appropriate counter when a task finishes using the resource. <i>StartRead</i> checks if a <i>writer</i> is using the resource, and if so, accepts <i>EndWrite</i>, causing the <i>reader</i> task to wait on the urgent queue and preventing calls to any other mutex member. When the current <i>writer</i> finishes writing, it calls <i>EndWrite</i>; then the waiting <i>reader</i> implicitly restarts in <i>StartRead</i> and increments <i>rcnt</i>. <i>StartWrite</i> begins with the same check for a <i>writer</i> and the same actions as for a <i>reader</i> if a <i>writer</i> is using the resource. Alternatively, if there are <i>rcnt</i> <i>reader</i>s using the resource, the <i>writer</i> loops and performs <i>rcnt</i> <i>accept</i>s of <i>EndRead</i>, one for each of the completing <i>reader</i> tasks. After the last <i>reader</i> finishes reading and completes its call to <i>EndRead</i>, the waiting <i>writer</i> implicitly restarts and increments <i>wcnt</i>. Because the <i>accept</i> statement strictly controls entry into the monitor, new (calling) tasks may not enter out of order.</p><h3>Coroutine Monitor</h3><p>The properties of a coroutine and monitor can be combined to generate a concurrency abstraction for resource sharing and synchronization along with retaining data and execution state; see <a name="rl5"></a><a href="#l5">Listing Five</a>.</p><p>A coroutine monitor is ideal for an FSM used by multiple threads, such as a shared formatter printer. The printer is the shared resource called by multiple threads to print each thread's data, and the printer can be a complex FSM organizing the data into rows and columns with appropriate markings and headings. Combining these fundamental properties into a single construct simplifies the job of developing the solution for a complex problem.</p><h3>Task</h3><p>The properties of a coroutine monitor can be combined with a thread to generate a concurrency abstraction for an active object that dynamically manages a resource; see <a name="rl6"></a><a href="#l6">Listing Six</a>, for example.</p><p>Active objects appear in many concurrent languages. The use of both wait/signal on condition variables and accepting mutex members occurs frequently in a task (less so in a monitor). Finally, because the destructor is a mutex member, it can be accepted to determine when to terminate a task or monitor. </p><p><a name="rl7"></a><a href="#l7">Listing Seven</a>(a) shows a basic worker task, <i>Adder</i>, generating the subtotals for each row of a global matrix by summing the elements of a particular row. (Global variables are used to simplify the example.) In &micro;C++, the member routine <i>uMain::main</i> serves as the program's <i>main</i> (starting) routine. This routine reads the matrix and starts a block that creates an array of <i>Adder</i> tasks, one for each row of the matrix. Each task's <i>main</i> starts implicitly after its constructor completes&#151;no explicit start is needed. Similarly, no explicit join is needed because the block containing the array of tasks cannot end until all the tasks in the array terminate, otherwise, the storage for the tasks could be deallocated while threads are executing. After all tasks in the block terminate, the block allocating the array of tasks ends, and the subtotals generated by each worker task can be safely summed to obtain the total. The constructor for each <i>Adder</i> task selects a specific row to sum by incrementing a shared variable; no mutual exclusion is necessary for the selection as each task of the array is created serially. The <i>main</i> member of each <i>Adder</i> task adds the matrix elements for its particular row in its corresponding subtotal location.</p><p><a name="rl7"></a><a href="#l7">Listing Seven</a>(b) shows a classic administrator server, where clients call different members for service. The server may provide multiple interface members for different kinds of clients and client requests. A client's call may be serviced immediately or delayed using condition variables. The server's <i>main</i> loops accept client calls using the<i> _Accept</i> statement; an accepted call may complete immediately or require subsequent servicing and signalling of the delayed client. Finally, the server's destructor is also being accepted to know when the server is being deleted by another thread.</p><h3>Miscellaneous &micro;C++  Features</h3><p>&micro;C++  has a number of other features that integrate concurrency with C++:</p><ul>  <li>Both termination and resumption exception handling are supported, as well as the ability to raise exceptions among coroutines and tasks; see <a name="rl8"></a><a href="#l8">Listing Eight</a>(a). For resumption, the stack is not unwound, and control returns after the <i>_Resume</i> when the handler completes. The <i>_At</i> clause provides nonlocal delivery of an exception to another coroutine or task. Nonlocal delivery of exceptions is controlled by _<i>Enable</i> and _<i>Disable</i> statements; see <a name="rl8"></a><a href="#l8">Listing Eight</a>(b). Specifying no exceptions enables/disables all exceptions.</li>  <li>The execution environment can be structured into multiple clusters of tasks and processors. Each cluster has a scheduler to control selection of its tasks to run on its processors; tasks and processors can migrate among clusters. </li>  <li>C++ streams and UNIX files/sockets are augmented to be thread safe, object-oriented, and nonblocking; for example, safe stream I/O is performed like this:</li><blockquote>isacquire( cin ) &gt;&gt; . . .;<br>osacquire( cout ) &lt;&lt; ...&lt;&lt; endl;</blockquote>  <li>	   The declaration at the start of the I/O expression provides necessary locking of the specified stream for the duration of the expression. There are three classes for accessing sockets: <i>uSocketServer</i>, <i>uSocketAccept</i>, and <i>uSocketClient</i>, which hide most of the socket complexity and support connectionless and connected protocols with timeout capabilities.</li>  <li>Basic real-time programming is available through three extensions of the task:<br></li><blockquote>_RealTimeTask R {...}; <br>_PeriodicTask P {...};<br>_SporadicTask S {...};</blockquote>  <li>	   Fixed and dynamic priority schedulers are provided for use with clusters, including a transitive priority-inheritance protocol. The <i>_Accept</i> statement is extended to handle timeouts:</li><blockquote>_Accept( M1, M2 ) {...}<br>else _Accept ( M3 ) {...}<br>else _Timeout( 1 ) {...}       // restart after <br>			// 1 second if <br>			// no call</blockquote>  <li>There is a debug mode for testing with many assertions and runtime checks, and &micro;C++ also generates reasonable error messages. &micro;C++ compiles on GCC 3.2 or greater and Intel icc 8.1/9.0; for Linux Intel x86/Itanium and AMD 32/64; Solaris 8/9/10 SPARC; and IRIX 6.x MIPS. </li></ul><h3>Conclusion </h3><p>Providing concurrency via low-level libraries such as pthreads makes no sense for C++. This approach is error prone and does not integrate with existing C++ mechanisms. Medium-level approaches that attempt to leverage existing language features with a concurrency library also fall short, as programmers still struggle with multiple coding conventions and limitations of use, and some primitive concurrency properties are still hidden from the compiler. To truly help you and the compiler, concurrent programming requires high-level concurrency models and constructs. The three fundamental properties in concurrency&#151;thread, execution context, and mutual-exclusion/ synchronization&#151;can be integrated directly into C++'s core programming notion&#151;the class&#151;and subsequently work with other C++ mechanisms. This approach retains the language's object-oriented programming model and provides multiple concurrency approaches and models, while requiring only a few new keywords and mechanisms in C++. &micro;C++ is a full implementation of these ideas, providing a system that lets you tackle complex concurrent projects. </p><p><b></b></p><p><b></b></p><p><b>DDJ</b></p>		<br><br><b><a name="l1"></a>Listing One</b><br><pre>_Coroutine C {  void main() { // distinguished member / executes on coroutine's stack    ...suspend()... // restart last resume  }public:  void m1(...) {... resume();...} // restart last suspend  void m2(...) {... resume();...} // restart last suspend};</pre><a href="#rl1">Back to article</a><br>			<br><br><b><a name="l2"></a>Listing Two </b><br><pre>_Coroutine Phone {public:  enum status { MORE, GOOD, BAD };private:  char ch;  status stat;  void main() {    int i;    stat = MORE; // continue passing characters    if ( ch == '(') { // optional area code ?      for ( i = 0; i &lt; 3; i += 1 ) {        suspend();        if ( ! isdigit(ch) ) { stat = BAD; return; }      }        suspend();        if ( ch != ')') { stat = BAD; return; }          suspend();      }      for ( i = 0; i &lt; 3; i += 1 ) { // region code ?         if ( ! isdigit(ch) ) { stat = BAD; return; }           suspend();      }      if ( ch != '-') { stat = BAD; return; } // separator ?      for ( i = 0; i &lt; 4; i += 1 ) { // local code ?        suspend();        if ( ! isdigit(ch) ) { stat = BAD; return; }      }      stat = GOOD;  }public:  status next( char c ) { // pass one character at a time to FSM    ch = c;    resume(); // activate coroutine    return stat;  }};</pre><a href="#rl2">Back to article</a><br>			<br><br><b><a name="l3"></a>Listing Three</b><br><pre>_Mutex class M { // default MES for public member routines  // SHARED DATA ACCESSED BY MULTIPLE THREADS  uCondition c1, c2[10], *c3 = new uCondition; //different condition variables  // default for private/protected is no MES  void m1(...) {... /* MES statements */...} // no MES  _Mutex void m2(...) {... /* MES statements */...}; // MESpublic:  void m3(...) {.../* MES statements */...} // MES  _Nomutex void m4(...) {...} // no MES    ... // destructor is ALWAYS mutex};</pre><a href="#rl3">Back to article</a><br>			<br><br><b><a name="l4"></a>Listing Four </b><br>(a)<pre>_Mutex class DatingService {    uCondition Girls[20], Boys[20];    int GirlPhoneNo, BoyPhoneNo;  public:    int Girl( int PhoneNo, int code ) {        if ( Boys[code].empty() ) {             Girls[code].wait();             GirlPhoneNo = PhoneNo;    } else {             GirlPhoneNo = PhoneNo;             Boys[code].signalBlock();    }    return BoyPhoneNo;  }  int Boy( int PhoneNo, int code ) {    if ( Girls[code].empty() ) {         Boys[code].wait();         BoyPhoneNo = PhoneNo;    } else {         BoyPhoneNo = PhoneNo;         Girls[code].signalBlock();    }    return GirlPhoneNo;  }};</pre>(b)<pre>_Mutex class ReadersWriter {    int rcnt, wcnt;public:    void ReadersWriter() {        rcnt = wcnt = 0;    }    void EndRead() {        rcnt -= 1;    }    void EndWrite() {        wcnt -= 1;    }    void StartRead() {        if ( wcnt == 1 ) _Accept( EndWrite );        rcnt += 1;    }    void StartWrite() {        if ( wcnt == 1 ) _Accept( EndWrite );        else while ( rcnt &gt; 0 )            _Accept( EndRead );        wcnt += 1;    }};</pre><a href="#rl4">Back to article</a><br>			<br><br><b><a name="l5"></a>Listing Five</b><br><pre>_Mutex _Coroutine CM { // default MES for public member routines   uCondition c1,c2[10],*c3 = new uCondition; // different condition variables   void m1(...) {.../* MES statements */ ...} // no MES   _Mutex void m2(...) { .../* MES statements */ ...}; // MES   void main() {...} // distinguished member / has its own stackpublic:   void m3(...) { ...resume()/* MES statements */ ...} // MES   _Nomutex void m4(...) { ...resume(); ...} // no MES   ...// destructor is ALWAYS mutex};</pre><a href="#rl5">Back to article</a><br>			<br><br><b><a name="l6"></a>Listing Six</b><br><pre>_Task T { // default MES for public member routines   uCondition c1,c2[10],*c3 = new uCondition; // different condition variables   void m1( ... ) {.../* MES statements */ ... } // no MES   _Mutex void m2(...) {.../* MES statements */...}; // MES   void main() {...} // distinguished member/has own stack/thread starts herepublic:   void m3(...) {.../* MES statements */ ...} // MES   _Nomutex void m4(...) {...} // no MES   ...// destructor is ALWAYS mutex};</pre><a href="#rl6">Back to article</a><br>			<br><br><b><a name="l7"></a>Listing Seven </b><br>(a)<pre>const int rows = 10, cols = 10;int M[rows][cols], ST[rows];_Task Adder { // add specific row    static int row; // sequential access    int myrow, c;    void main() {        ST[myrow] = 0; // subtotal location        for ( c = 0; c &lt; cols; c += 1 )             ST[myrow] += M[myrow][c];    }  public:    Adder() { myrow = row++; } // choose row};int Adder::row = 0;void uMain::main() {    // read matrix    {        Adder adders[rows]; // create threads    } // wait for threads to terminate    int total = 0; // sum subtotals    for ( int r = 0; r &lt; rows; r += 1 )         total += ST[r];    cout &lt;&lt; total &lt;&lt; endl;}</pre>(b)<pre>_Task Server {    uCondition delay;    void main() {        for ( ;; ) { // for each client request            _Accept( ~Server ) { // terminate ?              break;            // service each kind of client request            } else _Accept( workReq1 ) {              ...              delay.signalBlock(); // restart client              ...            } else _Accept( workReq2 ) {              ...            }        }        // shut down  }public:  void workReq1( Req1_t req ) {       ...delay.wait();...// service not immediate?       // otherwise service request    }    void workReq2( Req2_t req ) { ... }    ...};</pre><a href="#rl7">Back to article</a><br>			<br><br><b><a name="l8"></a>Listing Eight</b><br>(a)<pre>_Throw [ throwable-exception [ _At coroutine/task-id ] ] ; // termination_Resume [ resumable-exception [ _At coroutine/task-id ] ] ; // resumption</pre>(b)<pre>_Enable &lt;E1&gt;&lt;E2&gt;... {    // exceptions E1, E2, ... delivered}_Disable &lt;E1&gt;&lt;E2&gt;... {    // exceptions E1, E2, ... not delivered}</pre><a href="#rl8">Back to article</a><br>			</body></html>