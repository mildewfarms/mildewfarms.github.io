<html><head><title>Feb02: C Programming</title></head><body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000"><!--Copyright &#169; Dr. Dobb's Journal--><h1>Riding the Waves</h1><p><i>Dr. Dobb's Journal</i> February 2002</p><h3>By Al Stevens</h3><I>Al is DDJ's senior contributing editor. He can be contacted at <a href="mailto:astevens@ddj.com">astevens@ddj.com</a>.</I><hr><p>Over the past several months, I've described a C++ project that involves playback of music on a PC. The project is not just another media player. It has some special requirements related to mixing and merging audio tracks in real time. Earlier columns contain the details of the project itself. This month, I'll address one part of it &#151; waveform playback and recording on the Win32 platform. </p><p>Up until now, my project used homegrown and imported Winamp plug-ins to experiment with various file formats and playback techniques. I discussed that approach last month. The time came, however, when I had to insert audio playback into my own application. I toyed with the notion of using existing plug-ins, but since I need recording as well as playback, I decided to bite the bullet and learn how waveform processing works with Win32.</p><DDJADVERTISEMENT INLINE><p>First some basics: A digital waveform is represented in memory as a sequence of numbers. Each number is a sample. Each sample represents the relative amplitude of the waveform at a specific point in time. The more samples per second, the more accurately the digital waveform represents the original analog waveform. Each sample is represented by a signed integer. The more bits in the integer, the more accurately the digital waveform represents the dynamic range of the original waveform signal. Multiple-channel waveforms typically store the samples for each channel in adjacent integers. So, for example, a stereo signal has a left-channel sample followed by a right-channel sample to represent the two signals' amplitudes at the time of that sample. Consequently, three data values must accompany a sequence of samples for it to be correctly played through an audio system. These values specify the number of samples per second, the number of bits per sample (typically 8 or 16), also called the "sample resolution," and the number of channels.</p><p>If you need to know any more than that, including graphs and pictures that make it clearer, I recommend <i>A Programmer's Guide To Sound, </i>by Tim Kientzle (Addison-Wesley, 1998). I keep plugging Tim's book. I like it. I wish some columnist liked one of my books as much as I like Tim's.</p><p>There's more to know if you are dealing with files of waveforms. There are many data formats and compression algorithms for representing waveforms in data files. I'm not discussing these issues this month, and Tim's book is an excellent resource for them. My project uses a raw, pulse-coded modulation (pcm) format, which is simply a record of the samples in the sequence in which they are to be played with fixed values for sample rate, sample resolution, and number of channels. File formats are not important to this work at this time.</p><p>Several hours poring through the Win32 programming books in my library turned up only two that explain waveform processing. One is Tim's book and the other is the venerable <i>Programming Windows</i> Fifth Edition, by Charles Petzold, (Microsoft Press, 1999). Petzold shows how to write C programs that record and playback waveforms. Tim presents a complete waveform playback program in C++ that integrates most file formats and thoroughly queries the installed audio system to find one that matches the requirements of the current waveform. Neither of these solutions is quite what I needed, but both were instrumental in getting me started toward my goal, which is to use C++ classes that encapsulate waveform recording and playback.</p><p>By looking at Charles's and Tim's code, I learned how to apply the Win32 wave API. After that, the Win32 API reference documentation itself was all I needed. </p><p>The processes are surprisingly small, but they represent a complex mechanism. By building this mechanism into C++ classes, I can have its benefits long after having forgotten its details. Other programmers can use the classes without ever needing to understand the details. This is what encapsulation is supposed to deliver, after all.</p><p>With these classes, an application integrates waveform processing. The Win32 API includes high- and low-level waveform functions from which you choose depending on your requirements. If your program records and plays back only standard .WAV files, the high-level Media Control Interface (MCI) functions are your best bet. I used them in a simple voice recorder/playback application called "Storch" (<i>DDJ,</i> September 1999). For more complex audio processing, the low-level audio services are better. That's what this project uses.</p><h3>The <i>Wave</i> Class</h3><p>Playback and recording have several things in common, which are encapsulated in a common abstract base class named <i>Wave</i>, defined and implemented in wave.h and wave.cpp (available electronically; see "Resource Center," page 5). The <i>Wave</i> class implements the three values that describe how to record or playback a waveform. It contains two data buffers for overlapped wave data processing, an integer that defines the length of the buffers in bytes, two WAVEHDR structures that the API uses to define the two buffers, and a WAVEFORMATEX structure that the playback and recording APIs use to define the waveform's characteristics.</p><p>I use <i>std::auto_ptr&lt;char&gt;</i> template objects to contain the buffers, which are dynamically allocated. This usage permits the class member functions to throw exceptions without worrying about undeleted resources.</p><p>The only <i>Wave</i> class member function is its constructor, which initializes the waveform-defining data members and the API structures and allocates memory for two buffers of samples. The constructor's samples parameter is a count of the number of samples to be stored in each buffer. (If you make this number too small, playback makes funny noises. 4096 seems to work well.) A sample might be 1 or 2 bytes, depending on the <i>b</i> parameter, which is the number of bits per sample, typically 8 or 16. A logical sample might occupy one or two sample positions in the buffer depending on the <i>nc</i> parameter, which is the number of channels in the waveform. The constructor computes the <i>buflen</i> data member value from arguments passed in these parameters by derived classes. The <i>rate</i> parameter defines the number of samples per second that are recorded to or played back from the waveform.</p><p>The <i>Wave</i> class is an abstract base class; its constructor and (empty) destructor are within the members controlled by the class's protected access specifier. </p><h3>Program Notes</h3><p>Observe that in the <i>Wave</i> class <i>auto_ptr</i> and <i>runtime_error</i> are not declared in the <i>std::</i> namespace. For some reason, Visual C++ does not put a lot of Standard C++ stuff in <i>std::</i> by default. I rummaged through the VC++ headers and concluded that you can probably enable the feature by <i>#defining</i> something, but I wonder why they don't set the standard way as the default instead of the other way around. The VC++ headers come from HP and SGI, where STL was created and where a widely used version of these standard library classes and functions is maintained. The headers make extensive and effective use of compile-time conditional <i>#define</i> statements to fit one source-code resource to the parameters of many compilers. That warms my heart. I've always been a fan of the preprocessor and am always put off when C++ gurus denigrate it and declare it no longer necessary. Yet these <i>#define</i> statements keep showing up in code from respected sources, code that has to live in the real world, not just in the rarefied laboratories of gurus.</p><p>A word about how I use exceptions in these classes. A more conventional implementation would derive exception classes from the standard ones and throw objects of them. I simply throw objects of <i>std::runtime_error </i>and include a text argument that the catcher can display by using the <i>std::exception::what()</i> member function. If I was going to use this library in a larger application where many kinds of exceptions needed to be caught, I'd probably build unique exceptions for these classes to throw.</p><h3>The <i>WavePlayer</i> Class</h3><p>Waveplayer.h and waveplayer.cpp (available electronically) define and implement the <i>WavePlayer</i> class, which is derived from <i>Wave</i> to implement waveform playback with the Win32 API. An application derives a class from the <i>WavePlayer</i> class and instantiates an object of the derived class to playback waveforms on the PC's audio system.</p><p><i>WavePlayer</i> includes an HWAVEOUT data member, which is the Win32 device identifier. It also includes data members that keep track of the object's current playback mode. <i></p><p>WavePlayer</i> is an abstract base class. The derived class provides an implementation of the <i>FillBuffer</i> pure virtual function to pass a buffer of samples to the class to playback. <i>WavePlayer</i> itself provides <i>Play, Pause, Resume,</i> and <i>Stop</i> public member functions that the application calls to perform those operations. Once playback begins, the derived class's <i>FillBuffer</i> implementation must be prepared to put samples in the buffer whenever it is called. <i>FillBuffer</i> inserts into the buffer pointed to by its first parameter up to the number of samples specified in its second parameter. <i>FillBuffer</i> returns the number of samples inserted. </p><p>An application can implement digital signal processing on the buffer of samples by overriding <i>WavePlayer::DSP</i>, which has the same parameters and return value as <i>WavePlayer::FillBuffer</i> but may return up to twice the number of samples specified in the second parameter. <i>WavePlayer</i> provides an empty DSP function implementation.</p><p>The <i>WavePlayer</i> class's constructor depends on the API's <i>waveOutOpen</i> function to find an appropriate audio playback device to match the characteristics of the waveform. If it can't find one or can't initialize the one it finds (perhaps another application has the device), the constructor throws an exception. Most contemporary PCs have sound cards that support CD quality waveforms (two channels, 44100 Hz, 16 bps). Some older sound cards, particularly the 8-bit cards of yore, can't do this. If you try to instantiate an object of a class derived from <i>WavePlayer</i> for CD-quality sound on a PC with an older sound card, the <i>WavePlayer</i> constructor throws an exception. Your program should catch that exception and instantiate the object with lower quality values, which means your program must downsize the samples before passing them for playback via the <i>FillBuffer</i> function. Converting 16-bit samples to 8-bit samples is simply a matter of dividing each sample by 2.</p><p>The <i>WavePlayer</i> constructor passes to <i>waveOutOpen</i> the address of a callback function to be called from the API whenever a buffer has been fully written to the audio system. The callback function, <i>WavePlayer::waveOutProc</i>, is a static member function of the <i>WavePlayer</i> class. </p><p>When the application calls <i>WavePlayer::Play(),</i> the function makes two calls to the class's private <i>FillBufferAndPlay</i> function, passing the addresses of the two WAVEHDR structures. <i>FillBufferAndPlay</i> calls the derived class's implementations of <i>FillBuffer</i> and DSP, updates the WAVEHDR structure, and calls the API's <i>waveOutWrite</i> function.</p><p>When the API calls <i>WavePlayer::waveOutProc</i>, the callback function intercepts the WOM_DONE message and calls <i>FillBufferAndPlay</i> for whichever buffer has completed its playback.</p><h3>The <i>WaveRecorder</i> Class</h3><p>Recording is similar to playback. Waverecorder.h and waverecorder.cpp (available electronically) define and implement the abstract <i>WaveRecorder</i> base class, which is derived from <i>Wave.</i> The application derives a class from <i>WaveRecorder</i> to implement the pure virtual <i>StoreData</i> member function. The <i>WaveRecorder</i> class calls this function when there are data in the input buffer that need to be stored. The application's derived class takes care of doing that. </p><p>As with <i>WavePlayer</i>, the <i>WaveRecorder</i> constructor depends on the Win32 audio system to find an appropriate audio recording device on the PC. If one cannot be found or initiated, the constructor throws an exception.<i></p><p>WaveRecorder::Record</i> is the only interface function other than the constructor and destructor. An application instantiates an object of its class derived from <i>WaveRecorder</i> and calls <i>Record</i> to begin recording. This function calls the API's <i>waveInAddBuffer</i> twice, once for each of the WAVEHDR structures. Then it calls <i>waveInStart</i> to begin the recording process.<i></p><p>WaveRecorder::waveInProc</i> is the callback function that the Win32 API calls when a buffer is filled and ready to be stored. It calls the private <i>SaveBuffer</i> member function, which calls the derived class's implementation of <i>StoreData,</i> and then calls <i>waveInAddBuffer</i> to let recording proceed in the buffer.</p><p>The derived class's <i>StoreData</i> function accepts a buffer of samples and does whatever the application needs to do with them. My application writes them to disk in raw PCM format. To stop recording, the application simply destroys the derived <i>WaveRecorder</i> object.</p><h3>Why Not DirectSound?</h3><p>I could have used the DirectSound component of DirectX for this project. I chose not to for three reasons. </p><ul>  <li>First, the project does not need the performance benefits that DirectSound offers.   <li>Second, users would be required to install DirectX and the appropriate sound card drivers to use my program.   <li>Third, I'd have to download the enormous DirectX SDK from Microsoft's web site, and I don't think my slow, fragile, boonies-bound dial-up connection would get it here before the next millennium. </ul><p>If you are interested in DirectSound programming, which you should be if you are developing games, a good start is <i>Windows 98 Programming Secrets, </i>by<i> </i>Clayton Walnum (IDG Books, 1998).</p><h3>Sound a Retreat</h3><p>My audio project will eventually become a commercial product. That is unfortunate in one respect because it means I must temporarily abandon my voyage into the world of Linux software development and retreat to the Win32 platform. Linux users traditionally expect their applications to be free, and there aren't enough of them in my targeted marketplace to make it worth the time and effort. However, my retreat is personally fortunate in another respect because I won't be writing about Linux programming for a while and will be spared the flames and arrows of outraged Linux devotees whenever I criticize something. Nobody minds if you fire volleys at Redmond, but one mustn't take potshots at the lovable little penguin. I can already hear the huge gasps of relief around the Linux development community; for a time, at least, they are free from the critical eye and unfettered pen of at least one old curmudgeon.</p><p>One criticism I made generated several responses. I referred to the sndconfig program that came with my Linux distribution as an evil program. Readers didn't mind that I called it evil; they mostly agreed. They objected because I failed to report that sndconfig comes only on Red-Hat and derivative distributions. My apologies and congratulations to those other Linux distributions that were wise enough not to include sndconfig.</p><p><b>DDJ</b></p></body></html>