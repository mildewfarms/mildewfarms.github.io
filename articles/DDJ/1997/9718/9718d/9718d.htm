<HTML>
<HEAD><TITLE>DDJ, Spring1997: Extending Java Streams</TITLE></HEAD>
<body bgcolor="FFFFFF">



<H1>
Extending Java Streams to Support Bit Streams
</H1>
Spring 1997 <I>Dr. Dobb's Journal</I>
<H2>
Implementing LZW compression  using Java
</H2>

<H3><i>by Laurence Vanhelsuw&eacute;</i></H3>

<P>Laurence is a freelance software engineer and author. He can be contacted at <I>lva@telework.demon.co.uk</I>.
<HR>
<IMG SRC="9718dins.jpg" WIDTH=105 HEIGHT=117 ALIGN=LEFT HSPACE=6 VSPACE=3 ALT="Insert">

The java.io package is Java's solution for shielding you from input/ output related device and platform dependencies. Of the 23 core java.io classes, 19 rely on the concept of a data stream (see Figure 1). A Java stream is simply a unidirectional, sequential flow of bytes that emanates from some concrete source (for input streams) or flows toward a concrete sink (for output streams). Input streams can only be read from, and output streams can only be written to.

<P>
In this article, I'll show how to subclass stream classes by designing and implementing I/O stream classes that support bit streams rather than byte streams. I'll then demonstrate these classes by deploying them in a Java implementation of the ubiquitous Lempel-Zif-Welch (LZW) data compression and decompression algorithm.<P>

<H2>
Java I/O Stream Class Basics
</H2>

Two superclasses, <I>InputStream</I> and <I>OutputStream</I>, form the roots of the dual stream inheritance branches. Example 1 shows the definition of the <I>InputStream</I> class, a good summary of what all input streams need to be able to do.<P>

<HR>
<B>Example 1</B>: <I>Abstract class InputStream interface</I>.

<PRE>public class InputStream extends Object {
   public abstract int read() throws IOException;
   public int read(byte b[]) throws IOException;
   public int read(byte b[], int off, int len) throws IOException;
   public long skip(long n) throws IOException;
   public int available() throws IOException;
   public void close() throws IOException;
   public synchronized void mark(int readlimit);
   public synchronized void reset() throws IOException;
   public boolean markSupported();
}
</PRE>
<HR>

<P>
The main methods are the three overloaded <I>read()</I> variants that let you read a single byte or a block of bytes at a time. The last three methods&#151;<I>mark()</I>, <I>reset()</I>, and <I>markSupported()</I>&#151;allow subclasses of <I>InputStream</I> to implement a multibyte "unread" function. Clients can drop a mark in the input stream and revert back to it at a later time if the class in question supports the unread feature. Most don't because, by default, <I>InputStream</I> returns "<I>false</I>" when its <I>markSupported()</I> method is called, and most subclasses inherit <I>markSupported()</I> without overriding it. Class <I>InputStream</I> is abstract because of one single component that is left unimplemented: the building block <I>read()</I> method, on which the other <I>read()</I> methods and the <I>skip()</I> method rely.

<P>
<I>OutputStream</I> is equally straightforward. It mainly provides equivalent <I>write()</I> methods to send bytes to any output stream (see Example 2). The mark/reset mechanism is not present in <I>OutputStream</I> because it doesn't make any sense on output.<P>
<HR>
<B>Example 2</B>: <I>Abstract class OutputStream interface.</I>
<PRE>public class OutputStream extends Object {
   public OutputStream();
   public abstract void write(int b) throws IOException;
   public void write(byte b[]) throws IOException;
   public void write(byte b[], int off, int len) throws IOException;
   public void flush() throws IOException;
   public void close() throws IOException;
}
</PRE>
<HR>
<P>
Table 1 shows the data sources and sinks supported by the core input and output stream classes. In addition to these, classes in the java.net networking package produce input and output stream objects that connect to various network sources (like a TCP stream) and destinations. Unlike the input stream classes, the output stream classes do not support writing data to a String since Java Strings are read only. Furthermore, you can expect Sun's future Java API additions to support and rely on stream objects.<P>
<HR>
<B>Table 1</B>:<I> Data sources and sinks supported by core input- and output</I>.

<PRE>
<B>Data Types    Input Class            Output Class</B>

external files   FileInputStream           FileOutputStream
Strings          StringBufferInputStream 
byte arrays      ByteArrayInputStream      ByteArrayOutputStream
pipes            PipedInputStream          PipedOutputStream</PRE>
<HR>
<P>
You can further divide both the input and output branches of java.io's inheritance hierarchy into two types of classes:

<P>
<UL>
<LI>Those that connect to specific data sources (for input streams) or data sinks (for output streams).
<LI>Those that enhance stream functionality.
</UL>

In general, the constructor of a stream class is what allows you to specify the entity to which your stream object will connect. For example, objects of class <I>FileInputStream</I> accept data from a file, so <I>FileInputStream</I> constructors look like: <PRE>public FileInputStream(String name) throws 
  FileNotFoundException.

public FileInputStream(File file) throws
  FileNotFoundException.

public FileInputStream(FileDescriptor fdObj)
</PRE>

<P>
All three constructors let you specify a file with content that will be used to feed read requests to the input stream. On the output side of the java.io hierarchy, the same approach is used (<I>ByteArrayOutputStream</I> being an exception).<A HREF="9718dlis.htm#1"> Listing One</A>  shows an example Java program that uses class <I>FileInputStream</I> to calculate character frequencies.

<P>
<H2>
The Filter I/O Classes
</H2>

Things become more interesting when you look at the two subhierarchies rooted in classes <I>FilterInputStream</I> and <I>FilterOutputStream</I>. Example 3 shows <I>FilterInputStream</I>'s 
definition.<P>
<HR>
<B>Example 3</B>: <I>Class FilterInputStream interface.</I>

<PRE>public class FilterInputStream extends InputStream {
   protected InputStream in;
   protected FilterInputStream(InputStream in);
   public int read() throws IOException;
   public int read(byte b[]) throws IOException;
   public int read(byte b[], int off, int len) throws IOException;
   public long skip(long n) throws IOException;
   public int available() throws IOException;
   public void close() throws IOException;
   public synchronized void mark(int readlimit);
   public synchronized void reset() throws IOException;
   public boolean markSupported();
}
</PRE>
<HR>
<P>
Class <I>FilterInputStream</I> looks almost exactly like <I>InputStream</I>. The crucial difference is the constructor's signature: The <I>FilterInputStream</I> constructor takes any other <I>InputStream</I> object as an argument. This simple difference (along with the protected instance variable <I>in</I>) allows you to chain input streams together to form input-processing pipelines of arbitrary complexity, all built from concrete, reusable instances of various <I>FilterInputStream</I> classes. The same powerful and flexible features are in the output-stream class hierarchy.<P>

<B>Figure 1:</B> <I>Package java.io inheritance hierarchy.
</I><P>
<IMG SRC="9718dfig1.gif" ALT="Diagram" ALIGN=TOP WIDTH="490" HEIGHT="346">


<P>
Figure 2 illustrates a fictitious input-processing pipeline. In Step 1, unencoded, uncensored, and unformatted text originating from the Internet enters the pipeline. Step 2 buffers this data in large chunks, thereby enhancing the performance of the entire pipeline. Step 3 decodes the text into plain ASCII. Step 4 enforces the CDA and substitutes certain unspeakable words with sequences of Xs (I entirely support the Free Speech On-line campaign, so this example is purely tongue-in-cheek.) Finally, Step 5 reformats the text so it fits properly on cheap, low-resolution displays hooked up to the NCs of the future.

<P>
Figure 2 shows the general raison d'&ecirc;tre for all filter stream subclasses&#151;enhancing stream functionality.


<P>
<B>Figure 2: </B><I>A fictitious input-
processing pipeline.</I><P>

<IMG SRC="9718dfig2.gif" ALT="Diagram" ALIGN=TOP WIDTH="252" HEIGHT="432">



<P>
<H2>
Chaining Filter Stream Objects 
</H2>

The sequence of stream object constructor invocations determines the structure of your pipelines. You can significantly improve the performance of the <I>CharFreq</I> program in <A HREF="9718dlis.htm#1">Listing One</A> by turning the single-stage <I>FileInputStream</I> "pipeline" into a two-stage, buffering pipeline. Simply replace the line constructing the <I>FileInputStream</I> object with <I>file = new BufferedInputStream(new FileInputStream(args[0]) );</I>. Note that this change does not affect any other parts of the program. Although the main loop is now invoking <I>read()</I> on a <I>BufferedInputStream</I> object, the program's function is the same. The chaining mechanism is limitless; you could "wrap" the above <I>BufferedInputStream</I> object with yet another type of input stream, thus creating a three-stage input pipeline, and so on, ad infinitum. This technique is as idiomatic within Java as using the value of assignments is in C or C++ (<I>if ((ch=getch()) == LF)</I>, for example).

<P>
Chained input or output pipelines frequently consist of three or more stream objects, so the aforementioned syntax can quickly become unmanageable. The preferred way of coding your chains is to use one constructor per line and declare variables to hold every object; see the coding template in Example 4.<P>
<HR>
<B>Example 4</B>: <I>Preferred method for coding input and output chains.</I>

<PRE>&lt;StreamType&gt; varNameSource = new &lt;StreamType&gt;( concrete source );
&lt;StreamType&gt; varNameLink1  = new &lt;StreamType&gt;( varNameSource);
&lt;StreamType&gt; varNameLink2  = new &lt;StreamType&gt;( varNameLink1);
         :                         :
&lt;StreamType&gt; varNameLinkN-1  = new &lt;StreamType&gt;( varNameLinkN-2);
&lt;StreamType&gt; varNameLinkN  = new &lt;StreamType&gt;( varNameLinkN-1);
</PRE>
<HR>

<H2>
Reading and Writing Arbitrary Bit Streams
</H2>

<I>BitStreamInputStream</I> and <I>BitStreamOutputStream</I> are subclasses of the filter stream classes. Our requirements for these bit-stream classes (see <A HREF="9718dlis.htm#2">Listings Two</A> and <A HREF="9718dlis.htm#3">Three</A>) are: 

<P>
<UL>
<LI>Support bitfields ranging in length from 1 to 32 bits inclusive.

<LI>Bitfields are aligned on their natural bitfield boundary (byte alignment is not special).

<LI>The current bitfield size can be altered at any point during reading or writing.
</UL>

<P>
Supporting 1- to 32-bit bitfields suggests two new methods: <I>readBitField()</I> for the input class, and <I>writeBitField()</I> for the output class. These two methods are the logical analogs of <I>read()</I> and <I>write()</I>.

<P>
On the input side, the return mechanism for <I>readBitField()</I> needs to use the same trick as <I>read() </I>as defined in <I>InputStream</I>. <I>read()</I> can either return a single byte or the integer &#173;1 (which represents EOF). Since the integer value of &#173;1 is equivalent to the byte value 255, <I>read()</I> returns a 32-bit <I>int </I>rather than an 8-bit <I>byte</I>. For the sake of consistency, but not elegance, I use the same approach, returning 64-bit <I>long </I>to allow 32-bit bitfields and &#173;1 for EOF. It would be much cleaner to use the Java exception mechanism to trap EOF. This technique is, in fact, used by class <I>DataInputStream</I>, but this is an exception (no pun intended).

<P>
Aligning bitfields on their natural bitfield boundaries is handled transparently: No methods are required to support arbitrary bitfield alignment. Altering the bitfield size suggests that the method <I>setBitFieldSize(int bfSize)</I> is present in both classes. Examples 5 and 6 show the interface definitions for these two classes.<P>
<HR>
<B>Example 5</B>: <I>Class BitStreamInputStream interface.</I>


<PRE>public class BitStreamInputStream extends FilterInputStream {
   public BitStreamInputStream(InputStream in)
   public BitStreamInputStream(InputStream in, int bitFieldSize)
   public long readBitField() throws IOException
   public void setBitFieldSize(int bits) throws IllegalArgumentException
   public int getBitFieldSize()
}
</PRE>
<HR>
<P>

<B>Example 6</B>: <I>Class BitStreamOutputStream interface.</I>

<PRE>public class BitStreamOutputStream {
   public BitStreamOutputStream(OutputStream out)
   public BitStreamOutputStream(OutputStream out, int bitFieldSize)
   public long writeBitField() throws IOException
   public void setBitFieldSize(int bits) throws IllegalArgumentException
   public int getBitFieldSize()
}</PRE>
<HR>
<P>
The <I>getBitFieldSize()</I> method is provided for completeness and symmetry. Both classes provide two constructor options. The simpler constructor creates streams supporting 8-bit bitfields. In other words, it produces an everyday byte-aligned byte stream by default. The second and (more useful) constructor allows you to explicitly specify the initial bitfield size for the stream.

<P>
Since I built my bit stream classes on top of byte stream classes (and not vice versa), I need to pack and align variable-sized bitfields into bytes for writing and unpack and align these same fields for reading.

<P>
To implement method <I>BitStreamInputStream.readBitField()</I>, I chose to use a single-byte buffer sitting between the stream and the bitfield assembly code. While this might be less efficient than using a larger buffer (say, 8 bytes, capable of holding the largest bitfield&#151;32 bits&#151;under all alignment circumstances), it greatly simplifies implementation and EOF handling. The basic structure of the algorithm is shown in Example 7 in pseudocode.<P>
<HR>
<B>Example 7</B>: <I>Pseudocode for BitStreamInputStream.readBitField().</I>
<PRE>bitField = 0
bitsToRead = current field size
while bitsToRead &gt; 0
    if read buffer is empty, re-fill byte read buffer (and possibly
      generate EOF here)
    extract largest possible subfield (possibly entire bitfield requested)
    gradually build bitField up by adding subfield to bitField (using
      shifts and an OR)
    decrement bookkeeping variable tracking the number of unread bits
      in buffer (bitsInCache)
    decrement bitsToRead by the number of bits extracted in this iteration
return bitField
</PRE>
<HR>

<P>
Instead of using an explicit bitstream pointer (the equivalent of a filepointer for byte streams) to track which bits have already been consumed, the code keeps the next bitfield left-aligned in the read buffer. Bitfield fragments (called "partials" or "subfields" in the code) are extracted from the read buffer and right-aligned before being shifted left the necessary number of bits and ORed into the bitfield construction variable (<I>bitField</I>).

<P>
The choice of alignment directions can be reversed without affecting the basic algorithm, although this would mean more than changing the few &lt;&lt; and &gt;&gt; operators. The algorithm and code are rather hard to understand because of their generic and very low-level character: Any size bitfield (from 1 to 32 bits inclusive), aligned to any bit boundary should be fair game to the algorithm. To convince yourself of the correctness of the algorithm, you should try pen-and-paper simulations using the following test cases:

<P>
<UL>
<LI>Bitfields of length 1 bit (repeat nine times to convince yourself byte boundaries are handled properly).

<LI>Bitfields of length 2, 3, 4, 5, 7, 8, 9, 15, 16, 17, 31, 32 bits.
</UL>
<P>

The bitfield-writing algorithm requires bit-shuffling operations similar to those in the reading algorithm, except it will be the write buffer (again a single byte) that receives bitfield fragments. These need to be aligned to the bitstream's current bit alignment. Whenever the write buffer contains eight bits of data, the buffer is flushed to make room for more bitfield data (either whole bitfields, if the current bitfield size is between 1 and 8, or parts of bitfields if the size is between 9 and 32).

<P>
While the bitfield-reading algorithm had to deal with encountering and passing an EOF, the writing algorithm has to ensure that all bitfield data is written when the stream is closed. This is done by overriding the <I>close()</I> method: When the <I>BitStreamOutputStream</I> is closed, it checks if there are any unwritten bits in the write buffer, and flushes them if they exist.

<H2>
A Question of Semantics</H2>

<I>BitStreamInputStream</I> and <I>BitStreamOutputStream</I> both inherit the <I>read()</I> and <I>write()</I> methods from their respective filter stream superclasses. Since these and other inherited methods know nothing about the new bit-stream model, and could corrupt the stream (by skipping or not writing bits), I had to reimplement these methods.

<P>
When subclassing a class, you should pay careful attention to the new semantics of your new class to ensure that these are as logical and as close to the original as possible. When designing my bit-stream classes, I had to decide the exact semantics for these same <I>read()</I> and <I>write()</I> methods in my extended classes. For the <I>read()</I> method, my options were:

<P>
<UL>
<LI>Read a bitfield of the current size (exactly like <I>readBitField()</I>).

<LI>Read a byte (normal byte alignment).

<LI>Read an 8-bit bitfield (arbitrarily aligned).
</UL>
<P>

While the first option is elegant, I rejected it because it deviates too much from the byte bias of the java.io classes. The <I>read()</I> and <I>write()</I> methods of all the java.io classes implicitly deal with 8-bit bytes. The second option can discard data depending on the alignment of the last bitfield and/or its size, so that option is rejected too. I chose reading an arbitrarily aligned 8-bit bitfield as the new behavior for <I>read()</I>. Symmetry forced me to use analogous semantics for the <I>write()</I> methods. Similar reasoning led me to decide that <I>skip()</I> shall skip multiples of 8 bits (and not an arbitrary number of bits).

<H2>
Using the Bit-Stream Classes: Implementing LZW Compression </H2>

One common application of reading and writing bitfields is data compression. As a real-life test suite for the bit-stream classes, I present a straightforward implementation of the LZW data compression and decompression algorithm, as explained by Mark Nelson ("LZW Data Compression," <I>Dr. Dobb's Journal</I>, October 1989), and further refined by Shawn M. Regan ("LZW Revisited," <I>Dr. Dobb's Journal</I>, June 1990).

<P>
I ignored Mark's C source code and used his pseudocode listings to implement the <I>compress()</I> and <I>decompress()</I> methods in class LZW. At one point, Mark refers to having the "implementation blues." However, using my bit-stream classes and the <I>Hashtable</I> class in Java's java.util package, I found coding to be refreshingly simple. 

<P>
As Shawn clearly explained in his article, one optimization of the LZW algorithm is to use dynamic code sizing (that is, bitfield sizes). While both authors found this to be an additional obstacle (which Shawn tackled), I found that, because of the bit-stream classes' dynamic bitfield size capability coupled with class <I>Hashtable</I>'s unlimited capacity, the Java implementation did not share these obstacles.

<P>
The design of the LZW class (<A HREF="9718dlis.htm#4">Listing Four</A>) uses a helper class, <I>LZWDictionary</I> (<A HREF="9718dlis.htm#5">Listing Five</A>), to encapsulate the core LZW data structure: a two-way code-to-string/ string-to-code look-up structure. While the previous articles on LZW used fixed-sized arrays (in C) to implement this functionality, I simply use two Hashtable objects&#151;one per look-up direction. This implementation, therefore, does not have any "table full" conditions: class java .util.Hashtable transparently grows whenever necessary.

<H2>
Java Performance Blues
</H2>

You might wonder why I didn't create even more filter stream subclasses that encapsulated the LZW algorithm. This would most definitely result in an elegant set of compressing and decompressing stream classes. However, the LZWClient demonstration program (<A HREF="9718dlis.htm#6">Listing Six</A>) clearly suffers from lack of speed. Even on my vanilla Pentium/100 using the vanilla Sun JDK, it was obvious that Java was being stretched to its limits by this implementation of the LZW algorithm. Casting the algorithm further in the powerful (but inefficient) harness of a filter stream subclass would cripple the code beyond rescue.

<P>
Do the new bit-stream classes cause the bottleneck? If you run the LZWClient program with the <I>&#173;prof </I>JVM option, then study the resulting profiling report generated in the file java.prof, you'll see that the bit-stream classes and their expensive-looking bit manipulation operations are not the cause. The top cycle guzzlers are <I>Hashtable</I>'s <I>containsKey()</I> and <I>put(),</I> and <I>StringBuffer</I>'s <I>append()</I> and <I>toString()</I>. Class <I>StringBuffer</I>'s involvement without my program's explicit usage of this class might seem surprising. The explanation lies with the behind-the-scenes reliance of Java compilers on class <I>StringBuffer</I> to translate simple string concatenation expressions like <I>stringA + stringB</I> into<I>((newStringBuffer(stringA)).append(stringB)).toString()</I>. Method <I>LZW.compress()</I> does, indeed, use the concatenation operator ('+') to append every newly read source character to the current string, hence the numerous <I>append()</I> and <I>toString()</I> invocations. Because the performance hot spots are not located in the bit-stream classes, I leave the optimization challenge (and fun) to you. 

<H2>
Conclusion
</H2>

Subclassing Java's standard I/O classes is straightforward. It allows you to create I/O pipelines that incorporate your own filters and enhancers. The elegance with which both operations can be performed is testimony to Sun's enlightened investment in design rather than implementation. The only current annoyance is Java's overall lackluster run-time performance. Luckily, this is only a temporary blemish on the language: Sun's hardware implementations of the Java Virtual Machine architecture will soon be incorporated into PC hardware accelerator cards, finally silencing the performance issue and allowing Java to take the throne.<P>


<A HREF="9718dlis.htm"> Listings </A> 
<P>


</BODY>
</HTML>




