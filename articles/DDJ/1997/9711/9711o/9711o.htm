<html>
<META NAME="year" CONTENT="1997">
<head>
<title>Dr. Dobb's Journal November 1997: Programmer's Bookshelf</title>
</head>

<body bgcolor="FFFFFF">
<!--Copyright &#169; Dr. Dobb's Journal-->
<h1>Perusing the Bookshelf</h1>

<p><i>Dr. Dobb's Journal</i> November 1997
</p>
<h3>By Gregory V. Wilson</h3>

<I>Greg is the author of Practical Parallel Programming (MIT Press, 1995), and coeditor with Paul Lu of Parallel Programming Using C++ (MIT Press, 1996). Greg can be reached at gvwilson@interlog.com.</I>

<hr>

<H4><I>Object-Oriented Software Testing:</I> <BR>
<I>A Hierarchical Approach</I><BR>
<I>Shel Siegel</I><BR>
John Wiley &amp; Sons, 1996<BR>
511 pp., $42.95<BR>
ISBN 0-471-13749-9</H4>

<H4><I>UML and C++:</I> <BR>
<I>A Practical Guide to</I> <BR>
<I>Object-Oriented Development</I><BR>
<I>Richard C. Lee and</I> <BR>
<I>William M. Tepfenhart</I><BR>
Prentice-Hall, 1997<BR>
437 pp., $68.75<BR>
ISBN 0-13-619719-1</H4>

<H4><I>Software Metrics:</I> <BR>
<I>A Rigorous and </I><BR>
<I>Practical Approach</I> <BR>
<I>Second Edition</I><BR>
<I>Norman E. Fenton and</I> <BR>
<I>Shari Lawrence Pfleeger</I><BR>
International Thomson <BR>
Computer Press, 1997<BR>
638 pp., $51.95<BR>
ISBN 0-534-95600-9</H4>

<H4><I>Programming Python</I><BR>
<I>Mark Lutz</I><BR>
O'Reilly &amp; Associates, 1996<BR>
880 pp., $44.95<BR>
ISBN 1-56592-197-6</H4>

<H4><I>Computing Tomorrow:</I> <BR>
<I>Future Research Directions in Computer Science</I><BR>
<I>Ian Wand and Robin Milner (eds.)</I><BR>
Cambridge University Press, 1996<BR>
373 pp., $39.95<BR>
ISBN 0-521-46085-9</H4>

<p>Iam not too demanding as a reader. I just want authors to explain things clearly and concisely, without trying too hard to be funny or profound. A few tidy diagrams to help me get through the difficult bits are always appreciated, of course, as is a title that accurately reflects a book's contents. But what do I find when I look through the shelves at the World's Biggest Bookstore here in Toronto? Recycled confusion, badly organized hype, and people trying <i>way</i> too hard to be gurus.</p>

<h3><i>Object-Oriented Software Testing</i></h3>

<p>Shel Siegel's <i>Object-Oriented Software Testing</i> exemplifies the last of these sins. I should have been warned off by the blurb on the back, which describes Siegel as "a quality degapper" (whatever that means), or by the introduction, which begins, "You read this book differently than you read other technical books. This book is a system." But no, I had to spend $50 to find out how badly the author wants people to believe he's a deep thinker.</p>

<p>The approach Siegel takes is briefly entertaining. He describes testing procedures using the terminology and concepts of object-oriented programming -- a test script is-a optimization approach, a class-object test script is-a test script, and so on. However, what useful advice he offers on structuring code for testing, and on different types of tests, is drowned in "Vision" and "Leadership" statements. I read whole pages without knowing what point they were trying to make, or whether they were trying to make a point at all.</p>

<h3><i>UML and C++</i> </h3>

<p>Richard Lee and William Tepfenhart's <i>UML and C++</i> was, in contrast, such a relief that it took me a while to realize that its title is somewhat misleading. The Unified Modeling Language, or UML, is a proposed standard for object-oriented class and interaction diagrams that unifies several popular existing notations. I picked up <i>UML and C++</i> because I found the draft standard hard going, and the "official" books from the UML's inventors are still (as I write this) being written.</p>

<p>Disappointingly, much of <i>UML and C++</i> appears to have been written around, rather than about, the UML. For example, the authors talk about "object interaction diagrams" and "event trace diagrams," and only mention parenthetically or in a footnote that the UML calls these "collaboration diagrams" and "sequence diagrams," respectively. The authors' real focus is on their own object-oriented analysis and design methodology. I found this reasonably interesting -- I've only been using C++ for two years, and still have a lot to learn about how to design object-oriented programs -- but Lee and Tepfenhart don't seem to know whether they are trying to teach OO analysis to beginners or to compare their methodology with others for the benefit of experienced practitioners. And every once in a while, I tripped over an unwelcome attempt at profundity, such as:</p>

<blockquote><p>
If you take the Eastern, or Taoist, approach to object-oriented analysis, you will...not be concerned with the specific application that you are implementing...</p>
</blockquote><p>or:</p>

<blockquote><p>
...Taoist philosophy tells us to focus on capturing the objects in the problem domain rather than on the objects that will help us solve the immediate problem.</p>
</blockquote>

<p>Sadly, the authors don't tell us what Catholic or Sunni philosophy has to say about programming. It probably has something to do with the sinfulness of <i>goto</i> statements...</p>

<h3><i>Software Metrics</i> </h3>

<p>Norman Fenton and Shari Pfleeger's <i>Software Metrics</i> shows what good technical writing can be. <i>Software Metrics</i> is not just a thorough, readable survey of the various proposals that have been made over the years for measuring the characteristics of programs; it is also a detailed critique of the sloppy way in which people have tried to use such measurements to predict how much effort would be required to develop and maintain software, and how reliable that software would be.</p>

<p>The first part of <i>Software Metrics</i> introduces the fundamentals of measurement theory. What does it mean to measure something? What kinds of measures are there, and -- more importantly -- what kinds of conclusions can we draw from different kinds of measurements? The second part of the book looks at software measurement in particular. Popular measures (COCOMO, function points, cyclometric complexity, and the like) are all described, and their weaknesses pointed out. Again and again, the authors show that the proponents of various metrics have failed to validate their metrics in even the most basic ways, and that many of their conclusions are, therefore, invalid. While writing this review, I read a prime example of what they are criticizing in the June 1997 issue of <i>C++ Report</i>. In fewer than ten pages, an author commits almost all of the crimes that Fenton and Pfleeger describe, and earns plaudits from the journal's editor for doing so.</p>

<p>Part Three looks at implementing software measurement in the workplace, and includes an interesting discussion about the nature of empirical research in software engineering. The book closes with a comprehensive annotated bibliography. If you have ever thought about measuring the progress of a software project, or about trying to predict the effort required to develop or maintain a program, this book will tell you what is feasible, what is just hype, and how to tell the difference between the two.</p>

<h3><i>Programming Python</i></h3>

<p>Mark Lutz's <i>Programming Python</i> is an equally good book, although very different in tone and approach. Python is a scripting language, similar in design and purpose to Perl, Tcl, and Visual Basic. It is well structured, with object orientation built in from the beginning, is freely available, and runs almost everywhere.</p>

<p>I hope that <i>Programming Python</i> will help win Python many new converts. Like most O'Reilly &amp; Associates books, it is well written, superbly edited, and informative. Lutz introduces the Python language and its major libraries (of which there are many), and shows how to embed Python in C and vice versa. There are many example programs, all clearly explained, and a CD-ROM with the whole Python release for Windows, Macintosh, and UNIX.</p>

<p>Despite its good qualities, Python is, and probably always will be, an example of Parkinson's Other Law, which states that "Perfection is achieved only at the point of collapse." Python appeared on the scene after its competitors were already established. It is my personal favorite among "glue" languages (a term attributed to John Ousterhout, who talks about the relative productivity gains due to OO and glue at http://inwww.sunlabs.com/people/john.ousterhout/scripting.html), and, if it had existed in 1985, its competitors would probably never have gotten off the ground, but its advantages are not so great as to persuade the hundreds of thousands of VB, Perl, and Tcl programmers out there to switch.</p>

<h3><i>Computing Tomorrow</i></h3>

<p>Finally, I came across <i>Computing Tomorrow</i>, edited by Ian Wand and Robin Milner, by accident, and am glad I did. Computing in the United States is fairly insular: Except for a few big-name events like the Japanese Fifth Generation Project, American programmers pay little attention to developments overseas. This collection of essays by prominent British computer scientists is, therefore, a refreshing introduction to alternative perspectives.</p>

<p>Most of the contributions were both informative and entertaining. Among these were Gazdar's discussion of the state of natural language processing, and Needham's acerbic look at the history of network design. </p>

<p>While the Cambridge Ring network might not be familiar to many American readers, Needham's observations on the paradigm gap between those who think that networks should behave like telephones and those who think of them as buses will probably continue to ring true ten years from now.</p>

<p>Even better were Littlewood's look at the meaning of software dependability and Peyton Jones' essay on how scaling up research projects to meet the demands of real use can lead to new research problems. Littlewood's contention is that software is not like other products of engineering, and so its reliability cannot be assessed using the methods developed for such things as metal fatigue. Software is "pure design," and software faults are almost always design faults. The study of software reliability should therefore look more at how people communicate than at code-based prediction of errors per thousands of lines of code.</p>

<p>Peyton Jones' closing essay, "On the Importance of Being the Right Size," should be read by every academic doing computer systems research, and (more importantly) by every member of the funding bodies that give such people their research grants. Drawing on his own experience with functional languages, Peyton Jones argues that the lessons learned from small research projects can be misleading, and that wholly new research topics can arise in the course of scaling up a compiler, an operating system, or a user interface to handle real-world issues.</p>

<p>Some of the other essays, which were condensed tutorials on topics such as algorithmic complexity, were a bit frustrating, since 20-odd pages isn't enough space to get a big idea across to anyone who doesn't already understand it. However, the many individual insights buried in these chapters still made them worth browsing.</p>

<p><b>DDJ</b></p>


<HR><I>Copyright &copy; 1997, Dr. Dobb's Journal</I><BR>

</BODY>
</html>
