<html>
<META NAME="year" CONTENT="1997">
<head>
<title>Dr. Dobb's Journal February 1997: UNIX Filesystems without I-Nodes</title>
</head>

<body bgcolor="FFFFFF">
<!--Copyright &#169; Dr. Dobb's Journal-->
<h1>UNIX Filesystems without I-Nodes</h1>

<p><i>Dr. Dobb's Journal</i> February 1997
</p>
<h2>NCP and SMP support in Linux</h2>

<h3>By Volker Lendecke</h3>

<I>Volker, who implemented the ncpfs and smbfs filesystems for the Linux kernel, studies mathematics and computer science at the University of G&ouml;ttingen, Germany. He can be contacted at lendecke@math.unigoettingen.de.</I>

<hr>

<p>Along with nfs, the Linux kernel smbfs and ncpfs filesystems make it possible to link Linux machines to virtually any file server -- from Pathworks to Windows NT 4.0, from NetWare to any NFS server -- across a LAN. When I was implementing smbfs and ncpfs, however, it became clear that Microsoft's Server Message Block (SMB) protocol is not designed to handle UNIX clients like Linux. SMB, the protocol that implements file services, is designed for DOS. Consequently, SMB has no notion of an i-node, the central structure in every UNIX file-system implementation. On the surface, this would appear to limit Linux's usefulness on heterogeneous networks. However, in this article, I present techniques I developed to work around this limitation.</p>

<h3>UNIX Filesystems</h3>

<p>The user's view of a UNIX filesystem is straightforward: Everything is arranged in a hierarchy of directories. But this hierarchical order does not reflect the filesystem's layout on disk. In reality, all things that can be stored in a filesystem -- normal files, directories, named pipes, device files, and so on -- are represented by i<sub></sub>nodes. An i-node stores everything the system needs to know about a file -- owner, size, permission bits, time stamps, and pointers to the file's data. Basically, the i<sub></sub>node is the file. You might expect to find the file name in the i-node, but you won't. The name is stored elsewhere. I<sub></sub>nodes are arranged in a large array stored at the beginning of a disk partition, or scattered around within the partition. The filesystem can only reference i<sub></sub>nodes via their numbers, the indexes into the i<sub></sub>node table.</p>

<p>The illusion of a hierarchical filesystem is created by the directory, a special type of file. On disk, directories look much like normal files; they have an i<sub></sub>node and data bytes. Their data simply consists of a list of filenames paired with i<sub></sub>node numbers. These pairs of names and i<sub></sub>nodes are what users see as files. The difference between normal files and directories is that users are not allowed to access the directories. If a program manipulated directories, the UNIX system could not maintain its hierarchical structure. This loose coupling between a file's name and the file itself is the reason you can have two different names for a single file. You just create two directory entries pointing to the same i<sub></sub>node; the names can even be in different directories. Moving files in the filesystem is also simple: Create a filename with the file's i<sub></sub>node number in the target directory and delete the file's entry in the source directory. In short, a file gets an i<sub></sub>node number when it is created. This i<sub></sub>node number remains constant during the lifetime of the file, no matter where you move it in the directory tree.</p>

<p>This central role of i<sub></sub>nodes can also be seen in the implementation of the Linux virtual filesystem (vfs). In fact, the i<sub></sub>node structure (see <a name="rf1"><a href="9702gf1.htm">Figure 1</A>) is the most important object in the Linux vfs. An i<sub></sub>node is read from a table on disk when the corresponding file is opened the first time, or when the user wants information about the file. For example, the command <i>ls -l</i> reads every file's i<sub></sub>node and shows the metadata of each file it lists. The i<sub></sub>node is written back when the last process that accessed the file closes it. All other operations that can be performed on a file, including read/writes, refer to the i<sub></sub>node.</p>

<h3>Drawbacks for Linux</h3>

<p>Both Microsoft's SMB protocol and early versions of Novell's NetWare Core Protocol (NCP) were designed to redirect all file-access functions of the DOS INT 0x21 to the server. The native DOS filesystem (that is, the FAT system) has no notion of i<sub></sub>nodes. FAT does not separate filenames from the files themselves. The meta data of the files is stored in the directory the file resides in together with its name. Because no i<sub></sub>nodes or i<sub></sub>node numbers are needed to implement the INT 0x21 interface, neither SMB nor NCP provide i<sub></sub>node numbers. All that is transferred over the network is the pathname of a file. In NCP, you can allocate 1-byte handles for parts of the path. But these handles cannot be used as i<sub></sub>node numbers, as they are too short and do not uniquely identify a file.</p>

<p>To implement a filesystem for Linux, you have to implement <i>read_inode()</i>. The upper layers of the Linux filesystem (implemented in the linux/fs/*.c source files) hand an i<sub></sub>node number to this function and expect the actual file-system implementation to fill a prepared i<sub></sub>node structure with the values the i<sub></sub>node has on disk. But what do you do when you can't ask the file server to give you "the size of the file with i<sub></sub>node 1234" because the server doesn't know anything about i<sub></sub>node 1234? That's the problem I faced when implementing a filesystem for Linux. Clearly, I had to find a way to fool the Linux kernel.</p>

<p>When writing smbfs and ncpfs, I had to identify all points in the Linux vfs layer that rely on the fact that a file is essentially an i<sub></sub>node with a fixed i<sub></sub>node number. I did not expect to find only two vfs routines to deal with i<sub></sub>node numbers: <i>lookup()</i> and <i>read_inode().</i> (<i>create()</i> is a third, but it works exactly as <i>lookup()</i> does.) The kernel asks <i>lookup()</i> for the i<sub></sub>node of a file, giving it the filename and the directory to search. <i>lookup()</i> finds the i<sub></sub>node number of the specified file, then calls <i>iget()</i> to read the i<sub></sub>node. <i>iget()</i> is a higher-level function that maintains a cache of i<sub></sub>nodes. When it does not find the requested i<sub></sub>node in its cache, it calls <i>read_inode()</i> with the i<sub></sub>node number it just got from <i>lookup()</i>.</p>

<p>So smbfs and ncpfs have to make sure that <i>lookup()</i> generates unique i<sub></sub>node numbers for all the i<sub></sub>nodes <i>iget()</i> holds in memory. And <i>lookup()</i> needs a way to tell <i>read_inode()</i> about the i<sub></sub>node numbers it has generated artificially. The Linux kernel doesn't care about the i<sub></sub>node number stored on disk or anywhere else. The i<sub></sub>nodes in memory are those that are referenced as open files from one or more processes and are the current working directory of a process. The numbers of all other i<sub></sub>nodes can be randomly chosen. The only problem that remains is determining how the filesystem should choose the i<sub></sub>node numbers. </p>

<p>One solution is to generate them randomly. However, this does not provide uniqueness. Another idea is to increment a counter whenever an i<sub></sub>node number is requested. But as Linux systems are expected to run for a long time and must therefore cope with wraparound, a list of numbers in use must be maintained. This is inefficient. The fastest solution turns out to be the simplest: The Linux kernel already has an extremely reliable number generator perfectly suited for this purpose -- <i>kmalloc()</i>.</p>

<h3>The <i>kmalloc()</i> Approach</h3>

<p>Normally, when a file-system type is added to Linux, the global i<sub></sub>node structure is augmented by the fields that are needed by the new type. This can be found in the file linux/include/fs.h. When I was developing smbfs on the stabilized kernel 1.2.13, this was not an option, because I wanted to run these filesystems as modules without kernel modifications. Additionally, the structures needed by smbfs and ncpfs are quite large, and I did not want to penalize all other filesystems with such a large structure. So I chose to store the smbfs/ncpfs-specific i<sub></sub>node data in a special <i>kmalloc()</i> structure. Now it's very fast to find unique i<sub></sub>node numbers: I simply use the address of the allocated structure. We know this number is unique across all filesystems and it references the corresponding structure without overhead.</p>

<p>I<sub></sub>node numbers are generated in the vfs function <i>lookup()</i>. This function allocates the special file<sub></sub>system<sub></sub>specific structure and gives its address as the i<sub></sub>node number to the kernel routine <i>iget()</i>. <i>iget()</i> finds that the i<sub></sub>node is not in memory yet and calls <i>read_inode</i> with the wanted number. <i>read_inode</i> is now able to find the file<sub></sub>system<sub></sub>specific data by a type cast. The routine <i>put_inode</i> can reliably <i>kfree</i> the data, and <i>free</i> the i<sub></sub>node number for later use.</p>

<p>This scheme works well from a kernel point of view. The first smbfs implementation used exactly this mechanism. Then the first users complained that the command <i>pwd</i> could not find the current working directory. As the kernel did not complain about any inconsistent structure, the i<sub></sub>node numbering scheme seemed to be insufficient. The <i>getwd</i> routine, used by <i>pwd</i>, runs as follows: It works its way back to the root directory via the ".." entries of the directories. It stores the i<sub></sub>nodes of all the directories it finds on its way to the root. Then it reads all the directories as <i>ls</i> would, and compares the i<sub></sub>node numbers it gets with the ones found on the way to the root. Directories are read until the current directory is found. Not really efficient, but under UNIX it's the only way to find the path to the current directory. </p>

<p>It should now be clear why the numbering scheme I implemented has to fail for <i>getwd</i>: Each time a directory is opened for reading, a new i<sub></sub>node number is created for it. So <i>getwd</i> has no chance to reconstruct the path to the current directory. To help <i>getwd</i>, not only do the i<sub></sub>nodes used by the kernel need fixed and unique numbers, but so do all the i<sub></sub>nodes that are parents and grandparents of any i<sub></sub>node used, up to the filesystem's mount point. Thus ncpfs and smbfs build up a tree of i<sub></sub>nodes that represents the directory structure currently in use. When an i<sub></sub>node is released (because the corresponding file is closed or the directory has been left by <i>cd</i>, for example), the corresponding file-system structure is <i>free()</i>ed. Now the path to the root of the mount point is traversed and each directory's file-system structure is released when it is not used by other parts of the directory tree.</p>

<p>By this enhanced scheme, <i>getwd</i> can be satisfied, but some as-yet-unfixed problems remain. In most cases, when you do a <i>ls -i</i> in an ncpfs-mounted directory, each directory entry is assigned the same i<sub></sub>node number. This is caused by the kernel <i>malloc</i> routine. When you <i>kfree()</i> a memory area and <i>kmalloc()</i> a memory block of the same size directly after, you get the same chunk of memory, resulting in identical i<sub></sub>node numbers for all directory entries. This is especially annoying because the nfs daemon relies on unique i<sub></sub>node numbers across the complete filesystem. </p>

<p>Another command that is broken by this scheme is an implementation of the <i>diff</i> command that tests whether the files have the same i<sub></sub>node, then refuses to compare the files if the numbers are the same. <i>cp</i> is another candidate: Sometimes it refuses to copy a file over an existing file, because it believes both to be the same file.</p>

<h3>Namespaces: NetWare has I<sub></sub>Nodes</h3>

<p>Again, Novell's NCP protocol was designed to implement DOS filesystem functionality. But when clients such as OS/2 and UNIX were used, NetWare had to cope with different notions of a filename. Although OS/2 and UNIX allow filenames that don't conform to the 8.3 convention, they do not agree about case sensitivity. To be able to cope with these needs, Novell introduced the concept of namespaces for NetWare 3. To handle namespaces, the NetWare core protocol was enhanced considerably.</p>

<p>From the protocol view, the NetWare 3 filesystem looks similar to UNIX filesystems. NetWare also seems to store i<sub></sub>nodes, which Novell calls "Directory Entries." The Directory Entry Table fulfills the same purpose as UNIX i<sub></sub>node tables. This central table contains everything relevant about a file, such as its size, its owner, and a reference to the file's data. The NCP namespace services let you access entries in this table and, thus, individual files by their indexes into this table. These indexes are 32 bits long and could be called the "i<sub></sub>node numbers" of the files.</p>

<p>There is one main directory entry per file, the original DOS filename entry. Each loaded namespace module adds another entry for each file. This is a complete directory entry of its own and, as such, also has a unique 32-bit number. It contains the filename according to the conventions the namespace expects, along with the number of the DOS filename entry. For example, the NFS namespace module stores up to 255 bytes of the filename, and knows that uppercase and lowercase filenames are different. </p>

<p>When a file is created, it is always created in a special namespace. For example, Windows 95 creates all files in the OS/2 namespace, giving the file a long filename. This file has to be visible from all other namespaces, so the other entries have to be created by NetWare itself. NetWare squeezes the name into the 8.3 scheme required by DOS and creates the corresponding DOS directory entry. Windows 95 has to do the same for the VFAT filesystem, where each file has an 8.3 filename in addition to its long filename. When a DOS workstation creates a file, NetWare does not have to truncate the filename, but it still has to create the additional entries in all the namespaces loaded. For volumes with many small files, the way namespaces are used can cause problems because lots of additional directory entries are allocated.</p>

<p>You can look at the namespace information with the NDIR program that Novell delivers with NetWare. When you call NDIR with the option /L, it will display the long filenames that are assigned to the files. Windows 95 only shows you the OS/2 and DOS namespace filenames, but NDIR will also show you the NFS and other namespace's filenames.</p>

<p>The namespace support of NetWare now makes it possible to solve the problem with the i<sub></sub>node numbers, as the protocol gives you 32-bit directory-entry numbers that uniquely identify files and directories in the NetWare filesystem. As in UNIX filesystems, where i<sub></sub>node numbers identify a file only within a filesystem, directory-entry numbers always refer to a NetWare filesystem, a volume. There might be two different files in different volumes with the same directory-entry number, as it is perfectly possible in UNIX. So to provide unique i<sub></sub>node numbers for ncpfs-mounted directories, you have to mount a single volume under one mount point. When you do this, the directory-entry numbers that NetWare shows the client via the NCP protocol are handed to user processes as i<sub></sub>node numbers, and user programs can rely on the i<sub></sub>node numbers to be unique on the complete filesystem. This way, the filesystems mounted can be reexported by nfs. </p>

<p>I implemented this as an option only, because it is possible that some NetWare servers have a lot of volumes, which would require many mount points for the complete server to be mounted. This could be expensive, since currently each ncpfs mount point uses one NetWare user license. The other issue is that standard Linux kernels allow only 64 mount points, which could be quickly exhausted. It's much cheaper to raise the Linux limit than the NetWare limit, but it's inconvenient. Consequently, you can still mount all volumes under one mount point, but you lose the reexportability.</p>

<h3>The Code</h3>

<p>In general, the techniques I've described here are implemented in the ncpfs and smbfs kernel code, as well as parts of the general Linux vfs layer. More specifically, the files dir.c and inode.c (available electronically; see "Availability," page 3) are excerpts from the ncpfs code that illustrates the concepts I've presented. The latest versions of smbfs and ncpfs can always be found via http://www.kki.org/linux-lan/.</p>


<p><b>DDJ</b></p>


<HR><I>Copyright &copy; 1997, Dr. Dobb's Journal</I><BR>

</BODY>
</html>
