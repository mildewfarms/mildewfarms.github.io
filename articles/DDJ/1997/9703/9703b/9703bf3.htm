<html>
<META NAME="year" CONTENT="1997">
<head>
<title>Dr. Dobb's Journal March 1997: Genetic Algorithms</title>
</head>

<body bgcolor="FFFFFF">
<!--Copyright &#169; Dr. Dobb's Journal-->
<h2>Genetic Algorithms </h2>
<h3><i>By Satinder Singh, Peter Norvig, and David Cohn </i></h3>
<p><i>Dr. Dobb's Journal</i> March 1997 </p>

<img src="9703bf3.gif">
<H4>Figure 3: (a) Utility (over a finite agent lifetime), defined as the expected sum of the immediate reward and the long-term reward under the best possible policy. s<sub>t</sub> is the state at time step t, Reward(s<sub>t</sub>,a) is the immediate reward of executing action a in state s<sub>t</sub>, N is the number of steps in the lifetime of the agent, and Reward<sub>t</sub> is the reward at time step t. The operator E{.} stands for taking an expectation over all sources of randomness in the system; (b) utility (over an infinite lifetime), defined similarly as (a). To avoid the mathematical awkwardness of infinite sums, we introduce a discount factor, 0 <img src="lteq10.gif" width="5" height="7"> <img src="gamma10.gif" width="5" height="7">&lt; 1, which counts future rewards less than immediate rewards. This is similar to the compound interest that banks use. </H4>


<p><a href="9703b.htm#rf3">Back to Article</A></p>

<HR><I>Copyright &copy; 1997, Dr. Dobb's Journal</I><BR>

</BODY>
</html>
