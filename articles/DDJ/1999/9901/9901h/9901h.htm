<html><head><title>Jan99: Dynamically Reconfigurable Servers</title></head><BODY BGCOLOR="#ffffff" TEXT="#000000" LINK="#0000ff" VLINK="#330066" ALINK="#FF0000">
<!--Copyright &#169; Dr. Dobb's Journal--><h1>Dynamically Reconfigurable Servers</h1><p><i>Dr. Dobb's Journal</i> January 1999</p><h2>Python's extensibility makes it easy</h2><h3>By Ron Klatchko</h3><I>Ron is manager of the Advanced Technology Group at the Center for Knowledge Management, University of California at San Francisco. He can be contacted at ron@ckm.ucsf.edu.</I><hr><p>With the advent of the Web, it is more important than ever to have systems that run continuously. It is always business hours somewhere in the world; there is no good time to bring down servers for maintenance. Over the life of the server, it may be necessary to import new data and code. Using the techniques I present here, it is relatively easy to implement servers that can import new modules and data at run time. This dynamically reconfigurable server -- available electronically (see "Resource Center," page 5) -- is implemented in Python, a portable, interpreted, extensible object-oriented programming language. Although the server I implement here runs on UNIX, Python runs on many platforms, including most flavors of UNIX, Windows, Macintosh, and OS/2. It is freely copyable and can be used without fee in commercial products. For more information (and source code) on Python, see http://www.python.org/. </p><p>Here at the UCSF Library and Center for Knowledge Management (CKM), I needed to implement a server that could verify that a user was associated with the campus. The initial requirements only specified students, staff, and faculty, but eventually would include postdoctorate researchers and employees from the clinical enterprise. I needed to have the server up and running before getting either the schema or data for the new groups. Since the server needed to be available 24-hours a day, it needed to dynamically add new code modules and data sets without being shut down.</p><h3>Dynamic Servers: Theory</h3><p>Dynamic servers are partitioned into a core engine and extension modules. The extension modules need to implement a common API so that the core engine can communicate with them. To keep the system flexible, the API should be kept as generic as possible. I have found that the most productive design is based on classes with a high-level interface. In my design, the server verifies users by comparing their provided credentials against entries from the different data sets. The core engine chooses several candidate user objects and keeps only those whose credentials match the user-supplied credentials. Each user type may require different types and numbers of credentials, and the credentials might be stored in varying formats (for example, student PINs that are one-way encrypted with UNIX's <i>crypt()</i>). Each extension module implements a class with a single entry point; this method takes an array of credentials and returns a Boolean indicating whether the credentials match the user. By delegating the entire verification process to the class, there is no need to require common fields or storage requirements for the different types.</p><p>Another important capability is being able to load a new class at run time. Python does this via the <i>import</i> statement. Unlike the Java statement of the same name or the C/C++ <i>include</i> statement, Python's version is a run-time command -- it instructs the interpreter to load the named module. Although the <i>import</i> statement does not directly support specifying the module via a string, you can use the <i>exec</i> statement to overcome this. <A NAME="re1"><A HREF="9901he1.htm">Example 1</A> defines a Python function that takes the name of the module you want to import, imports it into the module's namespace, and returns a reference to the module. Because Python treats all references identically, you can use the return value just like the name of a module you imported normally. Finally, you need to be able to access data or call code in your newly imported module. Depending on how you designed your API, you will need to proceed in one of two ways. If you have chosen constant names for your API, Python's use of references and late binding lets you access data, functions, and classes in your module directly (see <A NAME="re2"><A HREF="9901he2.htm">Example 2</A>). Although this is convenient, I find it confusing to have different classes with the same name.</p><p>Another option is to relate the module name to your API names. Python allows code to access module level references using the <i>__dict__</i> variable. Dictionaries are Python's implementation of associative arrays (also known as "hashes"). Once you have looked up a class reference, you still need to instantiate an object via the <i>()</i> operator (see <A NAME="re3"><A HREF="9901he3.htm">Example 3</A>). The syntax for dynamic references can be confusing. Working left to right and considering what each operator returns lets you understand the syntax. From the example, <i>mod.__dict__</i> accesses the namespace dictionary for the module. The <i>[]</i> operator does a lookup on the dictionary and returns a reference. Since the reference is for a class, you instantiate an object with the <i>()</i> operator.</p><h3>The <i>Shelve</i> Module</h3><p>The <i>shelve</i> module lets you skip all the dirty work. <i>Shelve</i> is a basic implementation of a persistent object store. It lets you store Python data structures (including user-defined classes) on disk. When you retrieve an object, <i>shelve</i> loads the module that implements the object's class.</p><p>You can use this power to greatly simplify writing a dynamic server. To add a new class to your server, just put the implementation module in the server's search path and add an object of the new class to <i>shelve</i>. When your server accesses the object, the new module will be loaded into your server. As long as the class supports your standard API, the server can immediately use the new object.</p><h3>Concurrent Access to Data</h3><p>Another issue you must handle in keeping your server continuously running is updating your data on the fly. One standard way to do this is using reader/writer locks. These locks allow many processes to read a file simultaneously, but only a single one to write it. Python's <i>fcntl</i> module provides access to reader/writer locks via file locking.</p><p>Anytime a write lock is held on your database, your server is unavailable; therefore, I wouldn't advise holding a write lock for an extended period of time. Unfortunately, it's sometimes not possible to release the write lock in a timely fashion. Here at the UCSF Library and CKM, our data feeds come from other parts of the campus. Rather then getting changes, I receive complete data snapshots. Replacing an old snapshot with the newly received one was easier than analyzing the differences and updating the current data. To do this, you must ensure the entire data file can be switched over atomically, so that the server will never attempt to access a partially written database.</p><h3>File Consistency via UNIX Inodes</h3><p>The standard UNIX filesystem uses inodes as an extra layer of indirection between a file's name and its contents. A filename references an inode, while an inode keeps a count of how many references there are to it and points to the file's contents; see <A NAME="rf1"><A HREF="9901hf1.htm">Figure 1</A>. Both filesystem entries and file-opening processes effectively increment the reference count (see <A NAME="rf2"><A HREF="9901hf2.htm">Figure 2</A>). The UNIX kernel looks up the inode when the <i>open()</i> call is made; from then on, the kernel has no further need of the filename. This use of reference counting helps maintain filesystem coherency. On UNIX, it is safe to delete a file while a process has it opened; the filesystem will not recycle the blocks the file is on until the process closes the file.</p><p>Understanding whether a UNIX system call interacts with a file's inode or with its content is key in implementing this process. If a file already exists, <i>open()</i> will preserve the file's inode and modify its contents. If you already have a new file available, you can use <i>rename()</i> to change the inode a filename refers to. <i>rename</i> takes a current filename and a new filename. If the new filename already exists, it decrements the reference count for its inode (and recycles the contents if it reaches 0); it then has the new filename point to the inode the current filename references, and removes the directory entry for the current filename. Finally, <i>unlink()</i> removes the directory entry for the specified filename and decrements the underlying inode's reference count. This should apply to most flavors of UNIX, although I have only verified it against Solaris 2.6 with the ufs filesystem and Red Hat Linux 5.0 (2.0.32) with the ext2 filesystem.</p><p>Let's examine what happens when you rename a file that a process has open. In <A NAME="rf3"><A HREF="9901hf3.htm">Figure 3</A>(a), <i>filename1</i> references <i>inode1</i>; a process had opened <i>filename1</i> so the process also has a reference to <i>inode1</i>; since both <i>filename1,</i> and a file descriptor reference the inode, it has a reference count of 2. After calling <i>rename</i> and specifying <i>filename2</i> as the current name and <i>filename1</i> as the new name, you have the situation pictured in <A HREF="9901hf3.htm">Figure 3</A>(b). <i>Filename1</i> now references <i>inode2</i> while the process continues to reference <i>inode1</i>; as long as the process keeps the file descriptor open, it will have access to the original file contents. Once the process closes the file descriptor, the file contents referenced by <i>inode1</i> will be recycled. The next time the process opens <i>filename1</i>, it will get the new contents.</p><p>Using a temporary filename before renaming keeps the current data set available even if problems arise. If a failure occurs when creating the new file, the original contents are still available with the correct name. If for some unforeseen reason, the server process needs to be restarted while the update process is running, a full set of data is available. It also allows for the concurrent update of multiple data files. Because the data feeds came from different departments, I found it easier to store students and employees in separate databases. Although I start each update processes simultaneously, each process continues at its own pace. Instead of needing to cooperate in communicating with the server, the server can reload all the data files each time a new file is ready.</p><h3>Simple IPC Using Signals</h3><p>Once the external process has updated the data file, the main process must be notified so it can use the new data. UNIX provides simple interprocess communication with signals. A process registers a function to be called upon signal arrival either with <i>sigaction()</i> or <i>signal()</i>. Other processes can send a signal with <i>kill()</i>. Since signals arrive asynchronously, you need to make sure that it is safe to change data files. Due to its cross-platform implementation, Python only implements common signal functionality; it does not allow you to temporarily block signals. There are a few strategies to deal with this; one of the simplest is to set a flag upon signal arrival and check for the flag in a place you know can safely reload the data files.</p><h3>Conclusion</h3><p>At this writing, my server has been running for six months without being shut down. In this time, is has gone through numerous data reloads and the addition of a new module -- neither of which has required any downtime. Application of the techniques I have presented here can allow your server to do the same.</p><p><b>DDJ</b></p><HR><I>Copyright &copy; 1999, Dr. Dobb's Journal</I><BR>
</body></html>