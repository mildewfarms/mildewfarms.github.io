<HTML>
<META NAME="year" CONTENT="1990">
<HEAD>

<TITLE>APR90:  BIDIRECTIONAL ASSOCIATIVE MEMORY SYSTEMS IN C++</TITLE></HEAD>
<body bgcolor="FFFFFF">
<h1> BIDIRECTIONAL ASSOCIATIVE MEMORY SYSTEMS IN C++<a name="00a4_0003"><a name="00a4_0003"></h1><P>
<h2><a name="00a4_0001"><a name="00a4_0000">Recent innovation makes associative memory practical for real-world problems</h2><P>
<h3>Adam Blum</h3><P>
<p><i><a name="00a4_0002"><a name="00a4_0000">Adam is a programmer analyst at Ketron Inc. of Arlington, Virginia, and is the principal developer of several commercial software packages.  His interests include compiler design, C++, and (of course) applications of neural nets.  He can be contacted at 1700 N. Moore St., Ste. 1710, Arlington, VA 22209, or on CompuServe at 72650, 1773.</i></p><hr><P>
Content-addressability was always a goal of early neural network pioneers.  It is a quest that has been pursued by computer scientists in general for decades.  However, the goal has proved highly elusive.  Search time has always depended on the amount of data stored, although much research has gone into reducing the slope of this curve.  Real-time pattern recognition (as applied to any number of fields, be it speech recognition, radar signature identification, or part classification) is still far from reality.  One particular neural-network construct, bidirectional associative memory (or BAM), has promised some solution to this problem.<P>
I'll first describe the BAM concept, then show you how a relatively recent construct, the Bam System, can make it immediately feasible for real problems.  Finally, I'll present an actual implementation of the Bam System written in C++.<P>
As developed by Bart Kosko, BAMs are a neural-network-based attempt at content-addressable memories.  They are based on a two-layer feedback neural network.  They attempt to encode m pattern pairs (A<SUB>i</SUB>,B<SUB>i</SUB>) where A<SUB>i</SUB> <img src="e12.gif"> {-1,+1}<SUP>n</SUP> and B<SUB>i</SUB> <img src="e12.gif"> {-1,+1}<SUP>p</SUP> in an n x p matrix M.  BAMs are globally stable and provide instant recall of either of the two-pattern pair elements.  However, BAMs face some limitations.  For large pattern lengths, n, storage requirements increase O(n<SUP>2</SUP>).  More importantly, storage capacity is only, on an average, m &lt; min(n,p).  Thus, for moderate pattern lengths, capacity of the matrix M becomes a problem. Recent research promises help for this problem.  However, some initial description of BAMs should be made.<P>
<h3><a name="00a4_0004">Encoding<a name="00a4_0004"></h3><P>
BAM encoding is accomplished by simply summing the correlation matrices of each of the pattern pairs.  That is, the matrix that encodes the first m pattern pairs, M, is simply:<P>
<pre>    
    m   
M = <img src="sum12.gif"> A<SUB>i</SUB><SUP>T</SUP>B<SUB>i</SUB>
   i=1
</pre><P>
Thus, to encode a pattern pair, simply produce its correlation matrix, A<SUB>i</SUB><SUP>T</SUP>B<SUB>i</SUB>, and add the values to the current matrix M.  For discrete implementations, it so happens that the matrix arithmetic works out better if 0s and 1s are encoded as -1s and +1s.  So the first step in the process will be to convert any {0,1} string to {-1,+1}.  <a href="9004a.htm#00a4_0005">Example 1</A> shows this process.<P>
<h4><a name="00a4_0005"><a name="00a4_0005">Example 1: The encoding process</h4><P>
<pre></pre><P>
If we are trying to encode<P>
<pre>
      A<SUB>1</SUB> = (101010) B<SUB>1</SUB> = (1100)
      A<SUB>2</SUB> = (111000) B<SUB>2</SUB> = (1010)
</pre><P>
we first convert to {-1,+1}.<P>
<pre>
      X<SUB>1</SUB> = (1 -1 1 -1  1 -1)      Y<SUB>1</SUB> = (1  1 -1 -1)
      X<SUB>2</SUB> = (1  1 1 -1 -1 -1)      Y<SUB>2</SUB> = (1 -1  1 -1)

                 X<SUB>1</SUB><SUP>T</SUP>Y<SUB>1</SUB> = 1  1 -1 -1
                        -1 -1  1  1
                         1  1 -1 -1
                        -1  1  1  1
                         1  1 -1 -1
                        -1 -1  1  1

              X<SUB>1</SUB><SUP>T</SUP>Y<SUB>2</SUB> = 1 -1  1 -1
                      1 -1  1 -1
                      1 -1  1 -1
                     -1  1 -1  1
                     -1  1 -1  1
                     -1  1 -1  1

                  M = 2  0  0 -2
                      0 -2  2  0
                      2  0  0 -2
                     -2  2  0  2
                      0  2 -2  0
                     -2  0  0  2
</pre><P>
Note that we can erase association (A<SUB>i</SUB>,B<SUB>i</SUB>) from M by adding -X<SUB>i</SUB>TY<SUB>i</SUB> to M.  But if we are using a {-1,+1} representation, this is the same as adding (A<SUB>i</SUB>,B<SUB>i</SUB>C) or (A<SUB>i</SUB>C,B<SUB>i</SUB>) to M (where C represents the pattern's complement).  This fact will become important in our implementation of the BAM system.<P>
<P>
<h3><a name="00a4_0006">Decoding<a name="00a4_0006"></h3><P>
After we have &quot;trained&quot; our BAM with the m pattern pairs (A<SUB>i</SUB>,B<SUB>i</SUB>), we want the BAM to recall pattern B<SUB>i</SUB> every time A<SUB>i</SUB> is presented to the matrix (and, conversely, recall A<SUB>i</SUB> every time B<SUB>i</SUB> is presented to the matrix).  It turns out that BAMs also have the property that B<SUB>i</SUB> will be recalled every time something close to A<SUB>i</SUB> is presented.  <a href="9004a.htm#00a4_0007">Example 2</A> outlines the steps involved in the decoding process.<P>
<h4><a name="00a4_0007"><a name="00a4_0007">Example 2: The decoding process</h4><P>
<pre></pre><P>
Each neuron b<SUB>j</SUB> in field Fb (Fa and Fb will be used to refer to the two pattern fields A and B) receives a gated input of all the neurons in Fa with a nonlinear threshold function applied.  In our bipolar discrete example a typical function might be:<P>
<pre>
  f(x,y) = 1 if x &gt; 0
  y if x = 0
  0 if x &lt; 0
</pre><P>
We now have a pattern B<SUB>1</SUB>.  However, we aren't done yet.  The output from pattern B is then fed back through the transpose of matrix M to produce pattern A<SUB>1</SUB>.  That is, each neuron A<SUB>i</SUB> in A receives gated input from each neuron B<SUB>j</SUB> in B and applies the same threshold function to it.<P>
<pre></pre><P>
A<SUB>1</SUB> is then sent back through the matrix again to produce B<SUB>2</SUB>, and on this goes.<P>
<pre>
  A --&gt; F(AM) --&gt; B<SUB>1</SUB>
  A<SUB>1</SUB> &lt;-- F(B<SUB>1</SUB>M<SUP>T</SUP>) &lt;-- B<SUB>1</SUB>
  A<SUB>1</SUB> --&gt; F(A<SUB>1</SUB>M) --&gt; B<SUB>2</SUB>
		.
		.
  A<SUB>i</SUB> --&gt; F(A<SUB>i</SUB>) --&gt; B<SUB>i</SUB>
  A<SUB>i</SUB> --&gt; F(B<SUB>i</SUB>M) --&gt; B<SUB>i</SUB>
</pre><P>
<P>
But it won't go on forever.  As shown in <a href="9004a.htm#00a4_0007">Example 2</A>, eventually the fields will &quot;resonate&quot; to steady patterns.  This property of BAMs is called &quot;global stability.&quot;  Lyapunov energy functions allow us to prove that BAMs are globally stable.<P>
<h3><a name="00a4_0008">Energy Functions and Stability<a name="00a4_0008"></h3><P>
Lyapunov showed that any function expressed in terms of the system parameters that is zero at the origin and has nonincreasing changes is globally stable.<P>
An energy function for the BAM can be E(A,B)= -AWB<SUP>T</SUP>.  This function is obviously zero at the origin (that is, zero when A and B are zero).  We just need to show that it has nonincreasing changes.  Well, <img src="delta12.gif">E<SUB>A</SUB>(A,B)= -AWB<SUP>T</SUP> and by the definition of our function f, each A<SUB>i</SUB> in A will be positive only if W<SUB>i</SUB>B is positive.  If A<SUB>i</SUB> is negative, W<SUB>i</SUB>B must also be negative.  Thus the change in energy will always be negative or zero.  The system is thus globally stable.<P>
<h3><a name="00a4_0009">Adaptive BAM<a name="00a4_0009"></h3><P>
As we have just described it, the connection matrix M is simply the sum of the correlation matrices of the patterns presented to it.  We can use more sophisticated equations to allow faster convergence or more accurate recall.  As long as such equations can also be shown to converge, we should have no problem with this.<P>
The simplest of these learning laws is called Hebb's law: m<SUB>ij</SUB> = -m<SUB>ij</SUB> + f<SUB>i</SUB>(x<SUB>i</SUB>) * f<SUB>j</SUB>(y<SUB>j</SUB>), where m<SUB>ij</SUB> is the connection weight between the neuron x<SUB>i</SUB> and neuron y<SUB>j</SUB>, and f<SUB>i</SUB> and f<SUB>j</SUB> are the threshold activation functions for x and y, respectively.<P>
Other laws that could be used include competitive learning and differential Hebb; there is much research on which of these is most effective.  In our implementation, we will be presenting a simple nonadaptive BAM.  However, it is easily extensible to the learning function of choice.<P>
<h3><a name="00a4_000a">Problems<a name="00a4_000a"></h3><P>
BAM faces two problems, the first of which is that the amount of storage taken up varies O(n<SUP>2</SUP>), where n is the pattern length (actually, it will vary O(np) where n is pattern length of A and p is pattern length of B).<P>
The second problem -- capacity -- is more critical.  Reliable retrieval of associations begins to degrade when the number of patterns stored, m, is greater than the minimum of the two-pattern dimensions.  In other words, to be reliable the matrix capacity is m &lt; min(n,p).<P>
For large pattern lengths, this is not so much of a problem, but many applications have inherently moderate pattern lengths.  We intuitively find it almost obvious that if a BAM can store only up to the minimum of its pattern lengths, it will be virtually useless for real-world applications.<P>
<h3><a name="00a4_000b">BAM Systems<a name="00a4_000b"></h3><P>
In 1989, Patrick Simpson of General Dynamics published a paper introducing the concept of a &quot;BAM System.&quot;  This is a rather uninformative name for a system that allows for multiple matrices when one matrix's capacity is saturated.  Perhaps a better name would be &quot;Multi-Matrix BAM&quot; or, because each matrix is just a representation of the connectivity between the two patterns, &quot;Multi-Connective BAM.&quot;  Anyway, it is an inventive way to overcome the severe problem of matrix capacity.<P>
The Bam System operates as follows: Pattern pairs are encoded one by one in a single BAM matrix, M<SUB>1</SUB>.  After each pattern pair is encoded, the matrix must be tested to ensure that each pattern pair stored can be recalled.  If a pattern pair cannot be recalled, the current pair is removed from the matrix.  We then attempt to store the pair in another connection matrix.  We continue to try to store it in other matrices M<SUB>i</SUB>, until it is stored such that all pattern pairs in that matrix can be recalled successfully.  The pattern association is then permanently stored in this matrix.<P>
Decoding, that is presenting one-half of a pattern and recalling the other half of the pair, is a bit more complicated.  Because we now have several matrices storing pattern associations, we don't know which one is the correct one to look in to recall the pattern pair.  To choose which pattern pair to recall from each matrix, we use the following criterion.<P>
We determine all the returned pattern pairs (X<SUB>i</SUB>,Y<SUB>i</SUB>) that have the same energy as the pair (A,Y<SUB>i</SUB>) (where A is the presented pattern).  Of these patterns we choose that pattern pair whose energy is closest to the matrix's orthogonal BAM energy.  (Orthogonal BAM energy is the energy a matrix would have if all its stored patterns were orthogonal, which turns out to be equal to the negative of the product of the pattern lengths, E* = -np.  Energy of a pattern pair can be calculated the same way as in our previous discussions, E =-XMY<SUP>T</SUP>, where X and Y are the two patterns.)<P>
There are some problems with the Bam System.  In order to keep checking that the patterns were stored reliably in each matrix (without corrupting the other patterns already in the matrix) the patterns need to be stored separately.  Also, the need to compute the &quot;best&quot; recall from each of the BAM matrices could be computationally prohibitive.  Parallel hardware (which, presumably, a BAM would be running on anyway) could possibly ease this burden.<P>
<h3><a name="00a4_000c">The Implementation<a name="00a4_000c"></h3><P>
C++ provides an excellent tool for implementing neural nets in general and BAMs in particular.  Most of the constructs in this discussion of BAMs were vectors and matrices.  This is a classic application of object-oriented programming.  Classes for vectors and matrices should go a long way toward making the implementation easier.  <a href="9004a.htm#00a4_0011">Listing One</A>  (page 84) is BAM.HPP, the BAM header file that contains the class definitions.  <a href="9004a.htm#00a4_0013">Listing Two</A> (page 84) is BAM.CPP, the BAM program file that contains the BAM implementation.<P>
The vector class is implemented in classic fashion (almost identical to Stroustrup's). Methods are provided for assignment, multiplication by scalar constant, and dot product.  This is all that is really necessary, but a few more methods are provided for completeness. Streams input and output are provided to read the patterns in and display patterns to the user.  The streams functions do the necessary (0,1) to (-1, +1) conversion discussed earlier.<P>
The matrix class is implemented as an array of pointers (int **), with indicators of the number of rows and columns.  It could conceivably have been implemented as an array of vector objects.  I chose representation for efficiency.  There are several constructors provided. The first simply initializes the matrix from specified dimensions.  These dimensions default to the particular application's two pattern lengths (specified by the ROWS and COLS constants).  Other constructors are provided to form a matrix from a pair of vectors by multiplying one vector by the transpose of another (M=AB<SUP>T</SUP>).  Standard matrix arithmetic functions are included.  Methods are also provided to form a vector from a row or column &quot;slice&quot; of the matrix.  Streams output is provided for debugging diagnostics.<P>
Another fundamental construct is the pattern pair.  This is, after all, what the BAM lets us do -- retrieve pattern associations.  Pattern pairs are represented by the &quot;vecpair&quot; (vector pair) class.  An &quot;encode&quot; operation will encode a vecpair.  A &quot;recall&quot; operation will return a vecpair, when supplied with a pattern (or &quot;vec&quot;).<P>
Once we have these vector, matrix, and vector pair classes, implementing the BAM is fairly simple.  The BAM is essentially just a matrix.  We use the C++ inheritance mechanism to inherit the matrix and all its functions.  We made the matrix's data structures &quot;protected&quot; instead of &quot;private&quot; so the derived BAM matrix class could use the matrix's data structures. We now just add a vecpair pointer for the pattern pair list and the BAM matrix functions.<P>
These consist mainly of the &quot;encode&quot; and &quot;recall&quot; functions central to the BAM.  Encode simply takes the &quot;vecpair&quot; corresponding to the association and adds it (with matrix add) to the current BAM.  Recall &quot;feeds&quot; the presented pattern through the matrix (with dot products and by applying a threshold function as discussed earlier) to return another vector.  We keep feeding the vectors back and forth until they stabilize to a consistent pattern association. There are also some auxiliary functions for checking the integrity of the BAM, returning its energy for a particular association (as discussed earlier), and for &quot;uncoding&quot; or removing an association from the BAM.<P>
The Bam System class consists of an array of pointers to BAM matrices.  Each time a BAM matrix is saturated, a new matrix is created, and the new pattern association is stored in it.  The major functions are again &quot;encode&quot; and &quot;recall.&quot;  Encode attempts to store the pattern association in each of the BAM matrices until it succeeds.  It will create a new BAM matrix if it runs out of matrices.  Recall performs a BAM matrix recall operation on each of the BAM matrices.  The returned association that is closest to the presented pattern and has the lowest energy relative to its matrix (as discussed earlier) is then returned as the &quot;correct&quot; pattern association.  Another function is provided to &quot;train&quot; the Bam System from a specified file of pattern associations.  The patterns happen to be represented as 01 strings, but this could be easily changed to whatever representation (for example, floating-point numbers, character strings) suits the specific application.<P>
Thanks to the wonders of C++, the code is very readable.  Most of the algorithms can be implemented in the same vocabulary as the theory.  Take a look at it to examine the mechanics in detail.  It should even be clearer (and certainly more specific) than the discussion above.<P>
<h3><a name="00a4_000d">The Test Program<a name="00a4_000d"></h3><P>
I've included a test program (TESTBAM.CPP, <a href="9004a.htm#00a4_0015">Listing Three</A>, page 88) that demonstrates an actual running Bam System.  A Bam System is created and told to &quot;train&quot; itself from the file TEST.FIL (see <a href="9004a.htm#00a4_0017">Listing Four</A>, page 88).  This file contains a set of simple &quot;pattern pairs,&quot; represented as (0,1) strings delimited by commas -- one pattern pair to a line.  Once the Bam System is trained, you can enter any pattern you want (using the 01 format mentioned) and the correct pattern association will be recalled.  If the pattern is slightly wrong, the correct pattern association will still most likely be recalled.  The make file, TESTBAM.MK (<a href="9004a.htm#00a4_0019">Listing Five</A>, page 88), shows how to construct this test program.<P>
<h3><a name="00a4_000e">What Can you Do With It?<a name="00a4_000e"></h3><P>
Uses of the Bam System are constrained only by your imagination.  Obvious uses include optical character recognition (the pixel patterns scanned in would be associated with the actual letters), voice recognition (the acoustic pattern would be associated with the actual word), or a super spell checker (word patterns associated with phonemestring patterns).  You can use a Bam System in just about any application where you have a large number of &quot;associations&quot; that you would like to be able to recall close to instantaneously, and where some tolerance for error would be useful.<P>
A successful application of BAM for radar signature classification was presented at the January 1990 International Joint Conference on Neural Networks (IJCNN).  However, it was not a Bam System, and the implementors had to resort to various other tricks to get around capacity limitations.  Several other associative memory applications appeared; but none of them were associative memory systems.  They all would probably run into the capacity roadblock eventually for large data sets.  Associative memories and BAMs have begun to appear implemented in VLSI, but again the capacity will prove to be a limitation for practical work. Bam Systems should have a radical effect on the usefulness of these chips.<P>
<h3><a name="00a4_000f">Conclusion<a name="00a4_000f"></h3><P>
Bidirectional associative memories appear to provide the content-addressable memory long sought after by computer scientists.  They provide instant recall of pattern association, tolerance for error and fuzziness in the provided pattern, and global stability.  However, by themselves they face some limitations.  Simple BAM matrices cannot encode more pattern pairs than the smaller of their two dimensions.  Some applications have inherently smaller pattern length, and, for them, matrix capacity will prove to be a severe limitation.  However, the Bam System appears to overcome this problem, making associative memory a reality.<P>
<h3><a name="00a4_0010">Notes<a name="00a4_0010"></h3><P>
Grossberg, S. The Adaptive Brain, I &amp; II. Boston, Mass.: Reidel Press, 1982.<P>
Kohonen, T. Self-Organization and Associative Memory.  Berlin, W. Germany: Springer-Verlag, 1977.<P>
Kosko, B. &quot;Bidirectional Associative Memories,&quot; IEEE Trans. Systems, Man, Cybernetics, Vol. SMC-L8, 49-60, Jan./Feb. 1988.<P>
Rumelhart, D.E., McClelland, J.L., eds., Parallel Distributed Processing, I &amp; II. Cambridge, Mass.: MIT Press, 1986.<P>
Simpson, P.K. &quot;Bidirectional Associative Memory Systems,&quot; Heuristics, 1989.<P>
Simpson, P.K., &quot;Associative Memory Systems,&quot; Proceedings of the International Joint Conference on Neural Networks, January 1990.<P>

BIDIRECTIONAL ASSOCIATIVE MEMORY SYSTEMS IN C++
by Adam Blum

<a name="00a4_0011"><a name="00a4_0011">
<a name="00a4_0012"></pre><B>[LISTING ONE]</B><pre><a name="00a4_0012">

////////////////////////////////////////////////////////////
// BAM.HPP  Provide vector, matrix, vector pair, matrix, BAM matrix, and
// BAM system classes and methods to implement BAM system concept.
// Extended note:
// This is an implementation of the concept of Bidirectional
// Associative Memories as developed by Bart Kosko and others.
// It includes the extended concept introduced by Patrick Simpson
// of the &quot;BAM System&quot;. Where reasonable Simpson's notation has been
// been maintained. The presentation benefits greatly from C++ and OOP, in that
// (I believe) it is both easier to understand than a &quot;pseudocode&quot; version,
// yet more precise (in that it works!)
// Developed with Zortech C++ Version 2.0 -- Copyright (c) Adam Blum, 1989,90

#include&lt;stdlib.h&gt;
#include&lt;io.h&gt;
#include&lt;stdio.h&gt;
#include&lt;string.h&gt;
#include&lt;limits.h&gt;
#include&lt;ctype.h&gt;
#include&lt;stream.hpp&gt;
#include &quot;debug.h&quot; // debugging devices
// where are Zortech's min,max?
#define max(a,b)   (((a) &gt; (b)) ? (a) : (b))
#define min(a,b)   (((a) &lt; (b)) ? (a) : (b))

// will be changed to much higher than these values
const ROWS=16;   // number of rows (length of first pattern)
const COLS=8;   // number of columns (length of second pattern)
const MAXMATS=10; // maximum number of matrices in BAM system
const MAXVEC=16; // default size of vectors

class matrix;
class bam_matrix;
class vec {
   friend class matrix;
   friend class bam_matrix;
   friend class bam_system;
      int n;
      int *v;
   public:
      // see BAM.CPP for implementations of these
      vec(int size=MAXVEC,int val=0); // constructor
      ~vec();   // destructor
      vec(vec &amp;v1); // copy-initializer
      int length();
      vec&amp; operator=(const vec&amp; v1); // vector assignment
      vec&amp; operator+(const vec&amp; v1); // vector addition
      vec&amp; operator+=(const vec&amp; v1); // vector additive-assignment
      vec&amp; operator*=(int i); // vector multiply by constant
      // supplied for completeness, but we don't use this now
      int operator*(const vec&amp; v1); // dot product
      vec operator*(int c); // multiply by constant
      // vector transpose multiply needs access to v array
      int operator==(const vec&amp; v1);
      int&amp; operator[](int x);
      friend istream&amp; operator&gt;&gt;(istream&amp; s,vec&amp; v);
      friend ostream&amp; operator&lt;&lt;(ostream&amp; s, vec&amp; v);
}; //vector class

class vecpair;

class matrix {
   protected:
   // bam_matrix (a derived class) will need to use these members
   // preferred to &quot;friend class&quot;, since there may be many derived
   // classes which need to use this
      int **m; // the matrix representation
      int r,c; // number of rows and columns
   public:
      // constructors
      matrix(int n=ROWS,int p=COLS);
      matrix(const vec&amp; v1,const vec&amp; v2);
      matrix(const vecpair&amp; vp);
      matrix(matrix&amp; m1); // copy-initializer
      ~matrix();
      int depth();
      int width();
      matrix&amp; operator=(const matrix&amp; m1);
      matrix&amp; operator+(const matrix&amp; m1);
      matrix&amp; operator+=(const matrix&amp; m1);
      vec colslice(int col);
      vec rowslice(int row);
      friend ostream&amp; operator&lt;&lt;(ostream&amp; s,matrix&amp; m1);
}; // matrix class

class vecpair {
   friend class matrix;
   friend class bam_matrix;
   friend class bam_system;
      int flag; // flag signalling whether encoding succeeded
      vec a;
      vec b;
   public:
      vecpair(int n=ROWS,int p=COLS); // constructor
      vecpair(const vec&amp; A,const vec&amp; B);
      vecpair(const vecpair&amp; AB); // copy initializer
      ~vecpair();
      vecpair&amp; operator=(const vecpair&amp; v1);
      int operator==(const vecpair&amp; v1);
      friend istream&amp; operator&gt;&gt;(istream&amp; s,vecpair&amp; v);
      friend ostream&amp; operator&lt;&lt;(ostream&amp; s,vecpair&amp; v);
      friend matrix::matrix(const vecpair&amp; vp);
};

class bam_matrix: public matrix {
   private:
      int K; // number of patterns stored in matrix
      vecpair *C; // actual pattern pairs stored
      int feedthru(const vec&amp;A,vec&amp; B);
      int sigmoid(int n); // sigmoid threshold function
   public:
      bam_matrix(int n=ROWS,int p=COLS);
      ~bam_matrix();
      // but we supply it with the actual matrix A|B (W is implied)
      void encode(const vecpair&amp; AB); // self-ref version
      // uncode only necessary for BAM-system
      void uncode(const vecpair&amp; AB); // self-ref version
      vecpair recall(const vec&amp; A);
      int check();
      int check(const vecpair&amp; AB);
      // Lyapunov energy function: E=-AWBtranspose
      int energy(const matrix&amp; m1); // Lyapunov energy function
}; // BAM matrix

class bam_system {
      bam_matrix *W[MAXMATS];
      int M; // number of matrices
   public:
      bam_system(int M=1);
      ~bam_system();
      void encode(const vecpair&amp; AB);
      vecpair&amp; recall(const vec&amp; A);
      // train equiv. to Simpson's encode of all pairs
      void train(char *patternfile);
      friend ostream&amp; operator&lt;&lt;(ostream&amp; s,bam_system&amp; b);
}; // BAM system class




<a name="00a4_0013"><a name="00a4_0013">
<a name="00a4_0014"></pre><B>[LISTING TWO]</B><pre><a name="00a4_0014">

///////////////////////////////////////
// BAM.CPP Provide vector, matrix, vector pair, matrix, BAM matrix, and BAM
// system classes to implement BAM systems
// Extended note:
// This is an implementation of the concept of Bidirectional
// Associative Memories as developed by Bart Kosko and others.
// It includes the extended concept introduced by Patrick Simpson
// of the &quot;BAM System&quot;. Where reasonable Simpson's notation has been
// been maintained. The presentation benefits greatly from C++ and OOP, in that
// (I believe) it is both easier to understand than a &quot;pseudocode&quot; version,
// yet more precise (in that it works!)
// Developed with Zortech C++ Version 2.0 -- Copyright (c) 1989,90 Adam Blum

#include&quot;bam.hpp&quot;

///////////////////////////////////
// vector class member functions

vec::vec(int size,int val) {
   v = new int[size];
   n=size;
   for(int i=0;i&lt;n;i++)
      v[i]=0;
} // constructor
vec::~vec() { delete v;} // destructor
vec::vec(vec&amp; v1) // copy-initializer
{
   v=new int[n=v1.n];
   for(int i=0;i&lt;n;i++)
      v[i]=v1.v[i];
}
vec&amp; vec::operator=(const vec&amp; v1)
{
   delete v;
   v=new int[n=v1.n];
   for(int i=0;i&lt;n;i++)
      v[i]=v1.v[i];
   return *this;
}
vec&amp; vec::operator+(const vec&amp; v1)
{
   vec sum(v1.n);
   sum.n=v1.n;
   for(int i=0;i&lt;v1.n;i++)
      sum.v[i]=v1.v[i]+v[i];
   return sum;
}
vec&amp; vec::operator+=(const vec&amp; v1)
{
   for(int i=0;i&lt;v1.n;i++)
      v[i]+=v1.v[i];
   return *this;
}
vec vec::operator*(int c)
{
   vec prod(length());
   for(int i=0;i&lt;prod.n;i++)
      prod.v[i]=v[i]*c;
   return prod;
}
int vec::operator*(const vec&amp; v1) // dot-product
{
   int sum=0;
   for(int i=0;i&lt;min(n,v1.n);i++)
      sum+=(v1.v[i]*v[i]);
   //D(cout &lt;&lt; &quot;dot product &quot; &lt;&lt; *this &lt;&lt; v1 &lt;&lt; sum &lt;&lt; &quot;\n&quot;;)
   return sum;
}
int vec::operator==(const vec&amp; v1)
{
   if(v1.n!=n)return 0;
   for(int i=0;i&lt;min(n,v1.n);i++){
      if(v1.v[i]!=v[i]){
         return 0;
      }
   }
   return 1;
}
int&amp; vec::operator[](int x)
{
   if(x&lt;length() &amp;&amp; x&gt;=0)
      return v[x];
   else
      cout &lt;&lt; &quot;vec index out of range&quot;;
}
int vec::length(){return n;} // length method

istream&amp; operator&gt;&gt;(istream&amp; s,vec &amp;v)
// format: list of ints followed by ','
{
   char c;
   v.n=0;
   v.v=new int[MAXVEC];
   for(;;){
      s&gt;&gt;c;
      if(s.eof())return s;
      if(c==',')return s;
      if(isspace(c))continue;
      v.v[v.n++]=((c!='0')?1:-1);
   }
}
ostream&amp; operator&lt;&lt;(ostream&amp; s, vec&amp; v)
// format: list of ints followed by ','
{
   for(int i=0;i&lt;v.n;i++)
      s &lt;&lt; (v.v[i]&lt;0?0:1);
   s &lt;&lt; &quot;,&quot;;
   return s;
}

///////////////////////////////
// matrix  member functions
matrix::matrix(int n,int p)
{
   //D(cout &lt;&lt; &quot;Constructing &quot; &lt;&lt; n &lt;&lt; &quot; x &quot; &lt;&lt; p &lt;&lt; &quot; matrix.\n&quot;;)
   m=new int *[n];
   for(int i=0;i&lt;n;i++){
      m[i]=new int[p];
      for(int j=0;j&lt;p;j++)
         m[i][j]=0;
   }
   r=n;
   c=p;
} // constructor
matrix::matrix(const vecpair&amp; vp)
{
   //D(cout &lt;&lt; &quot;Constructing matrix from: &quot; &lt;&lt; vp;)
   r=vp.a.length();
   c=vp.b.length();
   m=new int *[r];
   for(int i=0;i&lt;r;i++){
      m[i]=new int[c];
      for(int j=0;j&lt;c;j++)
         m[i][j]=vp.a.v[i]*vp.b.v[j];
   }
}// constructor
matrix::matrix(const vec&amp; v1,const vec&amp; v2)
{
   //D(cout &lt;&lt; &quot;Constructing matrix from &quot; &lt;&lt; v1 &lt;&lt; v2 &lt;&lt; &quot;\n&quot;;)
   r=v1.length();
   c=v2.length();
   m=new int *[r];
   for(int i=0;i&lt;r;i++){
      m[i]=new int[c];
      for(int j=0;j&lt;c;j++)
         m[i][j]=v1.v[i]*v2.v[j];
   }
}// constructor
matrix::matrix(matrix&amp; m1) // copy-initializer
{
   //D(cout &lt;&lt; &quot;matrix copy-initializer\n&quot;; )
   r=m1.r;
   c=m1.c;
   m=new int *[r];
   for(int i=0;i&lt;r;i++){
      m[i]=new int[c];
      for(int j=0;j&lt;c;j++)
         m[i][j]=m1.m[i][j];
   }
}
matrix::~matrix()
{
   for(int i=0;i&lt;r;i++)
      delete m[i];
   delete m;
} // destructor
matrix&amp; matrix::operator=(const matrix&amp; m1)
{
   for(int i=0;i&lt;r;i++)
      delete m[i];
   r=m1.r;
   c=m1.c;
   m=new int*[r];
   for(i=0;i&lt;r;i++){
      m[i]=new int[c];
      for(int j=0;j&lt;r;j++)
         m[i][j]=m1.m[i][j];
   }
   return *this;
}
matrix&amp; matrix::operator+(const matrix&amp; m1)
{
   matrix sum(r,c);
   for(int i=0;i&lt;r;i++)
      for(int j=0;j&lt;r;j++)
         sum.m[i][j]=m1.m[i][j]+m[i][j];
   return sum;
}
matrix&amp; matrix::operator+=(const matrix&amp; m1)
{
   //D(cout &lt;&lt; &quot;matrix additive assignment\n&quot;;)
   for(int i=0;i&lt;r&amp;&amp;i&lt;m1.r;i++)
      for(int j=0;j&lt;c&amp;&amp;j&lt;m1.c;j++)
         m[i][j]+=(m1.m[i][j]);
   return *this;
}
vec matrix::colslice(int col)
{
   vec temp(r);
   for(int i=0;i&lt;r;i++)
      temp.v[i]=m[i][col];
   return temp;
}
vec matrix::rowslice(int row)
{
   vec temp(c);
   for(int i=0;i&lt;c;i++)
      temp.v[i]=m[row][i];
   return temp;
}
int matrix::depth(){return r;}
int matrix::width(){return c;}

ostream&amp; operator&lt;&lt;(ostream&amp; s,matrix&amp; m1)
// print a matrix
{
   for(int i=0;i&lt;m1.r;i++){
      for(int j=0;j&lt;m1.c;j++)
         s &lt;&lt; m1.m[i][j] &lt;&lt; &quot; &quot;;
      s &lt;&lt; &quot;\n&quot;;
   }
}
//////////////////////////////////////////
// vecpair  member functions
// constructor
vecpair::vecpair(int n,int p) { }
vecpair::vecpair(const vec&amp; A,const vec&amp; B) {a=A;b=B;}
vecpair::vecpair(const vecpair&amp; AB) {*this=vecpair(AB.a,AB.b);}
vecpair::~vecpair() {} // destructor
vecpair&amp; vecpair::operator=(const vecpair&amp; v1)
{
   a=v1.a;
   b=v1.b;
   return *this;
}
int vecpair::operator==(const vecpair&amp; v1)
{
   return    (a == v1.a) &amp;&amp; (b == v1.b);
}
istream&amp; operator&gt;&gt;(istream&amp; s,vecpair&amp; v1)
// input a vector pair
{
   s&gt;&gt;v1.a&gt;&gt;v1.b;
   return s;
}
ostream&amp; operator&lt;&lt;(ostream&amp; s,vecpair&amp; v1)
// print a vector pair
{
   return s&lt;&lt;v1.a&lt;&lt;v1.b&lt;&lt;&quot;\n&quot;;
}
/////////////////////////////////
//bam_matrix  member functions
bam_matrix::bam_matrix(int n,int p):(n,p)
{
   // the maximum number of pattern pairs storable
   // is around min(n,p) where n and p are
   // the dimensionality of the matrix
   C=new vecpair[min(n,p)*2];
   K=0;
}
bam_matrix::~bam_matrix()
{
} // destructor
void bam_matrix::encode(const vecpair&amp; AB)
// encode a pattern pair
{
   //D(cout &lt;&lt; &quot;BAM Matrix encoding: &quot; &lt;&lt; AB;)
   matrix T(AB);
   (*this)+=T; // add the matrix transpose to the current matrix
   C[K]=AB;
   K++;
}
void bam_matrix::uncode(const vecpair&amp; AB)
// get rid of a stored pattern (by encoding A-B complement)
{
   //D(cout &lt;&lt; &quot;uncode\n&quot;;)
   vec v=AB.b*-1;
   matrix T(AB.a,v); // T is A transpose B complement
   *this+=T;// add the matrix transpose to the current matrix
   K--;
}
vecpair bam_matrix::recall(const vec&amp; A)
// BAM Matrix recall algorithm (used by BAM SYSTEM recall)
{
   int givenrow=(A.length()==width());
   D(cout&lt;&lt;&quot;BAM matrix recall of&quot; &lt;&lt; A &lt;&lt; givenrow?&quot;(row)\n&quot;:&quot;(col)\n&quot;;)
   vec B(givenrow?depth():width(),1);
   for(;;){ // feed vectors through matrix until &quot;resonant&quot; pattern-pair
      feedthru(A,B);
      if(feedthru(B,A))break; // stop when returned A = input A
   }
   D(cout&lt;&lt; &quot;resonant pair &quot; &lt;&lt; A &lt;&lt; &quot;\n and &quot; &lt;&lt; B &lt;&lt; &quot;\n&quot;;)
   if(givenrow)
      return vecpair(B,A);
   else
      return vecpair(A,B);
}
int bam_matrix::feedthru(const vec&amp;A,vec&amp; B)
{
   //D(cout &lt;&lt; &quot;Feeding &quot; &lt;&lt; A &lt;&lt; &quot;\n&quot;; )
   vec temp=B;int n;
   for(int i=0;i&lt;B.length();i++){
      if(A.length()==width())
         n=sigmoid(A*rowslice(i));
      else
         n=sigmoid(A*colslice(i));
      if(n)
         B.v[i]=n;
   }
   return B==temp;
}
int bam_matrix::sigmoid(int n)
// VERY simple (but classic one for BAM) threshold function
//
//         1   --------------
//              |
//  - -----------      +
//        -1
{
   if(n&lt;0)return -1;
   if(n&gt;0)return 1;
   return 0;
}
int bam_matrix::check()
// check to see if we have successfully encoded pattern-pair into this matrix
{
   D(cout &lt;&lt; &quot;Check BAM matrix for &quot; &lt;&lt; K &lt;&lt; &quot; pattern pairs\n&quot;;)
   vecpair AB;
   for(int i=0;i&lt;K;i++){
      AB=recall(C[i].a);
      if(!(AB==C[i])){
         D(cout &lt;&lt;&quot;failed check\n &quot;;)
         return 0;
      }
   }
   D(cout &lt;&lt; &quot;passed check\n &quot;;)
   return 1;
}
int bam_matrix::check(const vecpair&amp; AB)
{
   // different check routine for orthogonal construction BAM
   //check to see energy of present pattern pair to matrix
   // is equal to orthogonal BAM energy
   matrix T(AB);
   return energy(T)== -depth()*width();
}
int bam_matrix::energy(const matrix&amp; m1)
{
   int sum=0;
   for(int i=0;i&lt;depth();i++)
      for(int j=0;j&lt;width();j++)
         sum+=(m1.m[i][j]*this-&gt;m[i][j]);
   D(cout &lt;&lt; &quot;Energy of matrix &quot; &lt;&lt; -sum &lt;&lt; &quot;\n&quot;;)
   return -sum;
}

///////////////////////////////////////////
// bam system  functions
// top level of system (for now)

// constructor
bam_system::bam_system(int n)
{
   M=n;
   for(int i=0;i&lt;M;i++)
      W[i]=new bam_matrix;
}
bam_system::~bam_system() // destructor
{
   for(int i=0;i&lt;M;i++)
      delete W[i];
}
void bam_system::encode(const vecpair&amp; AB)
// encode the pattern pair AB into the BAOM system
{
   D(cout &lt;&lt; &quot;BAM System encode\n&quot;;)
   for(int h=0;h&lt;M;h++){
      W[h]-&gt;encode(AB);
      if(!W[h]-&gt;check())
         W[h]-&gt;uncode(AB);
      else
         break;
   }
   if(h==M){ // all matrices full, add another
      if(h&lt;MAXMATS){
         W[M]=new bam_matrix();
         W[M]-&gt;encode(AB);
         M++;
      }
      else{
         cout &lt;&lt; &quot;BAM System full\n&quot;;
         exit(1);
      }
   }
}
vecpair&amp; bam_system::recall(const vec&amp; A)
// presented with pattern A, recall will return pattern-PAIR
{
   vecpair XY[MAXMATS];matrix *M1,*M2;
   int E,minimum=0,emin=INT_MAX;
   D(cout &lt;&lt; &quot;BAM System recall\n&quot;;)
   for(int h=0;h&lt;M;h++){
      XY[h]=W[h]-&gt;recall(A);
      D(cout &lt;&lt; h &lt;&lt;&quot;-th matrix, returned vecpair &quot;&lt;&lt; XY[h];)
      M1=new matrix(XY[h]);
      E=W[h]-&gt;energy(*M1);
      if(A.length()==W[h]-&gt;width())
         M2=new matrix(XY[h].a,A);
      else
         M2=new matrix(A,XY[h].b);
      if (  ( E-(W[h]-&gt;depth()*W[h]-&gt;width()) &lt; emin )
              &amp;&amp; (E==W[h]-&gt;energy(*M2))
      )
      {
         emin=E-(W[h]-&gt;depth()*W[h]-&gt;width());
         minimum=h;
      }
      delete M1;
      delete M2;
   }
   return XY[minimum];
}
void bam_system::train(char *patternfile)
// A &quot;multiple-pair&quot; encode - which Simpson calls &quot;encode&quot;
// this could be used for initial BAM Sys training. However an up
// and running BAM Sys should only need to use &quot;encode&quot;.
{
   FILE *f=fopen(patternfile,&quot;r&quot;);int n=0;
   filebuf sfile(f);
   istream s(&amp;sfile,0);
   vecpair AB;
   for(;;){
      s &gt;&gt; AB;
      if(s.eof())break;
      D(cout &lt;&lt; &quot;Encoding &quot; &lt;&lt; n++ &lt;&lt; &quot;-th pattern pair:\n&quot; &lt;&lt; AB;)
      encode(AB);
   }
   D(cout &lt;&lt; &quot;Completed training from &quot; &lt;&lt; patternfile;)
}
ostream&amp; operator&lt;&lt;(ostream&amp; s,bam_system&amp; b)
// operator to print out contents of entire BAM system
{
   for(int i=0;i&lt;b.M;i++)
      s&lt;&lt; &quot;BAM Matrix &quot; &lt;&lt; i &lt;&lt; &quot;: \n&quot; &lt;&lt; *(b.W[i]) &lt;&lt; &quot;\n&quot;;
}




<a name="00a4_0015"><a name="00a4_0015">
<a name="00a4_0016"></pre><B>[LISTING THREE]</B><pre><a name="00a4_0016">

////////////////////////
// TESTBAM.HPP
// Interactive BAM System Demonstration Program. Used to verify BAM system
// algorithms and demonstrate them on an abstract (i.e. just 0s and 1s) case.
// Developed with Zortech C++ 2.0 -- Copyright (c) 1989,90 Adam Blum

#include&quot;bam.hpp&quot;

vec v;
vecpair AB;
bam_system B;
char *p;
char patternfile[16]=&quot;TEST.FIL&quot;; // file where test data is stored
int trace=0; // SET TRACE=&lt;whatever&gt; at DOS prompt to turn trace on
main()
{
     cout &lt;&lt; &quot;Interactive BAM System Demonstration\n&quot;;
     trace=(p=getenv(&quot;TRACE&quot;))?1:0;
     cout &lt;&lt; &quot;Training from &quot; &lt;&lt; patternfile &lt;&lt; &quot;\n&quot;;
     B.train(patternfile);
     D(cout &lt;&lt; &quot;Resulting BAM System\n&quot; &lt;&lt; B;)
     cout &lt;&lt;&quot;Enter patterns as 0's and 1's terminated by comma.\n&quot;
     &lt;&lt;&quot;Patterns must be length of &quot; &lt;&lt; ROWS &lt;&lt; &quot; or &quot; &lt;&lt; COLS &lt;&lt;&quot;.\n&quot;
     &lt;&lt; &quot;Null vector (just &quot;&quot;,&quot;&quot;) to end.\n\n&quot; ;
     for(;;){
          cout &lt;&lt; &quot;Enter pattern: &quot;;
          cin &gt;&gt; v;
          if(!v.length())break;
          if(v.length()!=ROWS &amp;&amp; v.length()!=COLS){
               cout &lt;&lt; &quot;Wrong length.\n&quot;;
               continue;
          }
          AB=B.recall(v);
          cout &lt;&lt; &quot;Recalled pattern pair\n&quot; &lt;&lt; AB;
     }
}




<a name="00a4_0017"><a name="00a4_0017">
<a name="00a4_0018"></pre><B>[LISTING FOUR]</B><pre><a name="00a4_0018">


1100101011010011,11101010,
0110110111110110,11010101,
1101111001010101,11110010,
1010101000010111,11001101,
0011001101011011,11110100,
1100101011010011,11101010,
0110100111110110,11010101,
1101110101010101,11110010,
1011101010010111,11001101,
0001011101011011,11110100,
1100101001010011,11101010,
0110110110110110,11010101,
1100111011010101,11110011,
1010000100010111,11001101,
0001101101011011,11110110,
1100100011010011,11100110,
0110110011110110,11010101,
1101111001010101,11110011,
1010100000011111,11001101,
0001100101111011,11111000,
1100101011010011,11011010,
0010100111110110,11010101,
1101111101010101,11110010,
1010111000010111,11101101,
0001000001011011,11110100,
1100101011010011,11101010,
0110110111110110,11010101,
1101111000010101,11110110,
1010100111010111,11001101,
0001000101011011,11110100,
0110110101110110,11010111,
1101111001010101,11110110,
1010111100110111,11001101,
0001000101011011,11110100,
1100101010010011,11101010,
0110110111110110,11010101,
1101111001010101,11110010,
1010110000010111,11001101,
0011000101011011,11110100,
0011010101111011,10010111,




<a name="00a4_0019"><a name="00a4_0019">
<a name="00a4_001a"></pre><B>[LISTING FIVE]</B><pre><a name="00a4_001a">

# TESTBAM.MK
# Make file for BAM System implementation tester
# Uses Microsoft Make
# Compiler: Zortech C++ 2.0
# To make with diagnostics enabled:
# make CFLAGS=&quot;-DDEBUG=1&quot; testbam.mk
#

CFLAGS=
.cpp.obj:
     ztc -c $(CFLAGS) $*.cpp
bam.obj: bam.cpp bam.hpp
testbam.obj: testbam.cpp bam.hpp
testbam.exe: testbam.obj bam.obj
     blink testbam bam;



<P>
<P>
</pre></BODY></HTML>
