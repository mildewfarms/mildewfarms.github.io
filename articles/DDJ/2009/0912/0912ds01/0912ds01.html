<title>Is Larrabee for the Rest of Us?</title>
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/Layout.css" type="text/css">
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/FontStyles.css" type="text/css">
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/newarticle.css" type="text/css">
<script src="../../../../forms/popwindow.js"></script>
</head>

<body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000">
<!--Copyright &#169; Dr. Dobb's Journal-->
<p><i>Dr. Dobb's Digest</i> December 2009</p>

<h1> Is Larrabee for the Rest of Us? </h1>

<h2> Can non-numerical application developers take advantage from the new LRBni instructions?</h2>
<P>
<h3>By Daniele Paolo Scarpazza</h3>


<P>
<i>Daniele Paolo Scarpazza is a member of the Multicore Computing Department at the IBM T. J. Watson Research Center. He is the author of articles and scholarly papers on parallel algorithms and performance optimization on emerging multicore architectures. </i>
<P>
<hr>
<P>

Larrabee, the new multicore processor that Intel will release in the next months, is going to catch most programmers unprepared. For once, it is difficult to estimate its potential on the basis of the very few details available. And programmers of non-numerical developers, traditionally secondary audience for GPGPU architects, are going to face an even steeper programming challenge.
	
<P>

In this article, I consider the example of regular-expression matching, arguably one of the hardest non-numerical workloads to parallelize, and map it onto LRBni, Larrabee's instruction set. I show that a good mapping of this code onto LRBni is possible, but only at the cost of a radical data-parallel redesign. Indeed, the data-parallel techniques that I learned on earlier SIMD (Single Instruction, Multiple Data) architectures become even more effective on Larrabee. Because of the wide SIMD nature of Larrabee, developers who  won't adopt a similar data-parallel approach risk leaving most of the processor unused, and thus up to 93% of its compute power on the table.
	
<P>

Unfortunately, at this point, nobody (outside Intel) can estimate how fast Larrabee will run the code I provide. With such complex instructions, potentially translated into dozens of serialized micro-instructions, and involving multiple potential cache misses, it will be a challenge for Intel engineers to match the throughput and power efficiency of more stream-lined RISC architectures featuring higher clock rates and simpler instruction.
<P>
<h3>Why Regular Expressions?</h3>
<P>

<P>
Regular expressions (RE) are those patterns that you feed to grep on the command line when searching log files for messages matching a given template, the ones that you provide to flex when designing the tokenizer for your newly invented programming language, the ones that tell network intrusion detection systems like Snort what malicious traffic looks like, etc.
<P>

<P>
You might wonder why, among many possible workloads I could examine, I chose regular expression matching. Here are five good reasons:
<P>
<ul>
<li>RE matching is the core of common and emerging applications like search-engine indexing, XML processing, application-level intrusion detection, and language analytics. In all of these, it is one important (if not the most important) consumer of execution time and hardware resources.
<li>RE matching relies on finite-state machines, a class of workloads notoriously hard to parallelize. In his famous presentation &#91;4&#93; -- almost a manifesto -- on parallel computing research, David Patterson mentions finite-state machines (FSM) as the #1 of his "dwarfs", i.e., workloads that deserve attention and effort.
<li>Larrabee is a SIMD architecture. On a SIMD architecture, each register contains multiple operands, and a SIMD instruction can process all those operands in parallel. We are used to 128-bit registers, divided in four 32-bit lanes. Larrabee has 512-bit registers, divided in 16 lanes. Traditionally, compilers don't usually do a very good job in translating irregular, non-numerical code into SIMD code. If you want good code, chances are you have to write SIMD code yourself, by hand. If you don't, you might leave up to 75% of the performance on the table on contemporary 128-bit SIMD architecture. On Larrabee, the potential loss is even higher: you might be using only 1/16 of the compute power (i.e., waste 93.75%).
<li>Presenting a realistic application in depth in this short space (and within the short attention span of a busy programmer) is a challenge. RE matching boils down to a handful of instructions, making this possible.
<li>RE matching is not your usual GPU workload. GPU architects catered primarily to the gaming and the computer graphics communities. More recently, the scientific and supercomputing communities have gained some attention by showing that GPGPUs can accelerate numerical, dense algorithms from domains such as fluid dynamics, protein folding and acoustics. But "the rest of us -- developers of non-numerical applications -- are still at the door, waiting. I use this example to show a way to exploit GPGPUs to carry out jobs previously thought "hard" to parallelize. There is no reason why, in a near future, most desktop applications (and not just games or graphics codes) should not offload their heavyweight kernels to GPGPUs.
</ul>
<P>

<P>
The main message of this article is that the programming challenges that LRBni brings about are not trivial, but also not new, and that they can be attacked successfully with data-parallel techniques that proved effective in the past. I propose an approach based on the complete elimination of the control flow from the compute kernels (the hot spots of your application), and its transformation into data flow. 
<P>

<P>
Thinking in terms of branch-less data flows is the most natural way to take advantage of SIMD. In the past, I was able to apply this approach on the same RE matching workload I am presenting here, while designing a  SIMD-based tokenizer kernel &#91;5&#93; intended for use in a search engine indexer &#91;6&#93; on the IBM Cell Broadband Engine processor. This kernel achieved 99.3% of cycle utilization, it is the fastest software tokenizer available on any architecture, and it delivers, with some restrictions, a level of throughput comparable to dedicated hardware. 
	
<h3>Much Ado About Something?</h3>
<P>

<P>
Larrabee is surrounded by hype, mystery, and controversy. More than a year has passed since Larrabee was first announced to the world in a SIGGRAPH 2008 paper <a href="http://portal.acm.org/citation.cfm?doid=1360612.1360617">Larrabee: A Many-Core x86 Architecture for Visual Computing</a>  &#91;1&#93;, and still nobody outside Intel has seen silicon or, for what it matters, a cycle-accurate simulator. Nevertheless, the anticipation keeps growing. While Intel keeps parceling out details, and competitors like nVidia react with nervous anxiety and criticism, most developers are left in the dark, wondering if it makes sense to commit resources and attention to the new platform, in the hope of accelerating most applications, or if Larrabee will just work well with regular, numeric, array-based workloads (like gaming graphics and physics) and won't be a true game-changer for everyone else. 
<P>

<P>
A stream of press releases, rumors, and blog posts have created more confusion, rather than shed light. Plus, we developers don't enjoy much rummaging through the news. We are much happier with final specifications, reliable benchmarks, and stable tools to play with. So, in this sea of dubious, fragmented and sometimes contradictory information, two events stand out. The first is Michael Abrash's article<a href="http://www.ddj.com/architect/216402188">A First Look at the Larrabee New Instructions (LRBni)</a> in Dr. Dobb's &#91;2&#93;, which finally detailed the new LRBni instructions. That article is, I bet, on its way to become the most cited non-peer-reviewed publication among academic, peer-reviewed papers of 2009-2010 in the high-performance computing field. The second is the release, last June, of Intel's <a href="http://software.intel.com/en-us/articles/prototype-primitives-guide/">C++ Larrabee Prototype Library</a> &#91;3&#93;, a simple header file that -- all the no-warranty disclaimers factored in -- provides the actual prototypes of the intrinsics associated to new instructions, along with reference semantics detailed in plain C code. This prototype library allows you to write, today, code that will run without major changes on the real hardware. The promise is that some day a compiler will read these intrinsics and emit corresponding LRBni instructions. This makes the library a convenient prototyping tool, especially if you have limited experience with writing SIMD code. 
<P>

<P>
Unfortunately, the library has a major weakness: it won't give you the slightest hint on the performance of the code you write. If you work in high-performance computing, you might be familiar with profiling and simulating your code, estimating its latency and throughput, and measuring indicators like cache misses ratios and Clocks Per Instruction (CPI). This library won't allow you to do any of these. 
	
<P>

This is, alas, a big question mark. With instructions of unprecedented complexity, that may potentially decompose into hundreds of microinstructions and entail up to 16 memory references, each taking even 800 clock cycles to complete in case of cache misses, estimating the performance of LRBni code on paper is a major challenge.


    <h3>What's Under the Hood</h3>
<P>

<P>
After the onset of the multicore revolution, chip designers are using a higher number of simpler, smaller, lower-clocked, more energy efficient cores rather than pushing the limits of a larger, power hungry, highly speculative, and less efficient single core.
<P>

<P>
Larrabee will include 32 or more cores, each of which is much simpler than the Pentium 4, and significantly simpler than the current Intel Core2 or i7 architecture. Cores will process instructions in order, sending out-of-order execution to history as a silicon-hungry and power-inefficient luxury of the past. Not only will Larrabee save on all the circuitry required for out-of-order execution, rumor has it that branch prediction will be simpler and branch mis-prediction penalties might cost up to 9 cycles.
<P>

<P>
Each core features 512-bit wide SIMD units for Larrabee. Cores will have similar traits as in other multicore architectures, i.e., relatively small amounts of local memory (256 kbyte per core) and high number of registers (128), a ring interconnect. Even the latency scaling among memory levels will be similar to earlier many-cores.
	
<P>

When developing compute-intensive code on Larrabee, developers should keep in mind two fundamental principles: 
<P>
<ul>
<li>Transform control flow into data flow 
<li>Use an explicit working set
</ul>
<P>

<P>
The first principle is crucial for avoiding expensive mis-prediction penalties. More important, branch elimination is essential to perform SIMD parallelization. The second principle allows for the best exploitation of the (small) per-core local memory. An explicitly streaming design avoids thrashing the caches, and a careful use of non-temporal hints won't pollute the caches with single-use data. 
<P>

<P>
Some less-than-pleasant manual unrolling of subsequent iterations of a loop (I call this "vertical unrolling") should still be able to pay off on Larrabee, given the relative abundance of registers. But at least, no  horizontal unrolling should be needed: horizontal unrolling consists in merging together loops that originally processed independent streams (see <a href="http://domino.research.ibm.com/comm/research_people.nsf/pages/scarpazza.pubs.html/$FILE/2009-06-ICS-scarpazza.pdf">High-performance Regular Expression Scanning on the Cell/B.E. Processor</a> &#91;5, Section 5.6&#93;, in order to fill the read-after-write dependency stalls within each loop iteration that the compiler can't fill. The reason why no horizontal unrolling should be needed is the 4-way Simultaneous Multi-Threading (SMT) that Larrabee cores feature: The hardware avoids stalls by switching effortlessly to whichever other thread is ready to compute. 
<P>

<P>
Additionally, Larrabee has masked scatter/gather instructions. Their impact is:
<P>
<ul>
<li>Code economy: One gather instruction may replace hundreds of scalar instructions. To convince yourself, try expressing a gather's equivalent in your favorite SIMD assembly. Remember to unpack 16 indexes from the SIMD register, do pointer arithmetic, perform 16 loads, and repack the 16 read values into the SIMD result register. If the gather is masked, prepend each of the 16 loads with tests and jumps. If needed, include type conversion/promotion code. Good luck. 
<li>No need for explicit packing and unpacking: As noted above, a gather instruction dereferences each 32-bit index (or pointer) in the ith  lane of vector register and returns the result in the same ith lane of the result vector register. On other SIMD architectures, you must manually unpack each pointer to a scalar register or rotate it to a predefined location before use.
<li>Masking: No need for speculated writes. One technique to avoid expensive branches is to write output speculatively &#91;5, Section 5.4&#93;. This means using (unconditional, unpredicated) store instructions that always write something. When not needed, they write invalid output to ignored locations. You shouldn't ever have to do this on Larrabee because scatter instruction allow you to mask each of the 16 stores. The hardware skips the writes you don't want, and will likely complete earlier if only a few are selected. 
</ul>
<P>

<P>
The rest of this article is an in-depth walk-through of a single piece of code, ported to LRBni.  The code I show is a simplified replacement for the kernels generated by flex, and you can use it to write your own high-performance lexical scanner. 
	
<P>

The example I present here is, if you want, a lazy port to LRBni of that tokenizer. Given its intended use (search engine indexing), it is oriented to yield high throughput on large numbers of independent streams, rather than low execution time on a single stream.



    <h3>Show Me Some Code Already!</h3>
<P>

<P>
Enough with the preliminaries, it's time to get our hands dirty. My example runs through the four pieces of code in Listings 1 through 4. These excerpts describe a simple tokenizer, to be used in a search engine indexer after case folding, not much different from the actual tokenizer that <a href="http://lucene.apache.org">Lucene</a> &#91;7&#93;, the most popular open-source search engine library, uses internally. Listing 1 shows the flex specification; Listing 2 contains the tokenizer kernel automatically generated by flex; Listing 3 is a rewrite that I find simpler to read and optimize; and, finally, Listing 4 shows my parallel implementation that exploits SIMD LRBni intrinsics.
	
<P>

Listing 1 is my specification that tells flex what patterns I'm looking for, and what actions to perform when patterns match. Note the three sections, separated by "%%" lines (if you are unfamiliar with this syntax, take a quick look at <a href="http://flex.sourceforge.net/manual/">flex's manual</a> &#91;8&#93;). The first section defines patterns such as letters, digits, alphabetic, and alphanumeric strings, e-mail addresses, company names, and stop words (i.e., words that you want to filter out). The second section says that we are looking for three classes of tokens: (1) stop words and stray single characters, which we ignore; (2) regular tokens that we keep unchanged; and (3) acronyms, that we emit with a special flag, so that they are marked for some post-processing (e.g. dot removal) in later stages. The third section, omitted here, would be the C implementation of utility functions like <b>emit_token</b>.
<P>
<pre  class="code">
<P>
LETTER       &#91;a-z&#93;
DIGIT        &#91;0-9&#93; 
P            ("_"|&#91;,-/&#93;)
HAS_DIGIT    ({LETTER}|{DIGIT})*{DIGIT}({LETTER}|{DIGIT})*
ALPHA        {LETTER}+
ALPHANUM     ({LETTER}|{DIGIT})+
ACRONYM      {ALPHA}"."({ALPHA}".")+
COMPANY      {ALPHA}("&"|"@"){ALPHA}
EMAIL        {ALPHANUM}(("."|"-"|"_"){ALPHANUM})*"@"{ALPHANUM}(("."|"-"){ALPHANUM})+
HOST         {ALPHANUM}("."{ALPHANUM})+
NUM          {ALPHANUM}{P}{HAS_DIGIT}|{HAS_DIGIT}{P}{ALPHANUM}|{ALPHANUM}({P}{HAS_DIGIT}{P}{ALPHANUM})+|{HAS_DIGIT}({P}{ALPHANUM}{P}{HAS_DIGIT})+|{ALPHANUM}{P}{HAS_DIGIT}({P}{ALPHANUM}{P}{HAS_DIGIT})+|{HAS_DIGIT}{P}{ALPHANUM}({P}{HAS_DIGIT}{P}{ALPHANUM})+
STOPWORD     "a"|"an"|"and"|"are"|"as"|"at"|"be"|"but"|"by"|"for"|"if"|"in"|"into"|"is"|"it"|"no"|"not"|"of"|"on"|"or"|"s"|"such"|"t"|"that"|"the"|"their"|"then"|"there"|"these"|"they"|"this"|"to"|"was"|"will"|"with"
KEPT_AS_IS    {ALPHANUM}|{COMPANY}|{EMAIL}|{HOST}|{NUM}
%%
{STOPWORD}|.|\n    /*do nothing*/;
{KEPT_AS_IS}       emit_token(CLASS_TOKEN, yytext);
{ACRONYM}          emit_token(CLASS_ACRONYM, yytext);
%%
/* C code omitted */ 

</pre>
<div class="caption">
<b>Listing 1</b>
</div>
<P>

<P>
You might remember from your college days that a finite-state machine (FSM) is sufficient to recognize a regular language. Flex generates that machine, in the form of C code, from the specification in Listing 1. That C code contains (among a sea of nitty-gritty details) two main blocks: The state transition table of the state machine (split in variables <b>yy_nxt</b> and <b>yy_accept</b>), and the C kernel that runs that machine, summarized in Listing 2. Don't be scared, I don't expect you to dive into this code, I just want to point out a few details. This code loops over the input, and it is divided into an inner loop and a switch block. The inner loop runs an FSM using the state transition table <b>yy_nxt</b> until it finds a valid pattern (i.e., the input characters between pointers <b>yy_bp</b> and <b>yy_cp</b>). When that happens, the switch block performs an appropriate action. Note that flex has preserved the actions we indicated in the specification, and they appear here as case 1, 2, and 3.
<P>
<pre  class="code">
<P>
while ( 1 ) /* loops until end-of-file is reached */
  {
    yy_cp = (yy_c_buf_p);
    
    /* Support of yytext. */
    *yy_cp = (yy_hold_char);
    
    /* yy_bp points to the position in yy_ch_buf of the start of
     * the current run. */
    yy_bp = yy_cp;    
    yy_current_state = (yy_start);
  yy_match:
    while ( (yy_current_state = yy_nxt&#91;yy_current_state&#93;&#91; YY_SC_TO_UI(*yy_cp) &#93;) &gt; 0 )
      {
	if ( yy_accept&#91;yy_current_state&#93; )
	  {
	    (yy_last_accepting_state) = yy_current_state;
	    (yy_last_accepting_cpos) = yy_cp;
	  }
	
	++yy_cp;
      }
      yy_current_state = -yy_current_state;
    
  yy_find_action:
    yy_act = yy_accept&#91;yy_current_state&#93;;
    
    YY_DO_BEFORE_ACTION;
    
  do_action:      /* This label is used only to access EOF actions. */
    
    switch ( yy_act )
      { /* beginning of action switch */
      case 0: /* must back up */
	/* undo the effects of YY_DO_BEFORE_ACTION */
	*yy_cp = (yy_hold_char);
	yy_cp = (yy_last_accepting_cpos) + 1;
	yy_current_state = (yy_last_accepting_state);
	goto yy_find_action;
	
      case 1:
	/* rule 1 can match eol */
	YY_RULE_SETUP
	/*do nothing*/;
        YY_BREAK
<P>
      case 2:
	YY_RULE_SETUP
	emit_token(CLASS_TOKEN, yytext);
        YY_BREAK
<P>
      case 3:
	YY_RULE_SETUP
	emit_token(CLASS_ACRONYM, yytext);
        YY_BREAK
	  ...
      }
  }

</pre>
<div class="caption">
<b>Listing 2</b>
</div>
<P>

<P>
The purpose of case 0 is related to the concept of back-up, and it requires a little explanation. Consider that flex's tokenizers always try to find the longest match; for example, when looking for pattern "i&#91;a-z&#93;*n",  the string "internationalization" matches, dominating all its shorter substrings ("in", "intern", "internation",  "ionalization", "ization", etc.), which are ignored. This feature is called longest-of-the-leftmost semantics. To implement it, the tokenizer may delay acting on a valid pattern; rather, it saves the current state and position in the input (the if statement within the inner while loop), and continues examining more input in an attempt to find a longer match. Sometimes the attempt succeeds, sometimes not. When it fails, the machine falls into a "back-up state", and reaches case 0. There, the machine restores the last saved accepting position, and executes the saved associated action.
<P>

<P>
For my convenience I rewrite that kernel in the form of Listing 3. The new form is easier to read and uses a single table <b>yy_next</b>, where each entry (a state code) contains both a state number and condition flags. The machine behavior is now regulated by condition flags. Whenever a match is found, the machine enters a final state, i.e., BIT_FINAL is active in the state code. If a token is matched (as opposed to a stop word), then BIT_TOKEN is active. If the token is an acronym, BIT_ACRONYM is active (to support more token types, you just need to reserve more flag bits). Finally, the save/back-up mechanism is cleanly regulated by BIT_SAVE and BIT_RESTORE flags. I wrote a simple utility to convert tables <b>yy_nxt</b> and <b>yy_accept</b> from the format that flex generates to table <b>yy_next</b>, in the format I just described. Also, you might have noticed that Listing 3 only saves and restores the last accepting position, and not the associated action. This is the result of an optimizing manipulation of the state machine, which is beyond the scope of this article &#91;5, Section 5.5&#93;.
<P>
<pre  class="code">
<P>
void tokenize ( unsigned char * const input, 
		unsigned char * const input_end)
{    
  state_t current_state = 0; // initial state
    
  unsigned char * yy_bp = input; // base pointer
  unsigned char * yy_cp = input; // current pointer
  
  unsigned char * last_accepting_cpos   = (unsigned char*) UNKNOWN;
<P>
  while (1) {   
    const unsigned char in_chr = *yy_cp;      
    const state_t next_code  = yy_next&#91;current_state * ALPHABET + in_chr&#93;;
    const state_t next_state = next_code &gt;&gt; 8 /* last 8 bits reserved for flags */;
<P>
    const bool is_final    = next_code & BIT_FINAL;
    const bool is_save     = next_code & BIT_SAVE;
    const bool is_restore  = next_code & BIT_RESTORE;
    const bool is_token    = next_code & BIT_TOKEN;
    const bool is_acronym  = next_code & BIT_ACRONYM;
  
    if (! is_final ) {	
      ++yy_cp;
      if ( is_save ) last_accepting_cpos   = yy_cp;
      if ( yy_cp &gt;= input_end ) goto the_end;
    } else {     
      if ( is_restore ) 
	yy_cp = last_accepting_cpos;      
      
      if (is_token) 
	emit_token(CLASS_TOKEN + is_acronym, yy_bp, yy_cp);       
            
      yy_bp = yy_cp;        	
    }	    
    current_state = next_state;	
  }
  
 the_end:
  ;
}

</pre>
<div class="caption">
<b>Listing 3</b>
</div>
<P>

<P>
The code you see in Listing 3 is sequential (as opposed to parallel) and scalar (no SIMD). I like to say it operates on one lane. To exploit the Larrabee's SIMD instructions, we extend this code to operate on the 16 lanes that Larrabee's 512-bit registers offer. The result is in Listing 4. 
<P>
<pre  class="code">
<P>
#define LANES 16
<P>
typedef union {
  __m512i mm;
  __m512  mf;
  __m512d md;
  uint32_t u32&#91;16&#93;;
} variant512_t;
<P>
#define EXTRACT(_x_,_i_) ({ variant512_t t = {mm:_x_}; t.u32&#91;_i_&#93;;})
#define CAST_F2I(_x_)    ({ variant512_t t = {mf:_x_}; t.mm;})
#define CAST_I2F(_x_)    ({ variant512_t t = {mm:_x_}; t.mf;})
<P>
inline __m512i _mm512i_mask_movd(__m512i v1_old, __mmask k1, __m512i v2)
{ 
  return CAST_F2I( _mm512_mask_movd( CAST_I2F(v1_old), k1, CAST_I2F(v2)) );
}
<P>
typedef struct { 
  uint32_t start;
  uint32_t stop;
  uint32_t type;
  uint32_t unused;
} tt_entry_t;
<P>
//unified output token table
tt_entry_t ttable_all  &#91; TEST_TOKEN_TABLE_SIZE * LANES &#93; align64;
<P>
tt_entry_t * ttp_start &#91; LANES &#93;; // beginning of per-automaton output table partition
tt_entry_t * ttp_end   &#91; LANES &#93;; // end of per-automaton output table partition
tt_entry_t * ttp_used  &#91; LANES &#93;; // end of valid data in the output table partition
<P>
void tokenize ( const unsigned char * const input_starts &#91;LANES&#93;, 
		const unsigned char * const input_ends   &#91;LANES&#93;)
{      
  const unsigned input_base  = 0;          /* zero for the moment, useful when the input will be above 4GB */
  void * const   stt_base   = yy_next;
<P>
  __m512i mm_current_states      = _mm512_set_1to16_pi( 0 ); 
  __m512i mm_next_states;
<P>
  //////// CONSTANTS /////////////////////////////////////////////////////////////////////////////////////////
  const __mmask mask_all_ones       = 0xFFFF; /* sixteen bits, all ones, used to check collective termination  */
  const __m512i mm_zeroes           = _mm512_set_1to16_pi( 0 ); 
  const __m512i mm_ones             = _mm512_set_1to16_pi( 1 ); 
  const __m512i mm_twos             = _mm512_set_1to16_pi( 2 );  /* to increment tteptr */
<P>
  const __m512i mm_final_mask       = _mm512_set_1to16_pi( BIT_FINAL   ); 
  const __m512i mm_save_mask        = _mm512_set_1to16_pi( BIT_SAVE    );
  const __m512i mm_restore_mask     = _mm512_set_1to16_pi( BIT_RESTORE );
  const __m512i mm_token_mask       = _mm512_set_1to16_pi( BIT_TOKEN   );
  const __m512i mm_acronym_mask     = _mm512_set_1to16_pi( BIT_ACRONYM );
  const __m512i mm_kill_flags_mask  = _mm512_set_1to16_pi( 0xFFFFFF00  );
<P>
  const __m512i mm_SR_ofs       = _mm512_set_1to16_pi( 8 /* shift right 8 bits */ );
  assert(ALPHABET == 128 /* if it is not, change the 7 below */);
  const __m512i mm_SL_alpha     = _mm512_set_1to16_pi( 7 ); // for shift left 7 ( == mul 128) operations  
  ////////////////////////////////////////////////////////////////////////////////////////////////////////////
<P>
  __m512i mm_bp   = * (const __m512i*) input_starts;
  __m512i mm_cp   = * (const __m512i*) input_starts;
  __m512i mm_lacp = * (const __m512i*) input_starts;
  __m512i mm_eob  = * (const __m512i*) input_ends;
<P>
  /* quadword index into the token table used, for use with scatterd */
#define TTEP_IDX(_dfa_) ( U32( (ttp_used&#91; (_dfa_)&#93;-ttable_all) ) * sizeof(tt_entry_t) / (4 /*SCALE*/) )
 
  __m512i mm_tte_idx = { TTEP_IDX( 0), TTEP_IDX( 1), TTEP_IDX( 2), TTEP_IDX( 3), 
			 TTEP_IDX( 4), TTEP_IDX( 5), TTEP_IDX( 6), TTEP_IDX( 7), 
			 TTEP_IDX( 8), TTEP_IDX( 9), TTEP_IDX(10), TTEP_IDX(11), 
			 TTEP_IDX(12), TTEP_IDX(13), TTEP_IDX(14), TTEP_IDX(15) }; 
 
  while (1) {   
    const __m512i mm_in_chars = CAST_F2I( _mm512_gatherd( mm_cp, input_base, _MM_FULLUPC_UINT8I, _MM_SCALE_1, _MM_HINT_NONE ));
        
    const __m512i mm_states_xalpha     = _mm512_sll_pi ( mm_current_states, mm_SL_alpha );   
    const __m512i mm_next_code_indexes = _mm512_add_pi ( mm_states_xalpha, mm_in_chars );        
    const __mmask mask_not_eob         = _mm512_cmpnle_pu(mm_eob, mm_cp); // "not at end-of-buffer" condition; 
    const __mmask mask_eob             = ~mask_not_eob;                   // "at end-of-buffer"     condition
    
          __m512i mm_next_codes        = CAST_F2I ( _mm512_mask_gatherd( CAST_I2F(mm_next_codes), mask_not_eob, mm_next_code_indexes, 
									 stt_base, _MM_FULLUPC_NONE, _MM_SCALE_4, _MM_HINT_NONE ));                               
    const __m512i mm_next_states       =  _mm512_sra_pi ( mm_next_codes, mm_SR_ofs);
<P>
    const __mmask mask_final           = _mm512_cmpnle_pu( _mm512_and_pi ( mm_next_codes, mm_final_mask   ),  mm_zeroes);
    const __mmask mask_save            = _mm512_cmpnle_pu( _mm512_and_pi ( mm_next_codes, mm_save_mask    ),  mm_zeroes);
    const __mmask mask_restore         = _mm512_cmpnle_pu( _mm512_and_pi ( mm_next_codes, mm_restore_mask ),  mm_zeroes);
    const __mmask mask_token           = _mm512_cmpnle_pu( _mm512_and_pi ( mm_next_codes, mm_token_mask   ),  mm_zeroes);
<P>
    const __m512i mm_are_acronym       = _mm512_and_pi ( mm_next_codes, mm_acronym_mask ); /* can be more than 1 bit */
    mm_next_codes = _mm512_and_pi ( mm_next_codes, mm_kill_flags_mask );
    const __mmask mask_not_final       = ~ mask_final;
<P>
    mm_cp             = _mm512_mask_add_pi ( mm_cp, mask_not_final & mask_not_eob,  mm_cp, mm_ones); 
    mm_current_states = _mm512i_mask_movd  ( mm_current_states, mask_not_eob, mm_next_states ); 
    mm_lacp           = _mm512i_mask_movd  ( mm_lacp,           mask_save,    mm_cp          );
    mm_cp             = _mm512i_mask_movd  ( mm_cp,             mask_restore, mm_lacp        ); 
  
    if ( mask_eob == mask_all_ones ) goto the_end; // all automata are complete
    
    /* selectively commit results into the output token tables */
    _mm512_mask_scatterd(ttable_all, mask_token, mm_tte_idx, CAST_I2F(mm_bp),          _MM_DOWNC_NONE, _MM_SCALE_4, _MM_HINT_NT );
    mm_tte_idx = _mm512_mask_add_pi ( mm_tte_idx, mask_token, mm_tte_idx, mm_ones ); 
    _mm512_mask_scatterd(ttable_all, mask_token, mm_tte_idx, CAST_I2F(mm_cp),          _MM_DOWNC_NONE, _MM_SCALE_4, _MM_HINT_NT );
    mm_tte_idx = _mm512_mask_add_pi ( mm_tte_idx, mask_token, mm_tte_idx, mm_ones ); 
    _mm512_mask_scatterd(ttable_all, mask_token, mm_tte_idx, CAST_I2F(mm_are_acronym), _MM_DOWNC_NONE, _MM_SCALE_4, _MM_HINT_NT );
    mm_tte_idx = _mm512_mask_add_pi ( mm_tte_idx, mask_token, mm_tte_idx, mm_twos /*1 + padding*/); 
<P>
    mm_bp = _mm512i_mask_movd( mm_bp, mask_final, mm_cp); 
  }
<P>
 the_end: ;  
  // export token table pointers to global vars
  const unsigned quadwords_per_entry = sizeof (tt_entry_t) / sizeof (uint32_t);
  for ( unsigned dfa ; dfa&lt;LANES ; dfa++) {
    const unsigned n_entries = EXTRACT(mm_tte_idx, dfa) / quadwords_per_entry;
    ttp_used&#91; dfa&#93; = ttable_all + n_entries;      
  }
}

</pre>
<div class="code">
<b>Listing 4</b>
</div>
<P>

<P>
In the preamble, I define a <b>variant512_t</b> union to allow convenient access to the contents of a 512-bit variable, as if it were a SIMD vector of integers, floats or doubles, or as a C array of 32-bit unsigned integers. Thanks to this union, I can write macros (lines 10-12) to extract elements and cast float vectors to integer vectors and vice versa, using clean, pointer-less GCC code (beware of my use of <a href="http://gcc.gnu.org/onlinedocs/gcc-3.3.6/gcc/Statement-Exprs.html">statement expressions</a> &#91;9&#93;). Other methods use brute-force pointer casting and dereferencing, and have disadvantages: They hijack the language type safety and mess with the compiler's type-based pointer aliasing rules (with noisy warnings and potentially incorrect code).
	
<P>

The need to cast SIMD vectors and the need for a masked move that operates on integer SIMD vectors (my <b>_mm512i_mask_movd</b> function) arise from Intel's choice to define gather and scatter intrinsics only for float vectors. I use a CAST_I2F before a scatter, to pretend I'm storing floating points, and a CAST_F2I after a gather. It's okay, Intel, we non-numerical programmers are used to being treated as a "secondary audience". We have been used to this since the days of MMX and SSEx.
	
<P>

The code explosion from Listing 3 to Listing 4 is common when doing SIMDization. The code grows for two reasons. First, we write at a lower level, where C operators like +, & and  &gt; become verbose intrinsics like <b>_mm512_add_pi</b>, <b>_mm512_and_pi</b>, and <b>_mm512_cmpnle_pu</b>. Except for manual register allocation, this is pretty much like writing assembly code. We have also inlined function <b>emit_token</b>.
<P>

<P>
A second, more profound, reason is that we have replaced control flow with data flow. With the exception of the <b>if</b> that verifies the termination condition, the 16 FSMs on the 16 lanes are processed by the same instructions, and therefore must follow the control flow. They can't diverge like separate threads, they can't take separate paths, they can't have their own <b>if</b>s, <b>while</b>s, and <b>switch</b>s. Each iteration in the <b>while</b> loop describes 16 FSMs, all simultaneously consuming input, performing a state transition and possibly generating output. The execution of these FSMs is conjoined like the life of 16 siamese twins (called "sexdecuplets", if Wikipedia can be trusted). This is true to the extent that if one FSM gets to the end of its input, it must keep iterating until all the other FSMs also complete. 
<P>

<P>
Each FSM sets a bit in variable <b>mask_eob</b> upon its end of buffer; when the mask is all ones, we are done. This is not a major issue and can be solved without performance degradation, but not without making the code more complex and difficult to explain.
<P>

<P>
As a consequence, we must rewrite the FSM's choices as branchless expressions. We use a technique sometimes called software-level speculation: we compute the result of both sides of a branch and then choose the relevant one with a selection instruction (and this takes more lines of code than the original branch.) On the Cell, you use the <b>spu_sel</b> intrinsic; on Larrabee, you use masked instructions. To see this technique in action, note the three masked scatter instructions in lines 109, 111, and 113. For each FSM, they store the values of <b>bp</b>, <b>cp</b>, and <b>token_type</b> at the end of that FSM's own token table. But this only happens if that FSM has matched a valid token in this iteration, as reflected by the respective bit in <b>mask_token</b>. Three associated masked adds (lines 110, 112, 114) conditionally advance the end-of-table indexes (<b>mm_tte_idx</b>), for the only automata that wrote output. Similarly, we turn the updates of <b>bp</b>, <b>cp</b>, and <b>last_accepting_cpos</b> (that appeared under if conditions in Listing 3) into masked adds or masked moves (lines 101-104).
<P>

<P>
Except for the <b>if</b> statement that detects the global termination condition, the code is branchless and it corresponds to the data flow of Figure 1. The figure represents precisely one iteration of the loop in Listing 4, where 16 conjoined FSMs read the respective inputs, load the next state codes from the state transition table, decode them (possibly generating outputs) and jump to the next states. A black box represents a vector variable, a grey box represents a constant, a red box represents a mask, and a blue circle represents a vector operation.
<P>
<div>
<a href="0912ds01f1.gif">Click image to view at full size</a>
<img src="0912ds01f1sm.gif">
<div class="caption">
<b>Figure 1</b>
</div>
</div><P>

<P>
You can unroll this code ad libitum with no special prologues or epilogues, and no impact on correctness. To increase performance, you can also remove the termination condition if everywhere but in the last unrolled iteration.
  

    <h3>Conclusions</h3>
<P>

<P>
I have shown how to port a simple, sequential piece of code into its fully-parallel, SIMDized version. I realize that the kind of effort required for the data-parallel redesign is not trivial, but I don't believe that it is beyond the reach of many programmers already involved in crafting hand-optimized code. 
<P>

<P>
This kind of human effort is crucial because compilers won't likely be able to deliver a similar quality of result. Furthermore, it is more important on Larrabee than on previous Intel machines because Larrabee's SIMD width is four times larger than the usual 128-bit SIMD units: As a consequence, non-SIMD code will likely leave a much higher performance fraction on the table.
<P>

<P>
On the bright side, coding with LRBni intrinsics seems more natural and less verbose than coding with SSE intrinsics. One iteration of the loop in the code I presented needs approximately 35 instructions to transition 16 finite-state machines (approximately 2.2 instructions/transition), while other 128-bit SIMD instruction sets require at least 100 instructions to transition 4 machines (approximately 25 instructions/transition). 
<P>

<P>
Don't get me wrong. Without a clue on instruction latencies, you can not translate these instruction economy statistics into performance figures. At this time, nobody except Intel may estimate the amount of clock cycles taken by any LRBni instruction. Scatter/gather instructions, for example, will likely be decomposed in multiple pointer arithmetic and store/load microinstructions, which might take a high cumulative number of clock cycles to complete. The performance of this code depends on how successful Intel engineers will be in squeezing LRBni instructions into a handful of clock cycles. It's not an easy task, especially for complex instructions like scaled, masked scatter/gather with type conversion. 
<P>
<h3>Acknowledgments</h3>
<P>

<P>
Thanks to Sally A. McKee, Jamin Naghmouchi, Michael Perrone and Greg Pfister for their useful comments.
<P>

<P>
Disclaimer: Any claim or information reported here on Larrabee or other Intel products may not be final or reliable. The author assumes no liability for the use or interpretation of information contained herein. This article reflects the views and the opinions solely of the author, which may not necessarily be endorsed or approved by IBM.
<P>
<h3>References</h3>
<P>

<P>
&#91;1&#93; L. Seiler, D. Carmean, E. Sprangle, T. Forsyth, M. Abrash, P. Dubey, S. Junkins, A. Lake,  J. Sugerman, R. Cavin, R. Espasa, E. Grochowski, T. Juan, P. Hanrahan, 2008. "<a href="http://portal.acm.org/citation.cfm?doid=1360612.1360617">Larrabee: A Many-Core x86 Architecture for Visual Computing</a>", ACM Transactions on Graphics, 27, 3, 2008. http://portal.acm.org/citation.cfm?doid=1360612.1360617
<P>

<P>
&#91;2&#93; M. Abrash, "<a href="http://www.ddj.com/hpc-high-performance-computing/216402188">A First Look at the Larrabee New Instructions (LRBni)</a>", Dr. Dobb's, April 1st, 2009. http://www.ddj.com/hpc-high-performance-computing/216402188
<P>

<P>
&#91;3&#93; Intel Software Network, <a href="http://software.intel.com/en-us/articles/prototype-primitives-guide/"> "C++ Larrabee Prototype Library</a>", June 19, 2009. http://software.intel.com/en-us/articles/prototype-primitives-guide/
<P>

<P>
&#91;4&#93; K. Asanovic, R. Bodik, J. Demmel, J. Kubiatowicz, K. Keutzer, E. Lee, G. Necula, D. Patterson, K. Sen, J. Shalf, J. Wawrzynek, K. Yelick, "<a href="http://science.officeisp.net/ManycoreComputingWorkshop07/Presentations/David%20Patterson.pdf">The Landscape of Parallel Computing Research: A View from Berkeley</a>". http://science.officeisp.net/ManycoreComputingWorkshop07/Presentations/David%20Patterson.pdf
<P>

<P>
&#91;5&#93; D. P. Scarpazza, G. F. Russell, "<a href="http://domino.research.ibm.com/comm/research_people.nsf/pages/scarpazza.pubs.html/$FILE/2009-06-ICS-scarpazza.pdf">High-performance Regular Expression Scanning on the Cell/B.E. Processor</a>", 23rd International Conference on Supercomputing (ICS'09), IBM T.J. Watson Research Center, Yorktown Heights, NY, USA, June 2009. http://domino.research.ibm.com/comm/research_people.nsf/pages/scarpazza.pubs.html/$FILE/2009-06-ICS-scarpazza.pdf
<P>

<P>
&#91;6&#93; D. P. Scarpazza, G. W. Braudaway, "<a href="http://domino.research.ibm.com/comm/research_people.nsf/pages/scarpazza.pubs.html/$FILE/2009-10-04-IISWC-scarpazza.pdf">Workload Characterization and Optimization of High-performance Text Indexing on the Cell Processor</a>", IEEE International Symposium on Workload Characterization (IISWC'09), Austin, TX, October 4, 2009. http://domino.research.ibm.com/comm/research_people.nsf/pages/scarpazza.pubs.html/$FILE/2009-10-04-IISWC-scarpazza.pdf
<P>

<P>
&#91;7&#93; The Apache Software Foundation. <a href="http://lucene.apache.org">Lucene</a>. http://lucene.apache.org
<P>

<P>
&#91;8&#93; V. Paxson, <a href="http://flex.sourceforge.net/manual/">flex:  a fast lexical analyzer generator</a>. http://flex.sourceforge.net/manual/
<P>

<P>
&#91;9&#93; The Free Software Foundation, Using the GNU compiler collection (GCC), "<a href="http://gcc.gnu.org/onlinedocs/gcc-3.3.6/gcc/Statement-Exprs.html">Section 5.1: Statements and Declarations in Expressions</a>". http://gcc.gnu.org/onlinedocs/gcc-3.3.6/gcc/Statement-Exprs.html
<P>


