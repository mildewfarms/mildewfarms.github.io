<HTML>
<META NAME="year" CONTENT="1995">

<HEAD>
<TITLE>AUG95: Alpha Blending Graphic Images</TITLE></HEAD>
<BODY BGCOLOR="#ffffff">
<h1>Alpha Blending Graphic Images<a name="009d_0029"><a name="009d_0027"><a name="009d_0000"></h1><P>
<h2>Combining images for special effects</h2><P>
<h3>Tim Wittenburg</h3><P>
<p><i><a name="009d_0028"><a name="009d_0000">Tim, who is a team leader at AmeriData Consulting, has developed flight-simulator technology for the U.S. Air Force and is author of Photo-Based 3D Graphics in C++ (John Wiley &amp; Sons, 1995).</i></p><hr><P>
Many memorable movie scenes have been created using a graphics technique known as &quot;blending.&quot; In <I>Jurassic Park</I>, for example, computer-generated dinosaurs were blended into existing live-action footage. <P>
This article describes a powerful graphics technique known as &quot;alpha blending&quot; (sometimes referred to as &quot;image compositing&quot;). Careful application of this algorithm permits two or more images to be composited in such a way that viewers can't detect that the resulting image is a composite. I'll present an abridged version of the Porter-Duff alpha-blending algorithm (described by T. Porter and T. Duff in their paper &quot;Compositing Digital Images,&quot; in the <I>SIGGRAPH '84 Proceedings</I>) and show several applications, including how blending can be used to create realistic shadows.<P>
The fundamental idea behind blending is that a third channel or image can be used to drive a blending process, which combines the image of the object to be blended (the &quot;cutout image&quot;) and background images. The blending techniques I present here combine the cutout and background images using the equation <I>B<SUB>ij</SUB>=C<SUB>ij</SUB> A<SUB>ij</SUB>+(1-A<SUB>ij</SUB>) B<SUB>ij</SUB></I>, where <I>i</I> and <I>j</I> are image column and row indexes, respectively, and <I>A<SUB>ij</SUB></I> is a factor (called &quot;alpha&quot;) that has a value between 0 and 1 inclusive. <I>B<SUB>ij</SUB></I> is a pixel in the output image and <I>C<SUB>ij</SUB></I> is a pixel in the cutout image. As <a href="1995009f.htm">Figure 1</A> illustrates, you implement blending by applying the blending equation to three image objects: the cutout image, the corresponding alpha image, and the output image. Each pixel (<I>i,j</I>) of the cutout image is assumed to be &quot;lined up&quot; or colocated with pixel (<I>i,j</I>) in the cutout's alpha image. Each pixel in the alpha image contains a number that can be interpreted as an alpha factor. The alpha factor acts as a translucency indicator: A value of 0 implies transparency and a value of 1 implies complete opaqueness.<P>
From another perspective, the blending equation replaces each background-image pixel with a weighted sum of itself and the corresponding cutout-image pixel. The weights are provided by alpha-image pixel values. It then follows that if each alpha factor in the alpha image is set to 1, the cutout image will replace the background pixel over which it is superimposed. If the alphas are all 0, then blending the cutout image into the background image will have no effect since each pixel in the cutout image will have effectively been made transparent. Even more interesting things start happening when you use alphas between 0 and 1. <P>
<h3><a name="009d_002a">Making an Alpha Image from a Cutout<a name="009d_002a"></h3><P>
An alpha image can be generated during the process of making a cutout image. The overall process of creating an alpha image is as follows:<P>
<OL>
<LI>Identify the object of interest.</LI>
<LI>Create a polygon &quot;mask&quot; over the object of interest and remove the background.</LI>
<LI>Remove unnecessary borders to create the cutout image and mask.</LI>
<LI>Create the alpha image by softening the edges of the mask image.</LI>
</OL>
For instance, the bottom portion of <a href="199500a0.htm">Figure 2</A> shows a mask image generated from an example tree-cutout image. The mask image was created by setting each pixel in the alpha image that corresponds to a pixel inside the cutout (tree) area to the value 255 (white). Conversely, all pixels which are located outside the cutout area are assigned the value 0 (black). The mask image could be called a &quot;binary image&quot; because it only has two values: 0 and 255. <P>
To convert the mask image into an alpha image, the edges of the white area in the mask image are smoothed. In smoothing, the mask-image alpha factors will be calculated in pixels along the edges of the tree that are greater than 0 and less than 1. When this mask image is then used to blend the cutout and background images together, an effect will be produced whereby the outermost edges of the tree are made translucent. The end result is that the normal effects of aliasing are reduced because pixels along the edges of the cutout tree image (where one form of aliasing occurs) are being combined with the background. <P>
<h3><a name="009d_002b">Edge Smoothing<a name="009d_002b"></h3><P>
To get the proper effect, you need to be very particular about performing edge smoothing in an alpha image. The top part of <a href="199500a1.htm">Figure 2</A> shows three sideview plots of the intensities in one horizontal line of the mask image shown in the bottom half of <a href="199500a2.htm">Figure 2</A>. The lower-intensity plot is labeled &quot;Unsmoothed.&quot; This plot shows the edge profile of the mask image. If you smooth the edges of the mask image by applying a simple, sliding-window average (or &quot;block&quot;) filter, the result is the situation diagrammed in the middle-intensity plot labeled &quot;Conventional Block Filter&quot; in the upper part of <a href="199500a3.htm">Figure 2</A>. In this case, the block filter will &quot;smear&quot; the mask image into areas for which there are no corresponding cutout-image pixels. The parts of the image affected are indicated by the small white triangular areas that lie outside the vertical lines denoting the edges of the cutout image. Nonzero alphas in these triangular regions will cause 0-valued pixels from the cutout image to be mixed into the background image; the result is that the blended image exhibits a dark halo. What you want instead is to smooth the mask image so that the alpha factors corresponding to 0 pixels in the cutout image remain 0. In other words, you only want to calculate alpha factors where the mask-image pixels are greater than 0. This approach will produce the result labeled &quot;Desired&quot; in the uppermost portion of <a href="199500a4.htm">Figure 2</A>, where the alpha factors along the edges of the tree are less than 1 and all alphas outside the edges of the tree are 0. Alphas lying in the interior of the cutout remain 255.<P>
<a href="#009d_002f">Figure 3</A>, a visual-effect scene created by compositing two maple-leaf models based on the same image, illustrates the blending effect. <a href="199500a5.htm">Figure 3(a)</A> is blended, while <a href="199500a6.htm">Figure 3(b)</A> is not. <a href="199500a7.htm">Figure 4(a)</A> is a close-up of the blended leaf border composited using alpha blending. <a href="199500a8.htm">Figure 4(b)</A>, on the other hand, is a close-up of the same portion of the leaf border, but unblended. The image in <a href="199500a9.htm">Figure 4(a)</A> exhibits less contrast than its unblended counterpart. This lack of contrast will cause the model's edges to remain unnoticed by your eye. In this case, what you don't see makes the difference. A cutout image and its corresponding alpha image can be used during scene generation to composite models into the final scene. Blending the cutout into the final scene minimizes the effects of aliasing.<P>
This edge-smoothing algorithm is implemented as a two-pass process in <a href="#009d_0031">Listing One</A>. In particular, the <I>smoothX3NN</I> function is applied to the three nearest neighboring pixels in the image's horizontal lines (which are oriented along the x axis of the world-coordinate system); the <I>smoothY3NN</I> function is applied to the three nearest neighboring pixels in vertical columns in the image. To smooth the mask image in both the x and y directions, a call must be made to each of the smoothing functions. The order in which the calls are made will not appreciably change the outcome. <P>
The <I>smoothX3NN</I> function makes a pass over the image, line by line. As the function traverses the pixels in each line, it calculates the average of the current pixel and one pixel on either side of it. These three pixels make up an &quot;averaging window.&quot; Function <I>smoothX3NN</I> writes an output pixel into the output alpha image (in the location corresponding to the center of the averaging window) only if the pixel in the center of the averaging window has a corresponding nonzero cutout-image pixel. Larger averaging windows make for greater smoothing effects. For example, a <I>smoothX4NN</I> and <I>smoothY4NN</I> could easily be constructed and applied to mask images. <a href="#009d_0031">Listing One</A> contains the edge-smoothing functions that convert a mask image into an alpha image.<P>
<h3><a name="009d_002c">Opaqueness, Shadows, and the Alpha-Scale Factor<a name="009d_002c"></h3><P>
Suppose you want to uniformly vary the opaqueness of all the alpha-scale factors in an alpha image. Instead of creating a new alpha image containing the scaled alpha factors, you can incorporate a scale factor into the blending equation as follows. First let <I>f</I> equal the new alpha factor, which incorporates the alpha-scale factor <I>s</I>, as in <I>f=sA<SUB>ij</SUB>/m</I>, where <I>m</I> is 255, the maximum 8-bit pixel value. Since <I>A<SUB>ij</SUB></I> ranges from 0 to 255, the alpha-scale factor <I>A<SUB>ij</SUB>/m</I> ranges from 0 to 1. The blending equation can then be rewritten as <I>B<SUB>ij</SUB>=f Ci<SUB>j</SUB>+(1</I>-<I>f) B<SUB>ij</SUB></I>. The new equation enables the contribution of the alpha image to the final, blended result to be scaled by varying <I>s</I>. By default, the alpha-scale factor is set to a value of 1 in the scene file. Setting it to 0.5 would cause a cutout-image pixel with a corresponding alpha-image pixel value of 255 (the maximum possible) to be combined with the output-image pixel in a ratio of 1:1. In other words, the output pixel would be a 50 percent mixture of both cutout-image pixel and background-image pixel. <a href="199500aa.htm">Figure 5</A> shows a visual-effect scene in which the same model is blended into a background image with four different alpha-scale factors. From left to right, the alpha scale factors are: 0.8, 0.6, 0.4, and 0.2. Varying the alpha-scale factor during generation of a sequence of images can result in morphing effects.<P>
Suppose, however, that you wish to add a shadow to a model. Using a variation of the alpha-scale factor idea, you can simply add to the scene file another model that uses the same image file as the original model. To add shadows, you first include another copy of each model in the scene file, renaming the model to indicate that it is a shadow. Now you interactively rotate and position each shadow model using the scene preview tool until they appear in the desired perspective. <P>
Once the shadow models have been suitably positioned, how do you make the shadows dark? Actually, you want to subtract an amount from the area of the background image upon which the shadow is cast. The amount to be subtracted can be determined from the alpha values and the alpha-scale value itself. You can cause such a subtraction to occur by making the alpha scale negative. In the case of a negative alpha-scale factor <I>s</I>, the blending equation is altered to the form <I>B<SUB>ij</SUB>=B<SUB>ij</SUB>+fC<SUB>ij</SUB></I>. Since <I>f</I> will be negative if <I>s</I> is negative, a subtraction is performed as desired. Obviously, a darker shadow requires a greater negative alpha-scale factor. A good starting point is to make alpha scale -0.2; this will subtract 20 percent of the alpha-image value from the background pixels. A lower bound is placed on <I>B<SUB>ij</SUB></I> so that it cannot have a calculated value of less than 1. <P>
The two leftmost shadows shown in <a href="199500ab.htm">Figure 6</A> were created by blending the alpha image itself into the background. The shadow of the spruce tree on the right side of <a href="199500ac.htm">Figure 6</A> was created by using the spruce-tree image itself as a source of values to subtract from the background image. The result is a more complex and interesting looking shadow. Since the shadow of an object can be occluded by the model from which it is derived, the shadow model is always rendered first.<P>
<h3><a name="009d_002d">The Blend Function<a name="009d_002d"></h3><P>
<a href="#009d_0033">Listing Two</A> implements the blending equation and incorporates the modifications for positive and negative alpha-scale factors. Note that the <I>blend </I>function accommodated the possibility that the blended output pixels may be offset by an amount specified in the function arguments <I>xOffset</I> and <I>yOffset</I>. <a href="#009d_0033">Listing Two</A> contains the function <I>blend</I>.<P>
<h3><a name="009d_002e">Summary<a name="009d_002e"></h3><P>
When you understand how alpha blending works, you can use it to smooth edges of cutout images, add shadows to existing models, alter the opaqueness of any model, and other special effects. You can also combine alpha blending with other graphics techniques, such as digital image warping (&quot;morphing&quot;); <a href="199500ad.htm">Figure 7</A> is an example of this. <P>

<B><a href="199500ae.htm">Figure 1</A>:</B> Implementing the blending equation.<p> 
<B><a href="199500af.htm">Figure 2</A>: </B>Generating a mask image from a cutout image.<p>
<a name="009d_002f"><B>Figure 3: </B><a href="199500b0.htm">(a)</A> Blended model; <a href="199500b1.htm">(b)</A> unblended model.<a name="009d_002f"><p>
<B>Figure 4: </B><a href="199500b2.htm">(a)</A> Closeup of unblended model; <a href="199500b3.htm">(b)</A> closeup of blended model (composited using alpha blending).<p>
<B><a href="199500b4.htm">Figure 5</A>: </B>Blending into a background image with different alpha-scale factors. <p>
<B><a href="199500b5.htm">Figure 6</A>: </B>Creating shadows by blending the alpha image itself into the background. <p>
<B><a href="199500b6.htm">Figure 7</A>: </B>Combining three-dimensional image warping with alpha blending for special effects.<P>
<P>
<h4><a name="009d_0030"><a name="009d_0031">Listing One<a name="009d_0031"></h4><pre>
void memImage::smoothX3NN(){
  int x, y;
  BYTE HUGE *myTemp = bytes;
  for (y = 1; y &lt;= imageHeight; y++){
    for (x = 1; x &lt; imageWidth; x++){
      if(x == 1 &amp;&amp; *myTemp &gt; 0){
        *myTemp = (*(myTemp)+ *(myTemp+1))*0.5;
      }
      else
      if(x == imageWidth &amp;&amp; *myTemp &gt; 0){
        *myTemp = (*(myTemp-1) + *(myTemp))*0.5;
      }
      else
      if(x &gt; 1 &amp;&amp; x &lt; imageWidth &amp;&amp; *myTemp &gt; 0){
        *myTemp = (*(myTemp-1) + *(myTemp)+ *(myTemp+1))*0.33333;
      }
      myTemp++;
    }
    myTemp+=pads;
  }
}
void memImage::smoothY3NN(){
  int x, y, y1, y2, y3, result;
  for (x = 1; x &lt;= imageWidth; x++){
    for (y = 1; y &lt;= imageHeight; y++){
      if(y &gt; 1) y1 = getMPixel(x, y - 1);
      y2 = getMPixel(x, y);
      if(y &lt; imageHeight) y3 = getMPixel(x, y + 1);
      result = 0;
      if(y == 1 &amp;&amp; y2 &gt; 0)
        result = (y2 + y3) * 0.5;
      if(y &gt; 1 &amp;&amp; y &lt; imageHeight &amp;&amp; y2 &gt; 0)
        result = (y1 + y2 + y3) * 0.33333;
      if(y == imageHeight &amp;&amp; y2 &gt; 0)
      result = (y1 + y2) * 0.5;
      setMPixel(x, y, (BYTE)result);
    }
  }
}
</pre>
<h4><a name="009d_0032"><a name="009d_0033">Listing Two<a name="009d_0033"></h4><pre>
short blend(memImage *inImage, memImage *alphaImage, memImage *outImage,
  float alphaScale, short xOffset, short yOffset){
  //
  //  Blend over the common area in input and mask images
  //
  short inputRows = inImage-&gt;getHeight();
  short inputCols = inImage-&gt;getWidth();
  short maskRows = maskImage-&gt;getHeight();
  short maskCols = maskImage-&gt;getWidth();
  short commonRows = min(inputRows, maskRows);
  short commonCols = min(inputCols, maskCols);
  //
  // each memImage is assumed to be opened for random access
  short x, y;
  BYTE maskPixel, inPixel, outPixel, addedPixel;
  float inWeight, outWeight;
  for(y = 1; y &lt;= commonRows; y++){
    for(x = 1; x &lt;= commonCols; x++){
      maskPixel = maskImage-&gt;getMPixel(x, y);
      if(maskPixel &gt; 0){
        inPixel = inImage-&gt;getMPixel(x, y);
        outPixel = outImage-&gt;getMPixel(x + xOffset, y + yOffset);
        inWeight = (float)maskPixel / 255.0 * alphaScale;
        outWeight = 1.0 - inWeight;
        if(alphaScale &gt; 0.0)
         addedPixel = (inWeight * (float)inPixel) + 
                                           (outWeight *(float)outPixel) + 0.5;
        else{
          addedPixel = (float)outPixel + (inWeight *(float)inPixel) + 0.5;
          // make certain shadows won't produce negative values
          if (addedPixel &gt; outPixel) addedPixel = outPixel;
        }
        if (addedPixel &lt; 1) addedPixel = 1; 
        if (alphaScale == 0.0) addedPixel = 0;
        outImage-&gt;setMPixel(x + xOffset, y + yOffset, addedPixel);
      }
    }
  }
  return 0;
}
</pre>

<HR><P>Copyright &copy; 1995, <I>Dr. Dobb's Journal</I></P></BODY></HTML>
