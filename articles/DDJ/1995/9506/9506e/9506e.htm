<HTML>
<META NAME="year" CONTENT="1995">

<HEAD>
<TITLE>JUN95: Thread Programming in UnixWare 2.0</TITLE></HEAD>
<BODY BGCOLOR="#ffffff">
<h1>Thread Programming in UnixWare 2.0<a name="026a_00ac"></h1><P>
<h2><a name="026a_00aa"><a name="026a_0000">Just say &quot;no&quot; to fork()</h2><P>
<h3>John Rodley</h3><P>
<p><i><a name="026a_00ab"><a name="026a_0000">John is an independent consultant in Cambridge, MA. He can be contacted at john.rodley@channel1.com.</i></p><hr><P>
With the advent of UnixWare 2.0, threads have made their way to the UNIX desktop. A superset of the thread specification in the POSIX Portable Operating Systems Standard (draft standard P1003.1c), threads have the potential to liberate UnixWare developers from the limitations of the age-old <I>fork()</I> model. Furthermore, threads let you exploit the capabilities of multiprocessing hardware. <P>
Before Version 2.0 (POSIX 1003.1c and SVR4.2 MP), UnixWare provided two ways to create new processes: <I>fork</I> and <I>fork-exec</I>. The <I>fork</I> system call creates an exact copy of the calling process and sets it running at the return from the <I>fork</I> call. The new process is a child of the old; it gets a copy of the parent's data space and valid file descriptors for all files opened by the parent. To start a different process, the child process calls <I>exec</I> right after the return from <I>fork</I>.<P>
With <I>fork()</I>, creating a new process consisted of a few lines of code, such as those in <a href="#026a_00ba">Example 1</A>. To start another process, a process had to clone itself, then ask the operating system which of the two copies it was. Until recently, <I>fork</I>/<I>exec</I> was the only avenue for concurrent programming. <P>
<h3><a name="026a_00ad">Lightweight Processes<a name="026a_00ad"></h3><P>
Pre-2.0 UnixWare kernels had only one type of process, which I call a &quot;heavy-weight process&quot; (HWP), and is the object of such calls as <I>ps</I>, <I>kill()</I>, and <I>getpid()</I>. HWPs still exist, but only as collections of lightweight processes (LWPs), which are the only schedulable entity in UW 2.0. An HWP consists of from one to MAXULWP LWPs. If you run a nonthreaded application in UW 2.0, in memory you will get an HWP that consists of a single LWP. In effect, instead of being a pointer to a piece of executable code, the HWP is now a pointer to a list of pieces of executable code. <P>
In multiprocessor systems, separate LWPs from a single HWP can run on different processors, allowing them to achieve true concurrency. The best example of the need for this is a print function. You want to hit the print button, then move on--not sit watching a dialog box that says, &quot;Now formatting page <I>n. </I>Please wait.&quot; <P>
Since the HWP concept is still supported, old process-specific calls such as <I>getpid</I>, <I>kill</I>, and <I>nice</I> work much as they did before. Therefore, you need analogues to those calls to control threads and their LWPs the way you've always controlled HWPs. <a href="#026a_00be">Table 1</A> lists some process-control calls and their threads' <I>lib</I> analogues.<P>
<h3><a name="026a_00ae">Threads<a name="026a_00ae"></h3><P>
Threads are not LWPs. The kernel itself knows nothing about threads, it only schedules LWPs. Each running LWP makes calls to the dynamic-threads library, which schedules threads to run on LWPs. So you now have two levels of scheduling: kernel scheduling of LWPs on processors and thread-library scheduling of threads on LWPs. A single instance of a thread can run, at different points in its life, on different processors and different LWPs. To really get this, you have to view the scheduled process as something completely independent from the lines of code that will run when that process gets scheduled. Think of the processor as a field, of each LWP as someone who has signed up to use the field, and of each thread as a particular activity such as baseball, soccer, or football. Now, when the kernel schedules someone to use the field, that person can play football for the entire time (a bound thread) or football for five minutes and baseball for ten. The kernel doesn't care. The person using the field (the threads library, through any of its LWPs) has to keep track of the games being played (thread instances) within the time that person uses the field. Thus, a thread is simply a series of logical statements, independent of the process, or processor upon which it might be executed.<P>
There are two basic kinds of threads: bound and multiplexed. A bound thread gets its own dedicated LWP. Each HWP has a number of LWPs in its pool, and it can run a particular multiplexed thread (muxthread) on any LWP in the pool at any given point.<P>
The major consideration in choosing between bound and multiplexed threads is the trade-off between performance and concurrency. On a uniprocessor, bound threads can have up to five times the context-switching overhead of muxthreads. Bound threads, though, enjoy the most concurrency. Five bound threads on a five-processor system could be running physically concurrently, one thread to a processor, while five muxthreads on the same system might end up running on a single processor.<P>
<h3><a name="026a_00af">Concurrency<a name="026a_00af"></h3><P>
Concurrency is easiest to understand in the multiprocessor model. In a multiprocessing machine, an LWP can be farmed out to another processor. Two LWPs, or two threads bound to different LWPs, running on different processors at the same time are running truly concurrently. If two muxthreads run on the same LWP, they can never run on separate physical processors, and can thus never be truly concurrent.<P>
Thus you can see the two extremes of concurrency: the maximum being one LWP per thread and the minimum being one LWP for all threads. In reality, the threads library will not let you pile a large number of threads onto a single LWP. UW 2.0 allows you to set the concurrency level through the <I>thr_setconcurrency</I> call. <a href="#026a_00c0">Listing One</A> (beginning on page 102) is a program that creates six additional multiplexed threads, each of which only prints out its process ID, LWP id, and thread id. <a href="#026a_00bc">Figure 1</A> shows the output from a run of the program with concurrency set to 1 (the minimum). Even at that setting, the threads library created two new LWPs (2 and 4) to run our spawned threads (2--7), proof that the concurrency level we set in <I>thr_setconcurrency</I> is a hint, not an order. <a href="#026a_00bd">Figure 2</A> shows the output when we increase the concurrency level by 1. A new LWP (5) appears. Notice also that from one iteration of the thread's main loop to the next, the thread can run on different LWPs.<P>
Another anomaly that leaps out when running <a href="#026a_00c0">Listing One</A> is that the first run creates three LWPs: the one running thread 1 (LWP1) and those running threads 2--7 (LWP2 and 4). Logically, there must have been an LWP3. In this case, the thread library's wrapper for the sleep function created its own bound thread and thus a new LWP, so you don't have absolute control over the number of LWPs in a process.<P>
Down in the details, scheduling and concurrency are even more complicated, but the bottom line is that two bound threads have the maximum probability of achieving true concurrency, while two muxthreads with concurrency level 1 have the minimum.<P>
<h3><a name="026a_00b0">What's in a Thread?<a name="026a_00b0"></h3><P>
The first decision in threading an application is which lumps of code should get their own threads. <a href="#026a_00bf">Table 2</A> lists categories of code granularity for threading. You need to mark medium- and coarse-grain functions for possible threading. A good example of a medium-grain function is a signal handler. Typically, a signal handler is a single function that does all its work within that function, or with calls to one or two other small functions. A typical coarse-grain function would be the serial I/O handler of a communications package. While it contains a huge amount of functionality, and correspondingly huge amounts of code, it needs user input to make a complete program.<P>
You also have to decide whether making two threads of execution concurrent yields any real-time gain to the user. If you have three functions--A, B, and C--where B can't start until A is done and C can't start until B is done, then making A and B concurrent gets you nowhere. If, however, B can start without A being done, then putting B in a separate thread could be a real-time win.<P>
<h3><a name="026a_00b1">Creation<a name="026a_00b1"></h3><P>
Creating a thread is as simple as making a call to <I>thr_create</I> with the address of the function that will be the &quot;main&quot; for that thread. Creating the new thread in a suspended state (THR_SUSPENDED) lets you specify exactly when the new thread begins to run. By calling <I>thr_continue</I>, the new thread begins processing at the first line of the function passed to <I>thr_create</I>. You can call <I>thr_suspend</I> at any time to pause your new thread.<P>
Note that with <I>thr_create</I> you can no longer rely on your stack to autogrow. The kernel supports autogrowth of a stack when you run out of stack space, but since the kernel isn't handling threads, it doesn't know anything about the threads' stacks. Thus, you have to allocate a big-enough stack right from the <I>thr_create</I> call.<P>
<h3><a name="026a_00b2">Threads and Signals<a name="026a_00b2"></h3><P>
You can set up separate signal masks for each thread in a process. A signal sent to a UNIX process from another UNIX process via <I>kill(process_id,signal_id)</I>, however, will only go to a thread enabled to catch that signal. If more than one thread is accepting a particular signal, the signal may be delivered to any accepting thread.<P>
For this and other reasons, Novell recommends that instead of dealing with signals on a thread-by-thread basis, applications mask all signals in all threads and dedicate a single thread to wait on incoming signals via <I>sigwait</I>. An &quot;object thread&quot; program that adds a signal handler thread to <a href="#026a_00c0">Listing One</A> is available electronically (see &quot;Availability,&quot; page 3). As always, it pays to build an appropriately limited signal set. Two new signals have been defined in UW 2.0 to support the threads lib, SIGWAITING and SIGLWP. SIGWAITING happens when all LWPs in the processes' LWP pool are blocked interruptibly. In <I>thread8</I>, this occurs when thread 1 is in <I>gets()</I>, thread 2 is sitting in a <I>sigwait()</I>, and all the other threads are either suspended or sleeping. If you add SIGWAITING to an object-thread program's signal set, the process will stop accepting user input.<P>
<h3><a name="026a_00b3">Shared Data<a name="026a_00b3"></h3><P>
To share data among HWPs, you have to use the System V shared-memory IPC. Threads, on the other hand, automatically share all global and static data. You can see this in <a href="#026a_00c0">Listing One</A>, where the variable <I>ulIterations</I> is a static in the thread-start function. Each thread increments <I>ulIterations</I> each time through the loop, and you get output like that in Figures <a href="#026a_00bc">1</A> and <a href="#026a_00bd">2</A>.<P>
If you made <I>ulIteration</I> an automatic variable, it would have gone on the stack, which is separate for each thread, and thus each thread would get its own, private copy, giving you output such as this:<P>
<pre>Thread1 Iteration 1
Thread2 Iteration 1
Thread1 Iteration 2
Thread1 Iteration 3
Thread2 Iteration 2</pre><P>
<h3><a name="026a_00b4">Interthread Coordination<a name="026a_00b4"></h3><P>
UW 2.0 supports a number of mechanisms for coordinating the activity of threads within a single HWP: locks, semaphores, and conditions. <P>
Mutual-exclusion locks are used to restrict resource access to a single thread. Lock the resource by calling <I>mutex_lock</I>. Any other thread calling <I>mutex_lock</I> for that mutex blocks until you call <I>mutex_unlock</I>. All the mutex calls take a pointer to a <I>mutex_t</I> structure as their first <I>arg</I> in order to identify the mutex. Under the rules of shared data, this <I>mutex_t struct</I> must be either global or static in order to be available to all threads.<P>
Reader-writer locks are a variation of mutex locks. They allow the application to place two different types of lock on the same resource. When performing a nondestructive operation on the resource (read), the app calls <I>rw_rdlock</I> to put a read lock on. Any number of threads can put read locks on a resource. If a thread attempts a write lock on the resource, it will block until the reader's unlock. When a thread acquires a write lock, all other readers and writers block until the single writer unlocks. In file-system terms, putting a read-lock on a resource is the equivalent of doing a <I>chmod 444</I> on a file (everyone can read, none can write), while putting a write lock is more like a <I>chmod 600 </I>(one can read/write, no others can read or write).<P>
Conditions provide a way for threads to wait on specific conditions without having to &quot;acquire&quot; a semaphore or a mutex. The pseudocode in <a href="#026a_00bb">Example 2</A> demonstrates this. <I>cond_wait</I> blocks until some thread validates the condition (sets <I>bLineIn</I> True) and calls <I>cond_signal</I> or <I>cond_broadcast</I>. We only sit in this loop retesting the condition because the condition could have been invalidated again by another thread that was also blocked on this condition and got scheduled before us.<P>
<h3><a name="026a_00b5">Thread Termination<a name="026a_00b5"></h3><P>
Terminating a thread is very similar to terminating a UNIX process. From inside the thread, you call <I>thr_exit</I> (which is called implicitly if the start function returns). From outside the thread, you have to send the thread a SIGTERM signal. To clean up, you can catch the signal, then call <I>thr_exit</I>. Suspended threads do not terminate until they are restarted.<P>
A process terminates when all non-daemon threads have terminated. A call to <I>exit()</I> or a return from <I>main()</I> (which implies exit) forces termination of all threads. A program that lets you interactively create and control a command-line-specifiable number of threads is available electronically. In the program, I precede the call <I>return(0)</I> at the end of <I>main()</I> with a call to <I>thr_exit()</I>. If you run this program and start up the threads, they'll start printing their output. While they're running, hit <I>q</I> to exit the main user-input loop. The spawned threads keep running, but <I>thread0</I> exits (the <I>return(0)</I> never gets executed). Run <I>thread9</I> again with the --d flag so that all threads are daemon threads and you see that the process (and all daemon threads) terminates when all nondaemon threads (thread 0, for instance) terminate.<P>
If, as Novell suggests, you create a separate signal-handling thread, either make it a daemon thread or make sure you have some way of killing it so that your process doesn't hang waiting for that endless thread to die.<P>
<h3><a name="026a_00b6">Threads and Libraries<a name="026a_00b6"></h3><P>
Those of us who suffered through the combination of OS/2 1.0 and Microsoft C 5.1 know all about the misery of non-reentrant libraries in a multithreaded environment--traps, mysterious hangs, crazy values. According to Novell, all the libraries delivered with 2.0 and the new SDK are thread safe. Third-party libraries are another story altogether. As usual, there's only one way to know for sure_.<P>
<h3><a name="026a_00b7">File I/O<a name="026a_00b7"></h3><P>
Sharing open-file descriptors introduces an atomicity problem that is almost certain to blow up any pre-SVR4.2 MP third-party library that does file I/O. Consider two threads, X and Y, which share an open-file descriptor. X wants to do a simple seek/read on that file, but <I>seek()</I> and <I>read()</I> are separate instructions, so X could be preempted between the two. During that preemption, Y could also call seek against that file descriptor, putting the descriptor's internal pointer someplace other than where X wanted it. When X regains control, it will read at the offset Y sought to, not the one X wanted. You could get around this by locking the file or surrounding all file ops with a semaphore, but those are pretty big hammers to use on such a small problem. <P>
To deal with this, UW 2.0 introduces <I>pread()</I> and <I>pwrite()</I>, which are atomic combinations of <I>lseek</I>/<I>read</I> and <I>lseek</I>/<I>write</I>. The calls are identical to <I>read </I>and <I>write </I>except that they take an extra argument--the offset from beginning of file to seek to. These calls do not change the file descriptors' internal file pointer as <I>lseek </I>would. <P>
<h3><a name="026a_00b8">Other Considerations<a name="026a_00b8"></h3><P>
Now that you're free of <I>fork</I>/<I>exec</I>, the temptation is to go out and write a new thread for everything (16 million threads!), but you should check that impulse just a little. There is a kernel-enforced limit on the number of LWPs that one user id can have. This is a kernel tunable called &quot;MAXULWP.&quot; It has a range of 1--65000 and defaults to 200, which should suffice for all but the most esoteric programs. <a href="#026a_00c0">Listing One</A> uses a kludgy method for obtaining MAXULWP. According to Novell, there is no supported way for a nonroot user to obtain MAXULWP.<P>
<h3><a name="026a_00b9">The Bottom Line<a name="026a_00b9"></h3><P>
UW 2.0 threads are easy to get running, and once you get used to it, they're a much more natural way of viewing problems than the old sequential model. Keeping in mind a few of the concepts and caveats I've discussed here should put you well on your way to writing the maximum multithreading program.<P>
<h4><a name="026a_00ba"><B>Example 1:</B> Calling a new process.<a name="026a_00ba"></h4><P>
<pre>if(( child_pid = fork()) != 0 )
    // do child process stuff
    exec( &quot;new_program&quot; );  // overlay this clone with a new executable
else
    // continue doing parent process stuff</pre><P>
<h4><a name="026a_00bb"><B>Example 2:</B> Pseudocode for conditions.<a name="026a_00bb"></h4><P>
<pre>cond_t MyCondition;              // All threads agree that this global                    
                                    condition indicates that a
                                 // line has arrived from the user.
mutex_t MyConditionsMutex;       // All threads agree that this mutex is  
                                    associated with
                                 // MyCondition.
// this is thread0
BOOL bLineIn = FALSE;
cond_init( &amp;MyCondition ...)
// spawn thread1
gets();
bLineIn = TRUE;
mutex_lock( &amp;MyConditionsMutex );
cond_signal( &amp;MyCondition );
mutex_unlock( &amp;MyCondition );

// this is thread1
mutex_lock( &amp;MyConditionsMutex )
do {
    iRet = cond_wait( &amp;MyCondition, &amp;MyConditionsMutex );
} while ( bLineIn == FALSE );
mutex_unlock( &amp;MyConditionsMutex );</pre><P>
<h4><a name="026a_00bc"><B>Figure 1:</B> <a href="#026a_00c0">Listing One</A> output at concurrency level 1.<a name="026a_00bc"></h4><P>
<pre>P1688 LWP2 - Thread 2 iteration 0
P1688 LWP2 - Thread 3 iteration 1
P1688 LWP2 - Thread 4 iteration 2
P1688 LWP4 - Thread 5 iteration 3
P1688 LWP4 - Thread 6 iteration 4
P1688 LWP4 - Thread 7 iteration 5
P1688 LWP2 - Thread 2 iteration 6
P1688 LWP2 - Thread 3 iteration 7
P1688 LWP2 - Thread 4 iteration 8
P1688 LWP2 - Thread 5 iteration 9
P1688 LWP4 - Thread 6 iteration 10
P1688 LWP4 - Thread 7 iteration 11
 ....</pre><P>
<h4><a name="026a_00bd"><B>Figure 2:</B> <a href="#026a_00c0">Listing One</A> output at concurrency level 2.<a name="026a_00bd"></h4><P>
<pre>P1688 LWP2 - Thread 2 iteration 0
P1688 LWP2 - Thread 3 iteration 1
P1688 LWP2 - Thread 4 iteration 2
P1688 LWP4 - Thread 5 iteration 3
P1688 LWP4 - Thread 6 iteration 4
P1688 LWP4 - Thread 7 iteration 5
P1688 LWP5 - Thread 2 iteration 6
P1688 LWP2 - Thread 3 iteration 7
P1688 LWP2 - Thread 4 iteration 8
P1688 LWP5 - Thread 5 iteration 9
P1688 LWP5 - Thread 6 iteration 10
P1688 LWP4 - Thread 7 iteration 11
 ....</pre><P>
<h4><a name="026a_00be"><B>Table 1:</B> Thread-specific calls and their process-specific analogues.<a name="026a_00be"></h4><P>
<pre>
Thread-Specific    Process-Specific   
Call               Analogue            

thr_create         fork/exec
thr_exit           exit
thr_join           wait
thr_kill           kill
thr_setprio        nice
thr_sigsetmask     sigsetmask (BSD)
pread              lseek/read
pwrite             lseek/write
getpid             thr_self</pre><P>
<h4><a name="026a_00bf"><B>Table 2:</B> Code granularity.<a name="026a_00bf"></h4><P>
<pre>
Code Granularity Level  Code Item              Comments  

Fine                    Loop                   May be threaded by 
                                                parallelizing
                                                compiler
Medium                  Standard one-page      Thread
                         function
Coarse                  Background serial I/O  Thread
                         communications 
                         handler
Super-coarse/gross      Program                Separate heavyweight process</pre><P>
<P>
<h4><a name="026a_00c0">Listing One <a name="026a_00c0"></h4><pre>

// A program to create and control a command line specifiable
// number of threads interactively.
//      command line arguments:
//         -b                 Create BOUND threads, defaults to multiplexed
//         -nthreads &lt;number&gt; Create number threads
// see code for explanation of interactive commands.

#include &quot;defines.h&quot;
#include &lt;sys/types.h&gt;
#include &lt;ctype.h&gt;
#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;
#include &lt;mt.h&gt;
#include &lt;sys/signal.h&gt;
#include &lt;thread.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;sys/lwp.h&gt;
#include &quot;listing1.hpp&quot;

#define MAX_THREADOBJECTS   65000
#define IDTUNE_CMD &quot;grep MAXULWP /etc/conf/cf.d/mtune | awk '{print $2}'&quot;
#define BUFSIZE 80

bool bBound;    // are we using bound or multiplexed threads??
pid_t getpid(), child1_pid, child2_pid;

int GetMAXULWP();
int flagset( int argc, char *argv[], char *flag );

// Main - create the number of threads specified on the command line, then sit
// in a loop accepting and executing interactive commands from the user.
int main( int argc, char *argv[] )
{
int i, k, iNumThreads;
Thread *pt[MAX_THREADOBJECTS];
int iMaxThreads;
int maxulwp;
int iNumRequestedThreads;
int thread_index;
int thread_id;
char kar;
char buffer[80];
int iConcurrencyLevel = 1;
int iRet;

maxulwp = GetMAXULWP();
if(( k = flagset( argc, argv, &quot;-nthreads&quot; )) &gt; 0 )
    iNumRequestedThreads = atoi( argv[k+1] );
else
    iNumRequestedThreads = MAX_THREADOBJECTS;
if( flagset( argc, argv, &quot;-b&quot; ) &gt; 0 )
    {
    bBound = TRUE;
    iMaxThreads = maxulwp + 1;
    }
else
    {
    bBound = FALSE;
    iMaxThreads = (maxulwp*4) + 1;
    if(( iRet = thr_setconcurrency( iConcurrencyLevel )) != 0 )
         printf( &quot;Error: thr_setconcurrency(%d) = %d\n&quot;, iConcurrencyLevel, iRet );
    }
printf( &quot;P%d LWP%d - Creating %d %s threads\n&quot;, getpid(), _lwp_self(), iNumRequestedThreads, 
         bBound?&quot;bound&quot;:&quot;multiplexed&quot; );
for( i = 0, iNumThreads = 0; i &lt; MAX_THREADOBJECTS &amp;&amp; i &lt; iNumRequestedThreads ; i++ )
    {
    if( bBound )
        pt[i] = new BoundThread();
    else
        pt[i] = new MultiplexedThread();
    if( !pt[i] )
        break;
    if( pt[i]-&gt;iCreateError != 0 )
        {
        printf( &quot;P%d - Thread create error %d\n&quot;, getpid(), pt[i]-&gt;iCreateError );
        delete pt[i];
        break;
        }
    iNumThreads++;
    if( iNumThreads == iMaxThreads)
        printf( &quot;P%d -\tNext thread will exceed MAXULWP (%d)\n&quot;, getpid(), maxulwp );
    }
printf( &quot;Following thread commands are available:\n&quot; );
printf( &quot;\ti - shows the status of all the threads\n&quot; );
printf( &quot;\ta - increments concurrency level\n&quot; );
printf( &quot;\tc - continues all the threads\n&quot; );
printf( &quot;\tc &lt;thread#&gt; - continues the specified thread\n&quot; );
printf( &quot;\ts - suspends all the threads\n&quot; );
printf( &quot;\ts &lt;thread#&gt; - suspends the specified thread\n&quot; );
printf( &quot;\tk &lt;thread#&gt; - sends SIGTERM to the specified thread\n&quot; );
printf( &quot;\tv - turns iteration printing on/off\n&quot; );
printf( &quot;\tq - ends the program\n&quot; );

sigignore( SIGTERM );
bool bKeepRunning = TRUE;
while( bKeepRunning )
    {   
    thread_id = -1;
    thread_index = -1;
    gets( buffer );
    kar = toupper( buffer[0] );
    for( i = 1; buffer[i] != '\0'; i++ )
        {
            if( !isspace( buffer[i] ))
            {
            thread_id = atoi( &amp;buffer[i] );
            for( i = 0; i &lt; iNumThreads; i++ )
                {
                if( thread_id == pt[i]-&gt;tid )
                    {
                    thread_index = i;
                    break;
                    }
                }
            break;
            }   
        }
    switch( kar )
        {
        case 'A':
            iConcurrencyLevel++;
            // iConcurr... is 1 based, while iNumThreads is 0 based
            if( iConcurrencyLevel &gt; (iNumThreads+1))
                printf( &quot;Error: would have more LWPs than threads!\n&quot; );
            else
                {
                if(( iRet = thr_setconcurrency( iConcurrencyLevel )) != 0 )
                    printf( &quot;Error: thr_setconcurrency(%d) = %d\n&quot;, iConcurrencyLevel, iRet );
                }
            break;
        case 'I':
            for( i = 0; i &lt; iNumThreads; i++ )
                printf( &quot;\tThread id %d - %s\n&quot;, 
                    pt[i]-&gt;tid, pt[i]-&gt;Ended?&quot;GONE&quot;:&quot;STILL RUNNING&quot; );
            break;
        case 'C':
            if( thread_id &gt;= 0 )
                pt[thread_index]-&gt;Continue();
            else
                for( i = 0; i &lt; iNumThreads; i++ )
                    pt[i]-&gt;Continue();
            break;
        case 'S':
            if( thread_id &gt;= 0 )
                pt[thread_index]-&gt;Suspend();
            else
                for( i = 0; i &lt; iNumThreads; i++ )
                    pt[i]-&gt;Suspend();
            break;
        case 'K':
            if( thread_id &gt;= 0 )
                pt[thread_index]-&gt;Kill( SIGTERM );
            else
                for( i = 0; i &lt; iNumThreads; i++ )
                    pt[i]-&gt;Kill(SIGTERM);
            break;
        case 'V':
            for( i = 0; i &lt; iNumThreads; i++ )
                pt[i]-&gt;bVerbose = pt[i]-&gt;bVerbose^0x1;
            break;
        case 'Q':
            bKeepRunning = FALSE;
            break;
        default:
            printf( &quot;Unknown command (%c) (%s)\n&quot;, kar, buffer );
            break;
        }
    }
// We really don't have to call End, because the return kills the 
// threads anyway, but cleanliness counts.
for( i = 0; i &lt; iNumThreads; i++ )
    pt[i]-&gt;End();
printf( &quot;P%d - Ending thread 0\n&quot;, getpid() );
return( 0 );
}
// flagset - tells whether a command-line flag was set. returns an index into
// argv where flag was detected. Use return val+1 to get arg following a flag
int flagset( int argc, char *argv[], char *flag )
{
for( int i = 1; i &lt; argc; i++ )
    {
    if( strcmp( argv[i], flag ) == 0 )
        return( i );
    }
return( -1 );
// This function greps MAXULWP out of mtune so that we can tell 
// when we're about to exceed the maximum allowable number of LWPs per user id.
int GetMAXULWP()
{
int maxulwp, i;
FILE *fp;
char buf[BUFSIZE];

if(( fp = popen( IDTUNE_CMD, &quot;r&quot; )) &lt; 0 )
    printf( &quot;P%d - Couldn't exec %s - skipping MAXULWP check\n&quot;, getpid(), IDTUNE_CMD );
else
    {
    i = 0;
    while (fgets(buf, BUFSIZ, fp ) != NULL)
        {
        maxulwp = atoi( buf );
        printf( &quot;P%d - Got MAXULWP value of %d\n&quot;, getpid(), maxulwp );
        i++;
        }
    if( i &gt; 1 )
        printf( &quot;P%d - ambiguous value for MAXULWP, skipping check\n&quot;, getpid() );
    pclose( fp );
    }
return( maxulwp );
}


</pre>
<HR><P>Copyright &copy; 1995, <I>Dr. Dobb's Journal</I></P></BODY></HTML>
