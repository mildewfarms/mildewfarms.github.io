<HTML>
<META NAME="year" CONTENT="1996">
<HEAD>
<!-- This document was built using HyperWriter Professional by NTERGAID Inc. -->
<TITLE>JUN96: LETTERS</TITLE></HEAD>
<body bgcolor="FFFFFF">
<h1>LETTERS<a name="01f6_0001"><a name="01f6_0001"></h1><P>
<h3><a name="01f6_0002">Amiga Fans<a name="01f6_0002"></h3><P>
Dear <I>DDJ</I>,<P>
Thank you for mentioning the Amiga in your article &quot;<I>Dr. Dobb's Journal </I>Excellence in Programming Awards&quot; (<I>DDJ</I>, March 1996). When I saw the name of my computer-of-choice next to the names of those big-named systems, I was beside myself. Those were ten letters that you didn't have to put in your article (well, 15, if you count the commas, spaces, and the hyphen) but, you put them in anyway.<P>
I know it's silly to be happy about something like that but, after the Commodore bankruptcy, I thought the Amiga might disappear from the face of the Earth. Hopefully, Amiga Technologies will be able to resurrect this fine machine.<P>
Maybe some day articles on AmigaDOS message passing will sit next to articles on Windows message passing in your magazine.  <P>
Michael S. Sage<P>
Amherst, Ohio   <P>
aa5964@freenet.lorain.oberlin.edu <P>
<h3><a name="01f6_0003">Quincy 96<a name="01f6_0003"></h3><P>
Dear <I>DDJ</I>,<P>
Al Stevens' &quot;C Programming&quot; column about Quincy 96 (<I>DDJ</I>, February 1996) sounds like a worthwhile project and I hope he continues extending it as mentioned to include some AppWizard/ClassWizard functionality. Example code is always of great help to developers working on development environments for their tools.<P>
Al mentions that &quot;no one has licensed or ported MFC to GNU C++&quot; (page 126). I should comment that my company offers a library called WM_MOTIF that allows developers to use MFC applications on the more popular UNIX environments. Ads for the library have appeared several times in <I>DDJ</I> over the past year, so you might have read about it. As part of that product, we provide the necessary changes to use MFC 2.52 and 3.1 with g++ (4.0 by February 1996). We do not include the Microsoft source code, only our changes applied automatically via a patch program. I believe two other companies also offer support for MFC under g++, with Microsoft's blessing. Information about our WM_MOTIF library and the WMMPATCH utility is available from our Web site (http://www.uno.com).<P>
When you extend your IDE further, you might consider porting it to Linux using a &quot;Lite&quot; version of WM_MOTIF. Requests for IDE functionality for gcc/g++ appear frequently on the Linux USENET groups (particularly comp.os.linux.development.apps).<P>
Jesus Alvarez<P>
jalvarez@uno.com  <P>
<h3><a name="01f6_0004">Majority Rule<a name="01f6_0004"></h3><P>
Dear <I>DDJ</I>,<P>
Thomas Nielsen's letter on majority rule (<I>DDJ</I>, February 1996) prompts me to recommend the book <I>Beyond Numeracy: An Uncommon Dictionary of Mathematics</I>, by John Allen Paulos (Random House, 1991).<P>
<I>Beyond Numeracy</I> contains a chapter addressing which voting system is the fairest, giving an example of 5 candidates and 55 voters. It turns out that there is a voting system that suits each candidate; that is, choose the voting system and you have chosen the candidate. This is not an academic exercise because here in Italy the political parties have been fighting for years to get their own voting system used, each of course wanting the one that gives them the most points. The other chapters in Paulos' book will be of interest to programmers, too.<P>
Owen F. Ransen<P>
rans001@IT.net <P>
<h3><a name="01f6_0005">The Future of Programming, Visual and Otherwise<a name="01f6_0005"></h3><P>
Dear <I>DDJ</I>,<P>
I loved your March 1996 issue. Keep up the good work. However, I disagree with a couple of sentences in Al Stevens' &quot;C Programming&quot; column. I know it is an opinion column, and he is entitled to his beliefs, but I object to serious journals, such as <I>DDJ,</I> spreading disinformation. Al writes: <P>
Will such 3-D visual programming environments eliminate the need for programmers to understand source code as we know it today? Not likely. C++ and Visual Basic have not eliminated assembly language. Or machine language, for that matter. In the future, when all else fails, you will look at an occasional memory dump, stack pointer, and interrupt vector, just as you do today.<P>
While I do remember looking at core dumps--back when they were from little donuts of magnetic material--I have not looked at one in at least 20 years. I can agree that for some small set of serious gurus, looking at the entrails of our programs may occasionally be informative. I believe that for most professionals using modern tools, there is no need.<P>
More importantly, I think journals such as <I>DDJ</I> have a responsibility to educate developers that hand-coded assembly programming has no place in modern systems. RISC systems, and RISC-like CPUs such as the P6, rely upon intelligent optimizing compilers to keep their pipelines full, their registers renamable, and the performance at the level claimed.<P>
It is simply impossible to optimize more than a handful of assembly instructions. Yet the PentiumPro (P6) has a 14-stage pipeline and three execution units. To have all of these parts working at rated speeds takes at least 17 stages of continuous work. Achieving the advertised performance takes a continuous stream of hundreds of optimized instructions.<P>
Computers (compilers) are good at repetitive calculations. Humans would go crazy from boredom before optimizing a meaningful amount of code. The next generation of CPUs from Intel and HP will use VLIW technology. This will further strengthen the demand for optimizing compilers. Hand-coded assembly language is dead for all but embedded systems. <I>DD</I><I>J</I>'s readers should be getting this as a consistent message.<P>
By the way, it will be interesting to see how interpreted languages such as Java, Smalltalk, and Visual Basic work on next- generation CPUs.<P>
Pat Farrell    <P>
Fairfax, Virginia<P>
http://www.isse.gmu.edu/students/pfarrell<P>
<I>Al responds:</I> Core dumps? I haven't looked at a core dump in years either, but I look at RAM dumps almost daily. I wonder how fortunate I would think myself to have been spared the rigors of assembly language, memory dumps, register contents, and such for 20 years. You might view it as a blessing; I would take it as a hindrance. Most contemporary debuggers allow us to view registers, memory buffers, and machine-language code unassemblies. Those debuggers are in the toolsets of virtually all programmers, not just for the so-called gurus. Those features are there because we need them. That need is not likely to go away any time soon.<P>
<h3><a name="01f6_0006">Plumbers and Programmers<a name="01f6_0006"></h3><P>
Dear <I>DDJ</I>,<P>
In your April 1996 issue, Al Stevens talks about getting programmers out of the closet so they can know when the insulation is not installed because the wiring's not done because the plumbers have not finished. His suggestion that programmers work in a virtual environment to make this possible ignores some more pressing problems in software development. The team must first learn why the wiring must be done before the insulation.<P>
Having changed employers more frequently than I care to admit, it has become clear that each business regards its product as unique. The theorists in our business are studying &quot;patterns&quot; as the newest trend in software development. The patterns have existed all along, it was EGO that refused to see it.<P>
chermann@cris.com<P>
<h3><a name="01f6_0007">Hashing it Out<a name="01f6_0007"></h3><P>
Dear <I>DDJ</I>,<P>
Andrew Binstock's article &quot;Hashing Rehashed&quot; (<I>DDJ</I>, April 1996) was interesting and timely, as I just finished writing a portable hash-table class for a project last month. Along with the square-root article and &quot;Swaine's Flames,&quot; this was quite the issue!<P>
While inspecting the PJW and Elf algorithms to see which one might be the most appropriate for my class, I kept noticing something interesting. If <I>sizeof( int)==sizeof( long)==4</I>, the algorithms are identical. Just now I ran them both through UNIX's /usr/dict/web2 and web2a, and indeed they always return the same results on my 32-bit system.<P>
Now, off to determine whether an expandable closed table would be appropriate for this class....<P>
Scott Hess <P>
Burnsville, Minnesota<P>
shess@winternet.com<P>
Dear <I>DDJ</I>,<P>
I read with much interest the article &quot;Hashing Rehashed,&quot; by Andrew Binstock (<I>DDJ</I>, April 1996). Andrew presents a decent article, however, I have an additional recommendation.<P>
First of all, searching through a linked list can be, at worst, O(n) in efficiency. This is due to the fact that it is possible, with an inefficient algorithm, to produce a &quot;hit&quot; on the same hash value numerous times. Instead of using a linked list to store the data off of the hash table, I suggest using a binary tree. That way, even if the hash function is poor, the binary tree will still return O(log2 n) access to the stored data. This is relatively easy to accomplish. Instead of the array or table pointing to the head of the linked list, change the table to point to the root of the tree. This, in addition to being a near-perfect hashing algorithm, will produce speedier results.<P>
Brigham W. Thorp<P>
West Simsbury, Connecticut   <P>
Brigg999@aol.com<P>
<h3><a name="01f6_0008">Parsing Parsers<a name="01f6_0008"></h3><P>
Dear <I>DDJ</I>,<P>
Bravo for Thor Mirchandani's article &quot;Building Parsers with Leopurd&quot; (<I>DDJ</I>, March 1996). I have seen too many software projects in which the use of LEX and YACC resulted in size, speed, and compatibility problems. Top-down parsers of the type that Thor describes are very simple to program and maintain. They can easily be an order of magnitude smaller and faster, because they don't have to wander around in all those big tables, and they don't have to build parse trees.<P>
I believe there is one mental block that prevents many programmers from programming and using top-down parsers. It is the idea of one-token look-ahead. I think look-ahead is counter intuitive because it means you scan in the next token immediately after accepting the current one, rather than immediately before. Many algorithms can be simplified by using look-ahead, not just parsers.<P>
Mike Dunlavey<P>
Needham, Massachusetts <P>
miked@mga.com<P>
<P>
<P>
<P>
<P>
<P>
<P>
<P>
<P>
<P>
<P>
<P>
<P>
<P>
<P>
<P>
</BODY></HTML>
