<html>
<head>
<title>Getting Better Search Results</title>
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/Layout.css" type="text/css">
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/FontStyles.css" type="text/css">
<link rel="Stylesheet" rev="Stylesheet" href="../../../../forms/newarticle.css" type="text/css">
<script src="../../../../forms/popwindow.js"></script>
</head>

<body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000">
<!--Copyright &#169; Dr. Dobb's Journal-->
<p><i>Dr. Dobb's Journal</i> May 2008</p>

<h1>Getting Better Search Results</h1>
<h2>Human-aided filtering can make the difference</h2>


<h3>By Bob Zeidman</h3>


<I>Bob is the president of Zeidman Consulting. He can be reached at <a href="mailto:Bob@ZeidmanConsulting.com">Bob@ZeidmanConsulting.com</a>.</I>

<hr>




<p>Search engines are great. Put in keywords and out pop hundreds, thousands, sometimes millions of web pages. But then what? How can you effectively look at all of those pages? Maybe it's time to put people back in the equation. After all, we can still do a few things better than computers, like quickly filtering out irrelevant information. With the right tools, the computer can even help us do this more efficiently. </p>

<p>In this article (which is based on a more detailed paper that was presented at the 11th World Multi-Conference on Systemics, Cybernetics and Informatics), I use human-aided filtering to focus in on useful information. I have incorporated human-aided filtering into a tool for finding software plagiarism. After the tool finds similar sections of code in two programs, the human and the computer work together to pinpoint the results that are most relevant. </p>


<h3>CodeMatch</h3>

<p>For the past decade, I've been an expert witness in intellectual property cases and asked to examine software source code from a plaintiff or defendant to determine whether one has plagiarized code from the other. Over time, I've found that the few existing tools for plagiarism detection were too inaccurate for situations where hundreds of millions of dollars could be at stake. Consequently, I developed my own tool called "CodeMatch" (www.safe-corp.biz/products_codesuite.htm).</p>

<p>CodeMatch uses four algorithms to determine the correlation between source-code files for different programs:</p>

<ul>
    <li>Statement Correlation. A measure of the number of identical statements. </li>
  <li>Comment Correlation. A measure of the number of identical comments.</li>
  <li>Identifier Correlation. A measure of the number of identical and nearly identical identifiers.</li>
  <li>Instruction Sequence Correlation. A measure of the longest sequence of identical instructions.</li>
  </ul>

<p>After using CodeMatch on a number of cases, I found that although it had great accuracy, it shared one deficiency with the other tools&#151;too much output. After examining the results, I often found information that was not relevant to the particular case on which I was working. Because a large comparison could take a week for results, it was impractical to rerun the comparison using new settings. I began to spend time manually filtering the results to obtain a more manageable and more relevant set of results. The main purpose of CodeMatch was to reduce the time I spent looking at lines of code. While it did reduce my time by at least an order of magnitude from manually examining code files, I now wanted to reduce the time I spent poring over the results. (My wife thinks this is a bit crazy since I get paid per hour.)</p>








<h3>Superfluous Results</h3>

<p>In reviewing the results of the comparison, often some specific files or specific source-code elements would show up throughout the results, skewing results and hiding important correlation information. For example, open-source files may have been used in one or both sets of files. In searching for plagiarized code, the open-source files would be highly correlated with each other, but these correlations were not important. Pieces of these files would show up throughout both sets of files and flagged as highly correlated.</p>

<p>Similarly, there were specific statements, comments, and identifiers that showed up in many places, but were not relevant to finding plagiarized code. Users searching for plagiarized code may find that two programs running on Linux both use the same system calls. Thus, files with these system calls will have a higher correlation. Common identifier names like "index," "count," and "result" showed up in many files, increasing correlation values, but were not necessarily signs of plagiarism.</p>

<p>Had these results been known upfront, some of them could have been eliminated before CodeMatch was run. However, given the number of files and the number of source-code elements, it was impractical to find these elements before performing the correlation. Also, the correlation itself pointed out many of these superfluous elements.</p>


<h3>CodeMatch  Post-Process Filtering</h3>

<p>To make examining the correlation results more useful and let users focus on the kinds of correlation that are most important, I added the ability to filter the results. After CodeMatch produces a database of results, this filtering can be performed on the database:</p>

<ul>
    <li>Statement filtering. A list of statements is created by users. Any correlation due to a statement on this list is eliminated.</li>
  <li>Comment filtering. A list of comments is created by users. Any correlation due to a comment on this list is eliminated.</li>
  <li>Identifier filtering. A list of identifiers is created by users. Any correlation due to an identifier on this list is eliminated.</li>
  <li>General file filtering. A list of file names is created by users. Any correlation between any file whose name appears on the list and any other file is removed from the results database.</li>
  <li>Specific file filtering. A list of file names with specific paths is created by users. Any correlation between a specific file on the list and any other file is removed from the results database.</li>
  <li>Folder filtering. A list of folders is created by the user. Any correlation between a file in a folder on the list and any other file is removed from the results database.</li>
  <li>Threshold filtering. Users can change threshold parameters, reducing the number of correlated file pairs that are displayed. Users can set minimum and maximum correlation scores to display and can set a maximum number of correlated files to display.</li>
  </ul>

<p>After the filtering is performed on the database, the correlation scores between file pairs are adjusted accordingly. I found that for large file sets, this filtering reduced the manual process of reviewing the results in order to find plagiarized source-code files from days to hours or even minutes. </p>

<p>My experience using filtering with CodeMatch can be generalized to any kind of information retrieval process. To understand how filtering can be used, it is important to first understand the different kinds of information retrieval processes and information display methods.</p>









<h3>Information Retrieval</h3>

<p>Since the best-known information retrieval process is probably web searching, I use it as an example. Information retrieval can be classified into two types&#151;exact match and best match.</p>

<p>The exact match type of information retrieval is represented by the Boolean retrieval method. In these cases, Boolean equations of keywords are entered by users and all objects in the information domain that meet the criteria are retrieved. Most search engines use exact matching; the information domain is the Web. Even the more sophisticated search engines that let users input natural-language queries are typically parsing the language to retrieve the keywords and Boolean equations.</p>

<p>Best-match information retrieval uses vector space and probabilistic retrieval methods that essentially try to understand what information a user wants, sometimes based on past searches or other stored user parameters, and then present the information to the user that seems closest to what the user wants. An example of this would be the book suggestions that Amazon.com presents to customers, based on the customer's search criteria and past searches.</p>



<div>
    
<!--  -->    
<img class="illowide" src="080401bz01_f1.gif" style="width:398">

<div class="caption" style="width:400">
Figure 1: Information retrieval.
</div>
</div>



<p>Figure 1 is a graphical representation of information retrieval, where <i>D</i> is the information domain, <i>Q</i> is the user's query, and <i>O</i> is the object retrieved by the query. <i>D<sub>U</i></sub> is the subset of the domain that meets the user's information need based on the retrieval process. Each arrow from an object to the query represents the relationship <i>R<sub>i</i></sub> between the query and object. For all retrieval methods, <i>D<sub>U</i></sub> is the set of all objects, such that <i>R<sub>i</sub>&gt;0</i>:</p>

<pre class="code">

D<sub>U</sub>={O<sub>i</sub> : R<sub>i</sub> &gt; 0 for all i}


</pre>
<p>However, the relationship can be further refined depending on whether the retrieval method is Boolean, Probabilistic, or Vector. For a Boolean retrieval method, <i>R<sub>i</i></sub> is a scalar 1 for all <i>i.</i> In other words, a Boolean method only retrieves objects that exactly match the query:</p>

<pre class="code">

R<sub>i</sub> = 1 for all i

</pre>
<p>For a probabilistic retrieval method, <i>R<sub>i</i></sub> equals <i>r(Q|O<sub>i</sub>)</i>, which is the probability that a user's query is met by retrieved object <i>O<sub>i</i></sub>. A probabilistic method retrieves information based on some threshold probability that the object is what the user wants:</p>

<pre class="code">

R<sub>i</sub> = r(Q|O<sub>i</sub>) for all i

</pre>
<p>For a vector space retrieval method, <i>R<sub>i</i></sub> equals <i>(Q,O<sub>i</sub>)</i>, which is the correlation between a user's query and some object <i>O<sub>i</i></sub>. A vector space method retrieves information that is similar to another object that the user desires:</p>

<pre class="code">


R<sub>i</sub> = (Q,O<sub>i</sub>) for all i

</pre>
<p>In addition to relationships between a query and the retrieved objects, note that there are relationships between various retrieved objects, represented by the arrows <i>R<sub>ik</i></sub> between objects <i>O<sub>i</i></sub> and <i>O<sub>k</i></sub>. I make use of this fact for post-process filtering. </p>


<h3>Information Display</h3>

<p>Once the information objects are retrieved from the domain, they must be displayed to users. There are two types of criteria that can be used for this display in order to rank the retrieved objects. </p>

<ul>
    <li>Internal criteria are criteria derived from the relationships determined during the retrieval process. </li>
  <li>External criteria are criteria determined in a new step unrelated to the retrieval process. </li>
</ul>

<p>Of course, combinations of internal and external criteria can also be used.</p>

<p>For best-match retrieval methods, the objects can be displayed in order according to their relationship to the query. Objects with higher probabilities or higher correlation values are displayed first. The relationships are used as the criteria for displaying the objects. For exact-match retrieval methods, internal criteria do not provide a way to display the results because all retrieved objects have a relationship of 1.</p>

<p>External criteria are often used to display the results of search engines. Perhaps the best-known example of external display criteria is the PageRank method used by Google that ranks pages according to how many other pages are linked to it. Other methods include the Hub-Threshold Kleinberg algorithm. I use the term <i>P</i><sub>i</sub> to generally represent ranking methods.</p>

<p>Regardless of which kind of ranking criteria is used, there is often also a display threshold. Retrieved objects that have a ranking below the display threshold are not shown to users. An object with a very low ranking is thought to be irrelevant and its relationship with the query is thought to be random, rather than due to any relationship that would be significant to users.</p>










<h3>Post-Retrieval Filtering</h3>

<p>What I propose is another step after retrieval and display to further refine the results and reduce the number of retrieved objects to one that is reasonable to examine. There are several ways this can be accomplished using combinations of object filters, new query filters, negative query filters, threshold filters, and object relationship filters.</p>

<p>Object filtering is the process of letting users eliminate individual objects or whole sets of objects from the user information domain <i>D<sub>U</i></sub>. This can be done by letting users specify objects to remove or categories of objects to remove. The removal process is dependent on the type of information being retrieved. When the retrieved objects are files, the criteria used to remove objects might be file name, location (path name), size, modification date, or creation date. With regard to CodeMatch, the general file filtering, specific file filtering, and folder filtering are examples of object filtering. In the case of a search engine, a user could specify to remove certain websites from the search results, or users could specify certain web page names to be removed. Users could also click on certain specific pages to be removed.</p>

<p>New query filtering refers to using a new query on the retrieved user domain <i>D<sub>U</i></sub> to create a new domain <i>D<sub>U</sub>'</i> that is a subset of <i>D<sub>U</i></sub>. Some search engines provide this kind of filtering by allowing the user to further search the retrieved results with a new Boolean expression of keywords.</p>

<p>Negative query filtering refers to applying a query to the retrieved information in order to eliminate objects. For instance, suppose the original query is a Boolean query to find all documents with the phrases "software," "source code," or "correlation." A query-based elimination filter would be one where the user eliminates all retrieved documents that contain the keyword "correlation." This would be equivalent to an original query to find all documents with the phrases "software" and "source code" but not "correlation." There are two reasons in particular that negative query filtering is useful:</p>

<ul>
    <li>If the user were to perform a new query to the search engine, it would require more resources (compute power, storage space, network bandwidth, and so on) than a negative query filter performed on the retrieved objects. For example, the negative query could be done locally on the client computer. </li>
  <li>If the query is a best-match query rather than an exact-match query, the negative query filter can be used to get results that may be difficult for users to define with a single query.</li>
</ul>

<p>Threshold filtering involves setting thresholds for displaying the retrieved objects to the user after the information has been retrieved. I define three kinds of threshold filters&#151;relationship thresholds, ranking thresholds, and number thresholds. Combinations of these thresholds are also possible.</p>

<p>With a relationship threshold, the value used for determining the threshold is the <i>R<sub>i</i></sub> relationship between the query and the objects. In other words, any object <i>O<sub>i</i></sub> with relationship <i>R<sub>i</i></sub> that is less than threshold <i>T</i> gets eliminated from the results. </p>

<p>Ranking threshold filtering can be based on the information display ranking. For example, the Google PageRank criteria can be used such that any object <i>O<sub>i</i></sub> with rank <i>P<sub>i</i></sub><sub> </sub>that is less than threshold <i>T</i> gets eliminated from the results.</p>

<p>Number threshold filtering is the process of simply reducing the number of objects in the user domain <i>D<sub>u</i></sub> to one that is more manageable. It requires that the information retrieval method be a best-match method or that the information display process uses a ranking method. Otherwise, for the exactmatch method, all retrieved objects have equal relationships to the query, and eliminating a specific number of them would have to be arbitrary. Given a number threshold <i>N,</i> if the retrieval method is best match, the objects <i>O<sub>i</i></sub> are ordered from highest to lowest by their relationship <i>R<sub>i</i></sub> until the number of objects displayed is <i>N.</i> If the retrieval method is exact match but the display process uses a ranking method, the objects <i>O<sub>i</i></sub> are ordered from highest to lowest by their ranking <i>P<sub>i</i></sub> until the number of objects displayed is <i>N</i>.</p>

<p>Thresholds need not be minimum thresholds. Maximum thresholds and combinations of minimum and maximum thresholds may be appropriate if the user wishes to study various aspects of the retrieved information such as statistical distributions of the information. Effectively, these thresholds can be used as low pass, high pass, and band pass filters.</p>

<p>An object relationship filter lets users select an object <i>O<sub>i</i></sub> that they feel is characteristic of an object that the user wants to see or that the user does not want to see. All similar objects are then removed, or all dissimilar objects are removed, depending on whether the filter is a positive object relationship filter or a negative object relationship filter.</p>

<p>For a positive object relationship filter, the user selects an object <i>O<sub>i</i></sub> and specifies a minimum relationship value <i>R<sub>M</i></sub>. Object <i>O<sub>i</i></sub> and all objects <i>O<sub>k</i></sub> such that the relationship <i>R<sub>ik</i></sub> between objects <i>O<sub>i</i></sub> and <i>O<sub>k</i></sub> is greater than or equal to the minimum relationship value R<sub>M</sub> are eliminated from the user information domain <i>D<sub>U</sub>.</i> In this case, object <i>O<sub>i</i></sub> is selected as an example of an object that the user feels is not relevant. In the case of a search engine, the user would select a web page that the user feels is not relevant. That web page and all similar web pages would be eliminated from the search results.</p>

<p>For a negative object relationship filter, the user selects an object <i>O<sub>i</i></sub> and specifies a minimum relationship value <i>R<sub>M</i></sub>. All objects <i>O<sub>k</i></sub> such that the relationship <i>R<sub>ik</i></sub> between objects <i>O<sub>i</i></sub> and <i>O<sub>k</i></sub> is less than the minimum relationship value <i>R<sub>M</i></sub> are eliminated from the user information domain <i>D<sub>U.</i></sub> In this case, object <i>O<sub>i</i></sub> is selected as an example of an object that the user feels is particularly relevant. In the case of a search engine, the user would select a web page that the user feels is most relevant, and all dissimilar web pages would be eliminated from the search results.</p>

<p>Object-relationship filtering lets users select objects to be included/excluded from the results without understanding the details of why the object is relevant or is not relevant. This can be very important because unsophisticated users can look at the results of a web search and recognize when they find good results and bad results, but may not define those good and bad results in terms of keywords. Object-relationship filtering has great potential for e-commerce. Often consumers may not be able to easily create keywords to define the items they desire. But they know it when they see it. They can click on an exemplary item from a search and obtain a list of all similar items.</p>


<h3>Conclusion</h3>

<p>Better methods of information retrieval will always be needed and these methods are improving regularly. Better methods of information display are also important and there is a great demand for it as evidenced by the success of Google, one of whose major innovations was in the area of information display. Automatic filtering of retrieved information is a great goal and research is going on in that area also. However, automatic filtering may never be 100-percent accurate and human-aided filtering has many great benefits that have yet to be fully exploited. </p>


<h3>References</h3>

<p>Nicholas J. Belkin and W. Bruce Croft, "Information Filtering and Information Retrieval: Two Sides of the Same Coin?" <i>Communications of the ACM,</i> 35(12), 29-38, 1992.</p>

<p>Sergey Brin and Lawrence Page, "The Anatomy of a Large-Scale Hypertextual Web Search Engine," <i>WWW7/Computer Networks </i>30(1-7): 107-117, 1998.</p>

<p>Peter W. Foltz and Susan T. Dumais, "Personalized Information Delivery: An Analysis of Information Filtering Methods," <i>Communications of the ACM</i>, 35(12), 51-60, 1992.</p>

<p>Lee Gomes, "Computer Scientists Pull a Tom Sawyer To Finish Grunt Work," <i>The Wall Street Journal</i>, June 27, 2007.</p>

<p>Peter Pirolli and Stuart K. Card, "Information foraging," P<i>sychological Review,</i> 106: 643-675, 1999.</p>

<p>G. Salton and M.J. McGill, <i>Introduction to Modern Information Retrieval</i>, McGraw Hill, New York, 1983.</p>

<p>Bob Zeidman, "Detecting Source-Code Plagiarism," <i>Dr. Dobb's Journal</i>, July 2004, 55-60.</p>

<p>Bob Zeidman, "Iterative Filtering of Retrieved Information to Increase Relevance," <i>The 11th World Multi-Conference on Systemics, Cybernetics and Informatics</i>, July 11, 2007.</p>















</body>
</html>