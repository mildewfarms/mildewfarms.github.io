<HTML>
<META NAME="year" CONTENT="1988">
<HEAD>

<TITLE>SP 88: OPENING EDITORIAL</TITLE></HEAD>
<body bgcolor="FFFFFF">
<h1>OPENING EDITORIAL<a name="0243_0003"><a name="0243_0003"></h1><P>
<h3><a name="0243_0001"><a name="0243_0000">Phillip Robinson</h3><P>
<p><i><a name="0243_0002"><a name="0243_0000">Phillip Robinson is an editor and designer at Virtual Information, a Sausalito, Calif., publishing and programming firm.</i></p><hr><P>
The notions of software engineering and CASE (computer-aided software engineering) sometimes get tangled together.  They aren't the same thing.  CASE is the application of computers to the creation, testing, and modification of software.  Software engineering goes beyond that, encompassing not only CASE but the entire process by which a program is imagined, structured, produced, verified, and maintained.  CASE tools can certainly organize and speed most any software engineering effort, but they will be most effective if they are themselves designed and used in harmony with proven software engineering techniques.<P>
After all, what is a CASE tool?  The term is usually given only to specialized prototyping programs, version-control utilities, and the like.  But a debugger is a CASE tool; so is an editor, for that matter, and even an operating system, with its attendant utilities.  These are all certainly helpful tools, and the proliferation of sophisticated CASE utilities on the PC level is nothing short of a godsend for personal computer programmers.  But the present form of these tools can sometimes obscure the more far-reaching questions of software engineering, such as: How should you organize the many steps and tools of a programming effort?  What interface metaphor is most productive?  How closely should a particular programming tool match its intended application area?  How can large projects be coherently arranged and scheduled to use many computers and many programmers?<P>
These are certainly not idle questions.  We devote a staggering number of hours to programming computers and are often left shaking our heads at the inadequate performance that is the result of our labor.  Heaps of features and entire applications are left waiting for that imaginary day when we will have the time to really get it right or even get to it at all.  Meanwhile, hardware designers from the individual chip to the mainframe system level can boast every year that their products are twice as fast, twice as effective, many times the power at less price than the hardware of yesterday.  Software designers are left in the dust, hoping for a few percentage point improvements in programming efficiency.  The number of lines of correct code per day expected from a top-ranked programmer is still in the double digits. Combine that excruciating fact with the common wisdom that larger programming teams can have serious communication problems, and you have a recipe for anguish.  (You've probably heard the joke, How long will it take twice as many programmers to finish the job?  Answer: Twice as long if you're lucky and if they finish at all.)<P>
Nor is the quest for programmer productivity one that only dreamers pursue.  The company or individual that comes up with a program in less time can often win the race outright, or at least claim a powerful position in the market.  If that program is also easily maintained and enhanced, the company or individual will have a head start every day of the competition.  If some of the program's code can be reused in the product that succeeds it, the race will be over almost before it starts.  Software productivity may even have an impact at the political level, from economic competition to military conflicts.  The U.S. military spends a great deal of money on software.  It even demanded a new programming language, armed to the teeth with software engineering ideas and structures, just so it could get its programming house in order.  So if it's so important, what about some answers?  How do you write good code quickly?  A good compiler with a library of reusable modules is vital, as is a flexible editor, a potent debugger, and other such tools.  These have long been advertised, reviewed, and otherwise touted in Doctor Dobb's and other journals.  Other important tools, however, don't get as much press.  Add a prototyper to the stew if you want to get some ideas right away about the program's general design and look.  If it's a big project, you might consider adding a version control utility, a documentation librarian, and other such CASE utilities.  There are even programs that help you analyze programs for their adherence to standards, and other programs that can draw a flowchart from someone else's program -- a real boon if you're stuck maintaining poorly documented code.  For some niches there are fourth-generation languages (4GL): programs that can automatically generate application programs from descriptions of the desired input and output.<P>
These utilities are part of one important avenue to improved programming productivity, and this special issue Sourcebook contains a guide to them, listing prices, platforms, and so on. Instead of rooting through the ads at the back of each programming magazine in your library, you can find the companies devoted to this market all collected in one place.  Along with that resource guide, we've included a glossary that explains the terms of software engineering and CASE to help you pin down some of the ambiguous phrases and marketese you may encounter when discussing CASE tools.  But the resource guide is not enough, by itself, to show where software engineering is going.  Nor is fast coding enough to make a good programmer.  You should know about research that points the way to huge improvements in productivity -- improvements that rocket far ahead of the mere doubling or tripling you might gain from an improved compiler or prototyper.  You need to know the limiting implications of today's accepted programming technology and menageries of discrete tools.  That's where the articles of this special issue come in.  They represent some of the most important directions of software engineering, discussing issues such as programming environments, intelligent prototyping, distributed computing, version control on large software projects, graphics and object-oriented languages, tool integration, and application-specific virtual machines.<P>
This issue touches on software engineering of both today and tomorrow, from the embedded real-time system through the personal computer to the network of workstations.  We planned this issue so that it will remain useful for years, long past the time when any particular company, program, or review of that program may have become history.  We've made a &quot;keeper,&quot; a volume that could easily hold a place on your shelves well into the 1990s.<P>
<ul>
<li>Software Engineering Environments by Stowe Boyd.  Software engineering and CASE haven't just appeared out of the blue.  As computer tools for programming were developed over the years, there have been repeated attempts to assemble those tools into coherent environments. Stowe Boyd discusses the history of these environments and puts today's important software engineering languages and environments -- such as Lisp, Smalltalk, Unix, DSEE, and NSE, and even hypertext -- into context and explains some of their strengths and weaknesses.</li>
<li>Software and the Single Programmer by T.G. Lewis.  Today's prototyping tools for personal computers -- such as Bricklin's Demo Program and the SmethersBarnes Prototyper -- are mostly vacuous.  They can be helpful in creating example screens and menus for a program, and for linking those elements together in a simulation of what that program would supposedly do. They don't, however, lead to actual programs or program code.  Professor Lewis of Oregon State has been working on Oregon Speedcode Universe (OSU), an intelligent graphic prototyping system which can directly generate a program.  He suggests that only this sort of radical change of programming style, away from today's linguistic paradigm, can yield productivity improvements of ten to a hundred times.</li>
<li>Embedded Systems Design -- A Special CASE? by David Kalinsky and James Ready.  Using real-time software development as an example, Kalinsky and Ready discuss the difficulties of putting CASE tools together.  They discuss the critical steps of software development -- from systems engineering and design through software design, coding, debugging, integration, testing, installation, and maintenance -- and how the CASE tools for each of those steps can be linked to their neighboring tools.</li>
<li>Using an API as a Developer Platform by Jeff Parker.  Parker describes how the proper selection of a programming metaphor, appropriate for a specific application area, or even the construction of a virtual machine on which to program, can have a great impact on programming results.  His own firm's LabVIEW is just such a virtual machine for computer-aided test and measurement.  Non-professional programmers can put together reusable graphical instrument components that resemble their physical counterparts to quickly build data acquisition and analysis programs.</li>
<li>Applying Workstation Technology to CASE by David Leblang and Tackling Large-Scale Programming Projects by William Courington, Jonathan Feiber, and Masahiro Honda.  This pair of articles -- from two of the leading workstation makers, Sun and Apollo -- talks about what happens to CASE and software engineering when you move beyond a single computer and a single programmer.  Large projects with dozens of programmers, hundreds of thousands of lines of code, and thousands of files disintegrate into chaos without robust version control and configuration management software.  Today, most such projects are handled on a local area network.  That can complicate the control task.  For example, the system must deal with parallel development -- concurrent access to a single file by programmers who want to make different changes.  It can also aid the programmers.  For instance, the unused power of other workstations can be brought to bear on a local problem through intelligently controlled distributed computing.  These articles discuss the issues and the competing products -- Sun's NSE and Apollo's DSEE.  This technology is already reaching into the realm of personal computers and will be critical in any large development effort of the 1990s.</li>
</ul>
<P>
<P>
</pre></BODY></HTML>
