
<html>
<head>
<title>August, 2004: C++ and the Perils of Double-Checked Locking: Part II</title>
</head>

<body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000">
<!--Copyright &#169; Dr. Dobb's Journal-->

<h1>C++ and the Perils of Double-Checked Locking: Part II</h1>
<p><i>Dr. Dobb's Journal</i> August, 2004</p>
<h2>Almost famous&#151;the <i>volatile</i> keyword</h2>


<h3>By Scott Meyers and Andrei Alexandrescu</h3>


<I>Scott is author of Effective C++ and consulting editor for the Addison-Wesley Effective Software Development Series. He can be contacted at http://aristeia.com/. Andrei is the author of Modern C++ Design and a columnist for the C/C++ Users Journal. He can be contacted at http:// moderncppdesign.com/.</I>

<hr>



<a href="0408ls1.html">volatile: A Brief History</a><br>


<hr>





<p>In the first installment of this two-part article, we examined why the Singleton pattern isn't thread safe, and how the Double-Checked Locking Pattern addresses that problem. This month, we look at the role the <i>volatile</i> keyword plays in this, and why DCLP may fail on both uni- and multiprocessor architectures.</p>

<p>The desire for specific instruction ordering makes you wonder whether the <i>volatile</i> keyword might be of help with multithreading in general and with DCLP in particular. Consequently, we restrict our attention to the semantics of <i>volatile</i> in C++ and further restrict our discussion to its impact on DCLP. </p>

<p>Section 1.9 of the C++ Standard (see ISO/IEC 14882:1998(E)) includes this information (emphasis is ours):</p>

<blockquote>
The observable behavior of the [C++] abstract machine is its sequence of reads and writes to <i>volatile</i> data and calls to library I/O functions.<br>
  Accessing an object designated by a volatile lvalue, modifying an object, calling a library I/O function, or calling a function that does any of those operations are all <i>side effects</i>, which are changes in the state of the execution environment.<br>

</blockquote>

<p>In conjunction with our earlier observations that the Standard guarantees that all side effects will have taken place when sequence points are reached and that a sequence point occurs at the end of each C++ statement, it would seem that all we need to do to ensure correct instruction order is to <i>volatile</i>-qualify the appropriate data and sequence our statements carefully. Our earlier analysis shows that <i>pInstance</i> needs to be declared <i>volatile,</i> and this point is made in the papers on DCLP (see Douglas C. Schmidt et al., "Double-Checked Locking" and Douglas C. Schmidt et al., <i>Pattern-Oriented Software Architecture,</i> Volume 2). However, Sherlock Holmes would certainly notice that, to ensure correct instruction order, the <i>Singleton</i> object <i>itself</i> must also be <i>volatile</i>. This is <i>not</i> noted in the original DCLP papers and that's an important oversight. To appreciate how declaring <i>pInstance</i> alone <i>volatile</i> is insufficient, consider <a name="re7"></a><a href="0408le7.html">Example 7</a> (Examples 1-6 appeared in Part I of this article; see <i>DDJ</i>, July 2004). </p>

<p>After inlining the constructor, the code looks like <a name="re8"></a><a href="0408le8.html">Example 8</a>. Though <i>temp</i> is volatile, <i>*temp</i> is not, and that means that <i>temp-&gt;x</i> isn't, either. Because you now understand that assignments to nonvolatile data may sometimes be reordered, it is easy to see that compilers could reorder <i>temp-&gt;x</i>'s assignment with regard to the assignment to <i>pInstance</i>. If they did, <i>pInstance</i> would be assigned before the data it pointed to had been initialized, leading again to the possibility that a different thread would read an uninitialized <i>x</i>.</p>

<p>An appealing treatment for this disease would be to <i>volatile</i>-qualify <i>*pInstance</i> as well as <i>pInstance</i> itself, yielding a glorified version of <i>Singleton</i> where all pawns are painted <i>volatile</i>; see <a name="re9"></a><a href="0408le9.html">Example 9</a>.</p>

<p>At this point, you might reasonably wonder why <i>Lock</i> isn't also declared <i>volatile</i>. After all, it's critical that the lock be initialized before you try to write to <i>pInstance</i> or <i>temp</i>. Well, <i>Lock</i> comes from a threading library, so you can assume it either dictates enough restrictions in its specification or embeds enough magic in its implementation to work without needing <i>volatile</i>. This is the case with all threading libraries that we know of. In essence, use of entities (objects, functions, and the like) from threading libraries leads to the imposition of "hard sequence points" in a program&#151;sequence points that apply to all threads. For purposes of this article, we assume that such hard sequence points act as firm barriers to instruction reordering during code optimization: Instructions corresponding to source statements preceding use of the library entity in the source code may not be moved after the instructions corresponding to use of the entity, and instructions corresponding to source statements following use of such entities in the source code may not be moved before the instructions corresponding to their use. Real threading libraries impose less draconian restrictions, but the details are not important for purposes of our discussion here.</p>

<p>You might hope that the aforementioned fully <i>volatile</i>-qualified code would be guaranteed by the Standard to work correctly in a multithreaded environment, but it may fail for two reasons.</p>

<p>First, the Standard's constraints on observable behavior are only for an abstract machine defined by the Standard, and that abstract machine has no notion of multiple threads of execution. As a result, though the Standard prevents compilers from reordering reads and writes to <i>volatile</i> data within a thread, it imposes no constraints at all on such reorderings across threads. At least that's how most compiler implementers interpret things. As a result, in practice, many compilers may generate thread-unsafe code from the aforementioned source. If your multithreaded code works properly with <i>volatile</i> and doesn't work without it, then either your C++ implementation carefully implemented <i>volatile</i> to work with threads (less likely) or you simply got lucky (more likely). Either case, your code is not portable.</p>

<p>Second, just as <i>const</i>-qualified objects don't become <i>const</i> until their constructors have run to completion, <i>volatile</i>-qualified objects become <i>volatile</i> only upon exit from their constructors. In the statement:</p>

<blockquote>
volatile Singleton* volatile temp = <br>
    new volatile Singleton;<br>

</blockquote>

<p>the object being created doesn't become <i>volatile</i> until the expression:</p>

<blockquote>
new volatile Singleton;<br>

</blockquote>

<p>has run to completion, and that means that we're back in a situation where instructions for memory allocation and object initialization may be arbitrarily reordered.</p>

<p>This problem is one we can address, albeit awkwardly. Within the <i>Singleton</i> constructor, we use casts to temporarily add "volatileness" to each data member of the <i>Singleton</i> object as it is initialized, thus preventing relative movement of the instructions performing the initializations. <a name="re10"></a><a href="0408le10.html">Example 10</a> is the <i>Singleton</i> constructor written in this way. (To simplify the presentation, we've used an assignment to give <i>Singleton::x</i> its first value instead of a member initialization list, as in <a name="re10"></a><a href="0408le10.html">Example 10</a>. This change has no effect on any of the issues we're addressing here.)</p>

<p>After inlining this function in the version of <i>Singleton</i> where <i>pInstance</i> is properly <i>volatile</i> qualified, we get <a name="re11"></a><a href="0408le11.html">Example 11</a>. Now the assignment to <i>x</i> must precede the assignment to <i>pInstance</i>, because both are <i>volatile</i>.</p>

<p>Unfortunately, all this does nothing to address the first problem&#151;C++'s abstract machine is single threaded, and C++ compilers may choose to generate thread-unsafe code from source like that just mentioned, anyway. Otherwise, lost optimization opportunities lead to too big an efficiency hit. After all this, we're back to square one. But wait, there's more&#151;more processors.</p>
<h3>DCLP on Multiprocessor Machines</h3>

<p>Suppose you're on a machine with multiple processors, each of which has its own memory cache, but all of which share a common memory space. Such an architecture needs to define exactly how and when writes performed by one processor propagate to the shared memory and thus become visible to other processors. It is easy to imagine situations where one processor has updated the value of a shared variable in its own cache, but the updated value has not yet been flushed to main memory, much less loaded into the other processors' caches. Such inter-cache inconsistencies in the value of a shared variable is known as the "cache coherency problem." </p>

<p>Suppose processor <i>A</i> modifies the memory for shared variable <i>x</i> and then later modifies the memory for shared variable <i>y.</i> These new values must be flushed to the main memory so that other processors see them. However, it can be more efficient to flush new cache values in increasing address order, so if <i>y'</i>s address precedes <i>x</i>'s, it is possible that <i>y</i>'s new value will be written to main memory before <i>x</i>'s is. If that happens, other processors may see <i>y</i>'s value change before <i>x</i>'s.</p>

<p>Such a possibility is a serious problem for DCLP. Correct <i>Singleton</i> initialization requires that the <i>Singleton</i> be initialized and that <i>pInstance</i> be updated to be non-null and that these operations be seen to occur in this order. If a thread on processor <i>A</i> performs step 1 and then step 2, but a thread on processor <i>B</i> sees step 2 as having been performed before step 1, the thread on processor <i>B</i> may again refer to an uninitialized <i>Singleton</i>.</p>

<p>The general solution to cache coherency problems is to use memory barriers: instructions recognized by compilers, linkers, and other optimizing entities that constrain the kinds of reorderings that may be performed on read/writes of shared memory in multiprocessor systems. In the case of DCLP, we need to use memory barriers to ensure that <i>pInstance</i> isn't seen to be nonnull until writes to the <i>Singleton</i> have been completed. <a name="re12"></a><a href="0408le12.html">Example 12</a> is pseudocode that closely follows an example presented by David Bacon et al. (see the "Double-Checked Locking Pattern is Broken"). We show only placeholders for the statements that insert memory barriers because the actual code is platform specific (typically in assembler).</p>

<p>This is overkill, as Arch Robison points out (in personal communication): </p>

<blockquote>
Technically, you don't need full bidirectional barriers. The first barrier must prevent downwards migration of Singleton's construction (by another thread); the second barrier must prevent upwards migration of <i>pInstance</i>'s initialization. These are called "acquire" and "release" operations, and may yield better performance than full barriers on hardware (such as Itainum) that makes the distinction.<br>

</blockquote>

<p>Still, this is an approach to implementing DCLP that should be reliable, provided you're running on a machine that supports memory barriers. All machines that can reorder writes to shared memory support memory barriers in one form or another. Interestingly, this same approach works just as well in a uniprocessor setting. This is because memory barriers also act as hard sequence points that prevent the kinds of instruction reorderings that can be so troublesome.</p>
<h3>Conclusion</h3>

<p>There are several lessons to be learned here. First, remember that timeslice-based parallelism on uniprocessors is not the same as true parallelism across multiple processors. That's why a thread-safe solution for a particular compiler on a uniprocessor architecture may not be thread safe on a multiprocessor architecture, not even if you stick with the same compiler. (This is a general observation&#151;it's not specific to DCLP.)</p>

<p>Second, although DCLP isn't intrinsically tied to <i>Singleton</i>, the use of <i>Singleton</i> tends to lead to a desire to "optimize" thread-safe access via DCLP. You should therefore be sure to avoid implementing <i>Singleton</i> with DCLP. If you (or your clients) are concerned about the cost of locking a synchronization object every time <i>instance</i> is called, you can advise clients to minimize such calls by caching the pointer that instance returns. For example, suggest that instead of writing code like <a name="re13"></a><a href="0408le13.html">Example 13</a>(a), clients do things like <a name="re13"></a><a href="0408le13.html">Example 13</a>(b). Before making such a recommendation, it's generally a good idea to verify that this really leads to a significant performance gain. Use a lock from a threading library to ensure thread-safe <i>Singleton</i> initialization, then do timing studies to see if the cost is truly something worth worrying about.</p>

<p>Third, avoid using a lazily initialized <i>Singleton</i> unless you really need it. The classic <i>Singleton</i> implementation is based on not initializing a resource until that resource is requested. An alternative is to use eager initialization; that is, to initialize a resource at the beginning of the program run. Because multithreaded programs typically start running as a single thread, this approach can push some object initializations into the single-threaded startup portion of the code, thus eliminating the need to worry about threading during the initialization. In many cases, initializing a <i>Singleton</i> resource during single-threaded program startup (that is, prior to executing main) is the simplest way to offer fast, thread-safe <i>Singleton</i> access.</p>

<p>A different way to employ eager initialization is to replace the Singleton Pattern with the Monostate Pattern (see Steve Ball et al., "Monostate Classes: The Power of One"). Monostate, however, has different problems, especially when it comes to controlling the order of initialization of the nonlocal static objects that make up its state. <i>Effective C++</i> (see "References") describes these problems and, ironically, suggests using a variant of <i>Singleton</i> to escape them. (The variant is not guaranteed to be thread safe; see <i>Pattern Hatching: Design Patterns Applied</i> by John Vlissides.)</p>

<p>Another possibility is to replace a global <i>Singleton</i> with one <i>Singleton</i> per thread, then use thread-local storage for <i>Singleton</i> data. This allows for lazy initialization without worrying about threading issues, but it also means that there may be more than one "<i>Singleton</i>" in a multithreaded program. </p>

<p>Finally, DCLP and its problems in C++ and C exemplify the inherent difficulty in writing thread-safe code in a language with no notion of threading (or any other form of concurrency). Multithreading considerations are pervasive because they affect the very core of code generation. As Peter Buhr pointed out in "Are Safe Concurrency Libraries Possible?" (see "References"), the desire to keep multi-threading out of the language and tucked away in libraries is a chimera. Do that, and either the libraries will end up putting constraints on the way compilers generate code (as <i>Pthreads</i> already does), or compilers and other code-generation tools will be prohibited from performing useful optimizations, even on single-threaded code. You can pick only two of the troika formed by multithreading, a thread-unaware language, and optimized code generation. Java and the .NET CLI, for example, address the tension by introducing thread awareness into the language and language infrastructure, respectively (see Doug Lea's <i>Concurrent Programming in Java</i> and Arch D. Robison's "Memory Consistency &amp; .NET").</p>
<h3>Acknowledgments</h3>

<p>Drafts of this article were read by Doug Lea, Kevlin Henney, Doug Schmidt, Chuck Allison, Petru Marginean, Hendrik Schober, David Brownell, Arch Robison, Bruce Leasure, and James Kanze. Their comments, insights, and explanations greatly improved the article and led us to our current understanding of DCLP, multithreading, instruction ordering, and compiler optimizations.</p>
<h3>References</h3>

<p>David Bacon, Joshua Bloch, Jeff Bogda, Cliff Click, Paul Hahr, Doug Lea, Tom May, Jan-Willem Maessen, John D. Mitchell, Kelvin Nilsen, Bill Pugh, and Emin Gun Sirer. The "Double-Checked Locking Pattern is Broken" Declaration. http://www.cs .umd.edu/~pugh/java/memoryModel/ DoubleCheckedLocking.html.</p>

<p>Steve Ball and John Crawford. "Monostate Classes: The Power of One." <i>C++ Report</i>, May 1997. Reprinted in <i>More C++ Gems</i>, Robert C. Martin, ed., Cambridge University Press, 2000.</p>

<p>Peter A. Buhr. "Are Safe Concurrency Libraries Possible?" <i>Communications of the ACM</i>, 38(2):117-120, 1995. http:// citeseer.nj.nec.com/buhr95are.html.</p>

<p>Doug Lea. <i>Concurrent Programming in Java</i>. Addison-Wesley, 1999. Excerpts relevant to this article can be found at http://gee.cs.oswego.edu/dl/cpj/jmm.html.</p>

<p>Scott Meyers. <i>Effective C++</i>, Second Edition. Addison-Wesley, 1998. Item 47 discusses the initialization problems that can arise when using nonlocal static objects in C++.</p>

<p>Arch D. Robison. "Memory Consistency &amp; .NET." <i>Dr. Dobb's Journal</i>, April 2003.</p>

<p>Douglas C. Schmidt and Tim Harrison. "Double-Checked Locking." In <i>Pattern Languages of Program Design 3</i>, Robert Martin, Dirk Riehle, and Frank Buschmann, editors. Addison-Wesley, 1998. http://www.cs .wustl.edu/~schmidt/PDF/DC-Locking.pdf.</p>

<p>Douglas C. Schmidt, Michael Stal, Hans Rohnert, and Frank Buschmann. <i>Pattern-Oriented Software Architecture,</i> Volume 2. Wiley, 2000. Tutorial notes based on the patterns in this book are available at http://cs.wustl.edu/~schmidt/posa2.ppt.</p>

<p>ISO/IEC 14882:1998(E) International Standard. Programming languages&#151;C++. ISO/IEC, 1998.</p>

<p>John Vlissides. <i>Pattern Hatching: Design Patterns Applied</i>. Addison-Wesley, 1998. The discussion of the "Meyers Singleton" is on page 69.</p>


<p><b>DDJ</b></p>




</body>
</html>