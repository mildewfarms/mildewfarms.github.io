<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 4.0//EN">


<HTML>
<HEAD>
<TITLE>v08, i08: A Comprehensive Approach to Log Files</TITLE>
<LINK REL=StyleSheet HREF="../../resource/css/sacdrom.css" TYPE="text/css" TITLE="CSS1">
</HEAD>

<body bgcolor="#ffffff" text="#000000" link="#990000" alink="#669999" vlink="#333366" topmargin=0 leftmargin=0>

<! -- Begin MASTER TABLE -- >
<!center><table width=600 cellpadding=0 cellspacing=0 border=0 bgcolor="#ffffff">

<tr>

<table cellpadding=5 cellspacing=0 border=0>
	<tr>

		<td><span class=navbarLink>Article</a></span></td>
		<td><a href="../../../../source/SA/1999/aug99.tar"><b class=codeListing>aug99.tar</b></a></td>

	</tr>
</table>


</tr>
<tr>
<! -- Begin Content ------ >
<td valign=top width=440 bgcolor="#ffffff">
<table width=100% cellpadding=15 cellspacing=0 border=0>
<tr><td valign=top>
<! -- Insert Content ------ >

<H1>A Comprehensive Approach to Log Files</H1><p>
<P>Andrew Mickish
<P>
My interest in analyzing and archiving log files was inspired mainly by the pursuit of profit. There are other reasons to maintain long-term archives of important files such as system logs, analyzing hacker activity that escaped attention earlier, or gauging usage trends to predict the need for server upgrades and redistribution of resources.<p>
Mostly, I wanted to document the increasing value of our company's Web site by recording the growing number of hits. This data is essential for showing customers, advertisers, investors, and management how much traffic is flowing through the site in justification of advertising fees and prices for hosting services.<p>
Additionally, after doing informal system administration for years, and occasionally deciphering various arcane configuration parameters for <B>syslog</B> and built-in log rotation systems, I finally decided to approach the problem comprehensively and craft a system that would record and notify me of important system events, and archive the raw data permanently.<p>
<B>What to Log</b><p>All services provided by a server ought to be logged and monitored. UNIX hosts offer user services such as Sendmail, Web servers, <B>ftp</B>, <B>telnet</B>, and <B>cron</B>. There are also integrated system services provided by the kernel itself, such as authentication of logins and the spawning of user shells.<p>
Apathy toward the events of a particular service suggests that the service is not being used and should not be provided. The presence of unused services at minimum unnecessarily impacts the performance of the server and obscures which services are actually essential. At worst, it provides a gateway for exploiting security vulnerabilities in the unattended services.<p>
For example, during system installation, it is tempting to install "everything", because this will certainly minimize the time spent tracking down and installing additional services and utilities later as the need arises. However, this choice typically installs and activates historically vulnerable services such as NFS (for accessing the server's file system) and <B>rshd</B>/<B>rlogind</B> (for getting a command prompt on the server without supplying a password).<p>
An administrator who has just realized the importance of this problem can get a sense of which services are offered in several ways:<p>
<p>
1. Use <B>ps</B> with verbose options (different for each UNIX, probably something like <B>ps -ef</B> or <B>ps aux</B> or <B>ps auxwww</B>) to show all processes being run by all users.<p>
2. Use <B>netstat -a</B> to see which ports are in a <B>LISTEN</B> state, indicating a service that is waiting for a connection attempt. The <B>ESTABLISHED</B> state indicates that the service is currently in use by a connecting client.<p>
3. Examine <B>/etc/inetd.conf</B> for services that are launched on an as-requested basis by the <B>inetd</B> daemon.<p>
4. Examine the <B>rc</B> startup files (different for each UNIX, probably somewhere like <B>/etc/rc.*</B>).<p>
5. Examine the timestamps, sizes, and contents of log files that already exist on the machine (usually in <B>/var/log</B> or <B>/var/adm</B>).<p>
<p>
Although disabling services is beyond the scope of this article, it usually involves commenting out the appropriate line in <B>/etc/inetd.conf</B>, removing the package of the service, or at least moving the startup script out of the <B>rc</B> directory so that it will not be started automatically.<p>
<B>Services that Use syslog</b><p>The more established UNIX services like Sendmail, <B>innd</B> (the Internet news daemon), and <B>named</B> (the DNS server daemon) have built-in logging capabilities based on the standard logging facility <B>syslog</B>. The <B>syslog</B> daemon is itself a service that is used by the others. Though these daemons already ask <B>syslog</B> to make log entries, <B>syslog</B> will ignore these requests if it has not been specifically told how to handle these messages.<p>
For example, the source code for Sendmail is littered with calls to the UNIX C library function <B>syslog()</B>, which sends messages to <B>syslogd</B> consisting of:<p>
<p>
1. The type of program requesting the log entry (e.g., mail, news, or a generic daemon).<p>
2. The priority of the message (e.g., <B>info</B>, <B>notice</B>, <B>warn</B>, <B>err</B>, or <B>emerg</B>).<p>
3. The text of the log entry.<p>
<p>
The Sendmail daemon sends <B>info</B> entries when it accepts or rejects incoming mail, and sends <B>notice</B> entries when it loses connection with a client. There are hundreds of other occasions when Sendmail makes entries depending on tasks that it succeeds or fails in performing.<p>
Therefore, in the case of <B>syslog</B>-oriented daemons, the issue is not how to get the services to generate log entries, but instead how to configure <B>syslog</B> to handle them.<p>
<B>Configuring syslog</b><p>The <B>syslog</B> configuration file is in <B>/etc/syslog.conf</B>, and looks something like this:<p>
<B><p>
<pre>
# Log everything (except mail and auth messages)
# of level info or higher.
*.info;mail.!=info;authpriv.!*      /var/log/messages

# Log all the mail messages in one place.
mail.*                              /var/log/maillog

# Log authorization messages in a protected file.
authpriv.*                          /var/log/secure

# Broadcast emergency messages to all users.
*.emerg                             *
</pre>
</b><p>The first entry in this configuration causes messages from all services of priority <B>info</B> through <B>emergency</B> to be logged to the file <B>/var/log/messages</B>, except those that come from mail or authentication services. This is reasonable, since Sendmail generates a lot of entries that would obscure more important messages, and authentication entries may contain sensitive information including passwords.<p>
The first entry also catches messages sent by daemons that do not have a specific name reserved for them. The DNS server daemon <B>named</B> is a good example of such a daemon, which may generate hourly statistics about its use (if it was enabled to do so when it was compiled). For this reason, it may be desirable to direct <B>daemon.info</B> messages to a separate log file, and specifically omit them from the main log file with <B>daemon.!=info</B>.<p>
The second entry directs all mail messages to <B>/var/log/maillog</B>, and the third entry directs authentication messages to <B>/var/log/secure</B>. In the last entry, the destination "*" means that the message should be shown on the screens of all currently logged-in users as a plea for help.<p>
Multiple machines can be configured to send their log entries to a central <B>syslog</B> server, known as a loghost, rather than keeping logs independently on each distributed machine. When configured correctly, the loghost will listen for UDP packets sent by the other machines, and write the messages to its local log files. The following procedure enables this feature for Red Hat Linux:<p>
<p>
1. On the loghost, add the command line parameter <B>-r</B> to the invocation of <B>syslogd</B> in the loghost's <B>rc</B> startup script, and<p>
2. On each distributed machine, add the following entry to <B>syslog.conf</B>:<p>
<p>
<pre>
# Send all messages to the loghost,
# and let it filter them
*.*                          @loghost
</pre>
</b><p>However, it should be obvious that enabling this feature opens up the loghost to a denial of service attack and pollution of its logs by an attacker. This feature should only be used when the loghost is behind a firewall, or in conjunction with using kernel firewall utilities on the loghost such as <B>ipfwadm</B> or <B>ipchains</B> to restrict access to specific <B>syslog</B> clients.<p>
The <B>man</B> pages for <B>syslog</B> have a discussion of the syntax, a lot of configuration examples, and a full list of the service types and severity levels. It is necessary to view the <B>man</B> pages for all of <B>syslog</B>, <B>syslog.conf</B>, and <B>syslogd</B> to see all the available information. Remember, <B>syslog</B> is the client library function invoked by each service; <B>syslogd</B> is the daemon configured with <B>syslog.conf</B>.<p>
<B>syslog Troubleshooting</b><p>If <B>syslog</B> does not write messages to the expected destinations, there are a couple of things to check.<p>
First, restart <B>syslogd</B> to make it re-read its configuration file. One way to restart <B>syslogd</B> is to send it a hangup signal, with the command <B>kill -HUP &lt;pid&gt;</B> where <B>&lt;pid&gt;</B> is the process id of <B>syslogd</B> obtained from the <B>ps</B> command. Another way, under Linux or Solaris, is to execute the startup script with the <B>restart</B> parameter, as in <B>/etc/rc.d/init.d/syslog restart</B>.<p>
Make sure that the destination file exists, which is a prerequisite for <B>syslogd</B> to modify it. The command <B>touch &lt;filename&gt;</B> will create an empty file. The next time <B>syslogd</B> is restarted, it will log the next appropriate message to the file.<p>
To send messages to another host, the other host must be configured to receive the messages. See <B>man syslogd</B> for specific instructions on how to do this for each specific version of UNIX.<p>
<B>Services that Don't Use syslog</b><p>A Web server is a good example of a service that uses its own independent logging mechanism. Web server logs tend to be enormous - on the order of megabytes per day for busy machines. The logs contain the names of all files that were requested and errors encountered while trying to serve requests. Additional configuration will log the type of browser that made the request and the last page that referred the user to the current page.<p>
Logging for the Apache Web server is controlled in <B>httpd.conf</B>, often found in <B>/usr/local/etc/httpd</B> or placed in <B>/etc/httpd/conf</B> by the standard Red Hat RPM distribution. The lines that control what will be written to the regular access logs look like:<p>
<B><p>
<pre>
LogFormat "%h %l %u %t \"%r\" %&gt;s %b" common
LogFormat "%{Referer}i -&gt; %U" referer
LogFormat "%{User-agent}i" agent

CustomLog logs/access_log common
CustomLog logs/referer_log referer
CustomLog logs/agent_log agent
</pre>
</b><p>The <B>LogFormat</B> directive defines an alias, in this case for the aliases <B>common</B>, <B>referrer</B>, and <B>agent</B>, to stand for the cryptic combination of format specifiers: <B>%h</B> is the requesting host, <B>%r</B> is the requested page, etc. Any of these aliases can subsequently be used in a <B>CustomLog</B> entry, which tells Apache how to write entries to the specified log file. (Note that the log directory is relative to the <B>ServerRoot</B> directory set elsewhere in the configuration file when the destination does not begin with a slash.)<p>
The configuration above directs Apache to write page accesses to <B>access_log</B>. The last page viewed by the browser before requesting the current page will be logged in <B>referer_log</B>, and the type of browser making the request will be logged in <B>agent_log</B>.<p>
An alternative to splitting the entries across multiple log files is to put them all in a single log file. The following definition puts all the information for each request on one line into <B>access_log</B>:<p>
<B><p>
<pre>
LogFormat "%h %l %u %t \"%r\" %&gt;s %b
          \"%{Referer}i\" \"%{User-Agent}i\"" combined

CustomLog logs/access_log combined
</pre>
</b><p>The logging of errors in Apache is reminiscent of <B>syslog</B>, with errors having various severity levels including <B>info</B>, <B>warn</B>, and <B>error</B>. The minimum priority of messages to be sent to the error log is controlled by the <B>LogLevel</B> directive:<p>
<B><p>
<pre>
ErrorLog logs/error_log
LogLevel warn
</pre>
</b><p>Once the Web server is configured to maintain its log files, take care that the log files do not grow out of control and fill up the file system. This can happen rather quickly, not only if the server is busy, but also if there is a configuration problem that causes the error log to grow unexpectedly large. Rather than deleting old log files, they can be compressed and archived systematically, which is a topic discussed at length below.<p>
<B>Monitoring Log Files</b><p>Given an assortment of log files on various machines, the best way to stay in touch with what's happening on each machine is to read the most recent entries in each log file. While some administrators might like to watch the live log files scrolling by using<B> tail -f &lt;logfile&gt;</B> on each one, there is a more convenient way to be periodically notified when entries are written.<p>
The script <B>logtail.pl</B> in Listing 1 reports on the entries made in a log file since the last time the log file was checked. (All listings for this article are available from the <I>Sys Admin </I>Web site: <B>www.sysadminmag.com</B> or from <B>ftp.mfi.com</B> in <B>/pub/sysadmin</B>.)<p>
<B><p>
<pre>
Usage:  logtail.pl &lt;logfile&gt; &lt;logposfile&gt;
</pre>
</b><p>The <B>&lt;logfile&gt;</B> parameter is the log file to monitor, and <B>&lt;logposfile&gt;</B> is a writable file where <B>logtail.pl</B> stores the length of <B>&lt;logfile&gt;</B> each time it is invoked. The script skips over the part of the log that was previously reported, echoing only the latest entries to <B>stdout</B>.<p>
When running <B>logtail.pl</B> as a cron job for each log file, the administrator will get mail containing all the entries made since the last invocation.<p>
<B><p>
<pre>
#
# Check the system log every day
#
55 3 * * * /usr/local/bin/logtail.pl
           /var/log/messages /var/log/messages.last
#
# Check the security log every day
#
56 3 * * * /usr/local/bin/logtail.pl
           /var/log/secure /var/log/secure.last
#
# Check the mail log every day
#
57 3 * * * /usr/local/bin/logtail.pl
           /var/log/maillog /var/log/maillog.last
</pre>
</b><p>If the <B>logtail.pl</B> scripts only run daily, it is important to time them to run just before log rotation occurs (see below), so that none of the entries are missed when the current log file is cleared.<p>
While it may seem a daunting task to read the system log file for each machine on a daily basis, proper sorting of messages into different logs depending on their priority means that only the non-informational messages need to be read with particular attention, and these can be scanned for new entries by the <B>logtail.pl</B> cron job more frequently (perhaps every minute). The <B>info</B> files can be read independently, to investigate problems detected in the higher priority files.<p>
This section would be incomplete without mentioning <B>swatch</B>, a utility that scans log files for specific patterns. <B>swatch</B> can sound terminal bells, send mail, or invoke secondary programs whenever it finds a matching pattern (such as "panic") in a log file. <B>swatch</B> is available from:<p>
<B><p>
<pre>
http://www.stanford.edu/group/itss-ccs/security/Bestuse/software.html
</pre>
</b><p>Configuring <B>swatch</B> for particular services and machines takes a bit of experience in knowing which log entries to expect, and which to be concerned about. Monitoring the raw log files with <B>logtail.pl</B> is the best way to gain this experience.<p>
<B>Rotating Log Files</b><p>Log rotation is the process of saving the current log file under a different name and starting a new log file in its place. The standard UNIX configuration keeps three or four generations of log files around, where the current log file is <B>messages</B>, and the next oldest is <B>messages.1</B>, and so on.<p>
Solaris has a straightforward approach to rotating the system log. By default, a cron job in the root account executes the simple shell script below to rename the current system log to a save file while moving existing saved files to older names, consequently throwing away the oldest one:<p>
<B><p>
<pre>
# Solaris /usr/lib/newsyslog
#
LOG=messages
cd /var/adm
test -f $LOG.2 &amp;&amp; mv $LOG.2 $LOG.3
test -f $LOG.1 &amp;&amp; mv $LOG.1 $LOG.2
test -f $LOG.0 &amp;&amp; mv $LOG.0 $LOG.1
mv $LOG   $LOG.0
cp /dev/null $LOG
chmod 644    $LOG
...
kill -HUP `cat /etc/syslog.pid`
</pre>
</b><p>Red Hat Linux introduced a significantly more flexible <B>logrotate</B> system, by which whole sets of log files can be controlled by a top-level <B>/etc/logrotate.conf</B> configuration file, and by individual service-specific configuration files in <B>/etc/logrotate.d</B>. By default, any log file whose name appears in a <B>logrotate</B> configuration file will be rotated weekly, keeping four old generations. When the compression feature is enabled in <B>logrotate.conf</B>, it will compress the old logfiles during the rotation. Only one configuration file is responsible for rotating all of the system logs:<p>
<B><p>
<pre>
# /etc/logrotate.d/syslog
#
/var/log/messages {
    postrotate
        /usr/bin/killall -HUP syslogd
    endscript
}
...
# similar entries for /var/log/{secure,maillog,spooler}
</pre>
</b><p>Both of these strategies constrain the names of the archived log files to just their original name with a numerical suffix, and the archive location is in the same place as the current file. It would be much nicer if the archived files could be renamed according to their dates, and the archived files moved onto a separate partition dedicated for permanent storage. The next section describes how to enhance these log rotation schemes with log file archiving.<p>
<B>Archiving Log Files</b><p>The script <B>archive.pl</B> in Listing 2 moves or copies arbitrary files from one directory into another, while compressing or renaming them according to their timestamp along the way. This script can be used independently, or integrated into a system's existing log rotation scheme.<p>
<B><p>
<pre>
Usage:  archive.pl --from &lt;srcfile&gt; --to &lt;destdir&gt;
                   [--suffix &lt;pattern&gt;] [--ifexists]
                   [--overwrite] [--compress]
                   [--keepsrc] [--keepdate]
                   [--keepbase] [--keepsuffix]
</pre>
</b><p>The optional parameters are all boolean switches that control whether the script should check whether the source or destination files exist before archiving, and control how to name the archive.<p>
By default, <B>archive.pl</B> interprets everything after the first dot (<B>.</B>) in a filename as its "suffix" by using the pattern <B>'\..*'</B> to match the suffix. This may not be desirable in a file named <B>boot.log.0</B>, which by default would be archived as <B>boot.19990801</B>. To archive this file as <B>boot.log.19990801</B>, the suffix pattern <B>'\.\d*'</B> would need to be used to identify only the numerical suffix of the file.<p>
The Solaris <B>newsyslog</B> script (discussed above) can be enhanced not to discard its oldest log file, but instead archive it in a separate directory, renamed by timestamp. Something like the following line could be inserted at the top of the script:<p>
<B><p>
<pre>
/usr/local/bin/archive.pl --from $LOG.3 --to archive
   --ifexists --compress --keepdate --keepbase
</pre>
</b><p>This line moves <B>messages.3</B> out of the current directory, places it in the <B>archive/</B> directory, renames it according to its timestamp, and finally compresses it to yield the file <B>archive/messages.19990801.gz</B>.<p>
Under Linux, similar instructions can be inserted into <B>logrotate</B> configuration files. Here is a modification to Apache's rotation file:<p>
<B><p>
<pre>
# Enhanced /etc/logrotate.d/apache
#
/var/log/httpd/access_log {
    prerotate
      /usr/local/bin/archive.pl             \
         --from /var/log/httpd/access_log.3 \
         --to /var/log/httpd/archive        \
         --ifexists --compress --keepdate   \
         --keepbase --suffix '\.\d*'
    endscript
    postrotate
        /usr/bin/killall -HUP httpd
    endscript
}
   
/var/log/httpd/error_log {
    prerotate
      /usr/local/bin/archive.pl             \
         --from /var/log/httpd/error_log.3  \
         --to /var/log/httpd/archive        \
         --ifexists --compress -keepdate   \
         --keepbase --suffix '\.\d*'
    endscript
    postrotate
        /usr/bin/killall -HUP httpd
    endscript
}
</pre>
</b><p>These modifications to Apache's <B>logrotate</B> file rescue <B>access_log.3</B> and <B>error_log.3</B> from being rotated out of existence. Instead, the access log is saved into, for example, <B>/var/log/httpd/archive/access_log.19990801.gz</B> where it can continue to be scanned by log file analysis tools.<p>
<B>Analyzing Archived Log Files</b><p>Once the log files are archived permanently, the administrator can conduct a retrospective analysis on system activity, attempted security breaches, and configuration problems. With a good bit of data available about what is usual and unusual activity in the system, an administrator can configure <B>swatch</B> (discussed above) to detect and sound an alarm in response to new system events.<p>
A particularly profitable endeavor involving archived Web server logs is to keep running retrospective summaries of all Web server activity since the server's origin. Presenting an up-to-date summary of server activity makes a great impression on customers who are considering advertising on a Web site, and on potential investors who want to take advantage of Web site traffic or even buy the whole domain.<p>
Setting up retrospective summaries involves storing all of the old access logs on-line and processing them hourly or daily with an analysis tool such as Analog:<p>
<B><p>
<pre>
http://www.statslab.cam.ac.uk/~sret1/analog/
</pre>
</b><p>Analog scans Web server log files and generates a summary of the number of pages and files accessed, organized in several views according to server directory, specific files, browser domains, and browser types.<p>
The Analog configuration file usually resides in <B>/usr/local/etc/httpd/analog/analog.cfg</B>, or may have been placed elsewhere by a contributed RPM. The configuration file must be modified with the locations of the logs it should analyze, and must contain a format string indicating how the Web server logs have been written. The <B>LOGFORMAT</B> directive is reminiscent of the corresponding <B>LogFormat</B> lines in the Apache configuration file:<p>
<B><p>
<pre>
# /usr/local/etc/httpd/conf/analog.cfg
#
LOGFORMAT (%S %j %u [%d/%M/%Y:%h:%n:%j] \
          "%j %r %j" %c %b "%f" "%B")
LOGFORMAT COMMON

LOGFILE /var/log/httpd/access_log*
LOGFILE /var/log/httpd/archive/access_log*

HOSTNAME "Company X"
LOGO companyx.gif

BROWSER ON
FULLBROWSER ON
REFERRER ON
REFSITE ON
OUTFILE "/home/httpd/html/stats/current.html"

DNSFILE "/usr/local/etc/httpd/analog/dnsfile.txt"
DNS WRITE
</pre>
</b><p>This configuration file tells Analog how to interpret the log files in the <B>httpd/</B> and <B>httpd/archive/</B> directories, and asks Analog to break the summaries into different views with respect to browser types and referring sites. The resulting summary is written to a Web page in the <B>stats/</B> directory in the active Web site hierarchy.<p>
A final flourish on top of up-to-date summaries is to archive the daily summaries, for retrospective review of growth over the life of the Web site. The following command uses the <B>archive.pl</B> script (discussed above) to rename the current summary generated by Analog to include its timestamp in its name, so that all the daily summaries will be listed under the <B>stats/</B> directory:<p>
<B><p>
<pre>
/usr/local/bin/archive.pl                      \
   --from /home/httpd/html/stats/current.html  \
   --to /home/httpd/html/stats -keepsrc        \
   --keepdate --keepsuffix --suffix '\.html'
</pre>
</b><p>The set of archived summaries will have names like <B>19990801.html</B>.<p>
<B>Conclusion</b><p>It is said that administrators who boast that no one has ever tried to hack into their servers do not know how to monitor their own systems. Common UNIX services already report their health and activities to the system logs, and these are the most important files for an administrator to review on at least a daily basis. The methods discussed in this article for filtering, monitoring, and archiving logs provide the administrator with crucial tools for detecting security threats and general problems with UNIX services.<p>
Don't forget, for a Web site whose revenue depends on server traffic, the skills gained through careful log file management translate quite tangibly into profit.
<p>
<h1>About the Author</h1><p>
Andrew Mickish graduated from Carnegie Mellon University with a degree in Computer Science. At CMU he worked on the graphical abstraction layer of early Java-like languages. He is currently a software engineer at SneakerLabs, Inc., developing and hosting high-performance Web applications in Java on Linux servers. He can be contacted at http://www.sneakerlabs.com/~mickish/.


<! -- Begin Content ------ >
<br>&nbsp;<br>
</table></center></td>
<! -- End Content ------ >

</table><!/center>
<! -- End MASTER TABLE -- >

</body></html>
