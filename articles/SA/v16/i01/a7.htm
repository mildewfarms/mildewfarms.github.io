<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 4.0//EN">


<HTML>
<HEAD>
<TITLE>v16, i01: Learning DTrace -- Part 5: Completing the Picture</TITLE>
<LINK REL=StyleSheet HREF="../../resource/css/sacdrom.css" TYPE="text/css" TITLE="CSS1"></HEAD>

<body bgcolor="#ffffff" text="#000000" link="#000000" alink="#669999" vlink="#333366" topmargin=0 leftmargin=0>
<! -- Begin MASTER TABLE -- >
<!center>
<table width=98% cellpadding=0 cellspacing=0 border=0 bgcolor="#ffffff">
  <tr>

<table cellpadding=5 cellspacing=0 border=0>
	<tr>

		<td><span class="navbarLink">Article</span></td>
		<td><a href="../../../../source/SA/2007/jan2007.tar"><b class=codeListing>jan2007.tar</b></a></td>

	</tr>
</table>


</tr>
<tr>
<! -- Begin Content ------ >
    <td valign=top width=527 bgcolor="#ffffff"> 
      <table width=100% cellpadding=15 cellspacing=0 border=0>
<tr>
          <td valign=top> 
            <! -- Insert Content ------ >
            <h1><img src="a7.gif" width="200" height="167" align="right">Learning DTrace -- Part 5: Completing the Picture</h1>
            <p> Chip Bennett
          <p> This article is the last of a five-part series on 
            DTrace. In part four, I provided examples of how DTrace can be used to 
            iteratively solve performance problems and profile an application. In this 
            final article, I'll cover more probe providers that will help monitor 
            the system and your applications, and I'll show you ways to use 
            DTrace at those times when the DTrace command isn't available. 
          <p>

            <B>The fbt Provider</B> 
          <p> The <b>fbt</b> (function boundary trace) provider gives you 
            the ability to establish probes for any kernel function. For this provider, <b>probemod</b> specifies the kernel module (i.e., unix, ip, nfs), <b>probefunc</b> names 
            the function, and <b>probename</b> stipulates whether you're instrumenting 
            the entry probe or the return probe. As an example, suppose I wanted to 
            show all of the kernel function calls for a system call. Let's create 
            a D program called sclist.d: 
          <p>

          <pre>
syscall::$1:entry 
{ 
   self-&gt;follow = 1; 
   printf ("syscall %s begins", probefunc); 
} 
fbt:::entry 
/ self-&gt;follow / 
{ 
} 
syscall::$1:return 
/ self-&gt;follow / 
{ 
   printf ("syscall %s ends", probefunc); 
   exit(0); 
} 
            </pre>
In this script, I'm using a macro argument to 
    make the script more flexible. When the D program is invoked, $1 will be 
    replaced with the name of a system call to be inspected. Once the <b>syscall</b> probe fires, <b>self-&gt;follow</b> is set to true, which will allow the <b>fbt</b> probes to trace the instruction flow. The <b>fbt</b> probe specifier instruments 
    all of the <b>fbt</b> entry probes, one for every kernel function. Surprisingly, 
    instrumenting that many probes doesn't take very long. (The D program 
    starts in a second or two.) An <b>fbt</b> probe will fire for every kernel 
    function that is entered, but nothing gets recorded until <b>self-&gt;follow </b> becomes true. Since our goal is just to see the kernel functions that are 
    called for a system call, this D program exits after the system call 
    returns:
    <p>

  <pre>
# dtrace -s sclist.d close 
dtrace: script 'sclist.d' matched 22461 probes 
CPU     ID                    FUNCTION:NAME 
0   3028                      close:entry syscall close begins 
0  11292                      close:entry 
0  12331               closeandsetf:entry 
0  14101                     closef:entry 
0  13860                  fop_close:entry 
0  19126                  ufs_close:entry 
0  14961                 cleanlocks:entry 
0  16405         flk_get_lock_graph:entry 
0  13622                cleanshares:entry 
0  17434                    vn_rele:entry 
0  14119                     crfree:entry 
0  12227            kmem_cache_free:entry 
0  11051                       setf:entry 
0   8123                 fd_reserve:entry 
0  12741               cv_broadcast:entry 
0   3029                      close:return syscall close ends 
    </pre>
Even though only a small portion of the instrumented 
    probes are recording data, all of the <b>fbt</b> probes are instrumented, so be 
    cautious where you try this script.
    <p> The usability of the <b>fbt</b> provider is enhanced by the 
      availability of OpenSolaris source code at: 
  <p>

  <pre>
http://opensolaris.org 
    </pre>
and books like <i>Solaris Internals</i>, Second Edition, by 
    Richard McDougall and Jim Mauro. The argument list for each kernel function 
    is available using the <b>args</b> array or the <b>argn</b> variables. You need to be 
    cautious when writing <b>fbt</b>-based scripts that name specific kernel 
    functions. There's no guarantee that a kernel function's 
    argument list will be the same from one Solaris release to the next, or 
    that the function will even still be present.
    <p> What would really be nice would be to see the flow as 
      a thread enters and returns from functions. To that end, there is a D 
      option called <b>flowindent</b>, which changes the output of the <b>fbt</b> provider. In 
      the following example (scflow.d), I'll instrument all of the <b>fbt:::return</b> probes in addition to the <b>entry</b> probes and add the <b>flowindent</b> option:
    <p>

   <pre>
#pragma D option flowindent 
syscall::$1:entry 
{ 
   self-&gt;follow = 1; 
   printf ("syscall %s begins", probefunc); 
} 
fbt:::entry, 
fbt:::return 
/ self-&gt;follow / 
{ 
} 
syscall::$1:return 
/ self-&gt;follow / 
{ 
   printf ("syscall %s ends", probefunc); 
   exit(0); 
} 
     </pre>
Here is what I captured using this script, but your 
    output may be different depending on the type of file being closed:
<p>

<pre>
# dtrace -s scflow.d close 
dtrace: script 'scflow.d' matched 44876 probes 
CPU FUNCTION 
0  =&gt; close                              syscall close begins 
0    -&gt; close 
0      -&gt; closeandsetf 
0        -&gt; closef 
0          -&gt; fop_close 
0            -&gt; ufs_close 
0              -&gt; cleanlocks 
0                -&gt; flk_get_lock_graph 
0                &lt;- flk_get_lock_graph 
0              &lt;- cleanlocks 
0              -&gt; cleanshares 
0              &lt;- cleanshares 
0            &lt;- ufs_close 
0          &lt;- fop_close 
0          -&gt; vn_rele 
0          &lt;- vn_rele 
0          -&gt; crfree 
0          &lt;- crfree 
0          -&gt; kmem_cache_free 
0          &lt;- kmem_cache_free 
0        &lt;- closef 
0        -&gt; setf 
0          -&gt; fd_reserve 
0          &lt;- fd_reserve 
0          -&gt; cv_broadcast 
0          &lt;- cv_broadcast 
0        &lt;- setf 
0      &lt;- closeandsetf 
0    &lt;- close 
0  &lt;= close         
                        
        syscall close ends 
</pre>

<b>The pid Provider</b>
<p> The <b>pid</b> provider does for user code what the <b>fbt</b> provider does for kernel code. Any user program that still has its external 
  symbol list, (linked with symbols included, and not stripped) can have <b>entry</b> and <b>return probes</b> instrumented. Let's start with an example 
  that displays all the calls made within a library function (libflow.d). 
  Notice the similarities to the <b>fbt</b> example: 
<p>

<pre>
#pragma D option flowindent 
pid$target:libc:$1:entry 
{ 
   self-&gt;follow = 1; 
} 
pid$target:::entry, 
pid$target:::return 
/ self-&gt;follow / 
{ 
} 
pid$target:libc:$1:return 
/ self-&gt;follow / 
{ 
   exit (0); 
} 
</pre>
The <b>pid</b> provider is similar in function to the <b>fbt</b> provider. The main difference, from our perspective, is that there is only 
    one kernel, but many processes. Similarly to how the profile provider 
    creates new probes as needed, the pid provider allows for the creation of 
    new providers. The actual provider name is the word <b>pid</b> followed by the 
    process ID number of the process being traced. So, the probe specification <b>pid123::abc:entry</b> would instrument an entry probe at the beginning of 
    function abc in process 123.
    <p> Our example script makes use of the <b>$target</b> macro to 
      specify the process ID number for a <b>pid</b> provider. We'll use the <b>-c</b> flag later to set the macro to the process ID of a process that we want to 
      trace. The first probe specification instruments a probe at the entry to a 
      function from the libc library. The function, specified with the <b>$1</b> argument macro, will also come from the DTrace command line. This is our 
      trigger probe. Similar to the <b>fbt</b> probe example, once the function we 
      specify has been called, the script will trace all of the user code calls 
      and returns until we return from the function with which we started: 
  <p>

  <pre>

# dtrace -s libflow.d -c ls closedir 
dtrace: script 'libflow.d' matched 6150 probes 
... 
dtrace: pid 138 has exited 
CPU FUNCTION 
0  -&gt; closedir 
0    -&gt; lfree 
0      -&gt; getbucketnum 
0      &lt;- getbucketnum 
0      -&gt; memset 
0      &lt;- memset 
0      -&gt; lmutex_lock 
0      &lt;- lmutex_lock 
0    &lt;- lfree 
0    -&gt; lmutex_unlock 
0    &lt;- lmutex_unlock 
0    -&gt; lfree 
0      -&gt; getbucketnum 
0      &lt;- getbucketnum 
0      -&gt; memset 
0      &lt;- memset 
0      -&gt; lmutex_lock 
0      &lt;- lmutex_lock 
0    &lt;- lfree 
0    -&gt; lmutex_unlock 
0    &lt;- lmutex_unlock 
0   | closedir:return 
0  &lt;- closedir 
    </pre>
In a second example, I've written a C program 
    that calls a recursive function to calculate factorial. We can use DTrace 
    to monitor the function calls and the values being passed. Here is the C 
    program (factorial.c) that we'll monitor:
<p>

<pre>
main() 
{ 
   int f; 
   f = fac(6); 
   return 0; 
} 
int fac (int n) 
{ 
   if (n &lt;= 1) 
      return 1; 
   else 
      return n * fac (n - 1); 
} 
</pre>
This is a traditional recursive algorithm, but it can 
    sometimes be a little confusing. DTrace allows us to see exactly 
    what's going on in the function without adding any debug code to the 
    C program. Our D program is called fac.d:
<p>

<pre>

pid$target:factorial:fac:entry 
{ 
   trace (arg0); 
} 
pid$target:factorial:fac:return 
{ 
   trace (arg1); 
} 
</pre>
We can choose whether or not to use flowindent, if we 
    like, with the <b>-F</b> option on the command line:
    <p>

  <pre>
# dtrace -s fac.d -c ./factorial 
dtrace: script 'fac.d' matched 2 probes 
CPU     ID                    FUNCTION:NAME 
0  46401                        fac:entry                 6 
0  46401                        fac:entry                 5 
0  46401                        fac:entry                 4 
0  46401                        fac:entry                 3 
0  46401                        fac:entry                 2 
0  46401                        fac:entry                 1 
0  46402                        fac:return                1 
0  46402                        fac:return                2 
0  46402                        fac:return                6 
0  46402                        fac:return               24 
0  46402                        fac:return              120 
0  46402                        fac:return              720 
dtrace: pid 258 has exited 

# dtrace -Fs fac.d -c ./factorial 
dtrace: script 'fac.d' matched 2 probes 
CPU FUNCTION 
0  -&gt; fac                                             6 
0    -&gt; fac                                           5 
0      -&gt; fac                                         4 
0        -&gt; fac                                       3 
0          -&gt; fac                                     2 
0            -&gt; fac                                   1 
0            &lt;- fac                                   1 
0          &lt;- fac                                     2 
0        &lt;- fac                                       6 
0      &lt;- fac                                        24 
0    &lt;- fac                                         120 
0  &lt;- fac                                           720 
dtrace: pid 263 has exited 
    </pre>
The <b>pid</b> provider can also instrument offset points 
    within a function. For example, <b>pid123::func:4</b>, instruments a point 4 bytes 
    from the start of the function. Additionally, if no <b>probename</b> is specified 
    for the probe, all of the instructions for the function are instrumented, 
    and each instruction execution is traced. Use of this capability, 
    indiscriminately, could make an application execute very slowly.
    <p>

    <b>Variables and Arrays Revisited</b>
  <p> We've looked at the different types of 
    user-defined variables as we needed them. Now let's take one more 
    look at all of the data types, just to round out the topic. 
  <p> D has all of the same data types as C, so much so, 
    that you can even include C system header files (i.e., <B>#include 
      &lt;stdio.h&gt;</B>), provided you use the <b>-C</b> option [1]. In addition to the C 
    data types, D also has real strings and associative arrays. Strings have 
    already been explained in previous segments, so let's get into more 
    details about arrays. 
  <p> Scalar arrays are declared and used in D the same way 
    they are in C. The following example uses scalar arrays of varying 
    dimensions and types: 
  <p>

  <pre>
int x[5][2]; 
int y[3]; 
string z[3]; 
struct { int a; char b; } s[5]; 
BEGIN 
{ 
   x[4][1] = 20; 
   y[2] = 10; 
   z[2] = "abc"; 
   s[3].b = 'c'; 
} 
    </pre>
Associative arrays are indexed by a comma-separated 
    list of keys that can be any scalar expression. Associative arrays are 
    usually defined by their first use. For example, <b>x["abc"</b>, <b>12*p] = 47</b>, defines an associative array of integers with a string key and an 
    integer key. Every assignment or reference after that must have the same 
    key types and value type. Unlike scalar arrays, there's no need to 
    declare the size of the array; storage is allocated as each location is 
    assigned. Associative arrays can also be explicitly declared. The 
    aforementioned array could be declared as <b>int x[string, int]</b>. As an 
    example, the following D program uses an associative array to keep track of 
    the first time a process calls the write system call:
    <p>

  <pre>
# cat firstwrite.d 
syscall::write:entry 
/ !first[pid] / 
{ 
   first[pid] = 1; 
   printf ("First write for %s(%d)", execname, pid); 
} 
# dtrace -s firstwrite.d 
dtrace: script 'firstwrite.d' matched 1 probe 
CPU   ID                FUNCTION:NAME 
0   3024                write:entry First write for sshd(5611) 
0   3024                write:entry First write for locale(5613) 
0   3024                write:entry First write for dtrace(5610) 
0   3024                write:entry First write for sshd(5597) 
0   3024                write:entry First write for sshd(5614) 
0   3024                write:entry First write for sshd(5616) 
0   3024                write:entry First write for cat(5618) 
0   3024                write:entry First write for ls(5620) 
    </pre>
The associative array, <b>first</b>, initially has no true 
    (1) values. Previously un-initialized locations return zero. The first time 
    a process calls write, the array location, keyed by the PID of the process, 
    is set to true (1). If that process does any more writes, the predicate 
    will prevent the probe clause from being executed. The end result is that 
    only the first write for each process is recorded.
<p> How would the previous example be accomplished if 
  there were no associative arrays? You certainly couldn't allocate a 
  scalar array with enough elements for every possible PID! You'd have 
  to use a smaller scalar array as a list of PIDs to search or create some 
  kind of linked list. The problem is that you can't search an array or 
  linked list. Do you remember why? That's right -- no flow 
  control statements. 
<p> D doesn't allow explicit declarations inside the 
  probe clause, so you can't declare variables with local scope, but 
  you can declare variables that are only associated with one thread or one 
  set of probe clauses. You've already met the former, thread-local 
  variables, which are created for each thread. Clause-local variables, on 
  the other hand, only maintain a value for the life of the clauses 
  associated with the firing of one probe. They are defined by using 
  "<b>this-&gt;</b>" in front of the variable name. Unlike global and 
  thread-local variables, they don't get initialized, so you have to 
  initialize them in your D program. They're great for accumulating 
  intermediate results for one pass through a set of clauses. 
<p>

<b>Defining Your Own Application Probes</b>
<p> It's one thing to be able to instrument probes 
  at any function within an application, but this doesn't necessarily 
  carry any meaning to someone who isn't familiar with the internal 
  workings of your application. DTrace has a mechanism called User-land 
  Statically Defined Tracing (USDT) that gives the programmer the capability 
  of creating instrumentation points anywhere in their code. The advantage 
  over the <b>pid</b> provider is that the abstraction these probes represent is 
  under control of the programmer. 
<p> For example, let's suppose you've written 
  a messaging system and you want to allow other programmers the capability 
  to debug message traffic. If you include the function symbols with the 
  executable, others could use the PID provider, but they would need access 
  to your source code, knowledge of the various functions that are involved 
  in message traffic, and how to interpret the arguments to these functions. 
  They may also need to write complex D clauses to drill down into your code 
  to get to key data elements. And then if you modify the function interfaces 
  and the internal data structures, you may break DTrace scripts that others 
  have written. USDT gives you the tools to provide probe points at higher 
  levels of abstraction (i.e., <i>msg-received</i> or <i>msg-sent</i>) along with whatever 
  data you deem appropriate. At the same time, you can safely make changes to 
  your code without affecting everyone else's use of DTrace with your 
  program, as long as you don't change the USDT probe points. 
<p> Let's look at a simple example. Here is a C 
  program that implements a stack of integers (push and pop), along with a 
  header file for common definitions, and a program to call the stack 
  routines to try them out: 
<p>

<pre>
# cat stack.c 
#include &lt;stdlib.h&gt;
typedef struct stackstruct 
{ 
   int item; 
   struct stackstruct *next; 
} STACK; 

static STACK *head = NULL; 

void push (int val) 
{ 
   STACK *temp; 
   temp = (STACK *) malloc (sizeof (STACK)); 
   temp-&gt;item = val; 
   temp-&gt;next = head; 
   head = temp; 
} 
int pop (void) 
{ 
   int val; 
   STACK *temp; 
   if (head) 
   { 
      val = head-&gt;item; 
      temp = head; 
      head = head-&gt;next; 
      free (temp); 
   } 
   else 
   { 
      val = 0; 
   } 
   return val; 
} 
# cat stack.h 
void push (int); 
int pop(void); 
# cat do-stack.c 
#include "stack.h"
main (int argc, char *argv[]) 
{ 
   int i, val; 
   for (i = 1; i &lt; argc; i++) 
      push (atoi(argv[i])); 
   while ((val = pop()) != 0) 
      printf ("%d\n", val); 
   return 0; 
} 
</pre>
The file stack.c contains routines that allow another 
    C program (in this case do-stack.c) to push and pop integers. The stack.h 
    program provides the push and pop interface definitions to do-stack.c, 
    which is a C main program that takes integer command line arguments and 
    pushes them onto the stack.
<p> Let's suppose you're the author of these 
  programs, and you want others to be able to monitor what the stack is 
  doing, with DTrace. At the same time, you don't want other 
  programmers to have to deal with the details of how the program works. 
  Additionally, it would be better if others could write DTrace scripts that 
  didn't break when you make code changes. To accomplish this, you can 
  add meaningful probe points into stack.c using the sdt.h system header file 
  and DTRACE_PROBE macros. Here is stack.c modified to include the USDT probe 
  points: 
<p>

<pre>
#include &lt;stdlib.h&gt;
#include &lt;sys/sdt.h&gt;
typedef struct stackstruct 
{ 
   int item; 
   struct stackstruct *next; 
} STACK; 
static STACK *head = NULL; 

void push (int val) 
{ 
   STACK *temp; 
   DTRACE_PROBE1(mystack,push,val); 
   temp = (STACK *) malloc (sizeof (STACK)); 
   temp-&gt;item = val; 
   temp-&gt;next = head; 
   head = temp; 
} 
int pop (void) 
{ 
   int val; 
   STACK *temp; 
   if (head) 
   { 
      val = head-&gt;item; 
      temp = head; 
      head = head-&gt;next; 
      free (temp); 
      DTRACE_PROBE1(mystack,pop,val); 
   } 
   else 
   { 
      val = 0; 
      DTRACE_PROBE(mystack,empty); 
   } 
   return val; 
} 
</pre>
The DTRACE_PROBE macro comes in different flavors 
    (DTRACE_PROBE, ...1, ...2, etc.) depending on how many arguments you want 
    to pass to a probe clause. The first two arguments to the macro are the 
    name of the USDT provider that is being created, and the name of the probe. 
    In this case, the provider will be called <b>mystack</b>, and the probe names are <b>empty</b>, <b>push</b>, and <b>pop</b>. Next, you need to create a provider definition file 
    for DTrace (mystack.d):
    <p>

  <pre>

provider mystack { 
   probe empty(); 
   probe push (int); 
   probe pop (int); 
}; 
    </pre>
The definition file lists all of the probes that will 
    be apart of the mystack provider. To aid in the abstraction, you should try 
    to make the probe names as self-explanatory as possible. Next, you need to 
    add the provider and probe definitions to the build process you use to 
    create the applications:
<p>

<pre>
# gcc -c stack.c 
# dtrace -G -s mystack.d stack.o 
# gcc do-stack.c mystack.o stack.o -o do-stack 
</pre>
The first line compiles your applications sources in 
    the usual way. The <b>dtrace</b> command uses the <b>-G</b> option, which generates an 
    object, in this case called <b>mystack.o</b>, which contains DTrace linkage 
    information. The resulting object is then included in the final executable 
    linkage (the third line). If you run the <b>do-stack</b> command without DTrace, 
    you get something like this:
    <p>

  <pre>
# ./do-stack 100 200 300 
300 
200 
100 
    </pre>
Now let's create a DTrace script (do-stack.d) 
    that makes use of this new set of probes. The provider name is going to be <b>mystack&lt;pid&gt;</b>, where <b>&lt;pid&gt;</b> is the PID of the executing program. 
    In my example, I'm going to use the <b>-c</b> flag to start the program with 
    the script, though, as you may recall, there are different ways to 
    associate a DTrace program with a process. Here's the DTrace script 
    that instruments all of the probes provided by mystack:
    <p>

  <pre>
mystack$target:::empty 
{ 
} 
mystack$target:::push 
{ 
   trace (arg0); 
} 
mystack$target:::pop 
{ 
   trace (arg0); 
} 
    </pre>
Now the moment of truth. Here is the output of the 
    DTrace command that runs the D program and the C program together:
<p>

<pre>
# dtrace -s do-stack.d -c "./do-stack 100 200 300"
dtrace: script 'do-stack.d' matched 3 probes 
300 
200 
100 
CPU     ID                    FUNCTION:NAME 
  0  46407                        push:push               100 
  0  46407                        push:push               200 
  0  46407                        push:push               300 
  0  46406                          pop:pop               300 
  0  46406                          pop:pop               200 
  0  46406                          pop:pop               100 
  0  46405                          pop:empty 
dtrace: pid 9692 has exited 
</pre>
In this example, the highest level of abstraction is 
    not much better than just using the <b>pid</b> provider, but I think you can see 
    that in a complex application, there is a lot of power to provide more 
    meaningful information that is directly related to your application.
    <p> One other point of interest -- if you want to 
      just list the probes that are being instrumented by your D program, you can 
      do that: 
  <p>

  <pre>
# dtrace -ls do-stack.d -c ./do-stack 
   ID   PROVIDER            MODULE                 FUNCTION NAME 
46405 mystack9611          do-stack                 pop empty 
46407 mystack9611          do-stack                 push push 
46406 mystack9611          do-stack                   pop pop 
    </pre>

    <b>Anonymous Tracing</b>
    <p> Early in the Solaris boot process, it isn't 
      possible for any DTrace consumers to be running, so DTrace provides the 
      capability for trace data to be accumulated without a consumer. This is 
      called "anonymous tracing". The most common use for this is to 
      give device driver developers the ability to monitor and debug their code 
      as it is being executed at system boot. 
  <p> The two main problems with operating DTrace at boot, 
    is that there is no way to run your DTrace program directly, and the 
    provider modules may not have been loaded yet. These problems are solved by 
    doing an "anonymous enabling". If you run your D program with 
    the <B>-A</B> option, DTrace adds information to /kernel/drv/dtrace.conf that will 
    cause all of the probes and actions in your D program to execute at system 
    boot, even though there is no consumer present. Additionally, <b>forceload</b> statements are added to /etc/system for each provider that you'll 
    need. 
  <p> As an example, let's suppose you wanted to see a <b>count</b> aggregation of all of the <b>pts</b> (pseudo-tty slave) function calls as 
    the <b>pts</b> driver is being loaded. To set this up, do the following: 
  <p>

  <pre>
# dtrace -A -n 'fbt:pts::entry { @[probefunc]=count() }'
dtrace: saved anonymous enabling in /kernel/drv/dtrace.conf 
dtrace: added forceload directives to /etc/system 
dtrace: run update_drv(1M) or reboot to enable changes 
    </pre>
When the system is rebooted, you'll see messages 
    showing that the appropriate probes are being enabled:
<p>

<pre>
NOTICE: enabling probe 0 (fbt:pts::entry) 
NOTICE: enabling probe 1 (dtrace:::ERROR) 
</pre>
Trace data has now been collected, but it has been 
    done so anonymously, without any consumer. After the system is booted, to 
    claim the anonymous data, run the <b>dtrace</b> command with the <b>-a</b> option. (You 
    also need to use the <b>-e</b> option to cause the command to exist after 
    consuming the anonymous trace data. Otherwise, it will continue to run, 
    waiting for new data.)
    <p>

  <pre>
# dtrace -ae 

  pts_detach                                   1 
  pts_attach                                   2 
  ptsclose                                     5 
  ptsopen                                      5 
  ptswsrv                                     15 
  ptswput                                     20 
    </pre>

    <b>Postmortem Tracing</b>
    <p> DTrace can also be useful in determining the root 
      cause of a system panic. If the system crashes while a DTrace program is 
      running, there will be DTrace data left in the primary buffer that has not 
      been consumed and reported by the <b>dtrace</b> command. You can use this data to 
      help find the root cause of the crash. This methodology, called postmortem 
      tracing, doesn't actually involve the DTrace command, but instead 
      uses the modular debugger (<b>mdb</b>) to extract the data. The <b>mdb</b> command has 
      DTrace extensions to display trace data and buffer information. 
  <p> Before showing you an example, I need to explain 
    something about buffer policies. By default, DTrace creates two buffers per 
    DTrace consumer and per CPU. This allows the DIF programs to write trace 
    data to one buffer, while your <b>dtrace</b> command (the consumer) reads the 
    other buffer. This buffer usage policy is called the "switch" 
    policy. There is an alternate policy, the "ring" policy, which 
    only uses one buffer. When this buffer becomes full, DTrace wraps around 
    and starts writing over the oldest data. If you use a ring buffer with 
    DTrace, when a panic occurs, the most current data will be left in the 
    buffer. 
  <p> As an example, I ran the the command <b>dtrace -n 'syscall:::entry' -b 16k -x bufpolicy=ring</b> to generate system call data in 
    a 16K ring buffer. After starting this command, I panicked the OS and 
    collected a crash dump. Then I invoked <b>mdb</b> with the crash dump. If more 
    than one <b>dtrace</b> command was running at the moment of the crash, there might 
    be several buffers available. The following mdb extensions will be helpful 
    in determining which buffer is the right one: 
  <p>

  <pre>
# mdb unix.0 vmcore.0 
Loading modules: [ unix krtld genunix specfs dtrace ufs ip sctp usba
fctl nca random nfs sppp crypto ptm sd cpc fcip ] 
&gt; ::dtrace_state 
                ADDR MINOR             PROC NAME                   FILE 
         300051d4ac0     2      30000315350 dtrace          3000780dc00 
&gt; 30000315350::ps 
S    PID   PPID   PGID  SID  UID      FLAGS       ADDR NAME 
R    659    627    627  627    0 0x4a004000 0000030000315350 dtrace 
&gt;
    </pre>
The <b>::dtrace_state</b> command displays the existing 
    DTrace buffers. In my case, there is only one. The name of the consumer is 
    listed, but of course, it's usually called "dtrace". You 
    can further inspect the properties of the consumer process with the <b>::ps</b> command applied to the process structure pointer. Using the PID of the 
    consumer process, you should be able to narrow in on the correct buffer.
    <p> Using the ADDR field from the <b>::dtrace_state</b> output, 
      we can display the trace data: 
  <p>

  <pre>
&gt; 300051d4ac0::dtrace 
CPU     ID                    FUNCTION:NAME 
0    119                      ioctl:entry 
0    119                      ioctl:entry 
0    253                  sysconfig:entry 
0    253                  sysconfig:entry 
0    189                  sigaction:entry 
0    189                  sigaction:entry 
0    119                      ioctl:entry 
0    211                       mmap:entry 
0    371                   schedctl:entry 
0    147                   lwp_park:entry 
0    305                lwp_sigmask:entry 
0    305                lwp_sigmask:entry 
0     33                       read:entry 
0    329                    pollsys:entry 
0    305                lwp_sigmask:entry 
0    305                lwp_sigmask:entry 
0     33                       read:entry 
0    329                    pollsys:entry 
0    305                lwp_sigmask:entry 
0    305                lwp_sigmask:entry 
0     33                       read:entry 
0    329                    pollsys:entry 
&gt;&gt; More [&lt;space&gt;, &lt;cr&gt;, q, n, c, a] ? 
    </pre>
In my example, I've only collected entry data 
    for each system call. Depending on the problem you are tracking down, you 
    will want to tailor the trace data to something specific to the problem.
<p>

<b>Summary</b>
<p> In this final article in the DTrace series, I've 
  covered the use of DTrace with applications in more detail and showed you 
  some methods for using DTrace at times when the DTrace command isn't 
  available. As you look back at all five parts to this series, I think you 
  can see that DTrace has a lot of power and flexibility to allow you to 
  drill down into a system or an application, monitor what's going on, 
  and get to the root cause of an issue more quickly. I hope you agree, as I 
  stated at the beginning of the series, that DTrace is one of the most 
  innovative features of Solaris 10. 
<p>

<b>Endnotes</b>
<p> 1. You might ask why you would need to include system 
  header files. The header files provide all of the structure definitions, 
  typedefs, and #defines for inspecting system data. You get some 
  declarations automatically when the probe fires, but not all. The problem 
  is that the header files were written for C, so they sometimes contain D 
  reserved words (like "string"). When this happens, the D 
  compiler generates an error. If you really need the header file for your D 
  program, the only solution is to make a private copy of it, change the word 
  that's reserved, and add the directory of your private header files 
  to an include list on the DTrace command line (<B>-I</B>). 
<p>

<b>Corrections </b>
<p> In part four of this series, when describing the <I>quantize</I> aggregation function, I incorrectly stated that each pail contains 
  values that are equal to or smaller than the value listed at the left of 
  the row, and I should have said that each pail contains values that are 
  equal to or greater than the value listed at the left of the row.  In 
  other words, a pail that's labeled 512 will contain values for 512 through 
  and including 1023, and then the next pail would be labeled 1024.  My 
  apologies for any confusion this may have caused. 
<p>

<i>Chip Bennett (<B>cbennett@laurustech.com</B>) is a systems 
  engineer for Laurus Technologies (<B>http://www.laurustech.com</B>), a Sun 
  Microsystems partner. He has more than 20 years experience with UNIX 
  systems, and holds a B.S. and M.S. in Computer Science. He consults with 
  Laurus and Sun customers on a variety of Solaris related topics, and he 
  co-chairs OS-GLUG, the OpenSolaris Great Lakes User Group (Chicago).</i>
<p>

</table>
    
</table>&nbsp;

<! -- End Content ------ >

<!/center>
<! -- End MASTER TABLE -- >

</body>



<! -- Begin Content ------ >
</html>
