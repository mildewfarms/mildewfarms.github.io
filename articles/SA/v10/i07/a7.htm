<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 4.0//EN">


<HTML>
<HEAD>
<TITLE>v10, i07: Proxy FTP without the Browser</TITLE>
<LINK REL=StyleSheet HREF="../../resource/css/sacdrom.css" TYPE="text/css" TITLE="CSS1">
</HEAD>

<body bgcolor="#ffffff" text="#000000" link="#000000" alink="#669999" vlink="#333366" topmargin=0 leftmargin=0>

<! -- Begin MASTER TABLE -- >
<!center>
<table width=98% cellpadding=0 cellspacing=0 border=0 bgcolor="#ffffff">
  <tr>

<table cellpadding=5 cellspacing=0 border=0>
	<tr>

		<td><span class="navbarLink">Article</span></td>
		<td><a href="../../../../source/SA/2001/jul2001.tar"><b class=codeListing>jul2001.tar</b></a></td>

	</tr>
</table>


</tr>
<tr>
<! -- Begin Content ------ >
    <td valign=top width=527 bgcolor="#ffffff"> 
      <table width=100% cellpadding=15 cellspacing=0 border=0>
<tr>
          <td valign=top> 
            <! -- Insert Content ------ >
            <H1><img src="a7.gif" width="200" height="174" align="right">Proxy 
              FTP without the Browser</h1>
            <p> <i>Robert Chuba and Anthony Caruso</i>
            <p> Consider a small unregarded little network, which is in protected 
              RFC 1918 IP space sitting behind a firewall. Direct access to the 
              Internet is not allowed. Instead, Web access is provided by an HTTP 
              proxy server. While this meets most of the office needs, downloading 
              files from an <b>ftp</b> site is only possible through the browser. 
              Writing an <b>ftp</b> script to periodically download files, such 
              as virus <b>.dat</b> files, is impossible. Instead of opening a 
              port on the firewall for <b>ftp</b> and breaking the rules just 
              for us, we decided to try something else.
            <p> Knowing we could access the <b>ftp</b> site via a browser, we 
              considered how the browser manages requests for <b>ftp://ftp.somesite.com</b> 
              when typed into the location text box. Further, we wondered if we 
              could use the same mechanism via a script to make <b>HTTP GET</b> 
              requests through the proxy. Listing 1, <b>pftp.pl</b>, or proxy 
              <b>ftp</b>, is the result of this exercise. (Listings are available 
              for download from the <i>Sys Admin</i> Web site: <b>http://www.sysadminmag.com</b>.)
            <p> Our script relies on the LWP (library for Web access in Perl) 
              UserAgent module. LWP is a collection of modules that provide an 
              API to Web functions and is part of the Linux standard distribution 
              that can be downloaded from:<b> http://www.linpro.no/lwp/</b>. The 
              UserAgent class implements simple WWW requests. Our script uses 
              the functions to make <b>ftp</b> requests instead of <b>http</b> 
              requests. Other than that, and some user interface options, the 
              script is essentially the same as the example in the UserAgent documentation.
            <p> <b>Usage</b>
            <p> The script has two modes of operation. It can be used from the 
              command line to <b>ftp</b> a file:
            <p> 
            <pre>
pftp.pl -u ftp.somesite.com/pub/docs/README
</pre>
            or to get a couple of files:
            <p> 
            <pre>
pftp.pl -u ftp.somesite.com/pub/docs -r README,freecode.tar.gz,morecode.tar.Z
</pre>
            <b>pftp.pl -help</b> lists the command-line options.
            <p> The script can also be used from a cron job. Though batching a 
              script is nothing new, we decided to use the data section to placed 
              defaults so the data stays with the script. That is, we wanted the 
              ability to change the name of the script to correspond with its 
              function. For example, we created a copy of the script named <b>pftp-av.pl</b> 
              and changed the data section to read:
            <p> 
            <pre>
__DATA__
proxyxport = 8080
ftpuser = anonymous
pftppwd=us@oursite.com
proxy = 10.1.1.1
url=ftp.antivirus.com/pub/newdatfiles
remotefiles = new.dat,update.txt,ver.txt
localpath=\\avserver\distribution\
</pre>
            This downloads the three files listed in the remote files parameter 
            from our fictitious antivirus distributor and places the files on 
            our antivirus server in the distribution share.
            <p> <b>The Script </b>
            <p> The first few lines of the script tell the interpreter which modules 
              we will be using. The only notable module we use is <b>Cwd</b>, 
              which is used for cross-platform independence. The next block of 
              code is simply for processing the command line. The usage message 
              is issued if the arguments to the script are incorrect.
            <p> The <b>while()</b> block that follows processes the <b>__DATA__ 
              </b>section to determine default settings. The data section can 
              contain any of the named parameters listed in the <b>GetOptions()</b> 
              call in the command-line processing block. For example, <b>-proxy</b> 
              is an argument to the script, so the data section can hold a default 
              proxy with the entry:
            <p> 
            <pre>
proxy = 10.1.1.1    # default proxy
</pre>
            Lines beginning with a #, blank lines, and white space are ignored. 
            Comments can also follow an entry and are removed by the line:
            <p> 
            <pre>
my($right,$comment) = split /#/,$r,2;
</pre>
            where <b>$r</b> holds everything to the right of the character <b>=</b> 
            for that entry. All variables (left-sides) are converted to lowercase 
            so they can be processed later.
            <p> The subsequent block sets the script's options. Anything 
              set on the command line overrides the defaults. Finally, a bit of 
              processing standardizes the URL entry. Remote files to be downloaded 
              are put into the list <b>@rfiles</b>. If <b>-remotefiles</b> is 
              not specified, we assume the file name is appended to the end of 
              the URL. The file name will be stripped off the URL and loaded into 
              <b>@rfiles</b>.
            <p> Now that everything is prepared, we instantiate the UserAgent 
              object, and set the member variables <b>env_proxy</b>, and proxy 
              for http and ftp. Looping through the list of <b>@rfiles</b>, the 
              script appends the file name to the URL and creates a new <b>HTTP::Request</b>. 
              If all goes well, the files are downloaded into the specified directory.
            <p> <b>Future Work</b>
            <p> Although this script meets our current production needs, we still 
              want to improve it. Features to be added when our copious free time 
              comes to fruition include: improved error-checking, the ability 
              to download entire directories, and to include a mechanism for authenticating 
              to a proxy. Actually, the last item isn't difficult, we didn't 
              want to implement it because we couldn't test it -- our 
              proxy doesn't require logins. If you'd care to improve 
              our script, please drop us a copy -- we'd like to see what 
              you do.
            <p> <b>Resources</b>
            <p> Perl: win32 -- <b>http://www.activestate.com</b>
            <p> 
            Tony Caruso has been Network/Systems consultant with MRE Consulting, 
            Inc. in Houston, TX for the last three years and has been hacking 
            code since he was 12 (on the Apple II). Tony has been working in both 
            NT and UNIX for 8 years. Tony holds an MS in Computer Science from 
            the University of Oklahoma and a BS in Electrical Engineering from 
            Louisiana Tech University.
            <p><i> Robert Chuba is a consultant for MRE. He is a systems analyst 
              with 2 years experience in Novell and 3 years in NT. Robert is working 
              on his BS at the University of Houston.</i>
          </table></table><br>&nbsp;<br>

<! -- End Content ------ >

<!/center>
<! -- End MASTER TABLE -- >

</body>



<! -- Begin Content ------ >
</html>
