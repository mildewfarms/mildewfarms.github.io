<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 4.0//EN">


<HTML>
<HEAD>
<TITLE>v10, i13: AIX Alternate Disk Installation</TITLE>
<LINK REL=StyleSheet HREF="../../resource/css/sacdrom.css" TYPE="text/css" TITLE="CSS1">
</HEAD>

<body bgcolor="#ffffff" text="#000000" link="#000000" alink="#669999" vlink="#333366" topmargin=0 leftmargin=0>

<! -- Begin MASTER TABLE -- >
<!center>
<table width=98% cellpadding=0 cellspacing=0 border=0 bgcolor="#ffffff">
  <tr>

<table cellpadding=5 cellspacing=0 border=0>
	<tr>

		<td><span class="navbarLink">Article</span></td>
		<td><span class="navbarLink"><a href="a5_f1.htm">Figure 1</a></span></td>
		<td><span class="navbarLink"><a href="a5_f2.htm">Figure 2</a></span></td>
		<td><a href="../../../../source/SA/2001/jun_sup2001.tar"><b class=codeListing>jun_sup2001.tar</b></a></td>

	</tr>
</table>


</tr>
<tr>
<! -- Begin Content ------ >
<td valign=top width=440 bgcolor="#ffffff">
<table width=100% cellpadding=15 cellspacing=0 border=0>
<tr>
          <td valign=top> 
            <! -- Insert Content ------ >
            <H1><img src="a5_pic.gif" width="200" height="174" align="right">AIX 
              Alternate Disk Installation</h1>
            <p> <i>Jeff Marsh</i>
            <p> In this article, I will describe some tools within AIX (some new, 
              some old) that can help you reduce the off-hours time spent by your 
              administration staff during maintenance upgrades. I will also show 
              you some uses for these same toolsets that can help you reduce recovery 
              times due to <b>rootvg</b> corruption.
            <p> <b>Alternate Disk Installation</b>
            <p> What is it? According to the IBM AIX Installation Guide:
            <p> "Alternate disk installation, available in AIX Version 4.3, 
              allows installing the system while it is up and running, allowing 
              installation or upgrade down time to be decreased considerably."
            <p> Thus, with another set of bootable drives within a server, you 
              can install maintenance (e.g., upgrade your system from AIX 4.3.3.04 
              to AIX 4.3.3.06) during the day without interruption or any effects 
              to the running applications. However, you will still need a reboot 
              to make it active.
            <p> The support model prior to Alternate Disk Installation required 
              all work to be done off-hours during an application maintenance 
              window that generally took two to four hours. Now you can reduce 
              that off-hour time from two to four hours per server to just the 
              time to reboot. I'll also show you how you can complete multiple 
              upgrades in that same reboot window using Network Installation Manager 
              (NIM).
            <p> <b>Requirements</b>
            <p> To enable Alternate Disk Installation, you need to install the 
              following base-level filesets and upgrade to at least these corresponding 
              fileset levels. These filesets do not require a reboot to install:
            <p> 
            <pre>
Base level filesets:            Fileset levels:
bos.alt_disk_install.rte              26
bos.alt_disk_install.boot_images      27
</pre>
            You will also need another free, bootable drive within your server. 
            In this case, you are configuring new servers with four internal drives 
            for systems administration purposes: two drives for the primary <b>rootvg</b> 
            mirrored, and two for <b>alt_disk_install</b> implementations. You 
            could get by with just one additional drive, but we prefer to have 
            two.
            <p> <b>How It Works</b>
            <p> Alternate Disk Installation works by cloning your primary <b>rootvg</b> 
              running on hdisk0 and hdisk1, for example, to a second set of drives, 
              hdisk2 and hdisk3. After the system completes those copies using 
              basic <b>find</b>, <b>backup</b>, and <b>restfile</b> utilities, 
              it will install the latest maintenance level you designate.
            <p> This process is shown in Figure 1. First, you clone hdisk0/1 to 
              hdisk2/3, and then you apply maintenance to the newly cloned hdisk2/3 
              while the applications continue to run against hdisk0/1.
            <p> To complete this task from SMIT, issue the following fast path. 
              You should expect to see the following panels:
            <p> 
            <pre>
smitty alt_clone

Clone the rootvg to an Alternate Disk:
Type or select values in entry fields.
Press Enter AFTER making all desired changes.

* Target Disk(s) to install                      [hdisk2 hdisk3]
  Phase to execute                               all
+
  image.data file                                []
/
  Exclude list                                   []
/
   Bundle to install                             [update_all]
+
    -OR-
  Fileset(s) to install                          []
  
  Fix bundle to install                          []
    -OR-
  Fixes to install                               []
  
  Directory or Device with images                [/mnt]
  (required if filesets, bundles or fixes used)
  
  installp Flags
  COMMIT software updates?                       yes
+
  SAVE replaced files?                           no
+
  AUTOMATICALLY install requisite software?      yes
+
  EXTEND file systems if space needed?           yes
+
  OVERWRITE same or newer versions?              no
+
  VERIFY install and check file sizes?           no
+
  Customization script                           []
/
  Set bootlist to boot from this disk
  on next reboot?                                yes
  
  Reboot when complete?                          no
+
  Verbose output?                                no
+
  Debug output?                                  no
+
[BOTTOM]
  
F1=Help             F2=Refresh          F3=Cancel
F4=List
F5=Reset            F6=Command          F7=Edit
F8=Image
F9=Shell            F10=Exit            Enter=Do
</pre>
            From the example above, note the following:
            <p> 
            <ul>
              <li> You are cloning to hdisk2 and hdisk3. 
              <li> You are running an <b>update_all</b> operation of maintenance 
                mounted in the <b>/mnt</b> mount point. (In this case, this is 
                a CD-ROM with the AIX 4.3.3.06 maintenance filesets.) 
              <li> You are specifying that this operation should change our bootlist 
                to hdisk2 and hdisk3 after completion. 
              <li> You are not asking the process to complete an immediate reboot 
                upon completion of the upgrade because this is something you want 
                to schedule in an appropriate maintenance window.
            </ul>
            At the completion of the operation, you will notice from the <b>bootlist 
            -m normal -o</b> command that the bootlist will be set to hdisk2 hdisk3, 
            and issuing an lspv command will show the following:
            <p> 
            <pre>
root@aknimp1:/&gt; lspv
hdisk0         000f261d90bf6ea0    rootvg         
hdisk1         000f261dae86d104    rootvg         
hdisk2         000f261db52d4d95    altinst_rootvg
hdisk3         000f261db52d4ca6    altinst_rootvg
hdisk4         000f018d07d4f412    None           
hdisk5         000f261dbde71c66    None           
hdisk6         000f261dbd8eea89    nimresvg       
</pre>
            At this point, you have cloned and installed the latest AIX maintenance 
            level during the day. You are now ready to activate that latest maintenance 
            with a reboot operation at whatever time is appropriate for the outage 
            to your application users. You can save significant off-hours time 
            for maintenance upgrades; our off-hours time has been reduced to the 
            time needed for a simple reboot.
            <p> <b>Alternate Disk Installation </b>--<b> After the Reboot</b>
            <p> After the reboot, issue the <b>oslevel</b> command or complete 
              the appropriate verifications to ensure your maintenance upgrade 
              occurred as expected. If you issue the <b>lspv</b> command, you 
              will notice the following:
            <p> 
            <pre>
root@aknimp1:/&gt; lspv
hdisk0         000f261d90bf6ea0    old_rootvg     
hdisk1         000f261dae86d104    old_rootvg     
hdisk2         000f261db52d4d95    rootvg         
hdisk3         000f261db52d4ca6    rootvg         
hdisk4         000f018d07d4f412    None           
hdisk5         000f261dbde71c66    None           
hdisk6         000f261dbd8eea89    nimresvg       
</pre>
            Both hdisk2 and hdisk3, from which you have booted, now show a volume 
            group identifier of rootvg. Hdisks 0 and 1 now show a volume group 
            of <b>old_rootvg</b> and are varied off.
            <p> Now, you have several options. My preference is to leave hdisk0 
              and hdisk1 alone with the old maintenance levels in case you need 
              to fall back on them.
            <p> Let's assume that after the reboot your applications aren't 
              working well with the latest maintenance. The previous support model 
              suggests that you need to get the <b>mksysb</b> backup taken prior 
              to your upgrade and begin a restore process. This could take two 
              hours or more, with the hope that the tape image was good. The new 
              support model with Alternate Disk Installation says to change your 
              bootlist back to hdisk0 and hdisk1 and to reboot the server. At 
              some future point, when you decide the maintenance is good and you 
              don't need to fall back, you can clone the latest maintenance 
              residing on hdisk2/3 back to hdisk0/1.
            <p> <b>Cloning Back to hdisk0/1</b>
            <p> To complete the cloning of hdisk2/3 back to hdisk0/1, you must 
              issue the following commands:
            <p> 
            <ul>
              <li> <b>alt_disk_install -W hdisk0 hdisk1</b> -- Wakes up the 
                <b>old_rootvg</b> 
              <li> <b>alt_disk_install -S</b> -- Puts the <b>old_rootvg</b> 
                back to sleep 
              <li> <b>alt_disk_install -X old_rootvg</b> -- Removes the <b>old_rootvg</b> 
                volume group name associated with hdisk0/1 from the ODM and assigns 
                them a value of "none", which will allow the cloning 
                to recur cleanly. 
              <li> <b> smitty alt_clone</b> -- Reclone back to hdisk0/1 using 
                the previous example.
            </ul>
            <p> I will discuss using the above commands further in the next section; 
              however, in order to reclone drives that have been previously used 
              to boot from, you must follow the commands verbatim to remove the 
              knowledge of the <b>old_rootvg</b> volume group name from the ODM.
            <p> <b>Other Uses for alt_disk_install</b>
            <p> Some other items that <b>alt_disk_install</b> may be helpful with 
              are:
            <p> 
            <ul>
              <li> Nightly backup of your system -- Using <b>alt_disk_install</b>, 
                you can backup your system nightly (or at whatever frequency is 
                appropriate) without having to manage <b>mksysb</b> tapes. If 
                you suffer some type of <b>rootvg</b> corruption, either major 
                or minor, you can restore using the data on the cloned drives. 
              <li> <b> mksysb</b> Images -- The <b>alt_disk_install</b> command 
                can be used to install images (AIX 4.3 or later) onto AIX 4.1 
                and later versions. 
              <li> You can also use <b>alt_disk_install</b> for recovery of corrupted 
                files in <b>rootvg</b> and to reduce the size of logical volumes 
                in <b>rootvg</b>, as described in the following sections.
            </ul>
            <b>Recovery of Corrupted Files in rootvg</b>
            <p> If you suffer major corruption (hdisk failure), and the server 
              crashes, and if you have cloned that data to another bootable drive, 
              you could interface with SMS, for example, to change your bootlist 
              to your other cloned drives and quickly recover the server.
            <p> If you suffer minor corruption within the <b>rootvg</b> where 
              a file or a few files are corrupted or inadvertently deleted, you 
              can wake up the cloned copy of the <b>rootvg</b> and copy those 
              deleted or corrupted files back to the primary <b>rootvg</b> while 
              the server is up and running.
            <p> In this example, you are booted against hdisk0/1 and have recently 
              cloned the system to hdisk2/3. To access the cloned copy of the 
              <b>rootvg</b> while the server is up and running, complete the following:
            <p> 
            <p> 1. <b>alt_disk_install -W hdisk2 hdisk3</b> -- Wakes up the 
              cloned copy:
            <p> 
            <pre>
root@aknimp1:/&gt; alt_disk_install -W hdisk2 hdisk3
Waking up altinst_rootvg volume group ...
Replaying log for /dev/alt_hd4.
</pre>
            2. From a <b>df -k</b> command, you will notice that the wake up command 
            has mounted the alternate <b>rootvg</b> logical volumes, which are 
            prefaced with <b>/alt_inst</b> prefix:
            <p> 
            <pre>
root@aknimp1:/&gt; df -k
Filesystem    1024-blocks    Free %Used  Iused %Iused Mounted on
/dev/hd4            49152    5608   89%   1226     5% /
/dev/hd2           753664    5056  100%  19966    11% /usr
/dev/hd9var         16384   14340   13%    222     6% /var
/dev/hd3            32768   30376    8%     98     2% /tmp
/dev/lvexport      131072  126772    4%     41     1% /export
/dev/lv01         4980736   94468   99%   4546     1% /export/lpp_source
/dev/lv02          917504  448868   52%  29468    13% /export/spot
/dev/lvmksysb    15204352 3381328   78%     31     1% /export/mksysb
/dev/lvadmin       131072  126868    4%     25     1% /admin
/dev/hd1            16384   15820    4%     20     1% /home
/dev/lvadsm         16384      56  100%     21     1% /var/adsm
/dev/alt_hd4        49152    5704   89%   1192     5% /alt_inst
/dev/alt_lvadmin   131072  126868    4%     25     1% /alt_inst/admin
/dev/alt_hd1        16384   15820    4%     20     1% /alt_inst/home
/dev/alt_hd3        32768   30376    8%     98     2% /alt_inst/tmp
/dev/alt_hd2       753664    5056  100%  19966    11% /alt_inst/usr
/dev/alt_hd9var     16384   14380   13%    219     6% /alt_inst/var
/dev/alt_lvadsm     16384    1848   89%     20     1% /alt_inst/var/adsm
</pre>
            3. Copy the corrupted files from the appropriate <b>alt_inst</b> logical 
            volume/filesystem. In this case, I corrupted my <b>/etc/hosts</b> 
            file, so I will issue the following command to restore it from my 
            latest cloned backup:
            <p> 
            <pre>
cp /alt_inst/etc/hosts /etc/hosts
</pre>
            4. When you have restored the required files, put the <b>altinst_rootvg</b> 
            back to sleep, which will unmount the <b>/alt_inst</b> logical volumes/filesystems 
            by issuing:
            <p> 
            <pre>
alt_disk_install -S
</pre>
            <b>Reducing Logical Volumes Size Within the rootvg</b>
            <p> Remember the pain associated with the need to reduce the size 
              of a logical volume within the <b>rootvg</b>? It took a tape restore 
              of the system to complete. Now, you can complete that reduction 
              within a simple cloning process. The steps to complete that process 
              are as follows:
            <p> 
            <p> 1. Issue a <b>mkszfile</b> command to create the <b>/image.data</b> 
              file.
            <p> 2. Edit the <b>/image.data</b> file and specify <b>SHRINK=yes</b> 
              in the <b>logical_volume_policy</b> stanza:
            <p> 
            <pre>
image_data:
        IMAGE_TYPE= bff
        DATE_TIME= Tue Oct 3 10:29:55 CDT 2000
        UNAME_INFO= AIX aknimp1 3 4 000F261D4C00
        PRODUCT_TAPE= no
        USERVG_LIST= nimresvg
        OSLEVEL= 4.3.3.10

logical_volume_policy:
        SHRINK= yes
        EXACT_FIT= no

ils_data:
        LANG=  en_US
</pre>
            3. Clone the <b>rootvg</b> to hdisk2 and hdisk3, specifying your customized 
            <b>/image.data</b> file by issuing one of the following commands:
            <p> <b>sm itty alt_clone</b> (remember to specify the location of 
              your <b>image.data</b> file on the <b>image.data</b> file prompt)
            <p> 
            <p> or
            <p> 
            <p> <b>al t_disk_install -i/image.data -B -C hdisk2 hdisk3</b> (from 
              the command line)
            <p> 4. After the completion of the cloning operation, wake up the 
              <b>altinst_rootvg</b> by issuing:
            <p> 
            <pre>
alt_disk_install -W hdisk2 hdisk3
</pre>
            5. Review your <b>df -k</b> output and compare the primary logical 
            volume sizing to their <b>/alt_inst</b> counterparts.
            <p> 6. If you are satisfied with the sizing reduction, change your 
              bootlist (bootlist <b>-m normal hdisk2 hdisk3</b>) and reboot.
            <p> <b>Network Installation Managment (NIM)</b>
            <p> I want to briefly discuss NIM and show how well it interfaces 
              with alternate disk installation. It can easily help you to manage 
              upgrades on a group of servers, thus saving you even more time.
            <p> <b>What Is NIM?</b>
            <p> Paraphrasing from the AIX Network Installation Management Guide 
              and Reference, "NIM is a base component of AIX and permits 
              and aids in the installation and maintenance of AIX, it's basic 
              operating system, and additional software and fixes that may be 
              supplied over the network. NIM provides for the customization of 
              machines both during and after installation. As a result, NIM has 
              eliminated the reliance of the systems administration staff on tapes 
              and CD-ROMs for software installation and maintenance."
            <p> In this case, you are using NIM to centrally manage a group of 
              standalone machines (NIM clients) from a centrally located network 
              attached to a NIM master. From the NIM master, you can manage operating 
              system installations, maintenance upgrades, <b>mksysb</b> images 
              for backup and recovery, installation of new servers (cloning), 
              and the re-installation of existing servers in case of a disaster.
            <p> There's a great deal of functionality provided by NIM. I 
              recommend reviewing the usage guide to see what NIM features could 
              benefit your environment. I also recommend a good Redbook from IBM, 
              <i>NIM: From A to Z in AIX 4.3</i> (SG24-5524-00), which was published 
              in February 2000.
            <p> I won't cover the specifics of setting up the NIM master 
              and the corresponding NIM client configurations; it is not an overly 
              complicated process. However, it will require someone with NIM-specific 
              knowledge to lay out the functional NIM environment. If you support 
              SP complexes, you have already had a fair amount of exposure to 
              NIM even though it is buried one layer below PSSP.
            <p> One key feature of NIM that will help manage a group of servers 
              concurrently is the Machine Group definition. Within NIM, you can 
              operate as easily on a single machine as you can a group of machines. 
              For instance, we have defined several machine groups within our 
              NIM master environment. These definitions allow us to operate on 
              a group of like servers concurrently. 
            <p> <b>How Does It Integrate with Alternate Disk Installation?</b>
            <p> NIM knows how to fully exploit Alternate Disk Installation. For 
              example, look at the initial clone and <b>update_all</b> operation. 
              Let's say you want to use NIM to extend the model (instead 
              of upgrading the maintenance level on a single server) and you want 
              to complete this operation on ten Lotus Notes servers that are similarly 
              configured and are defined in a Notes machine group within NIM. 
              From SMIT on the NIM master, issue the following fast path and you 
              will see this panel:
            <p> 
            <pre>
smitty nim_alt_clone 

Clone the rootvg to an Alternate Disk

Type or select values in entry fields.
Press Enter AFTER making all desired changes.
                                                   [Entry Fields]
* Target Machine / Group to Install                [NOTES]              +
* Target Disk(s) to install                        [hdisk2 hdisk3]
  Phase to execute                                 all                  +
  IMAGE_DATA resource                              []                   +/
    EXCLUDE_FILES resource                         []                   +/
     (leave blank to include all files in backup)
  
  BUNDLE to install                                []                   +
    -OR-
  Fileset(s) to install                            []
  
  FIX_BUNDLE to install                            []                   +
    -OR-
  FIXES to install                                 [update_all]
  
  LPP_SOURCE                                       [aix433_lppsource]   +
  (required if filesets, bundles or fixes used)
  
  installp Flags
    COMMIT software updates?                       yes                  +
    SAVE replaced files?                           no                   +
    AUTOMATICALLY install requisite software?      yes                  +
    EXTEND filesystems if space needed?            yes                  +
    OVERWRITE same or newer versions?              no                   +
    VERIFY install and check file sizes?           no                   +
  Customization SCRIPT resource                    []                   +/
  Set bootlist to boot from this disk
  on next reboot                                   yes                  +
  Reboot when complete?                            no                   +
  Verbose output?                                  no                   +
  Debug output?                                    no                   +
  Group controls (only valid for group targets):
    Number of concurrent operations                []                   #
    Time limit (hours)                             []                   #

F1=Help             F2=Refresh           F3=Cancel            F4=List
F5=Reset            F6=Command           F7=Edit              F8=Image
F9=Shell            F10=Exit             Enter=Do                    
</pre>
            In this example, you would cause every server defined in the Notes 
            Machine group to begin a process to clone itself from hdisk0/1 to 
            hdisk2/3. At the completion of the cloning operation, NIM would then 
            NFS-mount the <b>aix433_lppsource</b> resource (in this case, it's 
            the AIX 4.3.3 <b>lppsource</b> filesystem, which includes the 4.3.3.06 
            maintenance) and apply it to the newly cloned hdisk2/3 on each of 
            these servers. This also instructs NIM to change the bootlist on each 
            of these servers as a part of the operation but does not cause an 
            immediate reboot. I recommend, however, using NIM to schedule a reboot 
            of all these servers during the maintenance window.
            <p> All of this work, including the cloning and upgrading of the maintenance 
              level, can be completed during the day without affecting the running 
              application (e.g., Notes). For the previous support model, this 
              same upgrade would have taken about 2 hours per server plus reboot 
              time to complete during an application maintenance window, generally 
              in the middle of the night. If a single person worked to complete 
              this process, this could have taken about 25 hours spread across 
              multiple weekends to complete. With NIM and Alternate Disk Installation, 
              this upgrade outage can be reduced to the time to reboot these 10 
              servers concurrently (or about 30 minutes, in our case). Note that 
              your time may vary depending on speed of network, number of filesets 
              being updated, time to reboot, and problems encountered.
            <p> Figure 2 shows the process using NIM/Machine Groups and Alternate 
              Disk Installation. First, you instruct the NIM master to have each 
              of the servers in the defined machine group clone hdisk0/1 to hdisk2/3 
              (depicted in red). Then, NIM will NFS-mount the appropriate LPPSOURCE 
              filesystem containing the AIX 4.3.3.06 maintenance level and apply 
              that maintenance to the newly cloned drives (operation in green). 
              Again, this process happens concurrently on all servers in the defined 
              NIM machine group without affecting the running applications.
            <p> <b>Conclusion</b>
            <p> My team is in the process of rolling out this methodology change. 
              I think we can significantly reduce the amount of time spent in 
              support of our current AIX standalone infrastructure. I also think 
              Alternate Disk Installation and NIM, can help you better manage 
              your infrastructure and provide some consistency to your installation, 
              upgrade, maintenance, and build procedures. In conclusion, I hope 
              the above discussion will help you significantly reduce the amount 
              of off-hours time associated with maintenance or fileset upgrades 
              within AIX.
            <p> <i>Jeff Marsh is the Systems Advisor to the UNIX Server Team working 
              at American Century Investments, a premier investment manager serving 
              nearly two million individual and institutional investors. Jeff 
              can be contacted at: <b>jeffrey_marsh@americancentury.com</b>.</i>
          </table></table><br>&nbsp;<br>

<! -- End Content ------ >

<!/center>
<! -- End MASTER TABLE -- >

</body>



<! -- Begin Content ------ >
</html>
