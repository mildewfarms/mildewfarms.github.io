<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 4.0//EN">


<HTML>
<HEAD>
<TITLE>v10, i03: What to Do When the Server Doesn't Serve -- Duplicating Data</TITLE>
<LINK REL=StyleSheet HREF="../../resource/css/sacdrom.css" TYPE="text/css" TITLE="CSS1">
</HEAD>

<body bgcolor="#ffffff" text="#000000" link="#000000" alink="#669999" vlink="#333366" topmargin=0 leftmargin=0>

<! -- Begin MASTER TABLE -- >
<!center>
<table width=98% cellpadding=0 cellspacing=0 border=0 bgcolor="#ffffff">
  <tr>

<table cellpadding=5 cellspacing=0 border=0>
	<tr>

		<td><span class="navbarLink">Article</span></td>
		<td><a href="../../../../source/SA/2001/mar2001.tar"><b class=codeListing>mar2001.tar</b></a></td>

	</tr>
</table>


</tr>
<tr>
<! -- Begin Content ------ >
<td valign=top width=440 bgcolor="#ffffff">
<table width=100% cellpadding=15 cellspacing=0 border=0>
<tr>
          <td valign=top> 
            <! -- Insert Content ------ >
            <H1><img src="a3.gif" width="200" height="174" align="right">What 
              to Do When the Server Doesn't Serve -- Duplicating Data</h1>
            <p> <i>Brett Lymn</i>
            <p> In my previous article, (<i>Sys Admin</i>, February 2001) I talked 
              about providing file system failover using features of Sun's 
              cachefs implementation to provide a transparent serving of files 
              when the server is down. In this article, I will take a more traditional 
              approach to server failover and discuss duplicating data on multiple 
              servers and causing client machines to select another server if 
              the one that they are talking to stops responding.
            <p> The process by which a client automatically mounts file systems 
              from a server is called an automounter. An automounter is a daemon 
              that runs on the client machine that monitors a configured set of 
              directory paths. When an access is made to one of these monitored 
              paths, the daemon mounts the appropriate portion of the file system 
              from a remote server using NFS to make it appear as though the path 
              was always there. After a period of inactivity on the mounted path, 
              the daemon will unmount the path to prevent the system from accumulating 
              mounted file systems. On Sun systems, this is simply called the 
              automounter; for other systems, there is an open source equivalent 
              called <b>amd</b>. Both Sun's automounter and <b>amd</b> allow 
              for multiple servers to serve the same filesystem. On versions of 
              Solaris prior to 2.6, the binding of a client to a particular server 
              was resolved only at mount time. So, if the server from which your 
              client automounted a file system went down, too bad, you had to 
              reboot the client to force it to mount the file system from the 
              other server.
            <p> For <b>amd</b> and Sun's automounter on Solaris 2.6 and later, 
              the automounter daemon monitors the connection to the server. If 
              the connection to the server fails, the automounter automatically 
              tries to connect to the other listed servers so that the client 
              can continue working.
            <p> <b>Sun Automounter</b>
            <p> For Sun's automounter, two files are required to start the 
              automounter: one is called the direct map and the other is the indirect 
              map. The direct map may contain automounter configuration lines 
              but, in practice, this is discouraged because any changes to the 
              direct map require the automounter to be restarted before they take 
              effect. Normally, the automounter direct map will contain names 
              of files. These files are called indirect maps and are commonly 
              used to hold the automounter configuration because the indirect 
              maps can be updated and take effect without restarting the automounter.
            <p> The direct map is normally a file called <b>/etc/auto_master</b> 
              and contains lines like the following:
            <p> 
            <pre>
/file  /usr/automount/file_map
</pre>
            that specify the locations of the indirect maps. In the example above, 
            the automounted directory <b>/file</b> is controlled by the indirect 
            map <b>/usr/automount/file_map</b>. Note that you may store the indirect 
            maps anywhere that is accessible to the automounter daemon. My preference 
            is to put all of the indirect maps into a single directory, which 
            I typically share out to all the clients. As mentioned before, you 
            may put the contents of an indirect map into the direct map, but doing 
            so will create headaches later if you change your indirect maps. For 
            a typical automounted directory, the indirect map contains lines of 
            the form:
            <p> 
            <pre>
tree  server1:/share/file/tree
</pre>
            which tell the automounter that if a process accesses the directory 
            <b>/file/tree</b>, it should mount the file system <b>/share/file/tree</b> 
            from the machine server1 as <b>/file/tree</b>. The above example gives 
            no failover protection. If server1 goes down, then the client will 
            hang. The automounter syntax for specifying failover servers is a 
            space-separated list of file server names and directories in the automounter 
            entry, like this:
            <p> 
            <pre>
tree    server1:/share/file/tree server2:/share/file/tree
</pre>
            In this case (for automounters running on Solaris 2.6 and later), 
            if server1 goes down, then the automounter will automatically change 
            over to server2 for file serving. As noted earlier, automounters running 
            on versions of Solaris prior to 2.6 will need to have the machine 
            rebooted to change file servers.
            <p> <b>amd</b>
            <p><b> amd</b> may already be installed on your system. There are 
              quite a few vendors that bundle <b>amd</b> as part of the operating 
              system or as a package on the distributions CD. Red Hat Linux, for 
              example, has <b>amd</b> as a package on the latest distribution 
              CDs. Check your man pages to see if it exists. If it does not, then 
              check your vendor site for a downloadable package.
            <p> For <b>amd</b>, the concepts are like Sun's automounter, 
              but the syntax for the <b>amd</b> maps is different. <b>amd</b> 
              does not have a direct map in the same manner as Sun does. The mapping 
              of root directories to maps is either done on the command line in 
              simple cases, or by creating an <b>amd.conf</b> file. To perform 
              the same function as the <b>/etc/auto_master</b> file shown in the 
              previous example, we would add the following to the end of the <b>amd</b> 
              command line:
            <p> 
            <pre>
/file  /etc/amd/file_map
</pre>
            As with the Sun automounter, the <b>amd</b> map files should be put 
            into a single directory to ease the task of administering the <b>amd</b> 
            files. The <b>amd</b> syntax for the <b>file_map</b> file would be 
            as follows:
            <p> 
            <pre>
tree      -opts:=ro;type:=nfs;rfs:=/share/file/tree rhost:=server1
</pre>
            This tells <b>amd</b> to mount the shared file system <b>/share/file/tree</b> 
            from server1 as the tree subdirectory of the <b>/file</b> top-level 
            directory. The file system will be mounted read-only.
            <p> Again, this does not provide any failover protection. If the machine 
              server1 goes down, then the client will hang until server1 comes 
              back on line. As with Sun's automounter, <b>amd</b> can mount 
              a file system from multiple servers and will monitor the servers 
              to detect when one has gone down. To specify redundant file servers 
              in <b>amd</b>, more rhost parameters must be added to the entry. 
              So, to have two servers, server1 and server2, serving a replicated 
              file system to the clients, the <b>amd</b> map entry looks like:
            <p> 
            <pre>
tree      -opts:=ro,soft,intr;type:=nfs;rfs:=/share/file/tree rhost:=server1 rhost:=server2
</pre>
            Now, if server1 goes down when the file system is not mounted, the 
            client will automatically switch to server2 for the serving of the 
            files. Unfortunately, unlike Sun's automounter, if a process 
            is using the mount when the server goes down, that particular process 
            will hang. Subsequent processes that access the file tree will not 
            hang because <b>amd</b> will failover to the server that is still 
            up, but you will be left with a hung process. By using the <b>intr</b> 
            flag in the mount options, we can allow hung processes to be killed, 
            and the <b>soft</b> option will allow file operations to fail on a 
            server error rather than hang. Because of this behavior, any long-running 
            processes accessing the file system when the server fails will have 
            to be restarted. This can be done with a simple script that monitors 
            the server availability and performs a restart on critical processes.
            <p> I noticed another quirk with <b>amd</b> (using <b>am-utils</b> 
              version 6.0.1s11 on a NetBSD 1.5 machine). When using multiple servers 
              for a mount, once <b>amd</b> has marked a server as down, it will 
              not use that server to mount from, even after the server has come 
              back up. Thus, you should not rely on <b>amd</b> to load balance 
              your NFS traffic, because all the clients will automatically migrate 
              to your most reliable server.
            <p> <b>Synchronizing the Servers</b>
            <p> To make failover work, multiple servers must contain complete 
              copies of the exported file systems. One server is designated as 
              the "master" repository for the file system, and a periodic 
              job is run to update the files on the slave servers with any changes 
              using something like <b>rdist</b>, <b>rsync</b>, or <b>unison</b>.
            <p> The tool <b>rdist</b> normally comes standard on UNIX systems 
              and is intended for updating file trees from a master tree. The 
              command for performing the update:
            <p> 
            <pre>
rdist -R -c /share/file/tree server2
</pre>
            will update the directory tree <b>/file/tree</b> on server2 from the 
            server on which the <b>rdist</b> command was run. Though this is quite 
            straightforward, there are some problems using <b>rdist</b>. In the 
            past, <b>rdist</b> has been known for some easily exploitable security 
            holes, and since <b>rdist</b> was, by default, a setuid program, it 
            has been a target for intruders to gain root access. For this reason, 
            <b>rdist</b> may have been removed or disabled. Another problem with 
            <b>rdist</b> is that it requires equivalent access to the remote machine, 
            which means that the user running <b>rdist</b> on the master has access 
            to the other machines without requiring a password. This may cause 
            security problems in some environments.
            <p> Another method of syncing the file trees is to use some free software 
              called <b>rsync</b>. (See the Resources section for information 
              on obtaining <b>rsync</b> and other tools mentioned here.) The <b>rsync</b> 
              tool was written by Andrew Tridgell (the original author of Samba) 
              and is designed to efficiently copy files from one server to another. 
              <b>rsync</b> is efficient because it only transfers the differences 
              between the files on the master and the files on the slave machine, 
              which dramatically reduces the amount of data pushed over the network. 
              Not only does <b>rsync</b> make efficient use of network bandwidth, 
              but the transport method by which <b>rsync</b> talks to the remote 
              machine can be manually selected. By default, <b>rsync</b> will 
              use <b>rsh</b> to talk to the remote machine, but you can change 
              this to use something like <b>ssh</b> or <b>openssh</b>, which will 
              not only allow stronger verification of the remote machine's 
              credentials but also allow the traffic between the two machines 
              to be encrypted. To perform the same function as shown in the <b>rdist</b> 
              command above, but using <b>ssh</b> as our transport mechanism, 
              the <b>rsync</b> command looks like:
            <p> 
            <pre>
rsync -va --rsh /usr/local/bin/ssh --delete /share/file/tree/ server2:/share/file/tree/
</pre>
            One note of warning with <b>rsync</b> -- the trailing slashes 
            on the directory paths in the above example are important. If these 
            slashes are not there, <b>rsync</b> may eat your target directory 
            contents. So, it is wise to try out the <b>rsync</b> command on a 
            backed up sample directory to ensure you do not accidentally destroy 
            something important.
            <p> Another problem with <b>rdist</b> and <b>rsync</b> is that both 
              assume the master source is on a single machine, which limits where 
              the updates can be performed. If files on the slave servers are 
              updated without updating the master, then updates on the slave will 
              be overwritten the next time the master distributes files to the 
              slave servers. To overcome this, we can either strictly enforce 
              the rule that only the master server files are updated, or we can 
              use a program such as <b>unison</b>, which allows files to be updated 
              on multiple servers and can synchronize the updated files between 
              the servers automatically.
            <p> <b>unison</b> is currently under active development and is considered 
              beta software by the authors. Despite the beta status, the capabilities 
              that <b>unison</b> provides sound very promising in cases where 
              there is either the lack of discipline or lack of will to enforce 
              the rule of only updating one master server. <b>unison</b> will 
              detect conflicting changes between two file trees so that the administrator 
              can decide what to do about the conflict. If the file on one of 
              the machines has been modified but is unchanged on the remote machine, 
              then the two files are simply synchronized. By default, <b>unison</b> 
              uses <b>ssh</b> as its transport, so data is not sent over the wire 
              in the clear. The relative newness of <b>unison</b> does make selecting 
              it over <b>rdist</b> or <b>rsync</b> a more risky proposition, but 
              if you are willing to help debug the code or put up with some teething 
              problems, then <b>unison</b> may be a good choice for your site.
            <p> Although the approach of having multiple servers is simple, it 
              also has some disadvantages. The method can be used only for file 
              systems that will be mounted read-only on the clients. Also, any 
              updates to the file tree must be carried out only on the master 
              machine -- unless a program like <b>unison</b> is used to update 
              the servers. Finally, there is a small risk that the master server 
              will fail just when it is performing the update. If you have multiple 
              slave machines, you may encounter a situation in which one slave 
              has a truncated version of a file (because the server went down 
              during the copy) or some of the slave servers have an out-of-date 
              version of some files (because the master went down part way through 
              the update). If the slave servers are updated frequently and the 
              replicated file system is small, the chance of inconsistencies arising 
              is remote. However, these inconsistencies may cause much confusion 
              if they occur. You must also take into account that you are replicating 
              all the resources required to support the duplicated file systems. 
              This includes all machines and disk space, adding to the cost of 
              providing the failover capability. Also, there are some bursts of 
              network traffic involved in the synchronization process when the 
              servers replicate data between themselves, which may impact the 
              client network. To address this, you may want to set up a private 
              network between the servers rather than causing the replication 
              traffic to go across the client network.
            <p> <b>Conclusion</b>
            <p> That's it for this time. In my next article, I will look 
              at a more adventurous way of providing failover using a file system 
              specifically designed to handle network disconnections between the 
              client and the server.
            <p> <b>Resources</b>
            <p><b> rsync</b> information can be found at: <b>http://www.samba.org/</b>
            <p> 
            <p> <b>ssh</b> information can be found at: <b>http://www.cs.hut.fi/ssh</b>
            <p> 
            <p> <b>OpenSSH</b> information can be found at: <b>http://www.openssh.com/</b>
            <p> 
            <p> <b>unison</b> information can be found at: <b>http://www.utu.net/unison/unison.html</b>
            <p> <i>Brett Lymn works for a global company helping to manage a bunch 
              of UNIX machines. He spends entirely too much time fiddling with 
              computers but cannot help himself.</i> 
          </table></table><br>&nbsp;<br>

<! -- End Content ------ >

<!/center>
<! -- End MASTER TABLE -- >

</body>



<! -- Begin Content ------ >
</html>
