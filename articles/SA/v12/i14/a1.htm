<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 4.0//EN">


<HTML>
<HEAD>
<TITLE>v12, i14: Capacity Planning for the Masses -- Using the SE Toolkit and Orca</TITLE>
<LINK REL=StyleSheet HREF="../../resource/css/sacdrom.css" TYPE="text/css" TITLE="CSS1">
</HEAD>

<body bgcolor="#ffffff" text="#000000" link="#000000" alink="#669999" vlink="#333366" topmargin=0 leftmargin=0>

<! -- Begin MASTER TABLE -- >
<!center>
<table width=98% cellpadding=0 cellspacing=0 border=0 bgcolor="#ffffff">
  <tr>

<table cellpadding=5 cellspacing=0 border=0>
	<tr>

		<td><span class="navbarLink">Article</span></td>
		<td><span class="navbarLink"><a href="a1_f1.htm">Figure 1</a></span></td>
		<td><span class="navbarLink"><a href="a1_f2.htm">Figure 2</a></span></td>
		<td><span class="navbarLink"><a href="a1_f3.htm">Figure 3</a></span></td>
		<td><span class="navbarLink"><a href="a1_f4.htm">Figure 4</a></span></td>
	</tr>
	<tr>
		<td><span class="navbarLink"><a href="a1_f5.htm">Figure 5</a></span></td>
		<td><span class="navbarLink"><a href="a1_f6.htm">Figure 6</a></span></td>
		<td><span class="navbarLink"><a href="a1_f7.htm">Figure 7</a></span></td>
		<td><span class="navbarLink"><a href="a1_f8.htm">Figure 8</a></span></td>
		<td><span class="navbarLink"><a href="a1_f9.htm">Figure 9</a></span></td>
	</tr>
	<tr>
		<td><span class="navbarLink"><a href="a1_s1.htm">Sidebar</a></span></td>
		<td><a href="../../../../source/SA/2003/dec2003.tar"><b class=codeListing>dec2003.tar</b></a></td>

	</tr>
</table>


</tr>
<tr>
<! -- Begin Content ------ >
    <td valign=top width=527 bgcolor="#ffffff"> 
      <table width=100% cellpadding=15 cellspacing=0 border=0>
<tr>
          <td valign=top> 
            <! -- Insert Content ------ >
            <h1>Capacity Planning for the Masses -- Using the SE Toolkit and Orca 
            </h1>
            <p> Justin Buhler and Adrian Cockcroft</p>
            <p> </p>
            <p> </p>
            <p>Capacity planning is often overlooked by systems administrators 
              until they need to justify additional hardware resources, and that's 
              the wrong time to start. In this article, Adrian Cockcroft (author 
              of the <i>Sun Performance and Tuning</i> book) and I intend to show 
              that starting a capacity plan within your Solaris environment is 
              not as difficult as it sounds. We will introduce some key principles 
              for beginning your capacity planning and will show how we applied 
              those principles and the tools presented in this article during 
              the Winter 2002 Olympics. </p>
            <p> <b>Capacity Planning Principles</b>
            <p> The fundamental principle behind any capacity plan begins with 
              establishing an accurate baseline of your application's behavior 
              over a period of time that can be easily interpreted. The following 
              is a breakdown of this idea with the tools we use to achieve the 
              fundamental principle.
            <p> 
            <p> 1. A capacity plan starts with accuracy, so use the right tools.
            <p> A starting point is to capture accurate system behavior information 
              by using microstate accounting tools. This means your tools can 
              harvest the performance data from the system without becoming one 
              of the performance problems that needs to be investigated. The SE 
              Toolkit developed by Rich Pettit and Adrian Cockcroft is able to 
              accomplish this; not only are the access methods very lightweight, 
              but the interpreter itself is written such that execution speed 
              is very fast. SE Toolkit is available free from:
            <p> 
            <pre>
http://www.setoolkit.com
</pre>
            2. To make your system easy to understand, break down the system's 
            activity.
            <p> By breaking down the system into workload sets, you can intuitively 
              analyze the machine in terms of categories or "slices of a pie". 
              This categorizing or slicing is called workload analysis. Because 
              every system runs a mixture of workloads, you just need to pick 
              out the relevant processes and then aggregate the results. The rest 
              is considered overhead of unplanned activity.
            <p> The workollator.se class, which is included in the SE Toolkit 
              3.3, was written during the Winter 2002 Olympics, to ease the collection 
              of accurate data about a defined workload set in a single consistent 
              daily log. This allows you to see what each process or workload 
              is doing during the given period of time.
            <p> 3. "A picture is worth a thousand words", so make the raw data 
              intuitive to understand.
            <p> You need to be able to make sense of the data that you are collecting 
              about your workloads. Looking at thousands of lines of performance 
              data is not intuitive, even for gurus. Graphing your performance 
              data gives you the best visual representation of all of those numbers 
              and is much easier to decipher. One tool that enables this visualization 
              of your performance data is Orca, which is available from:
            <p> 
            <pre>
http://www.orcaware.com
</pre>
            The Orca utility is written by Blair Zajac and currently is free. 
            Orca uses the RRD for plots by Tobias Oetiker, available from:
            <p> 
            <pre>
http://people.ee.ethz.ch/~oetiker/webtools/rrdtool/
</pre>
            <p> and allows long-term data views ranging from hours to years. Orca 
              is also extended to use the SE Toolkit, and a new configuration 
              file described below adds workollator.se workload data parsing and 
              a set of standard plots.
            <p> 
            <p> Now, let's apply these principles and tools to a real-world example. 
              We used these tools to determine the capacity for the Winter 2002 
              Olympics. To begin, we must clarify the location and the purpose 
              of each of the tools. They are deployed in the following manner:
            <p> 
            <p> 
            <ul>
              <li> SE Toolkit and workollator.se are installed and configured 
                to run on the Solaris systems to be monitored. 
              <li> Orca, orca_gather.pl, and workload_extract.sh are installed 
                on the Solaris server, where information is to be centrally collected 
                and processed. 
              <li> The Web server is to be installed on the same server where 
                the Orca html output is stored. It is only used to serve html, 
                and no CGI configuration is needed.
            </ul>
            <p> Next, we can install the tools on the server to be monitored and 
              start harvesting our application's stats.
            <p> Download and install the SE Toolkit 3.3 from <b>http://www.setoolkit.com</b>. 
              We will next configure a shell script to capture your system's workloads 
              using workorallator.se on the host to be monitored. This script 
              uses environment variables that identify the processes, which make 
              the different workloads on the system. The environment variables 
              are:
            <p> 
            <p> <b>PW_CMD_WK#</b> -- Filter based on the command name.
            <p> <b>PW_ARGS_WK#</b> -- Filter based on the argument strings.
            <p> <b>PW_USER_WK#</b> -- Filter based on the user name.
            <p> 
            <p> Listing 1 shows an actual example from SLC Sun servers to capture 
              the workload information from the Winter 2002 Olympic Games. Listings 
              for this article are available from the <i>Sys Admin</i> Web site 
              at: <b>http://www.sysadminmag.com</b>.
            <p> Note that the PW_CMD_3 and PW_USER_3 on lines 5 and 6 have the 
              same workload number of _3. This is because we can stack variables 
              and then filter. We are filtering all the Java processes running 
              as the cis user. Also, the 300 after the workollator.se on line 
              14 represents the number of seconds after which the process will 
              wake up and capture the workload data in a daily log file, located 
              in the directory as defined by the OUTDIR variable.
            <p> An example of the log file created on the system by the workollator.se 
              configuration is shown in Figure 1. The file is created daily in 
              the directory /opt/orca/workload/ with the name of iso-cissvr-001-2002-02-19.
            <p> <b>Collecting Data Centrally Using rsync and SSH</b>
            <p> The workload data from the servers must be collected centrally 
              on to the Orca server for processing. In Salt Lake, we used a simple 
              Perl script using rsync (<b>http://www.samba.org/rsync</b>) and 
              SSH to read from a file the IP addresses and hostnames of all the 
              servers from which data needed to be collected. The SSH account 
              that was used to authenticate needed only read access to the workollator 
              logs in the directory as defined in the OUTDIR variable in our cis_workollator.sh 
              script (see Listing 2).
            <p> <b>Installing Orca</b>
            <p> The next step is to install Orca on a Web server machine. Orca 
              provides an excellent "Orca installation and configuration guide", 
              located in the contents of the package, which can be downloaded 
              from:
            <p> 
            <pre>
http://www.orcaware.com/orca
</pre>
            Orca needs only to know where the HTML pages are to be stored and 
            the location of your Web server access log. This information is only 
            used for the initial installation and can be changed in an Orca configuration 
            file. The version we are using for our installation is orca-0.27b3.tar.gz.
            <p> <b>Introduction to Orca and RRD</b>
            <p> Orca is a toolkit that will graph arbitrary data into HTML documents 
              using PNG or GIF graphics generated from an RRD (Round Robin Database). 
              RRD is the datastore, or database, that is used to store data in 
              units. RRD will generate time-defined graphs of the data stored 
              within the given RRD.
            <p> Orca is managed and configured from a single configuration file, 
              called orcallator.cfg (see Figure 2). The configuration file is 
              passed to the Orca application, which provides site-specific information, 
              such as where to go to find the files, the name of the files, and 
              what type of graphs to plot. The command to run after you have configured 
              Orca is normally:
            <p> 
            <pre>
#&gt;./orca -v -once  ../lib/orcallator.cfg
</pre>
            Figure 3 shows an example of the plot that is defined to generate 
            the CPU usage of a process.
            <p> We have provided a replacement for the orcallator.cfg, called 
              workollator.cfg, which should be passed to the Orca binary for the 
              configuration information about how to generate the RRDs and graphs 
              using the workload files. You must move the workollator.cfg file 
              to the same location as the orcallator.cfg, which is usually /usr/local/lib. 
              Next, you must modify the workollator.cfg and give it the relevant 
              parameters specific to your site.
            <p> The following parameters tell Orca where to find or place RRDs 
              and HTML files, as well as Orca's installation directory. Set these 
              to the proper places. See Figure 4:
            <p> 
            <p> <b>rrd_dir</b> -- Location in which RRD databases should be created 
              or already exist.
            <p> <b>html_dir</b> -- Location to write or update the html files.
            <p> <b>base_dir</b> -- Location of the Orca installation.
            <p> 
            <p> The regular expression shown in Figure 5 tells Orca where to find 
              the files and the name of those files to be loaded into RRDs. Note 
              that there is a bug in the current distribution of the workollator 
              script, so you need to remove the following line:
            <p> 
            <pre>
&lt;a href="http://www.sun.com"&gt;
</pre>
            <b>Processing the Workload Data</b>
            <p> Once all of the workload data has been transferred from the Solaris 
              servers to the Orca server, we must parse each of the daily workload 
              logs into individual files per workload. The workload_extrctor.sh 
              script (Listing 3) performs this task. Run this script in the directory 
              containing all of the workload files. The result should be that 
              additional directories are created (one for each hosts workload) 
              under the OUTPUTDIR directory, which each contains log files for 
              each day.
            <p> Examples of the workload directories created on the system by 
              the workload_extractor.sh configuration are shown below. A daily 
              log file is created under each of the host-workload directories 
              under /opt/orca/workload/, with the name of workol-2002-02-19.
            <p> 
            <pre>
#&gt; ls /opt/orca/var/workload
iso-cissvr-001____
iso-cissvr-001___bb
iso-cissvr-001___cis
iso-cissvr-001___root
iso-cissvr-001__tripwire_
iso-cissvr-001_httpd___
iso-cissvr-001_java___
iso-cissvr-001_java__cis
iso-cissvr-001_se.sparc___
iso-cissvr-001_Total___

#&gt; ls /opt/orca/var/workload/iso-cissvr-001_java__cis
workol-2002-02-17
workol-2002-02-18
workol-2002-02-19
workol-2002-02-20
workol-2002-02-21
workol-2002-02-22
</pre>
            The format of each daily file should contain only the workload-specific 
            data (see Figure 6).
            <p> You should now be able to run the Orca application and generate 
              your data. The <b>-v</b> flag will enable verbose logging on all 
              of the processing, which is useful when running Orca, especially 
              if it is the first time to run Orca:
            <p> 
            <pre>
./ORCA -v -once ../lib/workollator.cfg
</pre>
            After the Orca application has completed and has returned you to the 
            command prompt, navigate to the URL, which points to the Orca HTML 
            files that have been generated. Once you navigate to the URL specified 
            in your Web server configuration, you should see the index page shown 
            in Figure 7. By clicking on the CPU usage link at the bottom of the 
            index page, you should get the total CPU usage for each process as 
            shown in Figure 8.
            <p> An example of a process with high chld% percentages is our system 
              monitoring package, which executes a lot of shell scripts. See Figure 
              9.
            <p> Before we get into the actual planning model and examples, you'll 
              need to be familiar with the various performance data values and 
              how and why they are important. For a quick introduction, please 
              see the "Performance Data Values" sidebar.
            <p> <b>Workload Capacity Planning Model and Example</b>
            <p> Now that we have shown how to get the workload data into a nice 
              format, let's finish up with the formula that can be used to scale 
              the capacity of a system.
            <p> The formula for workload-based capacity planning should be based 
              on the workollator data, because this shows how much of the CPU 
              is being used by the workload you are interested in rather than 
              a system total. The system total can be considered as overhead or 
              possible bottlenecks to the workload being scaled. Note that the 
              workload shows what the workload uses in (%usr time) and what the 
              system does to service the workload in (%sys time).
            <p> The formula used in the workload-based capacity planning model 
              to scale the workload capacity is:
            <p> 
            <p> Total Sizing = Overhead + (Workload * Factor)
            <p> 
            <p> Overhead is everything else that is not included in the workload 
              being modeled or Overhead = (Total - Workload). Factor is how much 
              the workload has changed by or scale.
            <p> Here is an example of HTTP Server Single Workload CPU Usage:
            <p> 
            <p> HTTP Web Server Workload is using 15% (10 %usr + 5 %sys)<br>
              OVERHEAD is 5% total usage<br>
              Growth Factor is 5<br>
              Total CPU Usage 80% = 5% + (15% * 5)
            <p> 
            <p> The estimated total CPU usage if our workload grew by 5 times 
              would be approximately 80%.
            <p> Here is an example of a Mixed Workload Oracle and HTTP Web server:
            <p> 
            <p> ORACLE Workload is using 45% (35 %usr + 10 %sys)<br>
              HTTP Web Server Workload is using 15% (10 %usr + 5 %sys)<br>
              OVERHEAD is 15% total usage<br>
              Total Usage = 75%<br>
              Growth Factor for BOTH is 2<br>
              Total CPU usage is 135% = 15% + (15% * 2) + (45% * 2)
            <p> 
            <p> Remember that if you are using a multithreaded application, you 
              can think of 100% per CPU. For the workload above, we would be running 
              a workload that demands 1.35 CPUs; or if this were a single CPU 
              server, you would need to look at purchasing some additional hardware.
            <p> The more traditional method for sizing is (Total Sizing = Total 
              * Factor). This is generally a less accurate formula because it 
              assumes that all resources on the system scale with the same factor, 
              which is not generally the case.
            <p> <b>Conclusions</b>
            <p> By using the SE Toolkit and Orca, you will quickly be able to 
              establish a visual representation of your Sun servers' behavior 
              and the applications that are installed. This will enable you to 
              see and communicate a clearer and more accurate picture regarding 
              the resource usage of all the applications. Finally, coupled with 
              some general points, you should be able to develop a high-level 
              understanding of the capacity of your system based on the current 
              workloads configured on your system. With a few workload-based formulas, 
              you can begin your capacity planning.
            <p> <b>Acknowledgements</b>
            <p> I extend special thanks to Adrian, who is a great guy to work 
              with and truly an expert in the field of capacity planning and performance 
              analysis. Thanks also to my wife and daughter who show continuous 
              support through their patience.
            <p> <i>Justin Buhler is currently Senior UNIX Administrator, Schlumberger, 
              Major Event's division for the Athens 2004 Summer Olympics. His 
              previous projects include Salt Lake 2002 Winter Olympics. He can 
              be reached at: <b>jpbuhler@athens2004.com</b>.</i>
            <p> <i>Adrian Cockroft is Chief Architect for High Performance Technical 
              Computing at Sun. The author of many books regarding performance 
              and tuning and capacity planning, most notably </i>Sun Performance 
              and Tuning: SPARC and Solaris<i>, published by Sun Microsystems 
              Press/PTR Prentice Hall. Adrian is also co-author of the </i>SE 
              Toolkit<i>.</i>
          </table></table>&nbsp;

<! -- End Content ------ >

<!/center>
<! -- End MASTER TABLE -- >

</body>



<! -- Begin Content ------ >
</html>
