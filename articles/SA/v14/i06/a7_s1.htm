<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 4.0//EN">


<HTML>
<HEAD>
<TITLE>v14, i06: Testing the Reverse Options</TITLE>
<LINK REL=StyleSheet HREF="../../resource/css/sacdrom.css" TYPE="text/css" TITLE="CSS1">
</HEAD>

<body bgcolor="#ffffff" text="#000000" link="#000000" alink="#669999" vlink="#333366" topmargin=0 leftmargin=0>

<! -- Begin MASTER TABLE -- >
<!center>
<table width=98% cellpadding=0 cellspacing=0 border=0 bgcolor="#ffffff">
  <tr>

<table cellpadding=5 cellspacing=0 border=0>
	<tr>

		<td><span class="navbarLink"><a href="a7.htm">Article</a></span></td>
		<td><span class="navbarLink">Sidebar </span></td>
		<td><span class="navbarLink"><a href="a7_t1.htm">Table 1</a></span></td>
		<td><a href="../../../../source/SA/2005/jun2005.tar"><b class=codeListing>jun2005.tar</b></a></td>

	</tr>
</table>


</tr>
<tr>
<! -- Begin Content ------ >
    <td valign=top width=527 bgcolor="#ffffff"> 
      <table width=100% cellpadding=15 cellspacing=0 border=0>
<tr>
          <td valign=top> 
            <! -- Insert Content ------ >
            <h2><B>Testing the Reverse Options</B></h2>
            <P> Out of curiosity, we compared the performance of the various techniques 
              used to reverse a file. The results were interesting and sometimes 
              unexpected.
            <P> We created seven data files. The file names and the number of 
              lines in each file were as follows:
            <P> 
            <P> 1000000 enormous<br>
              100000 huge<br>
              10000 large<br>
              1000 medium<br>
              100 small<br>
              10 tiny<br>
              1 trivial
            <P> 
            <P> The data files contained the sentence "A rat in the house may 
              eat the ice cream." repeated multiple times, once per line, along 
              with a line number at the beginning of each line.
            <P> We created a test script for each of the different ways to reverse 
              a file. For example, the following script, called test_awk, tested 
              the <B>awk</B> commmand:
            <P> 
            <pre>
#!/bin/ksh

cd $(dirname $0)/../files
for file in $(ls -r)
do
   time awk '{ a[NR]=$0 } END { for(i=NR; i; --i) print a[i] } ' \
     $file &gt; /dev/null
done
</pre>
            The test scripts and the scripts used to create the data files are 
            located in the tarball (see <B>http://www.sysadminmag.com/code/</B>).
            <P> We executed the scripts on Solaris 7 running on an Intel AD450NX 
              server with 4 x 500 MHz processors, 2 GB memory, and minimal system 
              activity. Table 1 shows the average "real time" values reported 
              by the <B>time</B> command for each script tested against the seven 
              data files.
            <P> The script using shell arrays failed on the large, huge, and enormous 
              files with the error "subscript out of range". We tired of waiting 
              for the sed scripts to complete with the huge and enormous files. 
              Similarly, the vi script seemed destined to run forever while processing 
              the enormous file.
            <P> Of the scripts that could handle all seven data files, <B>tail</B> 
              was by far the fastest, processing the enormous file in 2.6 seconds. 
              Perl handled the enormous file in 5.2 seconds; <B>tac</B> took 18 
              seconds; the nl technique finished in 43 seconds; and our cool shell 
              script that uses dynamic variables finally finished processing the 
              enormous file after 223 seconds. In this case, cool doesn't equate 
              to fast.</table></table>&nbsp;

<! -- End Content ------ >

<!/center>
<! -- End MASTER TABLE -- >

</body>



<! -- Begin Content ------ >
</html>
