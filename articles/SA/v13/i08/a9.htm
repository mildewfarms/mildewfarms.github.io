<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 4.0//EN">


<HTML>
<HEAD>
<TITLE>v13, i08: Questions and Answers</TITLE>
<LINK REL=StyleSheet HREF="../../resource/css/sacdrom.css" TYPE="text/css" TITLE="CSS1">
</HEAD>

<body bgcolor="#ffffff" text="#000000" link="#000000" alink="#669999" vlink="#333366" topmargin=0 leftmargin=0>
<! -- Begin MASTER TABLE -- >
<!center>
<table width=98% cellpadding=0 cellspacing=0 border=0 bgcolor="#ffffff">
  <tr>

<table cellpadding=5 cellspacing=0 border=0>
	<tr>

		<td><span class="navbarLink">Article</span></td>
		<td><a href="../../../../source/SA/2004/aug2004.tar"><b class=codeListing>aug2004.tar</b></a></td>

	</tr>
</table>


</tr>
<tr>
<! -- Begin Content ------ >
    <td valign=top width=527 bgcolor="#ffffff"> 
      <table width=100% cellpadding=15 cellspacing=0 border=0>
<tr>
          <td valign=top> 
            <! -- Insert Content ------ >
            <h1><I><img src="../../resource/1_questions.gif" width="245" height="130" align="right">Questions 
              and Answers</i> </h1>
            <p><I>Amy Rich</i> </p>
            <p> <b><font size="+2">Q</font></b> I'm migrating from Solaris 8 to 
              Solaris 9. I use JumpStart to install all of our machines with 10MB 
              of space for the replica databases. I kept the same configuration 
              when moving to Solaris 9, and it told me that there was not enough 
              room for the state databases. Obviously things have changed, so 
              I'm wondering how much space I should be allocating for that slice 
              now. 
            <P> <b><font size="+2">A </font></b> With the version of Solaris Volume 
              Manager (called SDS in older releases), Sun recommends 100MB for 
              the slices containing the replicas. In Solaris 8, each replica occupied 
              1034 disk blocks of the partition. With the new version of SVM, 
              the default replica size is 8192 blocks, eight times the size of 
              those in Solaris 8. If you are upgrading to SVM from SDS, be sure 
              to increase the replica slice size. If you keep the slice size the 
              same and then remove a default-sized SDS replica and add a new SVM 
              one, you'll likely overwrite the blocks of the filesystem located 
              after your replica slice. You can specify the size of a replica 
              by setting a length when invoking metadb: 
            <P> 
            <pre>
metadb -l length_in_blocks
</pre> <b><font size="+2">Q</font></b> Our sendmail 8.12.11 server 
            handles mail for a domain that belongs to someone else. If this user's 
            machine is up, he wants all mail delivered to it. If his machine is 
            down, he wants all of the mail for his domain delivered to a username 
            on a different machine. Can you provide a custom ruleset that would 
            do what he's after?
            <P> <b><font size="+2">A </font></b> Let's say your user's domain 
              is client.domain, his machine is host.client.domain, and this other 
              email address is user@other.domain. You can create a mailertable 
              entry that will deliver his mail as desired.
            <P> First, add in the mailertable feature to the mc file with the 
              following and generate a new cf file:
            <P> 
            <pre>
FEATURE('mailertable')dnl
</pre>
            This will default to using a hash map for the mailertable file. If 
            you want to use a different kind of map, say dbm, specify this line 
            as:
            <P> 
            <pre>
FEATURE('mailertable', 'dbm -o /etc/mail/mailertable')dnl
</pre>
            Second, put the following line into /etc/mail/mailertable (depending 
            on your OS or any local customizations, this file may be called something 
            else):
            <P> 
            <pre>
client.domain   esmtp:[host.client.domain]:user@other.domain
</pre>
            The brackets around the machine name ensure that no MX lookups will 
            be done on the host, in case mail for that machine is usually handled 
            by another server. If MX lookups are desired, just remove the brackets.
            <P> Change directory to the location of the mailertable file and build 
              the mailertable map with the following commands (specifying the 
              correct map type for your installation):
            <P> 
            <pre>
makemap hash mailertable &lt; mailertable
</pre>
            You should now have a file called <B>/etc/mail/mailertable.db</B>. 
            Move your new cf file into place and send a HUP signal to sendmail.
            <P> <b><font size="+2">Q</font></b> We have a UDP application that 
              a consultant has written for us that's spawned from inetd. The application 
              isn't working quite right, and we're looking for some way to connect 
              to the daemon directly and interact with it for debugging purposes. 
              If this were a TCP application, I could just use <B>telnet</B>, 
              but, as far as I know, there's no way to use <B>telnet</B> with 
              UDP applications. Is there a switch to <B>telnet</B> or another 
              tool that would work?
            <P> <b><font size="+2">A </font></b> Telnet can only do TCP connections, 
              but you can use a program called <B>netcat</B> (<B>ftp://coast.cs.purdue.edu/pub/tools/unix/netutils/netcat/</B>) 
              to form the same kind of interactive connection with your UDP application. 
              <B>Netcat</B> is an invaluable debugging tool for UDP and TCP alike. 
              Instead of using <B>telnet</B> to debug your TCP applications, you 
              might consider switching to <B>netcat</B>. Even for TCP applications, 
              <B>netcat</B> has a few advantages. To quote from the README distributed 
              with the code:
            <P> Telnet has the "standard input EOF" problem, so one must introduce 
              calculated delays in driving scripts to allow network output to 
              finish. This is the main reason netcat stays running until the *network* 
              side closes. Telnet also will not transfer arbitrary binary data, 
              because certain characters are interpreted as telnet options and 
              are thus removed from the data stream. Telnet also emits some of 
              its diagnostic messages to standard output, where netcat keeps such 
              things religiously separated from its *output* and will never modify 
              any of the real data in transit unless you *really* want it to. 
              And of course telnet is incapable of listening for inbound connections, 
              or using UDP instead.
            <P> <b><font size="+2">Q</font></b> I've been trying to jumpstart 
              a U60 with Solaris 8 05/03. I get to the post-install script that's 
              installing patches, and it bombs out with the following error:
            <P> 
            <pre>
Patch number 110668-04 has been successfully installed.
ERROR: Unable to use /tmp/patchadd-18782543 due to possible security issues.
ERROR: Unable to use /tmp/patchadd-18782543 due to possible security issues.
Patchadd is terminating.
</pre>
            I've successfully used this same JumpStart setup on another machine, 
            so I'm not sure what's wrong. What security issues could possibly 
            exist on a machine that's just been installed and hasn't even left 
            the private JumpStart network yet? Logins aren't enabled, and everything 
            is automated so the procedure should be exactly the same.
            <P> <b><font size="+2">A </font></b> You're running into an issue 
              with the <B>patchadd</B> program, not anything external to your 
              machine. The version of <B>patchadd</B> that comes with Solaris 
              8 05/03 does not remove its tmp files when installing patches. This 
              occasionally results in tmp filenames being reused before they're 
              cleaned out. <B>Patchadd</B> flags this as a possible security violation 
              because the name it wishes to use already exists in the tmp directory. 
              For more information, take a look at bugid 4678605:
            <P> 
            <pre>
http://sunsolve.sun.com/private-cgi/ \
  retrieve.pl?type=0&amp;doc=bug%2Fsysadmin%2Fpatch_utility%2F4678605
</pre>
            The workaround is to manually remove the tmp files after each <B>patchadd</B> 
            run, but if you're automating things, this may be easier said than 
            done. If you're running your post-install scripts from <B>/etc/rcX.d</B> 
            files, you may want to boot single-user mode, install the patches 
            by hand (defeating the purpose of automating the installs), and then 
            reboot, picking up where you left off in the post-install scripts. 
            You could also split your patching into files and call <B>rm</B> in 
            the tmp directory between two separate runs of <B>patchadd</B>. This 
            latter approach will preserve your automation but take slightly more 
            time, because <B>patchadd</B> is invoked twice.
            <P> <b><font size="+2">Q</font></b> We process a large number of digital 
              pictures and put them into online photo albums using Autogallery. 
              Unfortunately, the digital pictures almost always come in as <B>FILENAME.JPG</B>, 
              and Autogallery wants the filename extension to be a lowercase .jpg. 
              Is there an easy way to have all the files converted on the fly 
              when they're transferred from their respective cameras?
            <P> <b><font size="+2">A </font></b> You don't say how you're pulling 
              the photos off the camera, so doing it on the fly there would depend 
              on your method. If you're using Autogallery, though, the easiest 
              approach might be to modify the <B>build_list</B> script in the 
              tools directory. Before the <B>ls</B> line that creates the file 
              "thelist", add code similar to the following:
            <P> 
            <pre>
for i in *.JPG;
do
  if [ ! -f 'basename $i .JPG'.jpg ]; then
    echo "moving $i -&gt; 'basename $i .JPG'.jpg"
    mv -i $i 'basename $i .JPG'.jpg
  fi
done
</pre>
            You can also make this a separate script and invoke it somewhere else 
            before the <B>ls</B> line, too.
            <P> <b><font size="+2">Q</font></b> I've just started working at a 
              company that's running an old version of <B>sendmail</B> with a 
              <B>sendmail.cf</B> file that's been hand modified for years. For 
              security purposes, we definitely need to upgrade <B>sendmail</B>. 
              Is there a way I can generate a valid <B>sendmail.mc</B> file from 
              the existing <B>sendmail.cf</B> file so we have a fairly smooth 
              transition?
            <P> <b><font size="+2">A </font></b> There is no way to actually generate 
              an mc file from a cf file, but you can get a good idea of what's 
              changed if the version you're currently running supported mc files 
              from the beginning. Very old versions of <B>sendmail</B> did not 
              use <B>m4</B> to generate the cf file and modifying it by hand was 
              the only way to go.
            <P> If you have a sufficiently recent version of <B>sendmail</B>, 
              make sure that you have the necessary files to generate a cf file 
              from an mc file. If you don't have the files on the machine already, 
              download the source for the same version of <B>sendmail</B> that's 
              running on the machine.
            <P> Determine which features and mailers were used by doing the following:
            <P> 
            <pre>
grep '$Id:' sendmail.cf
</pre>
            Or, for older versions of sendmail:
            <P> 
            <pre>
grep '@(#)' sendmail.cf
</pre>
            Next, create an mc file with those features and mailers defined. Generate 
            the cf file from the mc file you just created and use <B>diff</B> 
            to determine any differences between the two.
            <P> Read the contents of the file <B>cf/README</B> from the old version 
              of <B>sendmail</B> and try to correlate any changes to definitions 
              or other macro settings. Modify your mc file and create new cf files 
              until you've eliminated the differences between your test cf file 
              and the production cf file.
            <P> As a note of warning, make absolutely sure that you use the same 
              version of <B>sendmail</B> to build the test cf files, or there 
              will likely be a large number of differences that you won't be able 
              to accurately connect with an mc file modification.
            <P> <b><font size="+2">Q</font></b> I'm trying to compile libxml2 
              2.6.7 on a Solaris 8 machine with SMCgcc 3.3.2. It gets most of 
              the way through the compile and then fails near the end with the 
              following error (there are several files that have linking issues 
              with <B>libz.a</B>):
            <P> 
            <pre>
Text relocation remains referenced against symbol offset in file
&lt;unknown&gt;                       0x734
/usr/local/lib/libz.a(inflate.o)
.
.
.
ld: fatal: relocations remain against allocatable but non-writable sections
collect2: ld returned 1 exit status
make[3]: *** [libxml2.la] Error 1
</pre>
            I verified that <B>/usr/local/lib/libz.a</B> is there and has the 
            right permissions. Other programs compile fine against it, too. If 
            I disable libz support, everything builds fine, but I'd really like 
            to compile with libz. Is this a bug in gcc, libz, or libxml2? Is there 
            a workaround?
            <P> <b><font size="+2">A </font></b> I've seen a number of people 
              report the same sorts of failures with various versions of gcc and 
              Solaris, but the common fix seems to be using a shared libz library 
              instead of a statically built version. This also has the benefit 
              of only needing to upgrade the libz library in the event of a security 
              libz hole instead of recompiling every software package that was 
              statically linked against <B>libz.a</B>.
            <P> <b><font size="+2">Q</font></b> Our environment includes a mix 
              of Unix- and Windows-based machines. One of the scripts on the Unix 
              machines needs to know the NetBIOS names of the Windows machines, 
              but I don't know a good way to cull this information from the network. 
              I was going to try to hack something together from bits of Samba 
              code, but thought I'd check here first to see whether I'd be reinventing 
              the wheel.
            <P> <b><font size="+2">A </font></b> There's a tool called NBTscan 
              that runs on both Windows and various flavors of Unix. Check the 
              NBTscan Web page at:
            <P> 
            <pre>
http://www.inetcat.org/software/nbtscan.html
</pre>
            for the source code, or you might be able to install it via a package 
            or port depending on your OS. NBTscan queries machines at UDP port 
            137, so it will pick up any machine answering there, including Samba-enabled 
            machines. If you're blocking UDP 137 on any of the machines from which 
            you need information, you'll miss those boxes. NBTscan also has a 
            GTK2-based GUI called xNBTscan, available from:
            <P> 
            <pre>
http://md2600.dyndns.org/~daten/
</pre>
            If you're using the command-line version, NBTscan, you can specify 
            the address/address range in one of three forms:
            <P> 
            <pre>
192.168.1.1       A single IP in dotted-decimal notation.
192.168.1.0/24    A network address and subnet mask.
192.168.1.1-127   A network address range.
</pre>
            Without any other options, the <B>nbtscan</B> binary outputs the IP, 
            NetBIOS Name, server, user, and MAC address:
            <P> 
            <pre>
nbtscan 192.168.1.0/24

  Doing NBT name scan for addresses from 192.168.1.0/24

  IP address      NetBIOS Name   Server    User      MAC address
  --------------------------------------------------------------------
  192.168.1.0     Sendto failed: Permission denied
  192.168.1.3     MACHINE1       &lt;server&gt;  USER1     00-50-da-b7-e5-7c
  192.168.1.4     MACHINE2       &lt;server&gt;  MACHINE2  d2-80-e4-6c-a1-33
  192.168.1.255   Sendto failed: Permission denied
  192.168.1.5     MACHINE3       &lt;server&gt;  MACHINE3  00-00-00-00-00-00
</pre>
            Various other command-line options allow you to format the output 
            so that it's suitable for <B>/etc/hosts</B> format, lmhosts format, 
            or for importing into a database.
            <P> <b><font size="+2">Q</font></b> I've enabled BSM on my Solaris 
              8 boxes and now my root cronjobs are failing. Other users are working 
              just fine, though, so I'm not sure what's so special about root. 
              Generally, if there's a permissions problem, it's ONLY root that 
              works, but I seem to have the reverse of that. Any clues as to what 
              might be wrong?
            <P> <b><font size="+2">A </font></b> This Web site:
            <P> 
            <pre>
http://www.boran.com/security/sp/Solaris_bsm.html
</pre>
            lists several items to check if cron is failing on BSM-enabled boxes. 
            For example, make sure that all of the c2 audit patches are installed. 
            Also make sure that each user who has a crontab file also has a .au 
            file:
            <P> 
            <pre>
/var/spool/cron/crontabs/root
/var/spool/cron/crontabs/root.au
</pre>
            If you're using <B>ssh</B> to connect to the machine before issuing 
            the crontab command to edit the file, the <B>USER.au</B> file is not 
            created correctly because of the default way UID switching in <B>sshd</B> 
            happens. Without a valid USER.au file, the cronjobs aren't executed, 
            as mentioned above. To work around this, enable <B>UseLogin</B> in 
            the <B>sshd_config</B> file, but be sure that you don't have security 
            issues with the <B>login</B> program before enabling this option. 
            If you're up on your Solaris patches, this shouldn't be a problem.
            <P> If your cronjobs are running but you're receiving messages saying 
              that the job failed, verify that you're not sending stdout/stderr 
              to <B>/dev/null</B> so that you can identify the issue. You'll then 
              want to correct whatever is setting the exit code for the cronjob 
              to something other than zero.
            <P> <I>Amy Rich, president of the Boston-based Oceanwave Consulting, 
              Inc. (<B>http://www.oceanwave.com</B>), has been a UNIX systems 
              administrator for more than 10 years. She received a BSCS at Worcester 
              Polytechnic Institute, and can be reached at: <B>qna@oceanwave.com</B>.</I> 
          </table></table>&nbsp;

<! -- End Content ------ >

<!/center>
<! -- End MASTER TABLE -- >

</body>



<! -- Begin Content ------ >
</html>
