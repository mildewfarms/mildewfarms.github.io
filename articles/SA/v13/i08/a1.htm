<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 4.0//EN">


<HTML>
<HEAD>
<TITLE>v13, i08: Database Migrations the VxVM Way</TITLE>
<LINK REL=StyleSheet HREF="../../resource/css/sacdrom.css" TYPE="text/css" TITLE="CSS1">
</HEAD>

<body bgcolor="#ffffff" text="#000000" link="#000000" alink="#669999" vlink="#333366" topmargin=0 leftmargin=0>
<! -- Begin MASTER TABLE -- >
<!center>
<table width=98% cellpadding=0 cellspacing=0 border=0 bgcolor="#ffffff">
  <tr>

<table cellpadding=5 cellspacing=0 border=0>
	<tr>

		<td><span class="navbarLink">Article</span></td>
		<td><a href="../../../../source/SA/2004/aug2004.tar"><b class=codeListing>aug2004.tar</b></a></td>

	</tr>
</table>


</tr>
<tr>
<! -- Begin Content ------ >
    <td valign=top width=527 bgcolor="#ffffff"> 
      <table width=100% cellpadding=15 cellspacing=0 border=0>
<tr>
          <td valign=top> 
            <! -- Insert Content ------ >
            <h1><B><img src="a1.gif" width="200" height="167" align="right">Database 
              Migrations the VxVM Way</b></h1>
            <p> <I>Rainer Raab</i>
            <p> The duties of a Unix systems administrator range from the simple 
              and mundane, to the complex and mission-critical. We are often called 
              upon to reset a password, remove an unwanted file, restore a backup, 
              apply security patches, etc. Though not very challenging, these 
              tasks are important and must be performed with vigor. Less frequently, 
              we are enlisted to perform a challenging task, offering us a chance 
              to learn something new and prove our worth. Such tasks include operating 
              system upgrades, building Web server farms, allocating new disk 
              arrays, and database migrations, to name a few. Database migrations, 
              which are the most complex and mission critical, offer the most 
              reward and the opportunity to add new skills to one's oeuvre.
            <P> <B>Migration Methods</b>
            <p> The term database migration can mean a variety of things. It can 
              refer to the movement from one database to another where the data 
              is moved between the databases, such as moving from an Informix 
              IDS version 7.31 to a new IDS version 9.40 database using Informix 
              dbexport/dbimport utilities. Or, it can refer to the movement of 
              the database to an entirely new platform, such as moving from Solaris 
              2.6 on SPARC to Linux 2.6 or Windows Server 2003 on Intel x86. It 
              can refer to the movement of the database from one server to another, 
              such as moving from a Sun Enterprise E450 to a Sun Fire 4800 system. 
              Or, it can simply mean moving the database from one disk array to 
              another.
            <P> The operative word here is "move". An in-place upgrade of a database, 
              from one version to another, is not considered a database migration. 
              For example, upgrading an Informix IDS version 7.31 to IDS version 
              9.30 would not be considered a database migration.
            <P> Database migrations are initiated for a variety of reasons. Sometimes 
              they are done for increased performance. If database loads or nightly 
              database refreshes are taking too long, then a new server with more 
              or faster CPUs may help. Sometimes they are done for data reorganization. 
              Perhaps disk hot spots are leading to poor performance. Sometimes 
              migrations are done as part of server consolidation projects, where 
              entire departments are asked to move their databases to a single 
              server. Often, it's just a simple matter of economics. The original 
              environment may have become too costly due to high maintenance costs, 
              or the new environment may offer lower software licensing costs.
            <P> A number of database migration methods can be employed. The DBA 
              can unload the data to a transportable file format and recreate 
              the database from scratch on the destination system. If the new 
              environment supports the database's data files, the files can be 
              archived and copied to the target system using a slew of Unix utilities 
              (e.g., tar, cpio, pax, etc.). If the database data files are stored 
              on raw devices, the Unix <B>dd</B> command can be used to pipe the 
              data to the target system. If the raw devices are managed by a logical 
              volume manager (LVM), such as Veritas Volume Manager (VxVM), then 
              the data may be mirrored to new devices on a new array and then 
              physically moved to the target system. I'll demonstrate this last 
              method, using Veritas Volume Manager, to quickly and reliably migrate 
              a database.
            <P> <B>VxVM Migration Prerequisites</b>
            <p> Veritas Volume Manager, available for most Unix platforms, has 
              become the de facto LVM in many shops because of its advanced features 
              and standardized command set across platforms. To provide a brief 
              overview, VxVM allows the creation of volumes, which are logical 
              devices that appear to the operating system as a type of hard disk 
              or disk partition (i.e., a virtual disk). Volumes can be constructed 
              from one disk to many disks supporting various RAID levels (RAID-0, 
              RAID-1, RAID-5, etc.) as well as simple disk concatenation. The 
              advantages of volumes include increased storage capacity beyond 
              single disk, various degrees of data protection, increased read/write 
              performance, and ease of storage management to name a few.
            <P> Successful database migrations with VxVM require careful planning 
              and preparation, but the reward is well worth the effort. Before 
              the migration can begin, the DBA must determine the feasibility 
              of the migration, since not all migrations can be performed with 
              Veritas Volume Manager. There are several prerequisites for performing 
              a migration with VxVM.
            <P> First, the database should to be built from raw device volumes. 
              If it isn't, forget about using VxVM for the migration. Instead, 
              use any of the supplied database utilities or one of the aforementioned 
              Unix archive/copy utilities. Second, does the target database support 
              the original database's data files? If the migration is to a minor 
              version upgrade of the database on the same platform, then this 
              is most likely the case. However, if the migration is to a new major 
              version of the database, then the DBA may need to consult with the 
              database vendor first. In any event, if the new version of the database 
              doesn't directly support the database files, VxVM may still be used 
              for the migration and an in-place upgrade on the migrated database 
              can be performed. Unfortunately, a VxVM database migration to a 
              new platform, such as from Solaris to Windows, or to a new database 
              platform, such as from Informix to Oracle, is probably not possible.
            <P> If you've satisfied the VxVM database migration prerequisites, 
              then a database migration the VxVM way might just be for you.
            <P> <B>Setting the Stage</b>
            <p> So, you've outgrown your current server and decided to purchase 
              a new, more powerful replacement. Your current server is hosting 
              a multi-terabyte database on an old disk array and you need additional 
              disk space for growth, so you've decided to purchase a new disk 
              array as well. By purchasing both a new server and new storage, 
              you've set the stage to performing a database migration. By performing 
              the migration to a new server, you can continue to host the database 
              on the old server while copying/moving the data to a new, more powerful 
              server with more storage and without much downtime.
            <P> You've also consulted with the DBA, and he has satisfied all of 
              the VxVM migration prerequisites and has a game plan. The DBA is 
              going to stick with the same major version of the database software, 
              but with a minor upgrade. You've decided that the new server will 
              be running a new version of the operating system, and the DBA has 
              confirmed that the database software is supported. The plan is to 
              copy the database to the new server and bring it online with the 
              same name, allowing for two copies of the database to exist at once. 
              This will make migrating to the new database easier and transparent 
              to the users.
            <P> <B>Mirroring the Volumes</b>
            <p> With some careful planning, you've attached the new disk array 
              to the old server and configured the storage for use by the operating 
              system. Because the new disk array has more capacity than the old 
              array, disk space will not be an issue. To copy the data from the 
              old array to the new, you must add a new disk (LUN) to each of the 
              original VxVM disk groups, from the new array. Because the new LUNs 
              are much larger, you should initialize the LUNs, soon to be christened 
              VM disks by VxVM, with a large VxVM private region using the <B>vxdisksetup</B> 
              command:
            <P> 
            <pre>
vxdisksetup -i &lt;new_device&gt; privlen=8192
example: vxdisksetup -i c3t8d0 privlen=8192
</pre>
            The default private region length is 2048 (sectors), which I think 
            is too small for today's larger capacity disks. By increasing the 
            private region, VxVM can keep track of more objects (e.g., you can 
            create more volumes without worrying about running into a volume limit).
            <P> After initializing the disks, add the disks to the VxVM disk groups 
              with the <B>vxdg</B> command:
            <P> 
            <pre>
vxdg -g &lt;old_dg&gt; adddisk &lt;new_vm_disk&gt;=&lt;new_device&gt;
example: vxdg -g idsdg1 adddisk d2_lun1=c3t8d0
</pre>
            Be sure to add enough new disks to each of the original disk groups 
            to allow the volumes to be mirrored to the new disks.
            <P> If the volumes to be mirrored are simple volumes, you can use 
              the <B>vxmirror</B> command:
            <P> 
            <pre>
vxmirror -g &lt;old_dg&gt; &lt;old_vm_disk&gt; &lt;new_vm_disk&gt;
example: vxmirror -g idsdg1 s1_lun1 d2_lun1
</pre>
            The <B>vxmirror</B> command will mirror every volume in the disk group 
            from the old VM disk to the new VM disk. Perform this operation for 
            all of the disk groups until all the volumes have been mirrored from 
            the old array to the new. If your volumes are complex (e.g., VxVM 
            RAID-0, RAID-5, etc.), use <B>vxassist</B> or <B>vxmake</B> to create 
            the mirrors instead.
            <P> <B>Breaking the Mirrors</b>
            <p> When all of the volumes have been successfully mirrored, the next 
              step is to split or "break" them into two. It's a good idea to get 
              the DBA involved to schedule a database outage and shut down the 
              database before breaking the mirrors. You don't want changes to 
              be made to the database after you have broken the mirrors. You could 
              break the mirrors while the databases are online, but then you would 
              have to keep track of the changes and apply them manually later.
            <P> Breaking the mirrors is a cumbersome process because you need 
              to run the <B>vplex</B> command for each of the mirrored volumes:
            <P> 
            <pre>
vxplex -g &lt;old_dg&gt; dis &lt;new_volume&gt;
example: vxplex -g idsdg1 dis pdf11282004-02
</pre>
            I wrote a ksh function to automate this process. You can copy and 
            paste this into your own script. I don't like to automate VxVM tasks 
            too much, because there are many things that can go wrong if you let 
            a script take full control:
            <P> 
            <pre>
function make_vols {
dg=idsdg1
metadata=/var/tmp/$dg.config

plexes=$(vxprint -g $dg -mte '"d2_lun1" in (sd_disk)'|grep pl_name|awk -F= '{print $2}')
for plex in $plexes; do
echo "Disassociating $plex from disk group $dg"
#vxplex -g $dg dis $plex
volume_tmp=$(echo $plex|sed -e 's/-0[0-9]*$//')
volume=$(echo $volume_tmp"_d2")
echo "Creating new volume $volume using plex $plex"
#vxmake -g $dg -U gen vol $volume plex=$plex
echo "Extracting volume $volume metadata and appending it to $metadata"
#vxprint -hmvpsQqr -g $dg $volume &gt;&gt; $metadata
echo " "
done
}
</pre>
            Set the dg variable to the disk group with the mirrors you want to 
            break. The "d2_lun1" reference, in the function, is the name of new 
            VM disk you added to the disk group (from the new array). Change this 
            value to your own VM disk. I've commented out the VxVM commands to 
            protect you from accidentally running this function without understanding 
            what's really going on. Since every VxVM environment is different, 
            it's difficult to write scripts that will work in every situation. 
            I recommend using this function as a template for your own script.
            <P> Note that function not only breaks the mirrors, but that it also 
              creates new volumes (the volume names are appended by a "_d2" to 
              avoid conflicting with the existing volumes) from the disassociated 
              plexes on the new disk (it will become apparent later why we needed 
              to create new volumes in the first place). Also, the script extracts 
              all of the VxVM volume metadata to a flat file, which will be used 
              later. Run the function for each of your disk groups, until all 
              of the mirrors have been broken.
            <P> There is a caveat with extracting the metadata. I've noticed that 
              the permissions on the volumes do not get preserved. I'll present 
              a ksh function to correct this problem.
            <P> <B>Deporting the Disk Groups</b>
            <p> When all of the mirrors have been successfully split, the next 
              step is to delete the newly created volumes. Don't be alarmed -- 
              we'll restore the volumes later from the metadata we extracted earlier. 
              This step is necessary, because we must create new disk groups in 
              which to store our new volumes. We can then export the new disk 
              groups to our new server, leaving the old disk groups untouched.
            <P> Use this ksh function to remove the volumes:
            <P> 
            <pre>
function remove_vols {
dg=idsdg1
metadata=/var/tmp/$dg.config

volumes=$(grep "^vol " $metadata|awk '{print $2}')
for volume in $volumes; do
        echo "Removing volume $volume from $dg"
#vxedit -g $dg -r rm $volume
        echo " "
done
}
</pre>
            Once you've removed all of the new volumes, remove the new VM disks 
            too:
            <P> 
            <pre>
vxdg -g &lt;old_dg&gt; rmdisk &lt;new_vm_disk&gt;
example: vxdg -g idsdg1 rmdisk d2_lun1
</pre>
            Now you are ready to create new disk groups from the VM disks that 
            you just removed:
            <P> 
            <pre>
vxdg init &lt;new_dg&gt; &lt;new_vm_disk&gt;=&lt;new_device&gt;
example: vxdg init idsdg1_d2 d2_lun2=c3t8d0
</pre>
            The new disk groups should have a name similar to the old one. Once 
            you've created the new disk groups (there should be the same number 
            of new groups as old), restore the volume metadata that was extracted 
            earlier for every new volume that was created to the new disk group:
            <P> 
            <pre>
vxmake -g &lt;new_dg&gt; -d &lt;dg_meta_data&gt;
example: vxmake -g idsdg1_d2 -d /var/tmp/idsdg1.config
</pre>
            Once you restore the metadata, all of the volumes that you originally 
            removed from the old disk group will be restored like magic to the 
            new disk group. Do this for each new disk group.
            <P> After you've created the new disk groups with the restored volumes, 
              all that's left is to deport the new disk groups to the new server:
            <P> 
            <pre>
vxdg -n &lt;old_dg&gt; deport &lt;new_dg&gt;
example: vxdg -n idsdg1 deport idsg1_d2
</pre>
            Use the <B>-n</B> option to rename the disk groups back to original 
            disk group name during the deport operation. It's convenient to perform 
            the disk group renaming during the deport so that, when you import 
            the disk groups on the new server, the disk group names are the same 
            as on the old server. Deport all of the new disk groups.
            <P> <B>Importing the Disk Groups</b>
            <p> Once all of the new disk groups have been successfully deported, 
              disconnect the new array from the old server and attach it to the 
              new server. You'll have to go through the motions of making the 
              disk array visible on the new server. Don't fret about integrity 
              of the data. It's safely stored on the VxVM disks. Don't worry about 
              device renumbering either (e.g., the cxtxdx name changing on the 
              new server), because VxVM tracks disks by the information stored 
              in the private region on the disk and not by the operating system 
              device name.
            <P> Once you feel confident that all of the LUNs on the disk array 
              are accounted for and visible to the operating system, import the 
              disk groups:
            <P> 
            <pre>
vxdg import &lt;old_dg&gt;
example: vxdg import idsdg1
</pre>
            If you like, you can also use the menu-driven <B>vxdiskadm</B> command 
            to import disk groups (menu item 8: Enable access to (import) a disk 
            group). It conveniently lists all the disk groups that can be imported.
            <P> Import all of the formerly deported disk groups, using the original 
              name of the disk group on the old server (remember we deported the 
              disk groups with the rename option). Once all of the disk groups 
              have been imported, don't forget to rename to volumes back to their 
              original names. If you used the make_vols function, it appended 
              a "_d2" (or whatever value you chose) to the end of the new volume 
              names). Use this ksh function to rename the volumes:
            <P> 
            <pre>
function rename_vols {
dg=idsdg1
volumes=$(vxprint -g $dg -mte v_kstate|grep "^vol "|awk '{print $2}')
for volume in $volumes; do
        new_volume=$(echo $volume|sed -e 's/_d2$//')
        echo "Renaming volume $volume to $new_volume in disk group $dg"
        #vxedit -g $dg rename $volume $new_volume
        echo " "
done
}
</pre>
            Modify this function if you used something other than "_d2" for the 
            new volumes. Do this for all of the disk groups.
            <P> Before starting the volumes, make sure that the permissions on 
              the volumes are correct. I've noticed that VxVM is not consistent 
              in restoring the owner and group id from the metadata. This is critical 
              for a database because the volumes must be owned by the database 
              id (e.g., Informix or Oracle). Use this ksh function to correct 
              the problem:
            <P> 
            <pre>
function fix_vols {
dg=idsdg1
volumes=$(vxprint -g $dg -mte v_kstate|grep "^vol "|awk '{print $2}')
for volume in $volumes; do
        echo "Changing ownership and mode on $volume in disk group $dg"
        #vxedit -g $dg set mode=0660 user=informix group=informix $volume
        echo " "
done
}
</pre>
            Set "mode=", "user=", and "group=" to the correct values. Double-check 
            that the permissions/ownerships on the volumes match those of the 
            old server before starting the volumes:
            <P> 
            <pre>
#vxrecover -g &lt;old_dg&gt; -Esb
example: vxrecover -g idsdg1 -Esb
</pre>
            When volumes have all been started, it's again time to get the DBA 
            involved. If the database uses symbolic links to the raw device volumes, 
            rather than referencing the devices directly, you will need to recreate 
            the symbolic links.
            <P> For example, for the following Informix IDS root dbspace (rootdbs), 
              the volume /ids_prod1/rootdbs is really a symbolic link to the raw 
              volume:
            <P> 
            <pre>
# onstat -d|grep "/rootdbs"
2ac06928 1   1   0     1000000  997130    PO-   /ids_prod1/rootdbs

# ls -la /ids_prod1/rootdbs
lrwxrwxrwx   1 informix   informix   33 Jun 10  2003 \
  /ids_prod1/rootdbs -&gt; /dev/vx/rdsk/idsdg1/rootdbs_prod1
</pre>
            The easiest way to recreate the symbolic links is to tar up the links 
            on the old server and copy and extract the tarball to the new. Once 
            the links have been created on the new server, make sure that they 
            point to the correct volumes. They should, because we used the same 
            disk group names as the old server during the disk group imports, 
            and we renamed the volumes back to their original names too.
            <P> If the database does use symbolic links, the links must be recreated 
              exactly. VxVM preserves the device names and consistently stores 
              the devices (volumes) in the /dev/vx directory (even across platforms). 
              If you copied the symbolic links correctly from the old server to 
              the new, the links will point to the right volumes.
            <P> Once the symbolic links have been verified as correct, the DBA 
              can install the database software and copy over any configuration 
              files needed from the old server to bring the database online. Once 
              the database is online and the DBA is satisfied with the results, 
              you can put another feather in your cap and call it a day.
            <P> <B>Conclusion</b>
            <p> It has come to my attention that Veritas Volume Manager for Unix 
              (versions 3.2 and above), includes several new features that automatically 
              perform some of the VxVM functions/commands I presented. Specifically, 
              the <B>vxdg</B> command has been enhanced to allow you to move, 
              join, and split disk groups. These enhancements will allow you to 
              more easily perform a database migration, but they do require an 
              extra license. It's probably worth it to purchase the license, but 
              it doesn't hurt to know the sordid details anyway.
            <P> The database migration method I presented using Veritas Volume 
              Manager is one that I have successfully used several times in the 
              past. It may not be as efficient for migrating smaller databases, 
              since there are many steps to perform, but it is well worth the 
              effort if you have a very large database to migrate. The methods 
              presented can be applied to other types of data migration, not just 
              databases. Perhaps you will find some new uses and pass them along.
            <P> <B>References</b>
            <p> Rockwood, Ben. <I>The Cuddletech Veritas Volume Manager Series: 
              Advanced Veritas Theory</I>. August 10, 2002. <B>http://www.cuddletech.com/veritas/advx/index.html</B> 
              (March 28, 2004)
            <P> Veritas Software Corporation. <I>Veritas Volume Manager 3.1.1 
              Administrator's Guide</I>. February 2001.
            <P> Veritas Software Corporation. <I>How to move a disk between disk 
              groups: TechNote ID: 182857</I>. October 9, 2002. <B>http://seer.support.veritas.com/docs/182857.htm</B> 
              (March 28, 2004)
            <P> <I>Rainer Raab is a Senior UNIX System Administrator consulting 
              for Wells Fargo Bank. He received his MBA in Computer Information 
              Systems from California State University at Hayward. When he's not 
              tinkering around with Linux, he's spending time with his lovely 
              wife and adorable newborn daughter. He can be reached at: <B>hopfen@sbcglobal.net</B>.</I></table></table>&nbsp;

<! -- End Content ------ >

<!/center>
<! -- End MASTER TABLE -- >

</body>



<! -- Begin Content ------ >
</html>
