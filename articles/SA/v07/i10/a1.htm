<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 4.0//EN">


<HTML>
<HEAD>
<TITLE>v07, i10: SysMon - A Systems Monitor</TITLE>
<LINK REL=StyleSheet HREF="../../resource/css/sacdrom.css" TYPE="text/css" TITLE="CSS1">
</HEAD>

<body bgcolor="#ffffff" text="#000000" link="#990000" alink="#669999" vlink="#333366" topmargin=0 leftmargin=0>

<! -- Begin MASTER TABLE -- >
<!center><table width=600 cellpadding=0 cellspacing=0 border=0 bgcolor="#ffffff">

<tr>

<table cellpadding=5 cellspacing=0 border=0>
	<tr>

		<td><span class=navbarLink>Article</span></td>
		<td><span class=navbarLink><a href="a1_f1.htm">Figure 1</a></span></td>
		<td><span class=navbarLink><a href="a1_f2.htm">Figure 2</a></span></td>
		<td><span class=navbarLink><a href="a1_f3.htm">Figure 3</a></span></td>
		<td><span class=navbarLink><a href="a1_f4.htm">Figure 4</a></span></td>
	</tr>
	<tr>
		<td><span class=navbarLink><a href="a1_f5.htm">Figure 5</a></span></td>
		<td><span class=navbarLink><a href="a1_f6.htm">Figure 6</a></span></td>
		<td><span class=navbarLink><a href="a1_f7.htm">Figure 7</a></span></td>
		<td><a href="../../../../source/SA/1998/oct98.tar"><b class=codeListing>oct98.tar</b></a></td>

	</tr>
</table>


</tr>
<tr>
<! -- Begin Content ------ >
<td valign=top width=440 bgcolor="#ffffff">
<table width=100% cellpadding=15 cellspacing=0 border=0>
<tr><td valign=top>



<H1>SysMon - A Systems Monitor</H1><p><p>
Bob Ess<p>
Managing UNIX desktops and servers in a large installation (more than 100 desktops and servers) can mean different things to different people. To a system administrator, it can mean "How do I put out all of the fires these users generate on a daily basis without losing my mind?". To an IT manager, it can mean "How many Ultra 5s do I have, how many Ultra 1s have 512 megs or more of memory, and what has my disk space consumption been like for the last 6 months?". Both of these perspectives present their own significant challenges, and their solutions are non-trivial to address.<p>
Any seasoned UNIX system administrator has written scripts to address the monitoring of system resources, whether they be disk, CPU, network, user logins, etc. Data of this nature is constantly requested by management to help them better allocate resources and plan budgets. Thus, it is imperative that the data be as accurate and timely as possible.<p>
SysMon is actually a series of scripts and tools, written over the past several years, that work in concert to provide accurate and timely system data. By using these tools in the manner described in this article, you will be able to track and identify the following:<p>
<ul>
<li>Workstation/Server Inventory
<li>Status of vital system processes on any machine
<li>Monitors for CPU, DISK and NETWORK for each monitored system
<li>Status of network printers including printer queues
<li>Status of network attached storage (Network Appliance filers)
<li>Status of any server and desktop with hypertext links showing:</ul>
<p><ul>
<li>- Change history<br>
<li>- Who is logged on to the machine<br>
<li>- Who has been logged in<br>
<li>- Uptime data<br>
<li>- System messages<br>
<li>- Who is doing what (<B>whodo</B>)</ul><p>
<ul><li>Disk consumption over a period of time. Data format exportable to common spreadsheet formats</ul><p>
The scripts used to construct SysMon include:<p>
<li><B> sys.conf</B> - For more information, see <I>Sys Admin</I>, September 1996
<li> <B>syschange</B> - For system change notification and history tracking (<B>syschange.html</B>, <B>syschange.cgi</B>)
<li><B> namon.sh</B> - To monitor Network Appliance Filers
<li><B>wsmon.sh</B> - To monitor any desktop or server system
<li><B>nightly.sh</B> - To keep all systems updated
<li><B>prtmon.sh</B> - To monitor network printers (HP specifically)
<li><B>syslist.cgi</B> - For presenting system configuration data via http
<li><B>getethers</B> - For polling all machines on all segments
<li><B>inv.cgi</B> - For presenting system inventory data via http
<li><B>diskdaily.sh</B> - For tracking server disk resources<p></ul><p>
I will look at these programs one at a time then show how they work together to help you better manage your systems. Figure 1 depicts the overall structure of the programs. (All listings for this article are available from <B>ftp.mfi.com</B> in <B>/pub/sysadmin</B>.)<p>
<B>sys.conf</b><p>This program and a related article, (called "Configuration Tracking") were published in the September 1996 issue of <I>Sys Admin</I>. The latest code has a few additions, but it remains relatively unchanged from its initial publication. This program is used to gather configuration information about a system, including both hardware and software data. A sample report that <B>sys.conf</B> will gather for you is shown in Figure 2.<p>
The newest version of <B>sys.conf</B> (available at <B>ftp.mfi.com</B>) uses GNU's RCS (Revision Control System) to maintain multiple versions of the baseline files that <B>sys.conf</B> will generate. This keeps the program from polluting the <B>/var/tmp</B> directory with unwanted copies of the configuration file.<p>
This program should be run from cron each night on every machine in your environment. It can be run by itself, or it can be called from another cron job, such as the <B>nightly.sh</B> script, which will be described later in this article.<p>
<B>syschange</b><p>In any UNIX environment that employs more than one system administrator, there must be accurate and timely communication among the administrators concerning significant changes performed on major servers. Why? Perhaps you have made a change to the <B>sendmail.cf</B> file on the mail server. Other administrators currently have no knowledge of the change you have made. Suddenly mail stops working. Another administrator goes into the <B>sendmail.cf</B> and starts making his/her own changes. Soon, changes are made that significantly impact your production environment, and there is no history or documentation of the changes to be referenced. RCS addresses this in regard to files. However, if a file is modified that is not under RCS control, or a significant change is made to a system (add a disk, add memory, crontab changes, reboots, etc.), there must be a mechanism in place to notify all responsible adminstrators and provide a repository for historical reference. <B>syschange</B> provides this mechanism, either from the command line or from a Web page. The concept and code behind <B>syschange</B> is very simple; send email to a mailing list with a message describing changes made to a system. Figure 3 shows a sample mail output for a change made to a system.<p>
Notice in particular the first line that reads:<p>
<pre>
[ System Change history for acme95: file:/acme/adm/syschange/acme95 ]<p>
</pre><p>Any mail recipient using the Netscape mail reader can click the file anchor, and the browser will display the directory containing all of the changes submitted for that particular system.<p>
The shell script <B>syschange</B> has three options: <B>-submit</B>, <B>-view</B>, and <B>-list</B>. You can create and distribute a change notice for system <B>server1</B> as follows:<p>
<pre>
syschange -submit server1
</pre><p>The script then prompts you for a change summary, the date of the change (defaulting to the current date), the time of the change (defaulting to the current time), whether downtime is anticipated and if so, how long the system will be unavailable. It also provides the option of opening an edit session to include in-depth details of the change.<p>
Once the change is documented, you are prompted for a list of mailing addresses to email. Obviously, an alias distribution list should be set up so you don't have to enter more than one email address.<p>
Finally, the script gives you the option of bailing out. If you do so, no harm done. If you commit to the change, it is recorded in the change database and email is sent to those you specified.<p>
To see which systems have change history files associated with them, use:<p>
<pre>
syschange -list
<p>
</pre><p>This will provide a list of systems and the number of changes recorded against them.<p>
To view the change history of a system, use:<p>
<pre>
syschange -view systemname</pre><p>
<p><p>
syschangewill then search the database and provide you with the number of changes recorded for the "systemname", and ask if you want the change records printed, mailed, or viewed.<p>
<B>syschange.html</B> and <B>syschange.cgi</B> have been provided to allow you to use the <B>syschange</B> facility with a Web interface.<p>
<B>namon.sh</b><p>We recently migrated from a centralized data access model to a distributed model. This minimizes the impact on the engineering community in the event of a server failure. We are also able to deliver data faster and more reliably using file server appliances than was achieved with a mammoth centralized server. We chose Network Appliance filers for several reasons, including cost, speed, and simplicity.<p>
Although the NetApp filers are simple to install, maintain, and operate, there are still subsystems that must be monitored for optimum performance. Since the filers do not have a traditional shell or a cron facility, I had to make use of the <B>rsh</B> facility available on the filers to implement monitoring. <B>namon.sh</B> is the script that must run on a host trusted to the monitored Network Appliance. It must either run as root or, as we run it in our shop, submit the <B>rsh</B> commands via <B>sudo</B>.<p>
The SysMon main screen will provide access to the following information about a filer:<p>
<ul>
<li>"green" status if the filer responds to a <B>ping</B>
<li><B>nfsstat</B> statistics
<li>Operating system version
<li>Disk space statistics
<li>Network interface statistics
<li>Snapshot schedule and disk usage
<li>Uptime numbers
<li>System configuration
<li>Real-time NFS, CIFS, HTTP, and CPU statistics</ul><p>
The script creates a small file for each of these above items, referenced as a link underneath the filer name on the SysMon opening page. The filer name is a link to the Network Appliance Web-based administration page.<p>
The shell code for this script is fairly straightforward with the exception of the line that returns the system real-time statistics. Again, since all commands must be done via the remote shell facility, all commands submitted must be processed as a one-line commands. The Network Appliance command <B>sysstat</B> takes only one argument - a number for an interval between updates. I needed a method to provide a 10-second snapshot of the system at any point in time. The one-liner below accomplishes this:<p>
<pre>
((sudo rsh $filer sysstat 1 &gt; ${WSMONDIR}/$filer/sysstat)&amp;);\
sleep 10;sudo kill -9 'ps -ef | grep [s]ysstat | awk '{print $2}''

</pre><p>How and why this works is left as an exercise to the reader.<p>
The number of NetApp filers you have will determine how often and how many instances of <B>namon.sh</B> must run. We currently have five filers, and the script takes around 3 minutes on a Sun Ultra 1. Because the cpu load will vary on whatever machine this script runs on, it is imperative that some type of program locking be implemented. There is nothing uglier than a cron job shell program run amuck on a workstation. When <B>namon.sh</B> is first invoked, it checks for a lockfile. If it finds one, it bails out and waits to be invoked again. If it does not find the lockfile, it creates one to prevent further invocations until this instance terminates. Simple, but effective.<p>
<B>wsmon.sh<p>
wsmon.sh</B> is the underlying centerpiece to the SysMon suite of programs. When first conceived, it attempted to be all things to all UNIX boxes, be they workstations, servers, print spoolers, mail servers, NFS servers, etc. It did this by "classing" a CPU with corresponding alert classes. For example, if a machine was a desktop machine, it ran only the code that checked for desktop alerts, such as <B>vold</B> or <B>sendmail</B>. As is usually the case, simpler is better. Instead, it now checks for "critical" processes on each machine it runs on, gathers statistical data, and writes out the HTML code to a common area that <B>syslist.cgi</B> will gather later.<p>
Several small files are output to the common repository for linking on the system's SysMon Web page:<p>
<ul>
<li><B>who</B>
<li><B>whodo</B>
<li><B>uptime</B>
<li><B>last</B>
<li><B>/var/adm/messages</B></ul><p>
The static output of a <B>top -d1</B> command for the top 15 processes<p>
<B>wsmon.sh</B> can easily be modified to check for whatever processes you deem critical to your operation. I have selected the following:<p>
<ul>
<li><B>inetd</B>
<li><B>syslogd</B>
<li><B>lpsched</B> (or equivalent print daemon)
<li>yp-related processes
<li>nfs-related processes
<li><B>sendmail</B>
<li><B>cron</B>
<li><B>automount</B>
<li><B>vold</B></ul><p>
I also check and flag the following three "critical" areas:
<ul><li>Disk usage above 95%
<li>A process eating more than 5% of CPU
<li>Network collisions greater than 5%</ul><p>
The critical processes are checked by dumping the output of the <B>ps</B> command to a file and <B>grep</B>ping for the process name via a case statement. Since we are going to be outputing HTML code from this script, I set a failed <B>grep</B> to a red ball gif, otherwise I use a green ball gif.<p>
The disk check is done simply to see if you are above a certain threshold in usage. You can set this to whatever you like. I check for anything above 98% for realtime monitoring. In actuality, if you have a disk approaching 80%, it is probably time to check historical usage and determine whether there is a need to increase the amount of disk the system needs. That is the purpose of <B>disk.sh</B>. I check the output of that program each morning. I use <B>wsmon.sh</B> disk monitoring for things that run away during the day (i.e., a runaway Netscape process filling up the CDE errorlog). Once this condition is observed and rectified via <B>wsmon.sh</B>, it prevents anomalous disk usage data from sneaking into the historical disk usage data.<p>
<B>wsmon.sh</B> checks for processes eating more than 5% of the CPU with the command:<p>
<pre>
ps -ef -o pcpu -o pid -o comm | awk \<br>  '{print $1, $2, $3}' | grep "^[5-9].*"
<p>
</pre><p>If there is an offending process, the program tags it and writes out the process name, PID, and usage. This is then given a red blinking ball to indicate the CPU is experiencing abnormal usage.<p>
The network indicator will change from green to red if collisions are in excess of 5%. This is done with simple division from the output of the <B>netstat</B> command. Figure 4 shows the html output of <B>wsmon.sh</B> running on a host.<p>
<B>nightly.sh</b><p>The <B>nightly.sh</B> script has been proven to be invaluable for the following:<p>
<ul>
<li>Non-realtime updates to a system's environment
<li>Data collection
<li>Verifying system integrity</ul><p>
The main concept of the <B>nightly.sh</B> is to put it in every machine's root crontab file (if it needs to run as root), and ensure all machines have NFS access to the same <B>nightly.sh</B>. Some people call this a network cron. You can make a change to only one file (<B>nightly.sh</B>), and it affects your entire environment. Generally, this is a good thing. Test your changes to the script on one machine before you push it out to the world. Depending on how you install workstations at your site, the root crontab should be modified on your master OS distribution server so all new installs get the new crontab without your intervention.<p>
One can argue that everything the <B>nightly.sh</B> is doing can be done in the initial install itself. This argument is not without merit. However, it has been my experience during the past 10 years that the only thing constant is change. And a mechanism is needed for pushing out that change. <B>rdist</B> addresses this for almost every situation, but I have still found a need for having the <B>nightly.sh</B> in place for the following:<p>
<ul>
<li>Collecting log data and moving to a common repository
<li>Calling the <B>sys.conf</B> program
<li>Checking disk space for morning report runs
<li>Keeping <B>motd</B> current
<li>Copying in crontab modifications</ul><p>
Listing 1 shows the code for the <B>nightly.sh</B> we run at our shop.<p>
<B>prtmon.sh</b><p>Printers are the bane of system administrators everywhere. They are a necessary evil in any computing environment. Any device with as much mechanics as modern day printers and plotters is going to make your life difficult. <B>prtmon.sh</B> will not relieve you of the heat, but it will provide you with the following information from a Web interface:<p>
<ul>
<li>Printer name
<li>Green ball if it's online, red ball if it's off the net
<li>Model
<li>Location
<li>Control panel contents
<li>Online status
<li>Uptime
<li>Link to the print spool queue
<li>Link to verbose printer information</ul><p>
All of this data is collected from Hewlett Packard printers using the jetadmin software. I have experimented a bit with the QMS printers and most the information is available as well.<p>
Listing 2 shows the code used to gather the printer data and to create Web page. (All listings for this article can be found at <B>ftp.mfi.com</B> in <B>/pub/sysadmin</B>.)<p>
<B>syslist.cgi<p>
syslist.cgi</B> is the main CGI script that will provide you with the output you see in Figure 5. It tables the servers, printers, and filers and provides an at-a-glance update of their status.<p>
<B>Servers</b><p>If you see a blinking red ball next to a server name, one of the following conditions exists:<p>
<ul>
<li>A process is using an inordinate amount of CPU
<li>Free disk space is at 3% or less
<li>Network collision are in excess of 5%
<li>A process you have deemed critical on the machine is no longer in the process list</ul><p>
Regardless of the status of the machine, by clicking on the link of the server name, you are presented with the screen you see in Figure 6.<p>
If the CPU status is green, the link will present you with the top 15 processes at the time <B>wsmon.sh</B> took a snapshot of the process table. If it is red, the link will show you the process consuming the most CPU.<p>
If the DISK status is green, the link will show you the most recent df. Snapshots are taken every 20 seconds (configurable) so the data is usually quite accurate. If the DISK status is red, the link will show you what filesystems have exceeded the threshold.<p>
If the network interface card is experiencing collisions at a rate of 5% or less, the NET status is green. Otherwise the status is red, and the link will show you the output of a <B>netstat -i</B> as well as the collision rate.<p>
Other links that are shown below the critical processes are:<p>
<ul>
<li><B>who</B> - output of the <B>who</B> command during the last snapshot
<li><B>whodo</B> - output of the <B>whodo</B> command during the last snapshot
<li><B>uptime</B> - output of the <B>uptime</B> command during the last snapshot
<li><B>last</B> - output of the <B>last</B> command during the last snapshot
<li>Messages - copy of <B>/var/adm/messages</B>
<li>Change history - a link to the change history database created by the <B>syschange</B> script.</ul><p>
<B>Printers</b><p>If the printer status is blinking red, the printer is not responding to a ping. Depending on how you feel about printers, this may not be such a bad thing. However, your users still want to print, so you should care.<p>
The printer link presents the image in Figure 7. There are two links at the top of the HTML table: the printer name, which has verbose status information gleaned from the HP JetAdmin software; and a link to the actual printer queue cgi script (<B>lpstat.cgi</B>).<p>
<B>Filers</b><p>If the FILERS are blinking red, they are not responding to <B>ping</B>s, and all other status links are irrelevant. Thankfully, we have found them to be quite reliable and use the links on the page to give us the following information:<p>
<B>nfsstat</B> - A server side <B>nfsstat</B> showing a typical <B>nfsstat</B> output<br>
<B>version</B> - The operating system version<br>
<B>df</B> - Disk space stats for the filesystem and the NetApp snapshot directory<br>
<B>netstat</B> - <B>netstat</B> statistics<br>
<B>snap</B> - The NetApp snapshot schedule<br>
<B>uptime</B> - Just as it says<br>
<B>sysconfig</B> - The filer configuration<br>
<B>messages</B> - The filer's messages file<br>
<B>sysstat</B> - Current system performance<br>
<B>inv.html</b><p>This simple script parses the files created by <B>sys.conf</B> and creates an HTML page representing your site's inventory. Written in Korn shell, it can take several minutes to parse through several hundred configuration files. I run this at 2:00 a.m. every morning.<p>
<B>getethers</b><p>This is a not a script but a C program written by Dave Curry of Purdue University. This program queries a segment and returns all responding mac addresses and corresponding IP address. I have found this to be an invaluable resource if keeping track of machines in a large shop. I run <B>getethers</B> every night for each segment, parse the output to create a list of all workstations and servers at our site, and use that list to remote copy the <B>sys.conf</B> configuration files.<p>
<B>diskdaily.sh</b><p>Although I don't currently employ the output of this program in the Web interface for SysMon, I have included it here because at some point I will. Also, I think it shows a simple but effective method for tracking disk usage at your site.<p>
The script provides two types of outputs. One is a space-delimited file for export into Excel. Three times a day, at 10:00 a.m., 12:00 p.m., and 3:00 p.m. I snapshot all disk space on the servers. The script outputs a line similar to the following:<p>
<pre>
980619_12:00 1427600651 782951294 616719433
</pre><p>Field one is the timestamp; field two is total configured disk space; field three is disk space used; and field four is disk space available. This file format exports very nicely to Excel and makes pretty charts that our managers all love to see. It provides real data about your disk usage over time.<p>
The script also outputs a detailed report for each server you designate. These reports can then be parsed at a later time to provide disk usage on a per-server basis.<p>
<B>Tying It All Together</b><p>Okay, so now we have three CGI scripts, seven Korn shell scripts and no clue how to make it all work. Granted, it can seem a bit like a spider web, but I hope the following will make installation and configuration a little less painful.<p>
Find a common NFS-accessible area in which to install the scripts. Also use a similar area to create an area for data repository. For example, you can create the following hierarchy:<p>
<B>/usr/local/sysmon</B> - This is the top level of the Sysmon heirarchy<p>
<B>/usr/local/sysmon/bin</B> - In this directory, the install program will install the following:<p>
<ul>
<li><B>wsmon.sh</B>
<li><B>namon.sh</B>
<li><B>prtmon.sh</B>
<li><B>sys.conf</B>
<li><B>diskdaily.sh</B>
<li><B>invhtml.sh</B></ul><p>
<B>/usr/local/sysmon/servers</B> - This directory will initially be empty. After the first run of <B>wsmon.sh</B>, it will contain the HTML and data files used by <B>syslist.cgi</B>.<p>
<B>/usr/local/sysmon/disks</B> - This directory will initially be empty as well. After the first run of <B>diskdaily.sh</B>, it will contain the directory "reports" and the file "usage".<p>
<B>/usr/local/sysmon/printers</B> - After the first run of <B>prtmon.sh</B>, this directory will contain the HTML and statistics files for all configured printers.<p>
<B>/usr/local/sysmon/configs</B> - This directory will hold all configuration files created by <B>sys.conf</B>.<p>
<B>/usr/local/sysmon/gifs</B> - This directory holds the gifs used for the Web pages.<p>
Pull down the code file from the <I>Sys Admin</I> <B>ftp</B> server (<B>ftp.mfi.com</B> in <B>/pub/sysadmin</B>). Uncompress and untar the file. After reviewing the README file for any gotchas, run the <B>install.sh</B> script. This will ask you a few pertinent questions about your environment. Once done, it will install as much of SysMon as it can.<p>
You will still need to modify the root crontab on all machines. You can do this one of two ways:<p>
<ol>
<li>If you are absolutely sure that all of your workstations and servers have the exact same root crontab (unlikely), you can <B>rdist</B> out a new crontab file.
<li>If there are disparate crontabs running around, find or create a trusted host. Run <B>installcron.sh</B> on the trusted host. It will remote shell to all of the machine you specify and append the root crontab with the <B>nightly.sh</B> entry.</ol> <p>
Run <B>install_web</B> on your web server. This will install the following:<p>
<ul>
<li><B>  syslist.cgi</B> - This gives the sysmon main screen
<li><B>  syschange.html</B> - Browser-based <B>syschange</B> interface
<li><B>  syschange.cgi</B> - CGI script to process <B>syschange</B> data
<li><B>  lpstat.cgi</B> - CGI script to query printer queues and display that output in HTML.
Finally, run <B>install_S99sysmon</B> from your trusted host. This will install a startup script in <B>/etc/init.d</B> with a hard link into <B>/etc/rc2.d</B>. <B>sysmon.sh</B> will then be invoked at bootup.</ul> <p>
<B>Summary</b><p>This article and accompanying software and documentation have shown how to automatically track your network's resources, monitor major computing and printing sub-systems, and present the information in HTML. These scripts I have reviewed are like screwdrivers in your sysadmin toolbox. Bundled together, they present accurate and timely data about your network and its resources. Take the time to learn the in's and out's of these scripts and the SysMon framework. If you invest the time upfront, it will save you hundreds of hours over the long haul.




<h1>About the Author</h1><p>










Bob Ess is manager for the CAE UNIX Support Group for Fujitsu Network Communications in Richardson, Texas. Even though he is a manager, a trickle of his UNIX skills are allegedly intact. He can be reached at <B>bob.ess@fnc.fujitsu.com</B>.





















<br>&nbsp;<br>
</table></center></td>
<! -- End Content ------ >

</table><!/center>
<! -- End MASTER TABLE -- >

</body></html>