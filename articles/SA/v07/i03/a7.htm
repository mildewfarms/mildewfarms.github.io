<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 4.0//EN">


<HTML>
<HEAD>
<TITLE>v07, i03: RAID Basics</TITLE>
<LINK REL=StyleSheet HREF="../../resource/css/sacdrom.css" TYPE="text/css" TITLE="CSS1">
</HEAD>

<body bgcolor="#ffffff" text="#000000" link="#990000" alink="#669999" vlink="#333366" topmargin=0 leftmargin=0>

<! -- Begin MASTER TABLE -- >
<!center><table width=600 cellpadding=0 cellspacing=0 border=0 bgcolor="#ffffff">

<tr>

<table cellpadding=5 cellspacing=0 border=0>
	<tr>

		<td><span class=navbarLink>Article</span></td>
		<td><span class=navbarLink><a href="a7_f1.htm">Figure 1</a></span></td>
		<td><span class=navbarLink><a href="a7_s1.htm">Sidebar 1</a></span></td>
		<td><span class=navbarLink><a href="a7_t1.htm">Table 1</a></span></td>
		<td><a href="../../../../source/SA/1998/mar98.tar"><b class=codeListing>mar98.tar</b></a></td>

	</tr>
</table>


</tr>
<tr>
<! -- Begin Content ------ >
<td valign=top width=440 bgcolor="#ffffff">
<table width=100% cellpadding=15 cellspacing=0 border=0>
<tr><td valign=top>



<H1>RAID Basics</H1><p>
<p>Gilbert Held
<p>
RAID, by the very nature of its name (redundant array of inexpensive disks) can provide a degree of redundancy that enhances the availability of online storage. However, RAID, like other technologies, represents a family or class of products with different characteristics and features. While one particular type of RAID may not be suitable for a particular user requirement, another type of RAID may fully satisfy your organization's operating requirements. Thus, it is important to obtain an understanding of the different types of RAID systems and their advantages and disadvantages, which is the focus of this article.<p>
<B>Overview</b><p>RAID was developed as an economical method for obtaining fault-resilient disk storage. RAID has its roots in the University of California, Berkeley, where a five-level architecture was defined during 1987 as a mechanism for obtaining disk storage redundancy. Under the original five-level architecture, each level represented a different measure of performance, storage capacity, and resilience, with higher levels normally providing a higher level of fault-tolerance. Since the original definition of RAID, vendors have added extensions to the technology to provide different levels of fault-tolerance disk storage capabilities based upon their perceptions of user requirements. However, as discussed in this article, one level of RAID actually does not provide any data redundancy and instead provides a mechanism for enhancing disk I/O operations.<p>
Approximately a decade after the original five-level architecture was defined, RAID represents a critical component for ensuring that data for business applications, Web servers, and other mission-critical platforms remains available. Today you can obtain a variety of embedded RAID disk systems built into computers as well as stand-alone RAID arrays you can cable to a computer. Regardless of the method by which the RAID system is physically fabricated, its functionality and capability are related to the RAID level it supports. The best way to understand the capability and limitations associated with RAID is to examine each level, so I will do so.<p>
<B>RAID Levels</b><p>One of the limiting items in the paper published at Berkeley in 1987 was the fact that an array was not defined. To clarify this omission, we can define any disk subsystem architecture that combines two or more standard, physical disk drives into a single logic drive to obtain a level of enhanced performance or fault-tolerant data redundancy as a disk array. Using this definition, we see that RAID actually defines the methods by which data is recorded onto each drive in an array, leaving it to equipment vendors to manufacture products that group different numbers and types of disks into an array to obtain a specific storage capacity and access speed.<p>
<B>RAID Level 0</b><p>RAID Level 0 is the exception to the redundancy aspect of RAID. This level of RAID was not included in the original University of California paper as it does not provide redundancy. Instead, it was developed as a mechanism to enhance the performance of I/O requests.<p>
Under RAID Level 0, data is recorded in a predefined order across all drives used to form a disk array. This method of data recording in which data is written across multiple disks is referred to as data striping. Note that although there is no data redundancy, Level 0 enhances performance by balancing random I/O requests among all of the drives in the array. Applications where disk performance is critical, but data redundancy is not, would be good candidates for RAID Level 0. However, if you have two servers mirroring each other with a director balancing the load among servers, you might also consider RAID Level 0 for each server even if your application is critical. This is because you would gain disk I/O performance via data striping while retaining redundancy by server mirroring.<p>
From a physical perspective, RAID Level 0 can be considered as a connection of n disks cabled to a common controller. This means that the failure of the disk controller or any drive renders the array unusable.<p>
<B>RAID Level 1</b><p>RAID Level 1 represents the first RAID method that provides data redundancy. RAID Level 1 mirrors data stored on one disk by duplicating that data onto a second disk. Due to this method of redundancy, RAID Level 1 is often referred to as mirroring or shadowing disks.<p>
Under RAID Level 1, blocks are duplicated based upon the pairing of drives. Although this level permits read requests to be spread over both disks in a pair, the mirroring provides no improvement in performance when writing data. In fact, write performance may slightly suffer as two writes must now occur instead of one. Also, since one disk completely backs up another, the overhead of this pairing method reduces the usable storage capacity of n drives by 50 percent. Although many RAID Level 1 disk arrays use only two drives, other common Level 1 disk arrays consist of four, six, or eight disks, representing two, three, and four pairs of mirrored drives. From a physical perspective, RAID Level 1 resembles RAID Level 0 since both levels involve the use of a common disk controller to control multiple disks in a disk array. However, some vendors offer versions of Level 0 and Level 1 with independent data paths to drives obtained by an additional controller.<p>
<B>RAID Level 2</b><p>RAID Level 2 uses a Hamming error correction technique originally developed for random access memory. Dr. Richard Hamming, the inventor of the Hamming Code recently passed away. Dr. Hamming was a professor at the United States Navy Postgraduate School in Monterey, CA whose effort in developing error correction techniques formed the basis for significant enhancements to the reliability of storage and transmission systems. The use of an error correction technique provides a mechanism that enables the failure of one or more drives in a disk array to be compensated for by information stored on other drives.<p>
Under RAID Level 2, data is written across all of the disks in an array, similar to the manner by which data is stored under RAID Level 0. However, there are two key differences between the manner by which data is recorded under RAID levels 0 and 1. Under RAID Level 1, data is written across all data storage disks in the array one byte or bit at a time. In comparison, under RAID Level 0, data is written in blocks across all pairs of disks in the array. A second difference is that under RAID Level 1 an error-correction (Hamming) parity code is generated and stored which enables the reconstruction of lost data if one of the drives in the array should fail. Under other RAID levels it becomes possible to compensate for the failure of multiple drives; however, Level 2 only permits data recovery for the failure of one drive. The ability to reconstruct data from a failed disk is achieved by the use of the exclusive OR (XOR) function to generate parity. The sidebar "XOR Operations" illustrates how the failure of one drive in a RAID Level 2 array can be compensated for by using XOR operations to reconstruct the data from the remaining operational drives.<p>
Under RAID Level 2, data on four disks requires three extra disks in the array to store parity using a technique similar but more complex than that described in the sidebar. Through the use of a Hamming error correction code, data can also be reconstructed if a portion of a disk becomes corrupted. The use of RAID 2 requires drive spindles to be synchronized as a single I/O operation accesses all drives. Since data bits are read in parallel, the performance of RAID Level 2 for large data transfers can be very good. However, the fact that all disks in the array have the same characteristics as a single drive can degrade performance for small data transfers.<p>
<B>RAID Level 3</b><p>RAID Level 3 is similar to RAID Level 2 in that it interleaves data at the bit level across several drives. However, instead of using three extra drives to store parity, Level 3 uses one parity drive. When a fault is detected, the parity disk can be used to reconstruct the required information. Here the reduction in the number of parity drives is accomplished by adding intelligence to each disk in the array so they can detect corrupted data, enabling a reduction in the information required to be stored on the parity drive. While the reduction in the number of drives makes RAID Level 3 more economical than a Level 2 array, both RAID Level 3 and RAID Level 2 require that all disks in the group are accessed with any transfer. This means that small data transfers can adversely affect performance.<p>
<B>RAID Level 4</b><p>RAID Level 4 can be considered as a combination of RAID Level 0 and RAID Level 3. That is, RAID Level 4 provides data striping with parity. Under RAID Level 4, data is written in blocks or sectors across all of the disks used for data storage in the disk array, with an extra drive used for parity storage.<p>
Similar to RAID Level 0, RAID Level 4 enables high-speed reads; however, writes are degraded by the necessity to update parity data at each write occurrence. Another problem associated with RAID Level 4 occurs when small size data blocks are retrieved. This is because such operations require a relatively large overhead for the retrieval of data stored in small pieces across multiple disks. This characteristic makes RAID Level 4, along with Levels 2 and 3, lower on the list of solutions for such client-server applications as database updates and other transaction-oriented operations.<p>
<B>RAID Level 5</b><p>RAID Level 5 represents the final level specified in the original University of California paper. Under RAID Level 5, data and parity are distributed across multiple drives. Data is striped across multiple drives on a block basis, while parity-correcting information is stored on a different disk from the data that the parity-correcting codes reference.<p>
Figure 1 illustrates an example of the allocation of data under a four-disk RAID Level 5 system. Note that the distribution of parity information across all drives enables a RAID Level 5 system to operate with one non-operational disk so that recovery does not have to be performed immediately. Also note that since multiple read and write operations can be supported, the I/O performance of the disk array is enhanced in comparison with the use of a single drive or other RAID levels where the drives function as an entity. Thus, RAID Level 5 is well suited for database and other server applications and is, in fact, probably the most popular RAID level being shipped.<p>
<B>RAID Level 6</b><p>RAID Level 6 is an extension to the original five levels. RAID Level 6 improves upon RAID Level 5 by the use of a multi-dimensional parity scheme in which parity is generated for rows and for columns of disks in the array. The distribution of this multi-dimensional parity among disks in the array enables recovery of data even if two disks should fail. Thus, RAID Level 6 can be considered a combination of Level 5 in which parity is spread across multiple drives, Level 1 in which drives are mirrored, and Level 0 in which data is striped across drives in blocks.<p>
One of the more interesting features of RAID Level 6 is its ability to support mirroring on an odd number of disks. This is possible because mirroring is performed at the block level, which results in data always being mirrored on at least two drives. Some vendors have added additional features, such as redundant controllers, to RAID Level 6, which means you should ask vendors exactly how they support this version of RAID.<p>
<B>RAID Level 7</b><p>RAID Level 7 facilitates fast access to data. Under RAID Level 7, each I/O device is connected to a high-speed data bus with a central cache storage area used to support multiple host I/O paths. To enable each drive head to move independently of other heads, an operating system is embedded into the array. The operating system permits each drive head to operate independently and provides an improvement in performance over RAID levels where all disk heads move in parallel. Another improvement under RAID Level 7 concerns its ability for data recovery. Its structure consists of separate device cache and device control, as well as the use of an embedded operating system. This enables the support of optional additions for parity calculations that can be used to support data recovery in the event that up to four disks fail simultaneously.<p>
<B>RAID Level 10</b><p>RAID Level 10 is another extension to the original University of California specifications. RAID Level 10 gets its designation from the fact that it represents a hybrid implementation of Level 0 and Level 1. Thus, RAID Level 10 is a combination of data block striping and data mirroring.<p>
Under RAID Level 10, data striping is normally performed at the operating system level, while mirroring is performed by the disk controller. Level 10 provides a disk I/O capability similar to Level 0. From a data redundancy and fault-tolerance point of view, Level 10 is similar to Level 1.<p>
<B>Operational Considerations</b><p>Most RAID systems support two types of cache write operations, write-back and write-through. Under write-back caching the controller sends a data transfer completion signal to the host when the controller cache has received all the data in a transaction. Under write-through caching the controller sends the data transfer completion signal to the host when the disk subsystem has received all the data in a transaction. Although write-back caching improves performance in comparison to write through caching, the latter provides better data security capability.<p>
Another interesting aspect of RAID involves loading an operating system so that it recognizes the disk array. While this may appear to be a simple operation, certain procedures can alleviate hours of trial and error as well as a large degree of frustration.<p>
When you obtain a server with a built-in RAID system, some vendors ship their product without installing the operating system. This is particularly true concerning Windows NT as there are several options the user must select concerning its use in a network environment. However, if you attempt to install Windows NT directly, it will normally fail to automatically detect a vendor's RAID system. To allow Windows NT to correctly recognize the RAID system, you must first create a diskette containing configuration information needed by the operating system. To accomplish this, many computer server manufacturers ship a bootable CD-ROM, which allows you to create a diskette of configuration files for a particular operating system. Once this is accomplished, you would install Windows NT or another operating system and select the manual configuration option instead of the automatic option.<p>
In the good old days, it was rather taxing to configure a RAID controller that used a command-based syntax whose mnemonics made sense to few lay personnel. Fortunately, most controllers can be configured by the use of a graphic user interface which displays options, provides on-line assistance, and makes life easier. Modern GUI configuration screens permit users to specify the RAID level to be used, the logical drive size, number of stripes in an array, and the stripe size. Concerning the stripe size, you can usually expect the ability to set the stripe size at a power of 2kb, such as 2, 4, 8, 16, 32, 64, and 128kb. However, the ability to do so can be limited by the RAID level being configured. Since the type of data transferred (interactive vs. files) and the stripe size selected affects performance, it's a good idea to use the performance monitor included with many RAID systems to view the effect of your settings and then adjust them as necessary. In addition to the previously mentioned parameters, most configuration screens support: setting a write policy concerning the caching method to use, facilities to add and remove hot spares, initiate a low-level format of a drive, enable and disable alarms, and perform other operations.<p>
By carefully examining the operational characteristics of different RAID levels against your organization's operational requirements, you can select an appropriate disk array. By examining the manner by which an operating system must be installed to recognize your array, you can get your array online faster and avoid some potential frustration. Once up and running, most RAID systems will provide the fault-tolerance and reliability you seek. However, remember that RAID is no substitute for regular backups, and the latter can provide the recovery capability beyond that of any RAID level.




<h1>About the Author</h1><p>










Gilbert Held is an award winning lecturer and author. Gil is the author of more than 20 books and 250 technical articles. Some of his recent books include LAN Performance 2ed., Ethernet Networks 2ed., The Complete Modem Reference 3ed., and Data and Image Compression 4ed., all published by John Wiley &amp; Sons of New York and Chichester, England. Gil can be reached at <B>235-8068@mcimail.com</B>.






















<br>&nbsp;<br>
</table></center></td>
<! -- End Content ------ >

</table><!/center>
<! -- End MASTER TABLE -- >

</body></html>
