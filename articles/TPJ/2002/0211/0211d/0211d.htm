<html><head><title>Nov02: Better Documentation Through Testing</title></head><body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000"><!--Copyright &#169; The Perl Journal--><h1>Better Documentation Through Testing</h1><p><i>The Perl Journal</i> November 2002</p><h3>By brian d foy</h3><I>brian has been a Perl user since 1994. He is founder of the first Perl Users Group, NY.pm, and Perl Mongers, the Perl advocacy organization. He has been teaching Perl through Stonehenge Consulting for the past five years, and has been a featured speaker at The Perl Conference, Perl University, YAPC, COMDEX, and Builder.com.</I><hr><p>I document all of my modules and scripts, and although I readily find out about program errors because people are quick to tell me their script either fails to run or does the wrong thing, almost nobody reports problems with the documentation.</p><p>Perl has a basic document format called "Plain Old Documentation," or POD. The Perl documentation reader, perldoc, follows the adage, "Be strict in what you output, and liberal in what you accept." It takes most of the bad POD formatting that I give it and turns it into something the user can read. If I make errors in my POD markup, perldoc often silently fixes them. I have the same problem with HTML. I can write bad HTML that the browser fixes so it can display it.</p><p>Perl comes with a POD validator, <i>podchecker</i>, based on the <i>Pod::Checker</i> module, which is part of the Perl Standard Library. Given a file with POD directives, podchecker tells me where I messed up. I tell podchecker which file (not which module, like perldoc) to check and it shows me the POD errors and questionable constructs; see <A NAME="rl1"><A HREF="#l1">Listing 1</A>.</p><p>I am lazy, in the Perly sense of the word, so I want this to happen automatically. As I add new features to modules or move code around, I change the documentation. I may add more documentation, get rid of old explanations, or rearrange it. Anywhere in this process I might introduce a POD error. I do not want to use podchecker every time I make a change.</p><p>I could check the documentation just before I release a new version, but I usually forget to do that. I have automated most of the steps to release something to CPAN, so I should automate checking the documentation format as well.</p><h3><i>Test::Pod</i></h3><p>I wrote the <i>Test::Pod</i> module to automatically check my modules and scripts for POD errors. It does not check if I documented everything that I should have, like <i>Pod::Coverage</i> does. It simply wraps <i>Pod::Checker</i>, which only checks the POD markup, in a <i>Test::Builder</i> interface and calls it <i>pod_ok()</i>.</p><p>Once I have my <i>pod_ok</i> function, which I show in gory detail later, I can use it in a test script. This snippet uses <i>Test::More</i>, the basis of many new test files. <i>Test::More</i> comes with the latest stable version of Perl, 5.8.0, which also comes with <i>Test::Tutorial</i>, which explains the basics of testing.</p><PRE># t/pod.tuse Test::More tests =&gt; 1;use Test::Pod;pod_ok( 'blib/lib/ISBN.pm' );</PRE><p>The test fails if <i>Pod::Checker</i> finds a POD error in the ISBN.pm file from my <i>Business::ISBN</i> distribution.</p><p>Most of my distributions have more than one module in it, though. Andy Lester showed me a cool hack to test all of the modules without remembering which modules I had. If I add a new module to the distribution, this test finds it automatically.</p><PRE># t/pod.tBEGIN {    use File::Find::Rule;    @files = File::Find::Rule-&gt;file()-&gt;name(         '*.pm' )-&gt;in( 'blib/lib' );    }use Test::More tests =&gt; scalar @files;use Test::Pod;foreach my $file ( @files )    {    pod_ok( $file );    }</PRE><p>The <i>File::Find::Rule</i> module allows me to find all of the modules in the named directory and the build library ('blib/lib' in this case) very easily. Once I have all the filenames that I want to test in <i>@files</i>, I simply loop through <i>@files</i> to test each one.</p><p>I run this test like any other test file. Once I create the module Makefile from Makefile.PL, I run <i>make test</i>, which tells <i>Test::Harness</i> to do its magic. It runs all of the *.t files in the t directory, collects the results, and reports what it finds; see <A NAME="rl2"><A HREF="#l2">Listing 2</A>.</p><p>If a test fails, the <i>Test::Harness</i> report is different. In this case, I edited the ISBN.pm file to remove an <i>=over</i> POD directive so the POD now has an error. <i>Test::Pod</i> reports that it found an error at line 400. <i>Pod::Checker</i> correctly identifies the problem as a missing <i>=over</i>. <i>Test::Harness</i> prints a summary of the failed tests at the end; see <A NAME="rl3"><A HREF="#l3">Listing 3</A>.</p><h3>Creating the Test Module</h3><p><i>Test::Builder</i> is the brainchild of Michael Schwern and chromatic, and in my opinion, it's the best thing to happen to Perl in years. This module allows other people to plug into <i>Test::Harness</i> with their own specialized modules. The Comprehensive Perl Archive Network (CPAN) has about 20 specialized Test modules so far.</p><p>These specialized modules have the same advantages as any other module&#151;I can write a test function once and use it over and over again. The function standardizes the way I do things and moves more code out of the test files. I take any chance I can get to move code out of the test files. More code means more points of failure. I have to try really hard to mess up <i>pod_ok()</i>.</p><p>The <i>Test::Builder</i> interface is very simple. In my specialized test module, I create a <i>Test::Builder</i> object, which is a singleton, so all of the specialized test scripts play well together.</p><p>my $Test = Test::Builder-&gt;new();</p><p>I create a test function, called <i>pod_ok</i> in <i>Test::Pod</i>, that tells <i>Test::Builder</i> if the test succeeded or failed, and optionally outputs some error information. <i>Test::Builder</i>'s <i>ok()</i> method handles the result. If I think the test passed, I give <i>ok()</i> a true value, and a false value otherwise. The meat of <i>pod_ok()</i> is very simple&#151;tell <i>Test::Builder</i> the test either passed or failed.</p><PRE>sub pod_ok    {    $pod_ok = _check_pod();    if( $pod_ok ) { $Test-&gt;ok(1) }    else          { $Test-&gt;ok(0) }    }</PRE><p>Everything else in the function supports those simple statements in the <i>pod_ok</i> function. <i>Test::Builder</i> takes care of the rest.</p><p>To actually test the POD, I created an internal function, <i>_check_</i>pod, in <i>Test::Pod</i>; see <A NAME="rl4"><A HREF="#l4">Listing 4</A>. I already defined the constants NO_FILE, NO_POD, ERRORS, WARNINGS, and OK, which described the conditions that <i>Pod::Checker</i> can report. The function returns an anonymous hash. The result is the value of the <i>result</i> key, error messages are the value for the <i>output</i> key, the number of errors is the value of the <i>errors</i> key, and the number of warnings is the value for the <i>warnings</i> key. The rest of the code puts the right things in the hash.</p><p>The first line in the subroutine takes a filename off of the argument stack, and the third line checks the file's existence. If the file does not exist, the function returns an anonymous hash with the result NO_FILE.</p><p>The next bit of code ties the variable <i>$hash{output}</i> to <i>IO::Scalar</i>. <i>Pod::Checker</i> can write messages to a file handle, and I want to intercept that output. It shows up in <i>$hash{output}</i> instead of the terminal.</p><p>I get a POD checker object from <i>Pod::Checker</i>, and then parse the specified file. <i>Pod::Checker</i> puts all output in <i>$hash{output}</i>. The <i>do</i> block puts the numbers of errors and warnings in the right keys, then returns the right constant for the condition that <i>Pod::Checker</i> reported.</p><p>Finally, <i>_check_pod</i> returns the anonymous hash that the <i>pod_ok</i> function can use to tell <i>Test::Builder</i> what happened. The <i>pod_ok()</i> function (see <A NAME="rl5"><A HREF="#l5">Listing 5</A>) does the same thing it did before, although it has to do a little more work to decide if the test passed or not.</p><p>The first line takes a file name off of the argument list, and then passes that to <i>_check_pod</i>. The second argument specifies my expected result and default to OK. The third argument gives a name to the test that I can see in the verbose output of <i>Test::Harness</i>. It defaults to a message that includes the name of the file.</p><p>The rest of the function is a series of <i>if-elsif</i> statements, with one test for each possible condition. I can specify an expected result in the second argument. If <i>Pod::Checker</i> finds the condition I expected, then the test succeeds, and fails otherwise. If I do not specify an expected condition, <i>pod_ok</i> assumes I only want the test to pass if <i>Pod::Checker</i> finds neither error nor warnings.</p><p>Every branch of the <i>if-elsif</i> structure calls <i>Test::Builder</i>'s <i>ok()</i> method. If that branch represents a success, <i>pod_ok</i> passes 1 to <i>ok()</i>, and 0 otherwise.</p><p>If <i>pod_ok</i> fails a test, it also uses <i>Test::Builder</i>'s <i>diag()</i> method to give an error message.</p><h3>Conclusion</h3><p>Testing my work is simple if I use <i>Test::Builder</i>. I can create specialized test modules to check all sorts of things other than normal script execution. My modules have better-formatted documentation because <i>Test::Pod</i> automatically tells me about problems.</p><p><b>TPJ</b></p><H4><A NAME="l1">Listing 1</H4><pre>podchecker /usr/local/lib/perl5/site_perl/darwin/DBI.pm*** WARNING: (section) in 'perl(1)' deprecated at line 4926 in file /usr/local/lib/perl5/site_perl/darwin/DBI.pm*** WARNING: (section) in 'perlmod(1)' deprecated at line 4926 in file /usr/local/lib/perl5/site_perl/darwin/DBI.pm*** WARNING: (section) in 'perlbook(1)' deprecated at line 4926 in file /usr/local/lib/perl5/site_perl/darwin/DBI.pm*** ERROR: unresolved internal link 'bind_column' at line 1819 in file /usr/local/lib/perl5/site_perl/darwin/DBI.pm*** WARNING: multiple occurence of link target 'trace' at line - in file /usr/local/lib/perl5/site_perl/darwin/DBI.pm*** WARNING: multiple occurence of link target 'Statement (string, read-only)' at line - in file /usr/local/lib/perl5/site_perl/darwin/DBI.pm/usr/local/lib/perl5/site_perl/darwin/DBI.pm has 1 pod syntax error.</pre><P><A HREF="#rl1">Back to Article</A></P><H4><A NAME="l2">Listing 2</H4><pre>localhost_brian[3150]$ make testcp ISBN.pm blib/lib/Business/ISBN.pmcp Data.pm blib/lib/Business/ISBN/Data.pmPERL_DL_NONLAZY=1 /usr/bin/perl "-MExtUtils::Command::MM" "-e" "test_harness(0, 'blib/lib', 'blib/arch')" t/load.t t/pod.t t/isbn.tt/load....ok                                                                 t/pod.....ok                                                                 t/isbn....ok 20/21                                                           Checking ISBNs... (this may take a bit)t/isbn....ok                                                                 All tests successful.Files=3, Tests=25, 358 wallclock secs (116.90 cusr +  2.96 csys = 119.86 CPU)</pre><P><A HREF="#rl2">Back to Article</A></P><H4><A NAME="l3">Listing 3</H4><pre>localhost_brian[3152]$ make testcp ISBN.pm blib/lib/Business/ISBN.pmSkip blib/lib/Business/ISBN/Data.pm (unchanged)PERL_DL_NONLAZY=1 /usr/bin/perl "-MExtUtils::Command::MM" "-e" "test_harness(0, 'blib/lib', 'blib/arch')" t/load.t t/pod.t t/isbn.tt/load....ok                                                                 t/pod.....NOK 1#     Failed test (t/pod.t at line 12)                        # Pod had errors in [blib/lib/Business/ISBN.pm]# *** ERROR: =item without previous =over at line 400 in file blib/lib/Business/ISBN.pm# blib/lib/Business/ISBN.pm has 1 pod syntax error.t/pod.....ok 2/2# Looks like you failed 1 tests of 2.                       t/pod.....dubious                                                                    Test returned status 1 (wstat 256, 0x100)DIED. FAILED test 1        Failed 1/2 tests, 50.00% okayt/isbn....ok 20/21                                                           Checking ISBNs... (this may take a bit)t/isbn....ok                                                                 Failed Test Stat Wstat Total Fail  Failed  List of Failed----------------------------------------------------------------------------t/pod.t        1   256     2    1  50.00%  1Failed 1/3 test scripts, 66.67% okay. 1/25 subtests failed, 96.00% okay.make: *** [test_dynamic] Error 35</pre><P><A HREF="#rl3">Back to Article</A></P><H4><A NAME="l4">Listing 4</H4><pre>sub _check_pod    {    my $file = shift;        return { result =&gt; NO_FILE } unless -e $file;    my %hash    = ();    my $output;    $hash{output} = \$output;        my $checker = Pod::Checker-&gt;new();        # i pass it a tied filehandle because i need to fool    # Pod::Checker into thinking it is sending the errors    # somewhere so it will count them for me.    tie( *OUTPUT, 'IO::Scalar', $hash{output} );        $checker-&gt;parse_from_file( $file, \*OUTPUT);            $hash{ result } = do {        $hash{errors}   = $checker-&gt;num_errors;        $hash{warnings} = $checker-&gt;can('num_warnings') ?            $checker-&gt;num_warnings : 0;                   if( $hash{errors} == -1  ) { NO_POD   }        elsif( $hash{errors}   &gt; 0  ) { ERRORS   }        elsif( $hash{warnings} &gt; 0  ) { WARNINGS }        else                          { OK }        };        return \%hash;    }</pre><P><A HREF="#rl4">Back to Article</A></P><H4><A NAME="l5">Listing 5</H4><pre>sub pod_ok    {    my $file     = shift;    my $expected = shift || OK;    my $name     = shift || "POD test for $file";        my $hash = _check_pod( $file );                my $status = $hash-&gt;{result};        if( defined $expected and $expected eq $status )        {        $Test-&gt;ok( 1, $name );        }    elsif( $status == NO_FILE )        {        $Test-&gt;ok( 0, $name );        $Test-&gt;diag( "Did not find [$file]" );        }    elsif( $status == OK )        {        $Test-&gt;ok( 1, $name );        }    elsif( $status == ERRORS )        {        $Test-&gt;ok( 0, $name );        $Test-&gt;diag( "Pod had errors in [$file]\n",            ${$hash-&gt;{output}} );        }    elsif( $status == WARNINGS and $expected == ERRORS )        {        $Test-&gt;ok( 1, $name );        }    elsif( $status == WARNINGS )        {        $Test-&gt;ok( 0, $name );        $Test-&gt;diag( "Pod had warnings in [$file]\n",            ${$hash-&gt;{output}} );        }    elsif( $status == NO_POD )        {        $Test-&gt;ok( 0, $name );        $Test-&gt;diag( "Found no pod in [$file]" );        }    else        {        $Test-&gt;ok( 0, $name );        $Test-&gt;diag( "Mysterious failure for [$file]" );        }    }</pre><P><A HREF="#rl5">Back to Article</A></P></body></html>