<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <title>Capturing Video in Real Time - The Perl Journal, Summer 2000</title>
  <meta name="generator" content=
  "HTML Tidy for Linux/x86 (vers 12 April 2005), see www.w3.org">
  <meta name="vscategory" content="Perl">
  <meta name="vsisbn" content="">
  <meta name="vstitle" content="Capturing Video in Real Time">
  <meta name="vsauthor" content="Marc Lehmann">
  <meta name="searchdescription" content="">
  <meta name="vsimprint" content="The Perl Journal">
  <meta name="vspublisher" content="Earthweb">
  <meta name="vspubdate" content="Summer 2000">
  <!-- always update the article title and issue -->

  <!-- link to the previous and next documents relative to the current document -->
</head>

<body bgcolor="#FFFFFF">
  <font face="verdana" size="1">Issue 18, Summer 2000</font>

  <h2 align="center">Capturing Video in Real Time</h2>

  <h4><i>Marc Lehmann</i></h4>
  <!-- packages described, if necessary -->

  <div align="center">
    <table border="1" cellspacing="0" cellpadding="5">
      <tr>
        <td bgcolor="#CCCC99" align="center"><b>Packages</b></td>
      </tr>

      <tr>
        <td>
        Video::Capture::V4l..................................CPAN<br>

        Video::Frequencies...................................CPAN<br>

        Video::XawTV.........................................CPAN<br>

        Image::Magick..........................................CPAN<br>

        PDL (Perl Data Language)....CPAN, pdl.perl.org<br>
        Event.......................................................CPAN</td>
      </tr>
    </table>
  </div>

  <h3>Real Time Video in Perl?</h3>

  <p>Perl is not currently a common choice for real time
  applications. The dynamic nature of the language makes it
  difficult to predict run-time behavior (and speed) reliably.
  However, video capturing applications (for instance, digitizing a
  television signal and saving it to disk) have to be real time. If
  you miss a frame, it's gone forever, so your program has a
  deadline.</p>

  <p>One of my principles for programming is to use the right
  language for the job. In recent years this has mutated into
  "let's combine the strengths of various languages to solve a
  problem" or, more precisely, "write a Perl interface to the
  problem."</p>

  <h3>Video::Capture::V4l</h3>

  <p>The Video::Capture::V4l module was created to solve such a
  problem: I wanted to record a television show that was broadcast
  daily at different times, on a TV channel that didn't properly
  support the VPS (video programming service) signal to switch on
  my VCR. What I will describe here will <i>not</i> work in the
  U.S. &mdash; but being able to capture 50 704x528 fields per
  second with a 333 MHz dual Pentium II is worth attention
  anyway.</p>

  <p>To do this, I had to get at the video data and compare it with
  some pre-recorded sequence, trying to match the beginning of the
  show (which fortunately was always the same). Then I used Kermit
  to transfer commands to my HP-48 Calculator and switch on the
  VCR, but that's another story.</p>

  <p>The Video::Capture::V4l module solves this problem in a
  generic way. With it, you can control the tuner, capture frames,
  compress them using the RTjpeg codec, and do whatever processing
  you like in the time allotted. Another interesting area is the
  VBI (vertical blanking interval), which can contain interesting
  data like videotext, electronic program guides, intercast, and
  even MP3s.</p>

  <h3>Part I: Video Capturing</h3>

  <p>The V4l module follows the Video4linux standard (version 1),
  so all the documentation for Video4linux applies to the module as
  well. Actually, the documentation for the V4l module (<tt>perldoc
  Video::Capture::V4l</tt> once you've installed it) is nothing
  more than an enumeration of the supported constants.</p>

  <p>The simplest way to capture a single frame looks like
  this:</p>
  <pre>
 use Video::Capture::V4l;
&#13; # open the video device (the default is /dev/video0)
 my $grab = new Video::Capture::V4l
   or die "Unable to open video device: $!";
&#13; my $frame = $grab-&gt;capture(0, 640, 480);
 $grab-&gt;sync(0);
&#13; # now $frame contains 640x480x3 bytes of RGB (BGR) pixel data.
</pre>

  <p>While this is short, it's not exactly intuitive. The call to
  <tt>new Video::Capture::V4l</tt> creates a new V4l object and
  opens the video device. The memory will be allocated as long as
  this object exists, so a script should not use it longer than
  necessary.</p>

  <p>The next statement tells V4l that you want to capture a frame
  into the variable <tt>$frame</tt>. The first argument tells V4l
  the number of the frame you want to capture; most drivers can be
  told to capture up to two frames. Since we only want to capture a
  single frame, a zero (for "the first buffer") suffices.</p>

  <p>The second and third arguments are the width and height of the
  image. A standard PAL frame is 960 pixels wide and 625 lines high
  (of which only 768 x 576 contain usable image data), but most
  chipsets can scale the image in steps of 16 pixels, so other
  sizes are usually not a problem.</p>

  <p>The <tt>capture()</tt> method supports a fourth argument
  specifying the format of the video frame. The default (used in
  the above example) is <tt>VIDEO_PALETTE_RGB24</tt>, where pixels
  are stored linearly as groups of (blue, green, red) bytes (i.e.
  "BGRBGRBGRBGR...").</p>

  <p>Another useful format is <tt>VIDEO_PALETTE_GREY</tt> (each
  pixel is an intensity value between 0 and 255). Other formats are
  more hardware-oriented and less portable between chipsets.</p>

  <p>The <tt>capture()</tt> method returns a Perl scalar that will
  eventually contain the image data, which will be just large
  enough to hold all the pixels you requested. And it will be
  filled with garbage, since <tt>capture()</tt> is just a request
  to fill it once a frame is complete. You will therefore need to
  wait until the actual image data has arrived before manipulating
  the data, and you do this by calling the <tt>sync()</tt> method
  with the frame number you want to wait for.</p>

  <p>In the above example we just call <tt>sync(0)</tt> after the
  call to <tt>capture</tt>, to ensure that <tt>$frame</tt> contains
  the image.</p>

  <p>There are a number of ways to display the image data. All of
  them require that the BGR data is reordered to the more
  conventional RGB format. Since this whole process needn't be
  time-sensitive, we can use a simple regex:</p>
  <pre>
$frame =~ s/(.)(.)(.)/$3$2$1/gs; # takes a second or so
</pre>

  <p>You could also use PDL (the Perl Data Language; pdl.perl.org)
  and some dimension magic to get the same result much faster. But
  since you would usually only display images for debugging
  purposes, you could use this regex to view the BGR image in RGB
  mode by switching the red and blue channels.</p>

  <p>To display the image, we could save it as a PPM file and use
  an image viewer like <i>xv:</i></p>
  <pre>
  open PPM, "&gt;frame.ppm" or die "frame.ppm: $!";
 print PPM "P6 640 480 255\n$frame";
 close PPM;
 
</pre>Or pipe it directly into an image viewer, such as
ImageMagick's <tt>display</tt>:
  <pre>
  open IM, "| display -size 640x480 RGB:-" or die;
 print IM $frame;
 close IM;
</pre>Or use the ImageMagick Perl module:
  <pre>
 use Image::Magick;
&#13; my $img = new Image::Magick;
 $img-&gt;set(magick =&gt; 'RGB', size =&gt; "640x480");
 $img-&gt;BlobToImage($frame);
 $img-&gt;Display;
 
</pre>

  <p>Or even create a PDL and save, display, and modify it, in
  which case you don't even need the earlier regex
  substitution:</p>
  <pre>
 use PDL;
 use PDL::IO::Pnm;
&#13; # create an empty piddle. this should be done
 # outside the loop, actually, but doesn't hurt
 # much anyway
 my $img = zeroes byte, 3, 640, 480;
&#13; # replace pdl's data storage with our frame data
 ${$img-&gt;get_dataref} = $fr; $img-&gt;upd_data();
&#13; # reverse both the pixel order (BGR-&gt;RGB) and
 # the top/bottom, since this is what pdl requires
 $img = $img-&gt;slice("2:0,:,-1:0");
&#13; # write a pnm file
 wpnm $img, 'frame.ppm', 'PPM', 1;
</pre>

  <p>Instead of simply writing the image unchanged, we could
  perform some transformations on it. For instance, this enhances
  the contrast:</p>
  <pre>
 $img -= $img-&gt;min;
 $img = byte (ushort($img) * 255 / $img-&gt;max);
</pre><font face="verdana" size="1"><b>Figure 1a.</b> A frame from
<i>Plan 9 from Outer Space</i>.</font><br>
  <img src="images/lehmann-01.gif" width="319" height="240" border=
  "0" alt="A frame from Plan 9 from Outer Space."><br clear="all">

  <p>Or we could mask out parts of the image that are brighter than
  a given threshold. Figure 1a is a frame from the movie "Plan 9
  from Outer Space", captured with Perl and saved without any
  modifications. Figure 1b is another image, with part of the sky
  masked out (replaced by black) before saving, using PDL
  code.</p><font face="verdana" size="1"><b>Figure 1b.</b> Using
  PDL to black out the sky.</font><br>
  <img src="images/lehmann-02.gif" width="321" height="208" border=
  "0" alt="Using PDL to black out the sky."><br clear="all">

  <h3>Capturing Frames in a Loop</h3>

  <p>When capturing multiple frames, we have a classic buffering
  problem. While we're in the middle of processing one frame, we
  have to begin processing the next to avoid missing it. All V4l
  drivers can therefore accept at least one call to
  <tt>capture()</tt> in advance. To capture frames in a loop we
  have to start capturing the next frame and then sync on the
  previous one:</p>
  <pre>
 # It is always good to use variables for width and height
 my ($w, $h) = (640, 480);
&#13; my $buffer = 0; # the buffer to use next
&#13; # start capturing the first frame
 my $frame = $grab-&gt;capture($buffer, $w, $h);
&#13; # enter an endless capturing loop
 for (;;) {
    # start capturing the next frame
    my $next_frame = $grab-&gt;capture (1-$buffer, $w, $h);
&#13;    # sync the current frame
    $grab-&gt;sync($buffer) or die "unable to sync";
&#13;    # Now do something with the frame data in $frame
    dosomething $frame;
&#13;    # And now switch buffers
    $buffer = 1 - $buffer;
    $frame = $next_frame;
 }
</pre>

  <p>The variable <tt>$buffer</tt> contains the number of the
  buffer, 0 or 1, used to capture the current frame.
  <tt>1-$buffer</tt> is thus the number of the other buffer.</p>

  <p>So the loop simply starts by capturing the "next" frame
  (<tt>1-$buffer</tt>) and then syncs on the "current" frame. After
  that the script has 0.02 seconds (for the PAL and SECAM
  television formats; about 0.0167 seconds for NTSC) to process the
  image data. After processing, the buffers are switched, and
  <tt>$next_frame</tt> becomes the current frame
  (<tt>$frame</tt>).</p>

  <p>The example script <tt>examples/grab</tt> prints some
  information about your capturing hardware and then jumps into
  exactly this loop, so it's a good starting point when you want to
  create your own capturing applications.</p>

  <h3>Channels, Tuners, and Audio and Picture Settings</h3>

  <p>If the above scripts show white noise <i>without</i> printing
  an error, then your hardware probably wasn't initialized or tuned
  to a channel. In that case, starting a program like
  <tt>XawTV</tt> and selecting a TV channel before starting the
  Perl script should initialize your video card and tune it to a
  useful source.</p>

  <p>Most of my applications let the user use his program of choice
  to select the video source. In contrast, the V4l module offers
  full control over the video hardware.</p>

  <p>There are a number of building blocks in the V4l system, all
  of which are represented by some object on the Perl level. The
  most important of these objects is the "device" object, which
  represents a single video device in the system. It is returned by
  a call to <tt>Video::Capture::V4l-&gt;new</tt>(<i>path</i>) and
  can be used to query your hardware's name, type, and
  capabilities. The examples/grab script contains code that prints
  out all useful information about device (and other) objects:</p>
  <pre>
 print "Device: ";
 print "name ",$grab-&gt;name;
 print ", type";
 for (qw(capture tuner teletext overlay chromakey clipping
         frameram scales monochrome subcapture)) {
    print " $_" if eval "\$grab-&gt;$_";
 }
 print ", channels ", $grab-&gt;channels;
 print ", audios ", $grab-&gt;audios;
 print ", sizes ", $grab-&gt;minwidth, "x", $grab-&gt;minheight,
       "-", $grab-&gt;maxwidth, "x", $grab-&gt;maxheight;
 print "\n";
 
</pre>

  <p><tt>$grab-&gt;name</tt> returns the device name,
  <tt>$grab-&gt;capture</tt> returns a boolean specifying whether
  the hardware can do video capturing, and so on. Here's the result
  for my video card:</p>
  <pre>
 Device: name BT878(Hauppauge new),
         type capture tuner teletext overlay clipping
              frameram scales,
         channels 3,
         audios 1,
         sizes 32x32-924x576
</pre>

  <p>The "channels" entry shows the number of video sources the
  card supports; my card supports television, composite, and
  S-video inputs. The "audios" entry shows the number of audio
  sources.</p>

  <p>Each of the "channels" and "audios" is represented by another
  object, which is returned by a call to the <tt>channel</tt> and
  <tt>audios</tt> methods. To get information about the first video
  source, you would use a call to <tt>my $channel =
  $grab-&gt;channel(0)</tt>. The <tt>grab</tt> example script
  iterates through all channels and audio sources and prints some
  information about them:</p>
  <pre>
 Channel 0: name Television, tuners 1, flags tuner audio, 
type tv, norm 0
 Channel 1: name Composite1, tuners 0, flags audio, type 
camera, norm 0
 Channel 2: name S-Video, tuners 0, flags audio, type 
camera, norm 0
&#13; Audio Channel 0: volume 65535, bass 32768, treble 32768,
                  flags volume bass treble, name TV, mode 1,
                  balance 0, step 0
</pre>

  <p>You can change the settings for specific objects by calling
  the same methods used for querying, followed by a call of the
  <tt>set()</tt> method to inform the video driver of your change.
  For instance, to set the broadcast norm of the first channel to
  PAL:</p>
  <pre>
 my $channel = $grab-&gt;channel(0);
&#13; $channel-&gt;norm(MODE_PAL);
 $channel-&gt;set;
</pre>To tune the bass setting to its maximum, you do this:
  <pre>
 # get the audio object
 my $audio = $grab-&gt;audio(0);
&#13; # set bass to the maximum
 print "old setting: ", $audio-&gt;bass, "\n";
&#13; $audio-&gt;bass(65535);
 $audio-&gt;set;
&#13; print "new setting: ", $audio-&gt;bass, "\n";
</pre>

  <p>Another interesting attribute is the mode of the audio source.
  <tt>mode</tt> can be set to <tt>SOUND_MONO</tt>,
  <tt>SOUND_STEREO</tt>, <tt>SOUND_LANG1</tt>, or
  <tt>SOUND_LANG2</tt>. Most cards (or actually their drivers)
  automatically detect whether an audio source is mono, stereo, or
  dual-channel, so about the only time you need to change this
  setting is when you want to hear the second language in
  dual-channel mode (this is quite common in Europe).</p>

  <p>In addition to being able to control audio parameters, most
  cards can control picture settings. Just as your TV can change
  contrast, hue, color, and brightness, so can V4l:</p>
  <pre>
 my $picture = $grab-&gt;picture;
&#13; # the range of all settings is 0-65535
&#13; # set contrast to some medium level
 $picture-&gt;contrast(27648);
&#13; # the same for brightness
 $picture-&gt;brightness(32000)
&#13; # better leave the hue setting alone, as, for PAL,
 # changing the hue angle starts to cancel the color
 # this is only sensible for the NTSC norm... ;)
&#13; # we want a slightly color-intensive picture
 $picture-&gt;colour(32900);
&#13; # do not forget to call "set"!
 $picture-&gt;set;
</pre>

  <p>In general, both the audio and picture settings should only be
  changed by human interaction, as every card reacts differently to
  the values.</p>

  <p>Going back to the channels, we can see that the composite and
  S-video inputs have the type <tt>camera</tt>, which means they
  are hardwired to some physical device (usually a camera). The
  television input is of type <tt>tv</tt> and has a <tt>tuner</tt>
  associated with it.</p>

  <p>A tuner is used to select different channels multiplexed on
  the same medium. The tuner is what lets you tell your card which
  TV channel, out of all the channels you could possibly receive,
  is the one you want to receive now. Just like all other objects,
  you can access the tuner object by calling the <tt>tuner</tt>
  method of the V4l object:</p>
  <pre>
my $tuner = $grab-&gt;tuner(0);
</pre>

  <p>Check out the <tt>grab</tt> script to learn about your tuner's
  attributes. Mine has these:</p>
  <pre>
 Tuner 0: name Television, range 0-4294967295,
         flags pal ntsc secam, mode 0, signal 0
</pre>

  <p>The most important setting is <tt>mode</tt>, which must be one
  of <tt>TUNER_AUTO</tt>, <tt>TUNER_NTSC</tt>, <tt>TUNER_PAL</tt>,
  or <tt>TUNER_SECAM</tt>. Since <tt>TUNER_AUTO</tt> doesn't work
  with most cards, you'll probably have to choose the mode
  yourself. The <tt>signal()</tt> method returns the strength of
  the received video signal (0-65535) and can be used to decide
  whether there's video to be had on a particular frequency.
  Unfortunately, <tt>signal()</tt> is not well defined. It can take
  a few seconds until the card has finished its measurement, and
  not all cards support it.</p>

  <p>Interestingly, there is no method to set the frequency in the
  tuner object. The only way to set a frequency is using the
  <tt>freq()</tt> method of the <tt>Video::Capture::V4l</tt> object
  itself. I am not sure why Video4linux supports many tuners when
  you cannot use them independently, but hopefully the next version
  will be saner.</p>

  <p>Many programs (and many example scripts) use something like
  the following to tune to some channel (all values are
  hardwired):</p>
  <pre>
 use Video::Capture::V4l;
&#13; # Initialize the card and tune it to a specific frequency
&#13; # "Arte" uses this frequency in my city
 my $freq = 140250;
&#13; my $grab = new Video::Capture::V4l
    or die "unable to open video device";
&#13; my $channel = $grab-&gt;channel(0);
 my $tuner   = $grab-&gt;tuner(0);
&#13; # Let's use PAL
 $channel-&gt;norm(MODE_PAL); $channel-&gt;set;
 $tuner-&gt;mode(TUNER_PAL); $tuner-&gt;set;
&#13; # now tune
 $grab-&gt;freq($freq);
&#13; # and sleep for 400 milliseconds 
 # while letting the card lock to the channel
 select undef, undef, undef, 0.4;
</pre>

  <h3>Magic Constants for Frequencies?</h3>

  <p>Note that the above code hardcodes a frequency for the city
  where I live. You can expect that the frequencies used by TV
  stations will vary from town to town, or cable network to cable
  network. (That's why a new TV has to scan for available channels
  before it can be used.) Later in this article, I'll describe a
  small program that can automate this task. But first, I'll
  explain some of the standards used to manage these
  frequencies.</p>

  <p>To help poor programmers like us, there is a module called
  Video::Frequencies (part of the Video::Capture::V4l package),
  which does nothing more than export some useful tables. (Unlike
  its V4l mother module, it is fully documented.)</p>

  <p>For example, it tells me that Germany, Kuwait, and Sudan use
  the PAL format, while Chile, Taiwan, and the U.S. use NTSC. It
  also exports (among others) the hashes <tt>%NTSC_BCAST</tt> (U.S.
  broadcast), <tt>%NTSC_CABLE_JP</tt> (Japan cable) and
  <tt>%PAL_EUROPE</tt> (Europe broadcast).</p>

  <p>These hashes contain the official channel name to frequency
  mappings; for instance, <tt>%PAL_EUROPE</tt> defines channels
  21-69, E2-E12, S01-S03, and SE1-SE20. What counts is not these
  historically-derived and senseless designations, but that you
  often get a table from your cable or broadcast provider that
  tells you that, in your area, channel "E2" corresponds to
  "Zweites Deutsches Fernsehen".</p>

  <p>Instead of hardwiring the channel frequency we could also
  hardwire the channel designation (which is slightly better than
  before):</p>
  <pre>
 use Video::Frequencies;
&#13; $freq = $PAL_EUROPE{E2};
</pre>

  <h3>Example: Image Sequence Detection</h3>

  <p>In addition to the <tt>examples/grab</tt> script, there are a
  few other examples that might give you interesting ideas. The two
  scripts <tt>indexer</tt> and <tt>finder</tt> together implement
  the "identify re-occurring image sequences" task I needed to
  recognize my favorite show.</p>

  <p><tt>indexer</tt> is used to record an image sequence by
  scaling a 128x128 color image down by a factor of 8 (to 16x16)
  and writing these into a file named <tt>db</tt>. More interesting
  is the script <tt>finder</tt>, which constantly captures video
  images, scales them down (just like <tt>indexer</tt>), and
  compares them to the images stored in the database.</p>

  <p>While the first implementation of these scripts used PDL, I
  didn't want to waste more CPU power than necessary
  (<tt>finder</tt> might run in the background for many hours), so
  I implemented some functions inside the V4l module. While this is
  not very clean programming practice, it was easy to add a few
  functions to <tt>V4l/V4l.xs</tt>, written in C for speed. (My
  first prototype was written in PDL, of course.)</p>

  <p>The inner loop of <tt>finder</tt>, for example, is just:</p>
  <pre>
 # reduce2 reduces the image size by two in each dimension
 Video::Capture::V4l::reduce2($fr, $w&lt;&lt;4);
 Video::Capture::V4l::reduce2($fr, $w&lt;&lt;3);
 Video::Capture::V4l::reduce2($fr, $w&lt;&lt;2);
 Video::Capture::V4l::reduce2($fr, $w&lt;&lt;1);
&#13; # normalize() does some primitive contrast enhancement
 Video::Capture::V4l::normalize($fr);
&#13; # findmin compares the frame $fr to all images
 # in the database $db, by summing pixel differences
 ($fr, $diff) = Video::Capture::V4l::findmin ($db, $fr,
                        $expect_frame, $expect_count);
&#13; # remember the frame number
 push(@reg, $this_frame, $fr);
&#13; # linreg is a simple linear approximation
 my ($a, $b, $r2) = Video::Capture::V4l::linreg(\@reg);
 my $b1 = abs($b-1);
 if ($r2 &lt; 100 &amp;&amp; $b1 &lt; 0.01) {
    $found++;
    print "LOCKED\n";
    # do something
 }
</pre>

  <p><tt>findmin()</tt> simply compares the frame to all frames
  stored in the database by taking pixel differences and summing
  these together. The smaller the difference, the more similar the
  frames. While false hits are quite common, a linear regression
  afterwards filters them out. Since the images are sent in the
  same sequence as they were recorded, the detected frame numbers
  should increase monotonically by one when the script has
  synchronized the database to the video stream. The
  <tt>finder</tt> script tries to detect repeated sequences and
  filter out jitter.</p>

  <h3>Example: Real Time Video Capturing</h3>

  <p>The second capturing problem I had was to capture a full movie
  (&gt; 1 hour) in high resolution (640 x 480 or even higher). A
  small calculation will show you why this is indeed a problem: 640
  x 480 pixels, two bytes per pixel when digitized, and 25 frames
  per second makes for a data rate of 640 * 480 * 2 * 25 == 15
  megabytes per second. And that's not even full resolution. Nor
  does it include audio. It is very difficult (read: impossible) to
  get a PC to handle this data rate steadily over extended periods.
  Remember that there must never be a pause longer than 20
  milliseconds, or else the next frame will be lost.</p>

  <p>I first experimented with a program named <tt>streamer</tt>,
  striping the movie data to different partitions. However, even
  with real time priority, Linux sometimes paused the program for
  too long.</p>

  <p>The next thing to try was writing a new program, in Perl of
  course. The key idea was to compress the image data before
  writing it to the disk, since this not only saves space (one hour
  of uncompressed movie requires about 52 gigabytes!), but also
  cuts down on the required I/O bandwidth. I took the existing
  RTjpeg code by Justin Schoeman and wrote a Perl interface to
  it.</p>

  <p>The compelling reason to use Perl, however, was that my
  machine (a dual P-II 333) was fast enough to compress the stream
  in real time when I used two CPUs, but a single CPU wasn't fast
  enough. Thus, my capturing program had to manage a process that
  captures and which avoids other blocking syscalls, a process that
  captures the audio, and two or more processes that encode video
  images into a file. Splitting the encoding work into multiple
  processes (and files) also made it easier to surpass the two
  gigabyte filesize limit on Linux. Implementing all this logic and
  experimenting with different implementations in C would have been
  much more difficult.</p>

  <p>This capturing script is named <tt>examples/capture</tt> in
  the Video::Capture::V4l distribution. I confess that I'm lousy at
  designing user interfaces: you have to edit it manually before
  you can use it.</p>

  <p>The first thing the program does is to fork the audio
  capturing and video compression processes. It then goes into the
  "standard" capturing loop we already saw. It then writes the
  image data into a shared memory segment (using Perl's
  <tt>shmwrite</tt> builtin) and notifies an encoding process that
  a new frame has arrived, to avoid being paused by some slow
  subprocess (or heavy disk activity).</p>

  <p>The encoding process sits in a tight loop reading frame data,
  compressing it and writing it to a file:</p>
  <pre>
 # quality factor (255 is highest quality and corresponds to
 # a setting of 75 in the IJG jpeg library)
 my $Q = 255;
&#13; # $M is the motion suppression value. 0 is the highest quality
 my $M = 0;
&#13; # create the output file
 open DATA, "datafile" or die "$!";
&#13; # initialize the compressor (the RTjpeg codec is not
 # thread safe, so we need one process per encoder!)
 my $tables = Video::RTjpeg::init_compress(640, 480, $Q);
&#13; # also initialize motion suppression
 Video::RTjpeg::init_mcompress();
&#13; # save the compression parameters to the file
 syswrite DATA, $tables;
&#13; for (;;) {
    ...wait for next frame...
&#13;    # read the image data
    shmread $shm, $buf, $buffer * $fsize, $fsize;
&#13;    # Motion compression. Since many movies are shown
    # with black bars when broadcast on TV, you can
    # specify the offset and size of the image part you want
    # to compress. This saves a lot of time!
    my $fr = Video::RTjpeg::mcompress($buf, $M, $M&gt;1,
                                     $x, $y, $w, $h);
&#13;    # write the frame data
    syswrite DATA, $fr;
 }
</pre>

  <p>The script <tt>examples/xsview</tt> is a very simple viewer
  (not real time, of course) that reads the stream files and
  uncompresses the images in order. <tt>examples/mp2enc</tt> is a
  similar script that uses <tt>mp2enc</tt> to encode the images
  into a standard MPEG-1 (layer II) stream.</p>

  <p>The only remaining question I have is: "Why hasn't anybody
  else used the RTjpeg codec so far"? As far as I know, the V4l
  Perl module is the only place where that code is actually
  used.</p><b>Part II: The Vertical Blanking Interval</b>

  <p>In the second part of this article I will describe the
  vertical blanking interval (VBI) decoder included with the V4l
  module.</p>

  <p>Not all of the 625 lines of a standard PAL frame are used for
  the image; some of them are empty, providing the TV set with some
  regeneration time so that the electron gun can move from the
  bottom of the screen back to the top.</p>

  <p>32 of these empty lines can carry data &mdash; videotext, for
  example, or the VPS (video programming service) signal used to
  tell my VCR when a specific program starts and stops.</p>

  <p>Videotext is pretty boring, but I wanted to find out why the
  VPS signal didn't work for my favorite TV show. To give you an
  impression of what the VBI looks like, I made a few snapshots of
  the raw analog data. Figure 2a is a snapshot of the VBI area of
  <i>France 3</i>, which is quite boring and contains a line
  carrying the VPS signal (the first non-empty line), two test
  patterns, and a single line with videotext information. Since
  each PAL frame consists of two half-frames, the pattern is
  repeated for the other frame. Using only a single line for
  videotext means that you can receive about two videotext pages
  per second. The videotext line is a bit darker because the
  frequency used to transmit videotext is slightly higher than most
  other protocols used in the VBI.</p><font face="verdana" size=
  "1"><b>Figure 2a.</b> The vertical blanking interval of the
  <i>France 3</i> channel.</font><br>
  <img src="images/lehmann-03.gif" width="500" height="78" alt=
  "The vertical blanking interval of the France 3 channel.">

  <p>Figure 2b shows the VBI lines of <i>Premiere World</i>,
  featuring videotext (the first six lines), four lines of some
  encrypted data (it's pay-TV), a single line carrying the VPS
  signal, three lines used to transmit test patterns and two
  additional videotext lines. The pattern is then repeated for the
  second half-frame.</p><font face="verdana" size="1"><b>Figure
  2b.</b> The vertical blanking interval of the <i>Premeire
  World</i> channel.</font> <img src="images/lehmann-04.gif" width=
  "500" height="78" alt=
  "The vertical blanking interval of the Premeire World channel.">

  <p>The last example (Figure 2c) is from <i>NBC Europe</i>. Apart
  from the two bright test patterns, it consists of only videotext
  lines. The reason is that NBC Europe transmits MP3 data at 128
  kilobits per second, which requires almost the full bandwidth
  that is available. This also causes its much more random-looking
  appearance &mdash; videotext is quite repetitive compared to MP3
  data!</p><font face="verdana" size="1"><b>Figure 2c.</b> The
  vertical blanking interval of <i>NBC Europe.</i></font> <img src=
  "images/lehmann-05.gif" width="500" height="78" alt=
  "The vertical blanking interval of NBC Europe.">

  <p>Of course, you don't need to understand all these patterns to
  use the VBI module. An easier way to detect the kinds of services
  available on a channel is to run the <tt>examples/vbi-info</tt>
  script (a video capturing program like <tt>XawTV</tt> can run in
  parallel with a program using VBI, so that you can, for example,
  capture videotext in the background while viewing TV). Here is
  the output for some channels:</p>
  <pre>
 # France 3
  alloc[.........OOO.T...........OOO.T..]
  VT NI30/1[33f3=France 3]
 # Premiere
  alloc[TTT.TccccVOOOTT.TTT.Tcccc.OOOTT.]
  3/31[f] VPS[fdac=Premiere|PREMIERE] VT NI30/1[0000=]
 # Eurosport
  alloc[TTTTTTTTTVOOTTTTTTTTTTTTT.O.TTTT]
  VT 2/31[0] NI30/1[fe01=Euronews] 0/31[0] 7/31[0]
  2/31[ffffff] 3/31[7] EPG VPS[0000=|] 1/31[0]
 
</pre>

  <p><tt>alloc</tt> shows the allocation of VBI lines to services.
  A dot means that no signal was detected. <tt>T</tt> stands for
  videotext, <tt>V</tt> for VPS, <tt>c</tt> for encrypted video,
  and <tt>O</tt> for other signals. In addition to identifying the
  lines, <tt>vbi-info</tt> decodes the videotext and VPS lines a
  bit more. For instance, <i>France 3</i> transmits a so-called
  "Network Identification" code. You can import the hash
  <tt>%VT_NI</tt> from the <tt>Video::Capture::VBI</tt> module that
  maps NI-codes (like <tt>33f3</tt>) to station names (like
  <tt>France 3</tt>).</p>

  <p><i>Premiere</i> additionally sends a VPS line (which contains
  another datum called the CNI (Country and Network Identification)
  code. <tt>%VPS_VNI</tt> maps CNI codes to names.</p>

  <p><i>Eurosport</i> features videotext and an "Electronic Program
  Guide" (EPG).</p>

  <p>Some channels even send Intercast (IC), which is actually the
  Internet protocol over videotext!</p>

  <h3>Standards</h3>

  <p>Unfortunately, most of these protocols are based on videotext,
  which is a very old protocol. It was invented at a time where you
  had to be really careful not to waste a single bit, and where
  data compression wasn't used at all. The main task of the
  Video::Capture::VBI module therefore is to analyze the VBI lines
  and do all the bit-shifting and unscrambling of the VBI data,
  returning some decoded representation.</p>

  <p>To understand this, however, you still have to know what to
  expect. The best sources of information are the teletext
  (videotext) standards itself. The ETSI (European
  Telecommunications Standards Institute) publishes almost all of
  their standards on the web, and for free, which is very nice (and
  the exception for standards organizations). The appendix mentions
  some of the more important standards and their purpose.</p>

  <p>The ETSI standards apply only to PAL television, and therefore
  mostly to western European countries only. If you look at the
  source (<tt>VBI/VBI.xs</tt>) you can see that the PAL and NTSC
  formats use different frequencies to encode videotext, so you'll
  need to change the source to make it work with NTSC (just look
  for <tt>FREQ_VT_NTSC</tt> and follow the comments).
  Unfortunately, just changing the frequency won't work, since the
  actual encoding is different.</p>

  <p>This means that while PAL users can use the module out of the
  box, NTSC users will need to work at it &mdash; but can be sure
  that whatever they discover will be relatively new knowledge,
  since the millions of other V4l users all use PAL. If you find
  any standards on non-European teletext or other protocols I
  haven't found yet I'd love to hear from you.</p>

  <h3>Decoding VPS</h3>

  <p>Capturing vertical blanking intervals is even easier than
  capturing image data:</p>
  <pre>
 use Video::Capture::V4l;
 use Video::Capture::VBI;
&#13; my $vbi = new Video::Capture::V4l::VBI
     or die "unable to create VBI capturing object";
&#13; # the next line is optional
 $vbi-&gt;backlog(25); # max. 1 second backlog (~1600kb)
&#13; # we all love endless loops ;)
 for (;;) {
    # retrieve next vbi frame
    my $field = $vbi-&gt;field;
&#13;    # decode the field and iterate over
    # all lines
    for (decode_field $vbi, VBI_VPS) {
       #... do something
    }
 }
 
</pre>

  <p>Capturing and decoding the VBI are two separate tasks, and
  also two separate modules. The idea is that Video::Capture::V4l
  captures VBI data using the V4l API (which is very
  system-specific), but the actual VBI processing is done in an
  OS-independent way (Video::Capture::VBI). This means that, in the
  future, other API's besides V4l could be supported.</p>

  <p>The program first creates a VBI capture object (of type
  Video::Capture::V4l::VBI). The next line of code creates a cache
  of 25 frames. This is implemented by launching a separate thread
  that captures VBI frames and queues them in memory, so your
  program can take as long as one second to process a frame without
  losing any intermediate data. Since each frame requires 64
  kilobytes of memory, 25 frames require 1.6 megabytes. Not too
  much, but if your program is fast enough (or you can tolerate
  skipped frames) leave out this line to conserve memory.</p>

  <p>It then enters an endless capturing loop. If you want, you can
  use <tt>select</tt> (or the great <tt>Event</tt> module) to wait
  on the filehandle returned by the <tt>fileno</tt> method:</p>
  <pre>
 use Video::Capture::V4l;
 use Event;
&#13; my $vbi = new Video::Capture::V4l::VBI
     or die "unable to create VBI capturing object";
&#13; Event-&gt;io(fd =&gt; $vbi-&gt;fileno, poll =&gt; "r", cb =&gt; sub {
    my $field = $vbi-&gt;field;
    #... decode and process the field
 });
 
</pre>

  <p>Inside our capture loop, we just fetch the next VBI field and
  call <tt>decode_field()</tt>, a function exported from the
  <tt>Video::Capture::V4l</tt> module. <tt>decode_field()</tt>
  takes two arguments: the VBI data (a Perl scalar with a length
  that's a multiple of 2048) and a bitmask that specifies which
  types of VBI lines you are interested in, or'ed together. In this
  example that's merely <tt>VBI_VPS</tt>, but if we were interested
  in both VPS and videotext lines we would use <tt>VBI_VPS |
  VBI_VT</tt>.</p>

  <p><tt>decode_field()</tt> decodes all the lines that you
  requested and returns an array reference for each line it could
  decode (that is, it returns an array of array references). The
  content of these arrays depends entirely on the line data and
  differs for each packet type.</p>

  <p>All VPS lines follow the same pattern, including several
  time-related fields that specify the time of the <i>last</i>
  program that started. A VCR constantly compares the programmed
  date/time with the date/time sent via VPS and, if equal, starts
  recording. The reason this didn't work in my case -- the problem
  that inspired the module in the first place -- was that the VPS
  signal switch was performed manually. For instance, the change
  from 13:55 to 14:10 took a few seconds and went like this:
  <tt>13:55 =&gt; 14:55 =&gt; 14:15 =&gt; 14:10</tt>, and was often
  delayed or simply forgotten. <i>Sigh</i>.</p>

  <h3>The Autotune Script</h3>

  <p>Now we are ready to look at how the <tt>examples/autotune</tt>
  script works. If you use XawTV to watch television, you can
  automate the task of scanning channels. The basic idea of the
  autotune script is to scan through all channels, wait a bit, test
  wether a valid TV signal is being received, and try to identify
  the sender name. With all the modules we know, this should be
  relatively easy.</p>

  <p>First of all, we need control over both the tuner and the VBI
  device:</p>
  <pre>
 $v4l = new Video::Capture::V4l;
 $tuner = $v4l-&gt;tuner(0);
 $channel = $v4l-&gt;channel(0);
 $tuner-&gt;mode(TUNER_PAL); $tuner-&gt;set;
 $channel-&gt;norm(MODE_PAL); $channel-&gt;set;
&#13; $vbi = new Video::Capture::V4l::VBI or die;
</pre>

  <p>The next step is to load an existing <tt>~/.xawtv</tt> config
  file, which we can parse with the Video::XawTV module.</p>

  <p>One of the useful things stored inside the <tt>.xawtv</tt>
  file is the frequency table that should be used (for example,
  <tt>pal-europe</tt>). The Video::Frequencies module provides a
  hash named <tt>%CHANLIST</tt> that maps these
  frequency-table-names into the actual frequency table. Iterating
  through all possible frequencies is thus quite easy:</p>
  <pre>
 # create a new Video::XawTV-object and try to load
 # an existing ~/.xawtv file
 $rc = new Video::XawTV;
 eval { $rc-&gt;load("$ENV{HOME}/.xawtv") };
&#13; # use the frequency table specified in it
 $ftab = $rc-&gt;opt('freqtab') || "pal-europe";
 $freq = $CHANLIST{$ftab} 
or die "no such frequency table: $ftab";
&#13; # channel information will be stored here
 my @channels;
&#13; # now iterate through all frequencies
 for $chan (sort keys %$freq) {
    # tune to channel $chan and try to detect the sender
 }
&#13; # store the channel information int he XawTV-Object...
 $rc-&gt;channels(@channels);
 # and save it locally (don't overwrite the user's file!)
 $rc-&gt;save("xawtvrc");
</pre>

  <p>Inside the <tt>for</tt> loop, we first tune to the new
  frequency:</p>
  <pre>
   my $f = $freq-&gt;{$chan};
   print "tuning to $chan ($f)...";
   $vbi-&gt;backlog (0); # don't save frames from old channel
   $v4l-&gt;freq($f);
   select undef, undef, undef, 0.2;
 
</pre>

  <p>Before tuning we remove any saved VBI frames using
  <tt>backlog(0)</tt>. Otherwise we might miss a new channel while
  analyzing frames from the previous one.</p>

  <p>After setting the frequency, we have to wait a bit until the
  tuner stabilizes. While 200 milliseconds is good enough for my
  video card, it might be too long or too short for your card, so
  you might want to play around with that number if some channels
  can't be detected because the tuner can't cope with our
  speed.</p>

  <p>Once the tuner is stabilized we can measure the signal
  strength. If it is more than 30000, we assume that a sender was
  received.</p>
  <pre>
   if ($tuner-&gt;signal &gt; 30000) {
      # capture 30 frames (at least one second)
      $vbi-&gt;backlog (30);
      # wait some time so the buffer fills
      select undef, undef, undef, 1.6;
      # as long as frames are available...
      while ($vbi-&gt;queued) {
         # decode frame and analyze...
         for (decode_field $vbi-&gt;field, VBI_VT|VBI_VPS) {
            #
            #  check VBI line data
            #
         }
      }
   }
   
</pre>

  <p>The <tt>autotune</tt> script then jumps through hoops to do
  the actual sender name detection. It takes about a minute to scan
  all 106 frequencies in PAL-Europe (most of which are
  empty).</p><b>Decoding Videotext</b>

  <p>The VPS signal is pretty lame. It always uses the same format,
  is well-specified, and is very consistent between stations.
  However, videotext and teletext are nothing like that. They use a
  wild assortment of different encodings for different lines,
  binary data (MP3, Intercast), VCR programming information,
  subtitles, navigational hints, program guide information, and
  occasionally just plain text.</p>

  <p>This leads to the unsatisfactory situation where you have to
  first decode videotext pages, and then dissect some of those
  videotext pages into two or more datastreams, and finally decode
  these streams into EPG blocks, all just to get at the Electronic
  Program Guide. The Video::Capture::VBI module handles most of
  this.</p>

  <p>Now to the basics of videotext: The three digits used to
  select a specific teletext page (000-799) are actually three hex
  digits. The rule is: "If it's decimal digits, it contains
  human-viewable teletext data. If it's hexadecimal data, it's
  probably something else." "Normal" (non-subtitled) teletext pages
  contain 24 lines. Each VBI line corresponds to one line of the
  page (pages used for subtitles usually contain a single line
  only).</p>

  <p>The first line (number zero) contains only the page number,
  the sender name, and the current time. The lines that follow
  contain the meat of the data.</p>

  <p>In practice, there are oddities like <i>subpages</i> (pages
  consisting of more than one screen) and i<i>nterleaved pages</i>
  (since subtitles and other pages can temporarily interrupt other
  pages). Not to worry: all of this is handled by the
  Video::Capture::VBI::VT class. Using it is as simple as
  subclassing it:</p>
  <pre>
 package MyDecoder;
&#13; use Video::Capture::VBI;
&#13; # derive from videotext-decoder
 use base 'Video::Capture::VBI::VT';
&#13; # enter_page gets called for each assembled page
 sub enter_page {
    my($self, $page)=@_;
    my $sub = $page-&gt;{ctrl} &amp; VTX_SUB;
&#13;    printf "Teletext page %03x / %04x\n",$page-&gt;{page},$sub;
    print "subtitle page\n"  if $page-&gt;{ctrl} &amp; VTX_C5;
    print "newsflash page\n" if $page-&gt;{ctrl} &amp; VTX_C6;
&#13;    # now print the page
    for ($y=0; $y&lt;25; $y++) {
       my $x = $page-&gt;{packet}[$y];
       print $x ? decode_ansi decode_vtpage $x : "","\n";
    }
 }
&#13; # other (non-page-related) teletext packages end up here
 sub enter_packet {
    my $packet = $_;
 }
</pre>

  <p>The Video::Capture::VBI::VT class implements a simple teletext
  decoder. The class itself does nothing with the decoded data
  unless you overwrite either <tt>enter_page()</tt> or
  <tt>enter_packet()</tt>, which are called whenever pages or
  packets are received.</p><font face="verdana" size="1"><b>Figure
  3.</b> Text hidden in the vertical blanking interval.</font><br>
  <img src="images/lehmann-06.gif" width="396" height="297" border=
  "0" alt=
  "Text hidden in the vertical blanking interval."><br clear="all">

  <p>The VBI module defines two functions to convert the videotext
  data into a human-readable form: <tt>decode_vtpage()</tt>, which
  returns text in a national language encoding, and
  <tt>decode_ansi()</tt>, which takes that text and tries to
  approximate the page using ANSI codes. These functions can be
  used to display the blocky graphics of the vertical blanking
  interval, as shown in Figure 3.</p>

  <p>Figure 4 shows an index page using the <i>vtx</i> web
  interface (which is part of the PApp Perl module). Videotext
  suddenly becomes usable when it is hyperlinked!</p><font face=
  "verdana" size="1"><b>Figure 4.</b> Hypertext derived from the
  vertical blanking interval.</font><br>
  <img src="images/lehmann-07.gif" width="237" height="396" border=
  "0" alt=
  "Hypertext derived from the vertical blanking interval."><br clear="all">


  <p>To manipulate the Electronic Program Guide, the
  Video::Capture::VBI::VT module was subclassed to create the
  Video::Capture::VBI::EPG package. This can be used to present the
  user with a menu of choices ("all movies marked with 2 stars",
  "all documentaries", "all drama movies currently running" and so
  on). Since EPG's can be quite large (up to a quarter megabyte)
  and the data rate is low (sometimes less than one kilobyte per
  second) it can take up to twenty minutes to gather the entire EPG
  database.</p>

  <p>There are three programs in the V4l distribution that cope
  with EPG data: <tt>examples/getepg</tt>, which starts capturing
  EPG data as soon as it receives a valid data stream;
  <tt>examples/dumpepg</tt>, which simply dumps a database in text
  format; and <tt>examples/epgview</tt>, which is a curses-based
  (it requires the Curses module) interactive viewer. It
  continuously updates its display, so I often run it in a separate
  window for the whole evening. That way I always have an
  up-to-date program listing, shown in Figure 5. The perfect toy
  for a TV addict.</p><font face="verdana" size="1"><b>Figure
  5.</b> The Electronic Program Guide</font><br>
  <a href="images/lehmann-08.gif"><img src=
  "images/lehmann-08_th.gif" width="200" height="149" border="0"
  alt="The Electronic Program Guide"></a><br clear="all">
  <br>
  <!-- end of article -->
   _ _END_ _
  <hr>
  <i>Marc Lehmann studies Informatics at the University of
  Karlsruhe, but too much of his time he hacks on things like gcc,
  Gimp, and a lot of Perl.</i>
  <hr>

  <p><b>References</b></p>

  <p>Some resources for your video hacking:</p>&bull;
  Video::Capture::V4l. The module is available on any CPAN mirror
  and should compile cleanly using the CPAN shell.<br>
  &bull; <a href="http://v4l.sourceforge.net/" target=
  "resource window">http://v4l.sourceforge.net/</a>. the V4l module
  is also a project on SourceForge. You can get the newest version
  via CVS.<br>
  &bull; <a href=
  "http://www.wizards.dupont.com/cristy/ImageMagick.html" target=
  "resource window">http://www.wizards.dupont.com/cristy/ImageMagick.html</a>.
  ImageMagick is a formidable image manipulation package that even
  has a nice Perl interface!<br>
  &bull; <a href="http://roadrunner.swansea.uk.linux.org/v4l.shtml"
  target=
  "resource window">http://roadrunner.swansea.uk.linux.org/v4l.shtml</a>.
  The Video4linux standard and applications.<br>
  &bull; <a href="http://millennium.diads.com/bdirks/v4l2.htm"
  target=
  "resource window">http://millennium.diads.com/bdirks/v4l2.htm</a>.<br>

  The Video4linux standard Version 2.<br>
  &bull; <a href="http://www.etsi.org/" target=
  "resource window">http://www.etsi.org/</a>. European
  Telecommunications Standards Institute (ETSI) offers the
  following standards for download:<br>
  &bull; ETS 300 231, Programme Delivery Control (PDC)<br>
  &bull; ETS 300 706, Enhanced Teletext Specification<br>
  &bull; ETS 300 707, Electronic Programme Guide<br>
  &bull; ETS 300 708, Data transmission within Teletext<br>
  &bull; TR 101 231, Country and Network Identification (CNI)
  codes<br>
  &bull; TR 101 233, Code of practice for allocation of services in
  the Vertical Blanking Interval (VBI)<br>
  &bull; TR 101 288, Code of practice for an Electronic Programme
  Guide (EPG)<br>
  &bull; ETR 287, Code of practice for enhanced Teletext<br>
  &bull; ETR 288, Code of practice for an Electronic Programme
  Guide (EPG)<br>
  &bull; EN 300 294, 625-line television Wide Screen Signalling
  (WSS)<br>
  &bull; <a href="http://papp.sourceforge.net" target=
  "resource window">http://papp.sourceforge.net</a>. PApp:
  multi-page-state-preserving web applications.<br>
  Includes a sample application named vtx that "webbifies"
  videotext.<br>
  <!-- link to the previous and next documents relative to the current document -->
  <!-- end of file -->
</body>
</html>
