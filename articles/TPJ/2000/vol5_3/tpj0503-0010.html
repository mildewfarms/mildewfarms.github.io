<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <title>Parsing Natural Language with Lingua::LinkParser - The Perl Journal, Fall 2000</title><!-- end head -->
  <meta name="generator" content=
  "HTML Tidy for Linux/x86 (vers 12 April 2005), see www.w3.org">
  <meta name="vscategory" content="Perl">
  <meta name="vsisbn" content="">
  <meta name="vstitle" content=
  "Parsing Natural Language with Lingua::LinkParser">
  <meta name="vsauthor" content="Dan Brian">
  <meta name="searchdescription" content=
  "Parsing Natural Language with Lingua::LinkParser">
  <meta name="vsimprint" content="The Perl Journal">
  <meta name="vspublisher" content="Earthweb">
  <meta name="vspubdate" content="Fall 2000">
  <!-- always update the article title and issue -->

</head>

<body>
  <font face="verdana" size="1">Issue 19, Fall 2000</font>

  <h2 align="center">Parsing Natural Language with
  Lingua::LinkParser</h2>

  <h4 align="left"><i>Dan Brian</i></h4>
  <!-- packages described, if necessary -->

  <div align="center">
    <table width="475" border="1" cellspacing="0" cellpadding="5">
      <tr>
        <td bgcolor="#CCCC99" align="middle" colspan="2">
        <b>Resources</b></td>
      </tr>

      <tr>
        <td>Link Grammar Parser
        4.1...................................http://www.link.cs.cmu.edu<br>

        Lingua::LinkParser
        1.01....................................................................CPAN</td>
      </tr>
    </table>
  </div>

  <h3>I See a Pattern Developing</h3>

  <p>Regular expressions are one of the triumphs of computer
  science. While often intimidating to beginning programmers, the
  ability to capture complex patterns of text in succinct
  representations gives developers one of the most powerful tools
  at their disposal. Perl's pattern matching abilities are among
  the most advanced of any language, and certainly rank among those
  features which have served to make it one of the most popular
  languages ever created.</p>

  <p>However, regexes can't do everything. When the patterns in
  your data are complex, even Perl's regular expressions fall
  short. Natural languages, like English, aren't amenable to easy
  pattern matching: if you want to find sentences that express a
  particular sentiment, you need to first understand the grammar of
  the sentence, and regular expressions aren't sufficient unless
  you throw a little intelligence into the mix. In this article,
  I'll show how that can be done.</p>

  <p>We will make it possible to write code like this:</p>
  <pre>
    # create an array of everything cool
    while ($sentence =~ /\G($something_that_rocks)/g) {
        push (@stuff_that_rocks, $1);
    }
</pre>

  <p>Our notion of "what's cool" can depend not just on simple
  character patterns, but upon the words in a sentence, and in
  particular their role in the sentence and relationships to one
  another. In brief, this article explores the application of
  regular expressions to grammar. Note that I am <i>not</i>
  suggesting another syntax for regular expressions. From a Perl
  hacker's perspective, what I demonstrate here is an interesting
  application of Perl's overloading ability, and its usefulness
  when applied to a domain that's tough to parse: natural
  language.</p>

  <p>Before explaining the program, we'll explore the intelligence
  that we'll use to parse natural language: the Link Grammar.</p>

  <h3>Link Grammar</h3>

  <p>Many approaches to NLP (Natural Language Processing) have been
  pursued in the past few decades, but few are as popular as the
  Link Grammar parser,(Drs. Sleator and Lafferty hail from the
  computer science department of Carnegie Mellon University, and
  Dr. Temperley from the music department at Eastman. I wanted to
  go to Eastman. It didn't work out.) by Drs. Daniel Sleator, Davy
  Temperley, and John Lafferty. Rather than examine the basic
  context of a word within a sentence, the Link Parser is based on
  a model that words within a text form "links" with one
  another.</p>

  <p>These links are used not only to identify parts of speech
  (nouns, verbs, and so on), but also to describe in detail the
  <i>function</i> of that word within the sentence. It's one thing
  to know that a phrase consists of two adjectives and two nouns --
  but what you really want to know is which adjective modifies
  which noun. The Link Grammar does that for you.</p>

  <p>The Link Grammar is based on a characteristic that its
  creators call <i>planarity</i>. Planarity describes a phenomenon
  present in most natural languages, which is that if you draw arcs
  between related words in a sentence (for instance, between an
  adjective and the noun it modifies), your sentence is
  ungrammatical if arcs cross one another, and grammatical if they
  don't. This is an oversimplification, but it'll serve for our
  purposes.</p>

  <p>In Link Grammar vernacular, a <i>linkage</i> is a single
  successful parse of a sentence: a set of links in which none of
  the connecting arcs cross. A sample parse of the sentence, <tt>A
  camel is a horse designed by a committee</tt> is depicted in
  Figure 1.</p><font face="verdana" size="1"><b>Figure 1.</b> A
  sample parse, with links.</font><br>
  <img src="images/brian-fig1.jpg" width="395" height="77" border=
  "0" alt="Figure 1. A sample parse, with links."><br>
  <br>

  <table cellpadding="5" border="0" align="right">
    <tr>
      <td>
        <table border="0" width="375" cellpadding="5" cellspacing=
        "0" bgcolor="#EFEFCC" align="left">
          <tr>
            <td>
              <h3><font size="-1">A Few Link Grammar
              Connectors.</font></h3>

              <p><tt>A:</tt> connects pre-noun ("attributive")
              adjectives to following nouns:<br>
              "The BIG BLACK UGLY DOG chased me."</p>

              <p><tt>AN:</tt> connects noun-modifiers to following
              nouns:<br>
              "The TAX PROPOSAL was rejected."</p>

              <p><tt>C:</tt> connects conjunctions and some verbs
              to subjects of clauses:<br>
              "He SAID HE was sorry."</p>

              <p><tt>D:</tt> connects determiners to nouns:<br>
              "THE DOG chased A CAT and SOME BIRDS."</p>

              <p><tt>G:</tt> connects proper noun words together in
              series:<br>
              "GEORGE HERBERT WALKER BUSH is here."</p>

              <p><tt>J:</tt> connects prepositions with their
              objects:<br>
              "The man WITH the HAT is here."</p>

              <p><tt>M:</tt> connects nouns to various kinds of
              post-noun modifiers<br>
              (prepositional phrases, participle modifiers, and so
              on):<br>
              "The MAN WITH the hat."</p>

              <p><tt>O:</tt> connects transitive verbs to their
              direct or indirect objects:<br>
              "I GAVE HIM the BOOK."</p>

              <p><tt>S:</tt> connects subject nouns to finite
              verbs:<br>
              "The DOG CHASED the cat."</p>

              <p><tt>W:</tt> connects subjects of main clauses to
              the beginning of the<br>
              sentence, or the "wall".</p>

              <p><tt>X:</tt> connects punctuation symbols to words
              or each other.</p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>

  <p>The primary parts of speech are labeled with <tt>.n</tt> and
  <tt>.v</tt> to indicate that these words are nouns and verbs,
  respectively. The labels of the links between words indicate the
  type of link. For example, the <tt>J</tt> connector in this
  sentence indicates a connection between prepositions and their
  objects; in this case, the verb <tt>designed</tt> is connected to
  <tt>by a committee</tt>, identifying a prepositional phrase. The
  sidebar "A Few Link Grammar Connectors" briefly summarizes the
  links used above and elsewhere in this article.</p>

  <p>The Link Parser 4.0 provides 107 primary types of links
  (indicated by the uppercase letters), with many additional
  subtypes further detailing the relationship of words (indicated
  by the lowercase characters). While the accuracy of the parser is
  remarkable, it is tailored to newspaper-style grammar, and will
  fail with more conversational statements.</p>

  <p>The inner workings of the parser are fairly complex, but they
  use principles which might be familiar. A link grammar considers
  a sentence to be proper if it satisfies three conditions:</p>

  <p>1. Planarity: The link arcs above words do not cross.</p>

  <p>2. Connectivity: The links connect all of the words
  together.</p>

  <p>3. Satisfaction: Individual linking requirements of each word
  are satisfied.</p>

  <p>The parser uses a dictionary that contains the linking
  requirements of each word. For example, the words <tt>the,
  chased, dog,</tt> and <tt>cat</tt> are shown below with their
  linking requirements. The D within the box above the indicates
  that another word must connect with D to the right of the in
  order for the link requirements to be satisfied for that
  word.</p><font face="verdana" size="1"><b>Figure 2.</b> Some
  linking requirements</font><br>
  <img src="images/brian-fig2.jpg" border="0" alt=
  "Figure 2. Some linking requirements"><br>

  <p>For these words to form a sentence, the parser must find them
  in an order which satisfies the above three requirements. When a
  word has more than one row of connectors, only one side (left or
  right) of each row may be connected (e.g. <tt>cat</tt> has a row
  <tt>D</tt> and a row <tt>O/S</tt>, so <tt>D</tt> must be
  connected along with either <tt>O</tt> or <tt>S</tt>). When only
  one row exists on a single level (e.g. <tt>cat</tt> has
  <tt>D</tt>), one connector must be linked. The meaning of each
  link used here is indicated above. Thus, the following
  arrangement is correct: <tt>The cat chased the dog</tt>.</p>

  <p>The unused connectors are grayed out in this example. Since
  our second <tt>the</tt> connects to <tt>dog</tt> as a determiner,
  <tt>chased</tt> actually spans the length, connecting to
  <tt>dog</tt>. You can mentally shuffle these words to see that
  <tt>cat</tt> and <tt>dog</tt> could be swapped, and likely would
  be if our program had any semantic knowledge. Moving other words
  around, however, will break the link criterion and deem the parse
  ungrammatical.</p><font face="verdana" size="1"><b>Figure 3.</b>
  Linking requirements and inferred links.</font><br>
  <img src="images/brian-fig3.jpg" border="0" alt=
  "Figure 3. Linking requirements and inferred links."><br>

  <p>All of these requirements are stored in the Link Parser's
  dictionary files. The files use a "link dictionary language" to
  list the requirements for each word, and are themselves an
  interesting study in pattern representation. A highly optimized
  custom algorithm processes the data in these files, analyzing the
  possible links. This algorithm is yet another fascinating study
  in and of itself.(For those interested, the algorithm is similar
  to the dynamic algorithm for triangulation of a convex polygon,
  and has running time of O(N<sup>3</sup>). The general theory,
  optimizations, and formalisms are all detailed in the
  researchers&rsquo; papers. Frankly, it&rsquo;s remarkable that it
  runs as fast as it does given the computation required.)</p>

  <p>Because the researchers at CMU had the generosity and
  intelligence to make their project research open to developers
  like us, we can examine the ingenuity of their methods. We can
  use and modify their well-conceived API. We can extend and
  combine the functionality of their system with that of other
  language processing technologies. And, of course, Perl makes it
  all possible, practical, and inevitable.</p>

  <h3>Lingua::LinkParser</h3>

  <p>The Link Grammar parser itself is a complex piece of software
  implementing a complex theory of language. The Perl module
  Lingua::LinkParser directly embeds the parser API, providing an
  object-oriented interface that you can use from your Perl
  programs. Objects may be created to represent sentences,
  linkages, links, individual words, and the parser itself. As an
  example, consider the following code:</p>
  <pre>
  use Lingua::LinkParser;
  use strict;

  my $parser = new Lingua::LinkParser;        # create the parser
  my $text   = "Moses supposes his toses are roses.";
  
  my $sentence = $parser-&gt;create_sentence($text); # parse the sentence
  my $linkage  = $sentence-&gt;linkage(1);        # use the first linkage
  
  print $parser-&gt;get_diagram($linkage);         # print it out
</pre>This code will output:
  <pre>
    +-------------------------Xp------------------------+
    |                +------Ce------+                   |
    +---Wd--+---Ss---+      +--Dmc--+--Spx--+--Opt-+    |
    |       |        |      |       |       |      |    |
LEFT-WALL Moses supposes.v his toses[!].n are.v roses.n .
</pre>

  <p>Without delving into all the details, this diagram reveals
  some interesting things about the parser. First,
  <tt>supposes</tt> and <tt>are</tt> have <tt>v</tt> labels,
  indicating that they're verbs. The word <tt>roses</tt> is labeled
  n for noun, as is <tt>toses</tt>. The [!] tag next to
  <tt>toses</tt> indicates that the parser isn't familiar with this
  word, which usually means that it isn't a word at all. So even
  with a word it's never seen before, the Link Grammar can identify
  the part of speech</p>.

  <p>The diagrams help us understand the link grammar, but to use
  the information within a program requires access to the links
  themselves. Continuing with the program above, we will extract
  from the <tt>$linkage</tt> object an array of <tt>$word</tt>
  objects. These will spring into existence, along with a
  <tt>links()</tt> method to return an array of <tt>$link</tt>
  objects. Well, just watch:</p>
  <pre>
    my @words = $linkage-&gt;words;
    foreach my $word (@words) {
        print "\"", $word-&gt;text, "\"\n";
        foreach my $link ($word-&gt;links) {
            print "  link type '", $link-&gt;linklabel, 
              "' to word '", $link-&gt;linkword, "'\n";
        }
    }
</pre>An excerpt from the output:
  <pre>
    "Moses"
      link type 'Wd' to word '0:LEFT-WALL'
      link type 'Ss' to word '2:supposes.v'
    "supposes.v"
      link type 'Ss' to word '1:Moses'
      link type 'Ce' to word '4:toses[!]'
    "his"
      link type 'Dmc' to word '4:toses[!]'
    "toses[!]"
      link type 'Ce' to word '2:supposes.v'
      link type 'Dmc' to word '3:his'
      link type 'Spx' to word '5:are.v'
</pre>

  <p>Knowing the part of speech and linkages of each word allows us
  to use grammatical constructs in a program. Let's write one.</p>

  <h3>Irregular Regular Expressions, Overloaded</h3>

  <p>Returning to our original problem, how can we expand our
  pattern matches to handle grammatical constructs rather than
  simple combinations of metacharacters? We have two tools: the
  Link Parser just described, and Perl's <i>overloading</i>, which
  allows us to redefine how Perl's operators operate. In
  particular, we're going to redefine how Perl processes
  strings.</p>

  <p>Normally, operator overloading is used to extend the
  definition of common operators, like +, so that you can say
  things like <tt>$madness = $vanhalen_mp3 + $vivaldi_mp3</tt> and
  overlay two MP3s as a result.</p>

  <p>For our purposes, we overload double-quote processing in the
  Lingua::LinkParser::Linkage package so that when you print a
  linkage object, it displays a linkage diagram. Furthermore, to
  pattern match the data, we need a format that is more easily
  parsed, but still just a single string. Something like the
  following would be nice, listing the words with their links on
  each side in an ordered, linear format:</p>
  <pre>
(Wd:0:LEFT-WALL          "Moses"      Ss:2:supposes.v) \
(Ss:1:Moses              "supposes.v" Ce:4:toses[!])   \
(                        "his"        Dmc:4:toses[!])  \
(Ce:2:supposes Dmc:3:his "toses[!]"   Spx:5:are.v)     \
</pre>

  <p>We can get this type of output with <tt>print $linkage</tt> by
  modifying the file <tt>Linkage/Linkage.pm</tt> and changing the
  overload behavior. Figure 3 shows the change, illustrating the
  results of <tt>new_as_string()</tt> method rather than the
  <tt>as_string()</tt> method. Now, printing the object
  <tt>$linkage</tt> from the previous examples will output the text
  shown above, in one long string.</p>

  <p>Finally, we can pattern match that text to find what we're
  looking for. In this case, we're going to look for the
  <tt>Ss</tt> link from <tt>Moses</tt>, indicating a connector to
  the verb for our subject:</p>
  <pre>
    $Moses = '"Moses" ';
    $does_something = 'Ss:\d+:(\w+)\.v';
    $action_by_moses = "$Moses$does_something";

    if ($linkage =~ /$action_by_moses/o) {
        print "What does Moses do? He $1.\n";
    }
</pre>

  <p>This prints <tt>What does Moses do? He supposes</tt>. We could
  take the idea further by overloading the right side of our
  regular expressions and getting them to return <tt>word</tt>
  objects, but we won't.</p>

  <p>Peeking under the hood, here's how the overloading is
  implemented.</p>
  <pre>
use overload q("") =&gt; "new_as_string";

sub new_as_string {
    my $linkage = shift;
    my $return = '';
    my $i = 0;
    foreach my $word ($linkage-&gt;words) {
        my ($before,$after) = '';
        foreach my $link ($word-&gt;links) {
            my $position = $link-&gt;linkposition;
            my $text     = $link-&gt;linkword;
            my $type     = $link-&gt;linklabel;
            if ($position &lt; $i) {
                $before .= "$type:$position:$text ";
            } elsif ($position &gt; $i) {
                $after.= "$type:$position:$text ";
            }
        }
        $return .= "(" . $before . " \"" . $word-&gt;text . "\" " .
                   $after . ")" ;
        $i++;
    }
   "(" . $return . ")";
} 
</pre>

  <h3>What Sucks? What Rocks?</h3>

  <p>The "Operating System Sucks-Rules-O-Meter" by Don Marti
  (<a href="http://srom.zgp.org/" target=
  "resource window">http://srom.zgp.org/</a>) inspired Jon Orwant's
  "What Languages Suck" program, later adopted by Steve Lidie
  (<a href="http://www.lehigh.edu/~sol0/rules.html" target=
  "resource window">http://www.lehigh.edu/~sol0/rules.html</a>). It
  blesses all of our lives by counting the web sites that state
  <tt>visual basic sucks</tt>, <tt>perl rules</tt>, and so on. The
  numbers are then plotted on a graph, giving us a crude and
  comical sampling of the net's public opinions about
  languages.</p>

  <p>What if someone wanted to perform a search that would produce
  lists of anything that people think sucks or stinks, and rules or
  rocks? A quick search for <tt>rocks</tt> on Altavista reveals
  plenty of geology links, and news headlines like <tt>Senate
  confrontation rocks Capitol Hill</tt>. We just want those phrases
  that state that something rocks, so we need to analyze the
  grammar of the search results.</p>

  <p>First, we need to determine the syntax for the data we want to
  collect. We use the first script listed in this article to
  experiment, or we could think through the grammar a bit: the
  <tt>rock</tt> we are looking for is not only a verb, but a verb
  without an object. This would serve to differentiate our meaning
  from the two others mentioned above.</p>
  <pre>
        +------------Xp------------+
        +--Wd--+--Ss-+---Op---+    |
        |      |     |        |    |
    LEFT-WALL he studies.v rocks.n .
</pre>

  <p>Note that this diagram displaying only one linkage, but there
  might be many. In the above output from our script, <tt>He
  studies rocks</tt> has been parsed and labeled. The subject of
  the sentence (<tt>he</tt>) is shown with an <tt>Ss</tt> label,
  connecting a singular noun to the singular verb form
  (<tt>studies</tt>). This will be the connector we are looking for
  in our <tt>rocks</tt> phrase, but here it occurs with the wrong
  verb. It has identified <tt>rocks</tt> as a noun here, and linked
  <tt>rocks</tt> to studies with an <tt>Op</tt> connector. The Link
  Parser documentation tells us that <tt>O</tt> connects transitive
  verbs to direct or indirect objects, and so the <tt>p</tt>
  subscript reflects the plurality of the object,
  <tt>rocks</tt>.</p>
  <pre>
        +--------------------Xp-------------------+
        +-------Wd------+         +-----Os----+   |
        |      +---Ds---+----Ss---+     +--Ds-+   |
        |      |        |         |     |     |   |
    LEFT-WALL the earthquake.n rocks.v the city.n .
</pre>

  <p>This example recognizes the verb usage of <tt>rocks</tt> as an
  action being performed by <tt>earthquake</tt>. Do earthquakes
  rock? Not in the sense we are looking for, since <tt>rocks</tt>
  has a connector to <tt>the city</tt> as an singular object
  (indicated by <tt>Os</tt>). Objects suck, at least for our
  purposes. Let's try another.</p>
  <pre>
        +-----------------------Xp----------------------+
        +----------------Wd---------------+             |
        |      +------------D*u-----------+             |
        |      |    +----------AN---------+             |
        |      |    |      +-----AN-----+---Ss---+    |
        |      |    |       |           |        |    |
    LEFT-WALL the Perl programming.n language.n rocks.v !
</pre>

  <p>Again, <tt>rocks</tt> here is correctly recognized as a verb,
  and again, it is connected via <tt>Ss</tt> to a subject. But this
  time <tt>rocks</tt> is not a transitive verb, since it has no
  objects. The grammar of this sentence would satisfy our
  requirements for <tt>rocks</tt>. So now that we have the correct
  usage, how do we extract the subject? We don't want to use just
  <tt>language</tt> to compile our statistics &mdash; we want
  <tt>Perl programming language</tt>. To find a solution, take note
  of the <tt>AN</tt> connectors that span these words. The Link
  Grammar reference identifies this link type as connecting
  modifiers to nouns. In the case above, both <tt>Perl</tt> and
  <tt>programming</tt> are modifiers for <tt>language</tt>. We can
  plan at the outset to always look for modifier links to our
  subject, and include them in the data we extract from the
  sentence. And there's more that we'll need, as you'll see.</p>

  <h3>What Sucks, Regex Style</h3>

  <p>Once we have determined the general grammatical elements for
  which to search, we can write a program that finds those elements
  in a given text. Since we overloaded this object's string
  handling to return the linkage information in a linear format, we
  can now formulate a regular expression that represents the
  grammar we want to match.</p>
  <pre>
  $what_rocks  = 'S[s|p]' .          # singular and plural subject
                '(?:[\w\*]{1,3})*' . # any optional subscripts
                ':(\d+):' .        # number of the word
                '(\w+(?:\.\w)*)'; 
                                      # and save the word itself

  $other_stuff = '[^\)]+';          # junk, within the parenthesis
  $rocks       = '"(rocks*)\.v"';    # singular and plural verbs

  $pattern     = "$what_rocks $other_stuff $rocks";
  if ( $linkage =~ /$pattern/mx ) {
      print "$2 rocks.\n";
  }
</pre>

  <p>Our <tt>$what_rocks</tt> portion of this pattern looks for an
  <tt>S</tt> link from <tt>rocks</tt>, and stores the word itself
  in <tt>$2</tt>, with optional tags like <tt>.n</tt> after the
  word. (We will use the stored word number in a moment.) This
  regular expression works, but it works for <i>every</i> verb
  sense of <tt>rocks</tt> that has a subject, including <tt>the
  earthquake rocks the city</tt>. We need to limit our pattern to
  match only those usages of <tt>rocks</tt> that have no objects at
  all. Here, we add a pattern after <tt>$rocks</tt> to be sure that
  no <tt>O</tt> connectors exist for rocks:</p>
  <pre>
    # match anything BUT an 'O' link, to the end parenthesis
    $no_objects = '[^(?:O.{1,3}:\d+:\w+(?:\.\w)*)]*\)';
    $pattern    = "$what_rocks $other_stuff $rocks $no_objects";
</pre>

  <p>With these changes, the pattern only matches the verb
  <tt>rocks</tt> when it has no objects. But one problem remains:
  when we use our regex with proper nouns like <tt>Pat Metheny</tt>
  rocks or noun modifiers like <tt>the Perl programming language
  rocks</tt>, we get only one word as the thing that
  <tt>rocks</tt>. Our pattern is getting a bit messy, so rather
  than add to it, we'll add a statement within the <tt>if</tt>
  block to scoop up the rest of the names. Proper nouns are strung
  together with <tt>G</tt> connectors, and noun modifiers with
  <tt>AN</tt>.</p>
  <pre>
    if ( $linkage =~ /$pattern/mx ) {
        $wordobj  = $linkage-&gt;word($1); # the stored word number
        $wordtxt  = $2;
        $verb     = $3;
        @wordlist = ();
        foreach $link ($wordobj-&gt;links) { # process array of links
            if ($link-&gt;linklabel =~ /^G|AN/) {   
                $wordlist[$link-&gt;linkposition] = $link-&gt;linkword;
            }
        } 
        print join (" ", @wordlist, $wordtxt), " $verb\n";
    }
</pre>

  <p>Note how although we are looking for matches in
  <tt>$linkage</tt>, we are using a method,
  <tt>$linkage-&gt;word</tt>, in the next line. (Seeing objects
  used in both scalar and dereferenced context may look confusing
  at first.) Also, we store the words in the <tt>@wordlist</tt>
  array to maintain the order of these words. When run with
  sentences provided by the user, this block of code prints the
  following:</p>
  <pre>
    Enter a sentence&gt; <b>He studies rocks.</b>
    Enter a sentence&gt; <b>The earthquake rocks the city.</b>
    Enter a sentence&gt; <b>The Perl programming language rocks.</b>
       -&gt; <b>Perl programming.n language.n rocks</b>
    Enter a sentence&gt; <b>Linux rocks!</b>
       -&gt; <b>Linux rocks</b>
    Enter a sentence&gt; <b>He was telling me why he thinks that San Francisco rocks.</b>
       -&gt; <b>San Francisco rocks</b>
</pre>

  <p>The final listing for this program is in <a href=
  "tpj0503-0010a.html">Listing 1</a>, and includes additional
  modifications to permit possessive pronoun inclusions, grouping
  of possessive proper nouns, conjunctions, past tense, and
  attributive adjectives. A demonstration is shown below.</p>
  <pre>
    Enter a sentence&gt; <b>Roland Orzabal's music rocks.</b>
       -&gt; <b>Roland Orzabal 's.p music.n rocks</b>
    Enter a sentence&gt; <b>Strangelove rolls, rumbles, and rocks.</b>
       -&gt; Strangelove rocks
    Enter a sentence&gt; <b>The Perl conference rocked!</b>
       -&gt; <b>Perl Conference rocked</b>
    Enter a sentence&gt; <b>The shogimogu pyonuki dancers rock!!!</b>
       -&gt; <b>shogimogu[?].a pyonuki[?].a dancers.n rock</b>
</pre>

  <p>(Thanks to my wife for pointing out all of the grammar that
  would not work with my first attempts.)</p>

  <p>Although the parser has no clue what the <tt>shogimogu</tt>
  and <tt>pyonuki</tt> mean (nothing at all, as it happens), it is
  still able to identify these as attributive adjectives. Anyone
  who has ever used another grammar-based parser will appreciate
  this feat.</p>

  <p>We could compile literally thousands of patterns to match
  various grammatical phenomena, store them in constants within a
  module, and end up with a direct regex interface for analyzing
  grammar. That will be the Lingua::LinkParser::Regex module,
  currently in progress.</p>

  <h3>The What-Sucks-Ometer</h3>

  <p>Using this framework, the <i>What languages suck?</i>
  application could be extended to retrieve web links to the pages
  resulting from a search engine query for <tt>rocks</tt>,
  <tt>rules</tt>, <tt>sucks</tt>, and so on. The text of each page
  could then be split into sentences, parsed with the code shown
  here to find specific word usages, and graphing the results. I
  won't outline how such a utility would be developed; the
  documentation for the LWP and GD modules tells you all you need
  to know. If anybody does write it, I suggest having multiple
  exclamation points count progressively against the <tt>rocks</tt>
  rating of the subject, rather than for it. We need to discourage
  that. Thank you.</p>

  <p>Certainly the possible applications of this type of "regex
  grammar" extend far beyond the toy application I've shown here.
  Smart search engines, document categorizers, and automated
  response systems all can make use of similar front ends to
  natural language.</p>

  <h3>There's Lots More Here</h3>

  <p>The Link Grammar can hardly be fully described in this
  article, and I encourage anyone interested to delve further into
  the research in this field. There is lots of room here for
  continued innovation, and the parser itself has much more to
  offer than what's been described here.</p>_ _END_ _<br>
  <br>
  <hr>
  <i>Dan is not ashamed of the time he has spent playing</i> Diablo
  II. <i>He should be.</i>
  <hr>

  <h3>References</h3>

  <p>Link Grammar web site, <a href=
  "http://bobo.link.cs.cmu.edu/index.html/" target=
  "resource window">http://bobo.link.cs.cmu.edu/
  index.html/</a>.</p>

  <p>Daniel Sleator and Davy Temperley, <i>Parsing English with a
  Link Grammar</i>, Third International Work-shop on Parsing
  Technologies, August 1993.</p>

  <p>Daniel Sleator and Davy Temperley, <i>Parsing English with a
  Link Grammar</i>, Carnegie Mellon University Computer Science
  technical report CMU-CS-91-196, October 1991.</p>

  <p>Dennis Grinberg, John Lafferty, and Daniel Sleator, <i>A
  robust parsing algorithm for link grammars</i>, Carnegie Mellon
  University Computer Science technical report CMU-CS-95-125.</p>
  <!-- end of file -->
</body>
</html>
