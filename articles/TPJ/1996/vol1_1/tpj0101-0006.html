<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>
<head>
  <title>HTML Hacking with Regular Expressions - The Perl Journal, Spring 1996</title>
  <meta name="generator" content=
  "HTML Tidy for Linux/x86 (vers 12 April 2005), see www.w3.org">
  <meta name="vscategory" content="Perl">
  <meta name="vsisbn" content="">
  <meta name="vstitle" content=
  "HTML Hacking with Regular Expressions">
  <meta name="vsauthor" content="Tom Christiansen">
  <meta name="searchdescription" content=
  "These days it sometimes seems as though you can't even glance at a billboard or a TV commercial without seeing a URL. When a programmer wants to create, update, or analyze an HTML document in an automated fashion, Perl is the obvious tool they turn to. And no small wonder: nothing else comes close to Perl's utility and functionality for text munging. Modern releases of Perl offer significant improvements in regexp handling over initial releases: both stingy and greedy matching, look-ahead assertions and negations, national character support, and fine-grain control of multiline matching all give added power, while an &aelig;sthetically pleasing (or at least, not unpalatable) free-format layout renders what would have otherwise been write-only gobbledygook into something that's easy to read, write, and maintain. But regular expressions can still be daunting to beginner and expert alike, so here are a few pointers about how to construct patterns for handling some of the more common HTML-related issues.">
  <meta name="vsimprint" content="The Perl Journal">
  <meta name="vspublisher" content="Earthweb">
  <meta name="vspubdate" content="Spring 1996">
  <!-- always update the article title and issue -->

</head>

<body>
  <font face="verdana" size="1">Issue 1, Spring 1996</font>

  <h2 align="center">HTML Hacking with Regular Expressions</h2>

  <h4><i>Tom Christiansen</i></h4>
  <!-- packages described, if necessary -->
  These days it sometimes seems as though you can't even glance at
  a billboard or a TV commercial without seeing a URL. When a
  programmer wants to create, update, or analyze an HTML document
  in an automated fashion, Perl is the obvious tool they turn to.
  And no small wonder: nothing else comes close to Perl's utility
  and functionality for text munging. Modern releases of Perl offer
  significant improvements in regexp handling over initial
  releases: both stingy and greedy matching, look-ahead assertions
  and negations, national character support, and fine-grain control
  of multiline matching all give added power, while an
  &aelig;sthetically pleasing (or at least, not unpalatable)
  free-format layout renders what would have otherwise been
  write-only gobbledygook into something that's easy to read,
  write, and maintain. But regular expressions can still be
  daunting to beginner and expert alike, so here are a few pointers
  about how to construct patterns for handling some of the more
  common HTML-related issues.

  <h3>Manipulating Links</h3>

  <h4>...Finding Links</h4>

  <p>Probably the task most frequently attempted on an HTML
  document is extracting all the links. To do this in all but the
  most esoteric cases, the following moderately elaborate regular
  expression will suffice.</p>
  <pre>
#!/usr/bin/perl -n -00
while ( /&lt;\s*A\s+HREF\s*=\s*(["'])(.*?)\1.*?&gt;/gi ) {
        print "$2\n";
}
 
</pre>

  <p>Now, that's getting a bit hard to read. To fix this, just add
  the <tt>/x</tt> flag to your match and then indent the code
  however you like with an eye toward legibility. If you're running
  Perl 5.002 or better, you might also add comments to your pattern
  to give a blow-by-blow description of what you're doing.
  (Actually, sometimes you could do so in 5.000 and 5.001, but
  there were some compiler bugs that could make the comments
  confuse Perl.) By processing the input stream a paragraph at a
  time, you let the match spread over the whole paragraph; this is
  because sometimes there are newlines within tags, although seldom
  duplicate adjacent newlines. We use Perl's stingy matching
  feature of .*? to avoid .* expanding to more than we'd like.</p>
  <pre>
#!/usr/bin/perl -n00
while ( m{          # match repeatedly with /g
   &lt; \s* A          # this is an anchor
        \s+ HREF    # a link spec
        \s* = \s*   # here comes the link
        ( ["'] )    # either quote, saved in $1
                    # and \1
       ( .*? )      # the whole link, saved in $2
         \1         # the original $1 quote
       .*? &gt;        # the rest of the tag 
         }xsgi)     # /x for expanded patterns
                    # /s so . can match \n
                    # /g to get multiple hits 
                    # in one paragraph
                    # /i for case insensitivity
                    # on A and HREF
{
      print "$2\n";
} 
</pre>

  <h4>...Changing Links</h4>An activity related to link extraction
  is altering links. Perhaps the host name or path has changed.
  Perhaps links that used to read
  <pre>
   &lt;A HREF= "http://foo.com/somewhere/file"&gt;
</pre>

  <p>should now read</p>
  <pre>
   &lt;A HREF= "http://www.foo.com/elsewhere/file"&gt;
</pre>

  <p>instead. You'd like to perform the substitution on all the
  links, but nowhere else in the document. If you don't mind
  editing the whole file (and not just links), then a very simple
  substitution would suffice:</p>
  <pre>
perl -pi.bak -e 's,http://foo\.com/somewhere/,http://www.foo.com/elsewhere/,g'
</pre>

  <p>However, if you really care about modifying only legitimate
  links, you'll have to combine the last two programs. We'll use
  the <tt>-i</tt> flag to perform an in-place edit of the file,
  creating a backup with a "<tt>.bak</tt>" extension:</p>
  <pre>
#!/usr/bin/perl -p -i.bak -00
s[       
        (
        &lt; \s* A 
          \s+ HREF 
                 \s* = \s* 
                 ( ["'] ) 
         )
            http://foo\.com/somewhere/ 
         (
       ( .*? ) 
                         \2 
     .*? &gt; 
         )
 ][${1}http://www.foo.com/elsewhere/$2]xsgi;
</pre>

  <p>This isn't perfect, though, because it matches both
  "SOMEWHERE" and "somewhere". It also has some difficulties with
  HTML comments.</p>

  <p>But see below for a comment stripping program.</p>

  <h4>...Plaintext to HTML</h4>

  <p>What if you have a text file that contains URL references, and
  you'd like to fix them up to point to the proper place? You need
  a way to detect the URLs and highlight them properly. That way
  something like</p>

  <div align="center">
    http://host.com
  </div>becomes

  <div align="center">
    &lt;A HREF="http://host.com"&gt;http://host.com&lt;/A&gt;
  </div>

  <p>A problem: what to do if the URL has trailing punctuation?
  Consider something like ftp://host/path.file. Is that last dot
  supposed to be in the URL? We can probably just assume that a
  trailing dot doesn't count, but even so, most scanners seem to
  get this wrong. Here's a different approach. We'll store pieces
  of the pattern in variables for easier reading. (But we had
  better remember the <tt>/o</tt>, or else the pattern will run
  very slowly.) To get around the problem of trailing punctuation
  that might or might not be part of the URL, we'll give it our
  best guess by using one of Perl's look-ahead pattern assertions:
  (<tt>?= stuff</tt> ).</p>
  <pre>
#!/usr/bin/perl 
# urlify 

require 5.002; 
# well, or 5.000 if you strip the comments
 
$urls = '(' . join ('|', qw{
                            http
                            telnet
                            gopher
                            file
                            wais
                            ftp
                           } 
                   ) 
      . ')';
 
$ltrs = '\w';
$gunk = '/#~:.?+=&amp;%@!\-';
$punc = '.:?\-';
$any = "${ltrs}${gunk}${punc}";
 
while (&lt;&gt;) {
# use this if early-ish perl5 (pre 5.002)
# s{\b(${urls}:[$any]+?)(?=[$punc]*[^$any]|\Z)}
#                   {&lt;A HREF="$1"&gt;$1&lt;/A&gt;}goi;
s{
   \b           # start at word boundary
   (            # begin $1 
     $urls :    #  need resource and a colon
     [$any] +?  #  followed by one or more
                #  of any valid character, but
                #  be conservative and take
                #  only what you need to....
   )            # end $1 
   (?=          # a look-ahead, 
                #  non-consumptive assertion
       [$punc]* # either 0 or more punctuation
       [^$any]  #  followed by a non-url char
     |          # or else
        $       # the end of the string
   )
 }{&lt;A HREF="$1"&gt;$1&lt;/A&gt;}igox;
 print;
}
</pre>

  <p>In this code, we guessed at the resource types (gopher, html,
  etc). It's probably safer just to put in something like
  <tt>\w+</tt> instead, just in case new resource types someday
  appear which you'd like to handle.</p>

  <h3>Extracting Titles and Headers</h3>

  <p>Another common HTML-related task is extracting the title
  and/or headers from an HTML document. The first try might look
  something like</p>
  <pre>
perl -lne 'print $1 if m:&lt;TITLE&gt;(.*)&lt;/TITLE&gt;:'
</pre>

  <p>This says: print out anything between a &lt;TITLE&gt; and its
  closing &lt;/TITLE&gt; tag. When you run it on a simple test
  case, it works just fine. But then you try to run it over your
  whole doc tree, and you find that it misformats or entirely
  misses some of your HTML files. The first gotcha is that HTML
  tags aren't case sensitive, so you'd need a <tt>/i</tt> on the
  pattern match. The next one is that HTML tag contents can extend
  across line boundaries.</p>

  <p>Enabling multiline matching isn't enough to fix this: you also
  have to read in a multiline record. Setting the input record
  separator variable to the empty string (or<tt>undef</tt>) takes
  care of this, but you also have to use <tt>/s</tt> so that the
  pattern is treated as a single line and allows dots to match
  newlines.</p>

  <p>From the command line, that would be:</p>
  <pre>
perl -00 -lne 'print $1 if m:&lt;TITLE&gt;(.*)&lt;/TITLE&gt;:si'
</pre>

  <p>or from a script:</p>
  <pre>
#!/usr/bin/perl -00 -ln
print $1 if m:&lt;TITLE&gt;(.*)&lt;/TITLE&gt;:si;
<br>

or with more of an awk mindset:
<br>


#!/usr/bin/perl -n
BEGIN { ($/, $&rsaquo;) = ("", "\n") }
print $1 if m:&lt;TITLE&gt;(.*)&lt;/TITLE&gt;:si;

or for increased readability:
<br>

#!/usr/bin/perl 
use English;
$RS = '';

while ($paragraph = &lt;ARGV&gt;) {
        if ( $paragraph =~ m:&lt;TITLE&gt;(.*)&lt;/TITLE&gt;:si ) {
        print "$1\n";
        } 
}
</pre>

  <p>This all works fine until you come across the odd document
  with blank lines in the title, or extra fields in the &lt;TITLE
  TAG="stuff"&gt; line, or even more than one title. So you end up
  having to embellish your pattern until it becomes increasingly
  hard to understand and maintain for those who come after you.</p>

  <p>Blech.</p>

  <p>This brings us to the <tt>/x</tt> flag on pattern matching. By
  allowing embedded white space (and even comments as of Perl
  5.002), you can tremendously improve legibility and thus
  maintainability. Here's a full-blown solution to printing out all
  the titles in all the files on the command line, or STDIN if none
  are given.</p>
  <pre>
#!/usr/bin/perl -w

require 5.002;   
# or 5.001 if you remove the comments!

use strict; 
undef $/;               
@ARGV = ('-') unless @ARGV;
my($title, $filename);
while ($filename = shift) { 
        unless (open(HTML, $filename)) {
             warn "can't open $filename: $!";
         next;
        }
        my $html = &lt;HTML&gt;;
        my $count = 0;
        while ( $html =~ m{                      
                 &lt; \s* TITLE .*? &gt;                # begin tag
                 \s* (.*?) \s*                      # contents
                 &lt; \s* / \s* TITLE .*? &gt;      # end tag
                                }gsix ) {
       if ($count++) {
         warn "$filename has $count titles!\n";
         } 
         ($title = $1 || "&lt;UNTITLED&gt;") =~ s/\s+/ /g;
         write;
        } 
                }

format STDOUT =
@&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; ^&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
$filename,               $title
                         ^&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
~~                       $title
.
</pre>

  <p>Related to the task of printing out the title (or titles) in a
  document is dumping out the HTML outline:&lt;H1&gt;, &lt;H2&gt;,
  and so on. The approach is similar to the title-extraction
  program above. We'll assume that $html contains the entire
  document.</p>
  <pre>
while ( $html =~ m{ 
            &lt; \s* H (\d) \b .*? &gt; 
              \s*     (.*?) \s* 
            &lt; \s* / \s* H \1 \b .*? &gt; 
       }gsix ) 
  {
      my($level, $contents) = ($1, $2);
      for ($contents) {
          s/&lt;.*?&gt;//g;            # any extra tags 
          s/\s+/ /g;             # newlines and tabs
      } 
      print "$level.", " " x $level, $contents, "\n";
  } 
</pre>

  <h3>Reducing to Plaintext</h3>

  <ul>
    <li style="list-style: none">Here's another common task: you
    have an HTML document, and you want to remove all of its
    embedded markup text. This requires three steps:</li>

    <li>Stripping &lt;!-- html comments --&gt;</li>

    <li>Stripping &lt;TAGS&gt;</li>

    <li>Converting &amp;entities; into what they should be.</li>
  </ul>

  <p>This is complicated by the horrible specification for HTML
  comments: they can have embedded tags in them. The HTML
  specification inherits SGML's bizarre notion of comments, which
  can confuse even the most careful program that's trying to deal
  with them. For example:</p>
  <pre>
&lt;!DOCTYPE  HTML PUBLIC "-//IETF//DTD HTML 2.0//EN"
         -- This is an annoying comment &gt; --
&gt;
</pre>

  <p>Notice how that unquoted closing angle bracket doesn't
  actually end the tag? That's because it's in a comment. This is
  really annoying! Here's what makes up an HTML comment:</p>

  <p>Comments begin with a "&lt;!" and are followed by 0 or more
  comments; after that, each comment starts with a "--" and
  includes all text up to and including the next occurrence of
  "--". They may have trailing while space (albeit not leading
  white space). You can even have non-comment text up to that final
  "&gt;" character.</p>

  <p>Keeping this all straight requires more than a little care.
  Perhaps such a thing would be more easily coded using a tool like
  <i>lex</i>, but Perl's regexps are up to it if you give them a
  little help, with the <tt>/e</tt> flag.</p>

  <p>Here's a complete program to reduce an HTML doc to plaintext
  in three easy subsitutions:</p>
  <pre>
#!/usr/bin/perl -p0777
# striphtml ("striff tummel")

# how to strip out html comments and
# tags and transform entities in just
# three - count 'em three - 
# substitutions; sed and awk eat your 
# heart out. :-)

# as always, translations from this
# nacri rendition into more
# characteristically marine,
# herpetoid, titillative, or 
# indonesian idioms are welcome for
# the furthering of comparative
# cyberlinguistic studies.

require 5.001; 
# for nifty embedded regexp comments

# first we'll shoot all the 
# &lt;!-- comments --&gt;

s{ &lt;!     # comments begin with '&lt;!'
          # followed by 0 or more
          # comments;
   (.*?)  # this eats up comments
          # in non random places
   (      # not supposed to have any 
          # whitespace here
          # just a quick start:
   --     # each comment starts with
          # a '--'
     .*?  # and includes all text up
          # to and including the
   --     # next occurrence.  
     \s*  # and may have trailing
          # whitespace (but not
          # leading whitespace)
   )+     # repetire ad libitum
   (.*?)  # trailing non comment text
  &gt;       # up to a '&gt;'
}{
  if ($1 || $3) { # this silliness for 
                  # embedded comments in tags
     "&lt;!$1 $3&gt;";
  } 
}gsex;       # mutate into nada, nothing, 
             # and niente
 

# next we'll remove all the &lt;tags&gt;

s{ &lt;            # opening angle bracket
                #
   (?:          # Non-backreffing grouping
                #                        paren
       [^&gt;'"] * # 0 or more things that are 
                #       neither &gt; nor ' nor "
         |      # or else
        ".*?"   # a section between 
                #  double quotes (stingy match)
         |      # or else
        '.*?'   # a section between 
                #  single quotes (stingy match)
   )+           # repetire ad libitum
                # hm...are null tags (&lt;&gt;) 
                #                   legal?
  &gt;             # closing angle bracket
}{}gsx;         # mutate into nada, nothing, 
                # and niente


# finally we'll translate all &amp;valid; HTML 2.0 
# entities
 
s{ (
    &amp;           # an entity starts with a 
                # semicolon
    ( 
      \x23\d+   # and is either a pound 
                # (# == hex 23) and numbers
       |        # or else
      \w+       # has alphanumunders...
    ) 
   ;?           # a semicolon terminates, 
                # as does anything else
  )
} {
    $entity{$2} # if it's a known entity, 
                # use that. 
        ||      # But otherwise
        $1      # leave what we'd found. 
}gex;           # execute replacement - that's 
                # code not a string


# but wait! load up the %entity mappings
# enwrapped in a BEGIN so that we only 
# execute once since we're in a -p "loop". 
# awk is kinda nice after all.
BEGIN {

 %entity = (
    lt     =&gt; '&lt;', 
    gt     =&gt; '&gt;', 
    amp    =&gt; '&amp;', 
    quot   =&gt; '"',     # "  (vertical double quote) 
    nbsp   =&gt; chr 160, #    (space)
    iexcl  =&gt; chr 161, # &iexcl;
    cent   =&gt; chr 162, # &cent;
    pound  =&gt; chr 163, # &pound; 
    curren =&gt; chr 164, # &curren;
    yen    =&gt; chr 165, # &yen;
    brvbar =&gt; chr 166, # &brvbar;  (broken vertical bar)
    sect   =&gt; chr 167, # &sect;
    uml    =&gt; chr 168, # &uml;  (umlaut, or dieresis)
    copy   =&gt; chr 169, # &copy;
    ordf   =&gt; chr 170, # &ordf;  (feminine ordinal)
    laquo  =&gt; chr 171, # &laquo;
    not    =&gt; chr 172, # &not; 
    shy    =&gt; chr 173, # &shy;  (soft hyphen)
    reg    =&gt; chr 174, # &reg;
    macr   =&gt; chr 175, # &macr;
    deg    =&gt; chr 176, # &deg;
    plusmn =&gt; chr 177, # &plusmn;
    sup2   =&gt; chr 178, # &sup2;  (superscript two)
    sup3   =&gt; chr 179, # &sup3;  (superscript three)
    acute  =&gt; chr 180, # &acute;  (acute accent)
    micro  =&gt; chr 181, # &micro;  (micro sign)
    para   =&gt; chr 182, # &para;  (pilcrow)
    middot =&gt; chr 183, # &middot;
    cedil  =&gt; chr 184, # &cedil;  (cedilla)
    sup1   =&gt; chr 185, # &sup1;  (superscript one)
    ordm   =&gt; chr 186, # &ordm;  (masculine ordinal)
    raquo  =&gt; chr 187, # &raquo; 
    frac14 =&gt; chr 188, # &frac14;  (one-quarter)
    frac12 =&gt; chr 189, # &frac12;  (one-half)
    frac34 =&gt; chr 190, # &frac34;  (three-quarters)
    iquest =&gt; chr 191, # &iquest;
    Agrave =&gt; chr 192, # &Agrave;
    Aacute =&gt; chr 193, # &Aacute;
    Acirc  =&gt; chr 194, # &Acirc;
    Atilde =&gt; chr 195, # &Atilde;
    Auml   =&gt; chr 196, # &Auml;
    Aring  =&gt; chr 197, # &Aring;
    AElig  =&gt; chr 198, # &AElig;
    Ccedil =&gt; chr 199, # &Ccedil;
    Egrave =&gt; chr 200, # &Egrave;
    Eacute =&gt; chr 201, # &Eacute;
    Ecirc  =&gt; chr 202, # &Ecirc;
    Euml   =&gt; chr 203, # &Euml;
    Igrave =&gt; chr 204, # &Igrave;
    Iacute =&gt; chr 205, # &Iacute;
    Icirc  =&gt; chr 206, # &Icirc;
    Iuml   =&gt; chr 207, # &Iuml;
    ETH    =&gt; chr 208, # &ETH;  (capital Eth, Icelandic)
    Ntilde =&gt; chr 209, # &Ntilde;
    Ograve =&gt; chr 210, # &Ograve;
    Oacute =&gt; chr 211, # &Oacute;
    Ocirc  =&gt; chr 212, # &Ocirc;
    Otilde =&gt; chr 213, # &Otilde; 
    Ouml   =&gt; chr 214, # &Ouml;
    times  =&gt; chr 215, # &times;
    Oslash =&gt; chr 216, # &Oslash;
    Ugrave =&gt; chr 217, # &Ugrave;
    Uacute =&gt; chr 218, # &Uacute;
    Ucirc  =&gt; chr 219, # &Ucirc;
    Uuml   =&gt; chr 220, # &Uuml;
    Yacute =&gt; chr 221, # &Yacute;  (capital Y, acute accent)
    THORN  =&gt; chr 222, #&THORN;   (capital THORN, Icelandic)
    szlig  =&gt; chr 223, # &szlig;
    agrave =&gt; chr 224, # &agrave;
    aacute =&gt; chr 225, # &aacute;
    acirc  =&gt; chr 226, # &acirc;
    atilde =&gt; chr 227, # &atilde;
    auml   =&gt; chr 228, # &auml;
    aring  =&gt; chr 229, # &aring;
    aelig  =&gt; chr 230, # &aelig;
    ccedil =&gt; chr 231, # &ccedil;
    egrave =&gt; chr 232, # &egrave;
    eacute =&gt; chr 233, # &eacute;
    ecirc  =&gt; chr 234, # &ecirc;
    euml   =&gt; chr 235, # &euml;
    igrave =&gt; chr 236, # &igrave;
    iacute =&gt; chr 237, # &iacute;
    icirc  =&gt; chr 238, # &icirc;
    iuml   =&gt; chr 239, # &iuml;
    eth    =&gt; chr 240, # &eth;  (small eth, Icelandic)
    ntilde =&gt; chr 241, # &ntilde;
    ograve =&gt; chr 242, # &ograve;
    oacute =&gt; chr 243, # &oacute;
    ocirc  =&gt; chr 244, # &ocirc;
    otilde =&gt; chr 245, # &otilde;
    ouml   =&gt; chr 246, # &ouml;
    divide =&gt; chr 247, # &divide; 
    oslash =&gt; chr 248, # &oslash;
    ugrave =&gt; chr 249, # &ugrave;
    uacute =&gt; chr 250, # &uacute;
    ucirc  =&gt; chr 251, # &ucirc;
    uuml   =&gt; chr 252, # &uuml;
    yacute =&gt; chr 253, # &yacute;  (small y, acute)
    thorn  =&gt; chr 254, # &thorn;  (small thorn, Icelandic)
    yuml   =&gt; chr 255, # &yuml;
);


# now fill in all the numbers to match
# themselves
 
    foreach $chr ( 0 .. 255 ) { 
        $entity{ '#' . $chr } = chr $chr;
    }
}

</pre>

  <h3>Don't Reinvent the Wheel</h3>

  <p>By now, you've probably decided two things: first, that Perl's
  regular expressions can handle nearly any text-munging task you'd
  ever want to do to an HTML file, and second, that to catch all
  the fringe cases you have to be extremely careful and not a
  little clever. Fortunately, code has already been written and
  tested to perform all of the most common tasks, including parsing
  HTML files, decoding URLs, escaping special characters, testing
  remote HTTP references, and much, much more. It's all included in
  the <i>libwww</i> library, a set of Perl modules written by
  Martijn Koster and Gisle Aas. With the functions in these
  modules, many of the tasks above can be automated with solid code
  hidden away in a module. And not only can you, for example,
  extract all the links, you can actually make sure that they point
  to valid documents. For the latest version of this library, check
  your nearest <a href="http://www.perl.com/CPAN/SITES.html"
  target="resource window">CPAN</a> site.</p>

  <p>__END__ <!-- end of file --></p>
</body>
</html>
