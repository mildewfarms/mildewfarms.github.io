<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <title>Perfect Programming - The Perl Journal, Fall 1997</title>
  <meta name="generator" content=
  "HTML Tidy for Linux/x86 (vers 12 April 2005), see www.w3.org">
  <meta name="vscategory" content="Perl">
  <meta name="vsisbn" content="">
  <meta name="vstitle" content="Perfect Programming">
  <meta name="vsauthor" content="Nathan Torkington">
  <meta name="searchdescription" content=
  "Imagine a world ten years from now. Programmers know everything there is to know about their language, algorithms and requirements. They apply this knowledge to produce flawless programs, which work correctly the first and every time. Users read the manuals, never provide false or misleading input, and always know what to do next. Clients never change their minds and maintenance is unnecessary.">
  <meta name="vsimprint" content="The Perl Journal">
  <meta name="vspublisher" content="Earthweb">
  <meta name="vspubdate" content="Fall 1997">
  <!-- always update the article title and issue -->

  <!-- end head -->
</head>

<body>
  <font face="verdana" size="1">Issue 7, Fall 1997</font>

  <h2 align="center">Perfect Programming</h2>

  <h4><i>Nathan Torkington</i></h4>
  <!-- packages described, if necessary -->
  <font size="+2">I</font>magine a world ten years from now.
  Programmers know everything there is to know about their
  language, algorithms and requirements. They apply this knowledge
  to produce flawless programs, which work correctly the first and
  every time. Users read the manuals, never provide false or
  misleading input, and always know what to do next. Clients never
  change their minds and maintenance is unnecessary.

  <p>You can wake up now. We both know this won't happen so long as
  boneheads like us keep programming, morons like our customers
  keep giving us incomplete and perpetually changing requirements,
  and the prerequisite for being a user is that you demonstrate
  zero ability to read, think, or act without tech support or a
  programmer holding your hand. Everyone in the
  programmer-client-user world is a weak link, and programmers must
  be prepared for each person to make mistakes.</p>

  <p><b>User mistakes.</b> When users are to blame, it's typically
  because they do something like providing incorrect input to your
  program, or calling your program in an unexpected way. Paranoid
  programmers check everything provided by the users (and use the
  taint mechanism to help them). This has the side benefit of
  making their programs more secure against exploitation by The Bad
  Guys. The Bad Guys like to mess with a program's environment,
  input, and configuration files, in the hope they can trick it
  into displaying <tt>/etc/master.passwd</tt>, or changing the
  permissions of <tt>/bin/sh to 4755</tt>, making it setuid.</p>

  <p><b>Client mistakes.</b> Customers are fickle. Sometimes they
  request minor changes ("we want to sort the addresses by
  zipcode"); sometimes the changes are major ("the CEO just bought
  an Oracle database. Use it."). Changes run the risk of breaking
  software which previously worked. The programmer must write code
  in such a way that substantial changes in behavior can be
  implemented with minimum risk.</p>

  <p><b>Programmer mistakes.</b> Finally, as unwilling as we all
  are to accept it, programmers make mistakes. They're typically
  things like using variables which don't yet have a value, giving
  incorrect values to a function, and language misunderstandings
  like <tt>$#array vs @array</tt>. Programmers who believe in their
  own fallibility (does the Pope program in Perl?) write code that
  checks its values, checks return values from system calls, and
  uses tools like <tt>-w</tt> and <tt>use strict</tt>. These humble
  programmers also know how to debug when all else goes wrong.</p>

  <p><a href="tpj0203-0008a.html">Maurice Wilks, 1949</a></p>

  <p>What follows is a list of techniques that I've found useful in
  real programs. The larger the program you want to write, the more
  desirable these techniques become. One-liners, or even
  five-pagers, are short and uncomplicated enough that debugging
  them is easy. That can't be said for some of the 10,000 line
  multi-module nightmares that I've given birth to. Consider these
  techniques your armory for the fight.</p>

  <h3>Warnings with -w</h3>

  <p>This is the programmer's most useful debugging aid. As Larry
  says, Perl's biggest bug is that <tt>-w</tt> is optional. Some of
  the things that a hashbang line of <tt>#!/usr/bin/perl -w</tt>
  will catch are: use of undefined values (typically a sign that
  you're expecting a variable to have a value when it doesn't),
  non-numeric arguments (a string was given instead of a number,
  which probably means it would be interpreted as 0 instead of
  being flagged as an error), = instead of ==, and much more.</p>

  <p>Sometimes you want <tt>-w</tt> checks in some places but not
  others. If there's a chunk of code you just <i>know</i> will work
  even though <tt>-w</tt> complains about it, you can disable
  warnings as follows:</p>
  <pre>
{ 
    local($^W) = 0;             # disable warnings... 
    <i>your code here </i>
}                               # warnings back on now
</pre>

  <p>This traps only run-time warnings. Disabling compile-time
  warnings won't be possible until later versions of Perl.</p>

  <p>There has been a vigorous debate on the subject of <tt>-w</tt>
  in production programs. New versions of Perl have created new
  warnings, which show up as "errors" (broken web pages, strange
  <i>cron</i> mailings, STDERR sent to users' screens) in programs
  which previously worked. Tracking these down can be a non-trivial
  task. I like to keep my code -w clean for all versions, because
  it makes future changes easier to test with <tt>-w</tt>. Your
  mileage may vary.</p>

  <h3>The <tt>STRICT</tt> pragma</h3>

  <p>If you're using references or trying to write maintainable or
  reusable code, you probably want to <tt>use strict</tt>. This is
  a shorthand for <tt>use strict 'refs', 'subs', 'vars'</tt>, which
  catches the following things:</p>

  <p>&bull; <tt>use strict 'refs'</tt> prevents suspicious
  dereferences. If a subroutine expects a hard reference to a value
  (the kind of reference you get with \), but you supply it the
  wrong arguments or the right arguments in the wrong order, you
  can cause a string or a number to be inadvertently dereferenced.
  Consider this code:</p>
  <pre>
  sub setref { 
      my $string_ref = shift; 
      my $string     = shift;
      $$string_ref   = $string; 
  }

  # wrong argument order
  setref("Googol", $plexref);   
</pre>

  <p>Here, the <tt>setref()</tt> subroutine is passed "Googol"
  where it expects a reference to a string. Without <tt>use strict
  'refs'</tt>, Perl assumes you meant <tt>$Googol</tt>. This is
  called a <i>soft</i>, or symbolic, reference. When you use that
  pragma, however, Perl whines and dies. Because soft references
  are almost never needed, <tt>use strict 'refs'</tt> catches a lot
  of errors that would otherwise silently cause bizarre
  behavior.</p>

  <p>&bull; <tt>use strict 'vars'</tt> catches stray variables. It
  expects you to either qualify every variable completely
  (<tt>$Package::Var</tt>) or to declare them with <tt>my()</tt>.
  In almost every case, you really want to use <tt>my()</tt> to
  scope your variable so that code outside the file or block can't
  perturb its value. Using <tt>my()</tt> to predeclare all
  variables (or using cumbersome fully-qualified variable names)
  will predispose you to document your variables for the hapless
  fool who must modify your program in a year's time. Don't laugh.
  It might be you.</p>
  <pre>
if ($core-&gt;active) { 
    my $rems;           # active radiation in rems 
    my $rod_volume;     # volume of carbon rod remaining
    your code here
}
</pre>

  <p>&bull; <tt>use strict 'subs'</tt> forbids stray barewords.
  When it's in effect, you can't use the bareword style of calling
  subroutines with no arguments (e.g. <tt>$result = mysub;</tt>)
  unless the subroutine was declared before its use, either with a
  prototype or with the subroutine definition itself. If you don't
  want to predeclare, you must preface the subroutine call with
  <tt>&amp;</tt> or append <tt>()</tt> so that it looks like a
  subroutine call. This doesn't affect the use of barewords in
  hashes in curly braces (e.g. <tt>$hash{key}</tt>) or on the left
  side of the <tt>=&gt;</tt> symbol (e.g. <tt>%hash = (key =&gt;
  value)</tt>).</p>
  <pre>
use strict 'subs';

print count;      # an error with use strict 'subs'

sub count;        # prototyping count() is sufficient

# Not an error because Perl now knows about count()
print count;
</pre>

  <p>Note that simply saying <tt>sub mysub;</tt> before using the
  bareword <tt>mysub</tt> is enough to keep <tt>use strict
  'subs'</tt> quiet.</p>

  <h3>Tainting And Safe</h3>

  <p>When Perl encounters a variable whose value hasn't been
  hard-coded into the program, it marks the variable as tainted if
  the program is running under the <tt>-T</tt> flag, or if the
  program's permissions are setuid (meaning that it assumes the
  identity of its owner rather than whoever is running the
  program). Use of a tainted value in <tt>exec()</tt> or similar
  calls, or opening for writing a filename, causes a fatal error.
  To untaint data, you should extract the safe portion (for a
  filename, that might be <tt>/^([\w.\@-]+)$/</tt>) with a regular
  expression and use <tt>$1, $2, ...</tt> to access the part of the
  tainted variable guaranteed to be safe. Full details can be found
  in the <i>perlsec</i> manual page.</p>

  <p>Running with <tt>-T</tt> is almost always a good idea when
  you're programming defensively. It forces you to validate every
  piece of user-supplied data with regular expressions before you
  use them. Not only does this guard against potentially
  security-compromising errors, it also lets you catch situations
  where the user gives the wrong type of data (a string instead of
  a number, for instance).</p>

  <p>A different approach is to use the Safe module, which traps
  certain operations. You can run code that uses untrustworthy data
  inside a Safe "compartment," knowing that it can't
  <tt>unlink()</tt> files, <tt>fork()</tt> processes, or do other
  nasty things.</p>

  <h3>Checking Return Values</h3>

  <p>Not every <tt>fork()</tt> will succeed, not every file can be
  opened, not every child process terminates without error. The
  return values from system calls contain valuable information on
  the success or failure of those calls - check them!</p>

  <p>The most important things to check are return values of
  <tt>open()</tt>, <tt>fork()</tt>, <tt>exec()</tt>, and the
  contents of <tt>$?</tt> (<tt>$CHILD_ERROR</tt> if you use English
  - and why aren't you?( A good reason is that <tt>use English</tt>
  slows your program down, because it mentions <tt>$&amp;</tt> and
  <tt>$'</tt>, whose very presence retards every regular expression
  in your program.)).</p>

  <p>The same wisdom applies to CPAN or library modules, and to
  your own modules. Your modules should perform sanity checks and
  return <tt>0</tt> or <tt>undef</tt> if something went wrong.</p>

  <h3>Planning For Failure</h3>

  <p>Part of catching errors is deciding what to do when they
  occur. Even before I begin programming, I enumerate the various
  ways my code can fail, and then decide what to do for each
  possibility. With some errors it's okay to tell the user exactly
  what went wrong ("you gave me the name of a user who isn't in the
  database") but others shouldn't be made so public ("the database
  doesn't exist", or "I couldn't fork."). User errors typically
  warrant a message that pats their hand and gives them a chance to
  try again. System errors should be logged to a file, the
  administrators notified, and the user told that "the system is
  down" and they should try again later.</p>

  <h3>The Perl Debugger</h3>

  <p>There is only so much that stack traces and strategically
  placed <tt>print()</tt> statements can do. When you've located
  the problem, it can still be difficult to infer the cause. My
  next step is to write a small program that exhibits the bug and
  then steps through it with Perl's symbolic debugger (<tt>perl -d
  mysmallprogram</tt>). Of course, you can always invoke the
  debugger directly with <tt>perl -de 0</tt> to initiate an
  interactive session.</p>

  <p>Debugging will be most comfortable if you've installed the
  Term::ReadLine module, or if you use the Ilya Zakharevich's nice
  Emacs interface, <i>cperl-mode.el</i>. Even without these whizzy
  utilities, the debugger is still useful. You can step through
  your code and set breakpoints - locations in your program at
  which execution stops, giving you a chance to inspect or change
  variables, thus letting you discover the particular states that
  trigger the bug you're trying to fix. Consult the
  <i>perldebug</i> documentation for more information.</p>

  <h3>The Perl Profiler</h3>

  <p>When your program works, but runs as slow as a dog, Dean
  Roehrich's Devel::DProf module (available on the CPAN) will help
  you determine why. <tt>perl -d:DProf myprogram</tt> runs your
  program and creates a file called <i>tmon.out</i> in your current
  working directory. You then run the dprofpp program to analyze
  that file and display the fifteen subroutines occupying the most
  time.</p>

  <p>There are other features of the profiler (see the dprofpp
  documentation for more information) but this list of the most
  time-consuming subroutines is probably the most important. It
  pinpoints the parts of your program that use the most time, and
  hence most suited for optimizing, rewriting, inlining, or
  avoiding.</p>

  <h3>Stack Traces</h3>

  <p><a href="tpj0203-0008b.html">Generating a Stack Trace in a CGI
  Script</a></p>

  <p>The terse little warnings and <tt>die()</tt> messages that
  you're provided are often not sufficient when it comes to working
  out where things went wrong. For that you need the awesome power
  of Jack Shirazi's Devel::DumpStack. When I'm debugging a CGI
  script that refuses to play ball, I'll use the above code (try it
  on the TPJ web site, or at
  http://www.frii.com/~gnat/perl/articles/tpj7/stack.cgi), which
  traps warnings and fatal errors, displaying them in an HTML
  document instead of burying them in a web server error log. I
  wouldn't recommend leaving this code in your final product,
  however. The sight of a stack dump can mentally scar a user for
  life.</p>

  <p>_ _END_ _</p>
  <hr>
  <i>Nathan Torkington (<a href=
  "mailto:gnat@frii.com">gnat@frii.com</a>) cowrote the latest Perl
  FAQ with Tom Christiansen, is cowriting "The Perl Cookbook" with
  Tom Christiansen, and is currently doing system administration
  and Perl programming for Front Range Internet, an ISP in Fort
  Collins, Colorado (without Tom Christiansen).</i> 
  <!-- end of article -->
   <!-- end of file -->
</body>
</html>
