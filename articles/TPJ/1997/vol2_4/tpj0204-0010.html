<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <title>B-Trees - The Perl Journal, Winter 1997</title>
  <meta name="generator" content=
  "HTML Tidy for Linux/x86 (vers 12 April 2005), see www.w3.org">
  <meta name="vscategory" content="Perl">
  <meta name="vsisbn" content="">
  <meta name="vstitle" content="B-Trees">
  <meta name="vsauthor" content="Mark-Jason Dominus">
  <meta name="searchdescription" content=
  "B-Trees are often described as a good way to store and retrieve data, especially to and from disk. They're efficient to use and easy to program, and they're often mentioned but not so often discussed. They show up all over the place: In the Berkeley DB_File package, which is (semi-) standard with Perl, and in large high-performance databases. For example, B-Trees are the technology that underlying IBM's well-known VSAM files.">
  <meta name="vspublisher" content="Earthweb">
  <meta name="vsimprint" content="The Perl Journal">
  <meta name="vspubdate" content="Winter 1997">
  <!-- always update the article title and issue -->

  <!-- end head -->
</head>

<body>
  <font face="verdana" size="1">Issue 8, Winter 1997</font>

  <h2 align="center">B-Trees</h2>

  <h4><i>Mark-Jason Dominus</i></h4>
  <!-- packages described, if necessary -->
  B-Trees are often described as a good way to store and retrieve
  data, especially to and from disk. They're efficient to use and
  easy to program, and they're often mentioned but not so often
  discussed. They show up all over the place: In the Berkeley
  DB_File package, which is (semi-) standard with Perl, and in
  large high-performance databases. For example, B-Trees are the
  technology that underlying IBM's well-known VSAM files.

  <p>In this article we'll see how they work. First, we'll review
  how ordinary binary trees store data, and we'll see the potential
  disadvantages of that. Then we'll look over the B-Tree algorithm
  in the abstract, and see how it corrects the flaws of binary
  trees. Then we'll look at the code of a Perl module that
  implements the B-Tree algorithms and see how B-Trees can be
  implemented in Perl.</p>

  <p>Both binary trees and B-Trees are structures for storing and
  retrieving data, just like hashes. In fact, to the user, they
  look exactly like hashes. Each contains a collection of keys, and
  each key is associated with a particular datum. In order to be
  efficient, data structures should allow you to look up the datum
  associated with a particular key very quickly. Hashes, binary
  trees, and B-trees all do that.</p>

  <p>You're supposed to learn about binary trees early in your
  programming career, so that part of this article is supposed to
  be a review. If you don't know about binary trees yet, you might
  want to read a book on data structures first, such as the one in
  this article's bibliography. Otherwise, this article might not
  make much sense.</p>

  <h3>A Review of Binary Trees</h3>

  <p>A binary tree is made of <i>tree nodes</i>. Each node has a
  key-data pair, which from now on we'll call a KDP, and each node
  also has between zero and two <i>children</i>, which are also
  tree nodes. See Figure 1 below.</p>

  <p align="center"><img src="images/b_fig1.gif" align="center"
  alt="Figure 1: Binary tree node, with children" border="0" width=
  "250" height="83"></p>

  <p align="center"><font size="-1"><b>Figure 1:</b> Binary tree
  node, with children</font></p>

  <p>Children can have other children in turn, so the entire tree
  might be very big. Until we actually see the implementation later
  in this article, we're going to forget about the data; just
  imagine it's stored in the nodes along with the keys. The
  searching algorithms we'll see only look at the keys, never at
  the data, so we can ignore the data for a while. Figure 2 shows a
  little tree.</p>

  <p align="center"><img src="images/b_fig2.gif" align="center"
  alt="Figure 2: A little tree" border="0" width="250" height=
  "138"></p>

  <p align="center"><font size="-1"><b>Figure 2:</b> A little
  tree</font></p>

  <p>In the little tree of Figure 2, A and C are children of B. We
  also say that B is the parent of A and C. Nodes with no children,
  such as A, C, and E, are called <i>leaves</i>. The topmost node,
  which has no parent, is called the <i>root</i> - node D is the
  root here. Notice that if you ignore D and E, B is the root of
  its own little tree of just A, B, and C. This mini-tree is called
  the <i>left subtree</i> of D. The right subtree of D is the even
  smaller tree that contains just E and nothing else.</p>

  <p>Keys must be orderable, so that you can say for sure when one
  is "less than" another. The exact ordering method doesn't matter
  much, so for this discussion we'll suppose that the keys are
  strings and that the ordering is the usual string ordering
  defined by Perl's string comparison operators such as
  <tt>lt</tt>. So from now on when I say that one key is less than
  another, I mean the "less than" implied by <tt>lt</tt>.</p>

  <p>The essential property of the binary tree is this: If a
  certain node contains a key, say K, then the left subtree of that
  node contains only keys that are less than K, and the right
  subtree contains only keys that are greater than K.</p>

  <p>This means you can quickly search the tree for a particular
  key. Here's how: Suppose you're looking for K. Start at the root;
  if the key in the root is K, you've found it. If K is less than
  the key in the root, move down to the root of the left subtree
  and repeat the process; otherwise, move down to the right.
  Typically, each time you move down to a subtree, the number of
  nodes left below where you are will decrease by about half (hence
  the "binary" in the name), so you'll quickly find the node you
  want.</p>

  <p>Normally, if you search for a key and you don't find it,
  you've ended at a leaf. If the reason you were searching was that
  you wanted to add a key, you build a new node with your new key
  and data and attach it as a subtree of this leaf. Let's see an
  example, where the keys are B, D, C, A, E, delivered in that
  order. Figure 3, shows each stage of the construction.</p>

  <p>First we build a B node as the root. Then we attach D as the
  right subtree of B, because D is greater than B. Then we attach C
  as the left subtree of D. (C comes after B but before D.) Then we
  attach A as the left subtree of B. (A comes before B.) Then we
  attach E as the right subtree of D. (E comes after B and after
  D.)</p>

  <p align="center"><img src="images/b_fig3.gif" align="center"
  alt="Figure 3: Constructing a binary tree " border="0" width=
  "350" height="138"></p>

  <p align="center"><font size="-1"><b>Figure 3:</b> Constructing a
  binary tree</font></p>

  <p>The average depth of a key here is 2.2, which means that to
  look up a key to see if it is in this tree, you expect to perform
  about 2.2 comparisons with the keys in the tree.</p>

  <h3>The Problem with Binary Trees</h3>

  <p>The problem with binary trees is that sometimes, if you're not
  careful, you can build them wrong - and then they're unbalanced.
  What does this mean? You'd like the tree to be pretty shallow,
  because that means you'll never have to perform many comparisons
  to find out if a key is there or not. When the tree is shallow
  and bushy, no node's right subtree is much deeper than its left
  subtree. When this is true, the tree is said to be
  <i>balanced</i>.</p>

  <p>Let's see what happens when the tree isn't balanced. If, in
  the example above, we had encountered the keys A, B, C, D, E in
  alphabetical order, then instead of growing the tree we saw
  before, of maximum depth 3 and average depth 2.2, we would have
  the tree of Figure 4, of maximum depth 5 and average depth 3.
  It's more like a vine than a tree.</p>

  <p align="center"><img src="images/b_fig4.gif" align="center"
  alt="Figure 4: Constructing a binary tree " border="0" width=
  "250" height="177"></p>

  <p align="center"><font size="-1"><b>Figure 4:</b> When binary
  trees go wrong</font></p>

  <p>The average depth here is 3, which is 36% worse than the
  example tree we saw earlier. If you get unlucky in the way you
  build your tree, and you get a vine or a tall spindly thing that
  didn't get enough light, you pay a stiff performance penalty. In
  this case, whenever you search you make 36% more comparisons than
  you would be if the tree were nice and bushy. For larger trees,
  the costs of vininess are even worse.</p>

  <h3>B-Trees are Always Balanced</h3>

  <p>B-trees avoid this vine problem by incorporating two
  improvements over ordinary binary trees.</p>

  <p>First, the nodes contain many keys instead of only one, so the
  trees are not binary. Instead of nodes like the one in Figure 5,
  we use nodes like the one in Figure 6:</p>

  <p align="center"><img src="images/b_fig5.gif" align="center"
  alt="Figure 5: A typical binary tree node" border="0" width="393"
  height="83"></p>

  <p align="center"><font size="-1"><b>Figure 5:</b> A typical
  binary tree node</font></p>

  <p align="center"><img src="images/b_fig6.gif" align="center"
  alt="Figure 6: A typical binary tree node" border="0" width="350"
  height="79"></p>

  <p align="center"><font size="-1"><b>Figure 6:</b> A typical
  B-tree node</font></p>

  <p>The nodes are analogous to the nodes in a binary tree. The
  keys in a node obey the ordering</p>
  <pre>
Key0 &lt; Key1 &lt; Key2 &lt; ... &lt; KeyN-1
</pre>

  <p>so the keys in a node are always in sorted order.
  Furthermore,</p>
  <pre>
<font face="Verdana,sans-serif" size="-1">
All the keys in Subtree<sub>0</sub>     are less     than Key<sub>0</sub>.
All the keys in Subtree<sub>1</sub>     are greater  than Key<sub>0</sub>      and less than Key<sub>1</sub>. 
All the keys in Subtree<sub>2</sub>     are greater  than Key<sub>1</sub>      and less than Key<sub>2</sub>. 
...
All the keys in Subtree<sub>N-1</sub>  are greater  than Key<sub>N-2</sub>   and less than Key<sub>N-1</sub>.
All the keys in Subtree<sub>N</sub>     are greater  than Key<sub>N-1</sub>.
</font>
</pre>

  <p>To search the tree, you start at the root node, and perform a
  binary search on the keys in the node. This is the kind of search
  you use when you look something up in the encyclopedia or the
  telephone book; you can do this because the keys in the node are
  in sorted order. You look at a clump of names, determine whether
  the name you're looking for appears earlier or later, turn
  elsewhere in the book, and repeat.</p>

  <p>If the key you want is in the node, you're done. If the key
  you want isn't in the node, then you have found a key that is
  larger than the one you want or a key that is smaller, so you
  move down to the appropriate subtree in between and continue.
  Because the fan-out is greater, a B-tree is not as deep as a
  binary tree. This is the "moving down" portion of the B-tree
  algorithm.</p>

  <p>The real improvement, however, comes when you want to insert a
  new KDP (key-data pair) into a tree. When we insert, we have a
  trick that prevents the tree from getting too deep too quickly,
  and from turning into a vine. This is the "moving up" portion of
  the algorithm. Here's how it works.</p>

  <p>Every B-Tree has a constant <i>B</i>, and each node in the
  tree is allowed to have as many as <i>B</i> keys, but no fewer
  than <i>B/2</i>. (<i>B</i> is always even.) For concreteness,
  let's suppose that <i>B</i> is four. Then nodes are allowed to
  have as few as two keys and no more than four.</p>

  <p>Now suppose we've searched for a key and didn't find it. That
  means that we've moved all the way down to a leaf of the tree,
  and now we want to insert the new key. If the leaf has fewer than
  four keys already, there is no problem; we just put the new key
  into one of the empty slots in the node, and the tree is no
  deeper than before.</p>

  <p>If the leaf node is full - that is, it already has B=4 keys -
  we do something interesting. We insert the key into the node
  anyway. But now it's too big; it has five keys and it's only
  allowed four. The overstuffed node looks like Figure 7:</p>

  <p align="center"><img src="images/b_fig7.gif" align="center"
  alt="Figure 7: A typical binary tree node" border="0" width="347"
  height="60"></p>

  <p align="center"><font size="-1"><b>Figure 7:</b> An overstuffed
  B-tree node</font></p>

  <p>Then we break it in half, so that it looks like Figure 8:</p>

  <p align="center"><img src="images/b_fig8.gif" align="center"
  alt="Figure 8: A typical binary tree node" border="0" width="493"
  height="126"></p>

  <p align="center"><font size="-1"><b>Figure 8:</b> An overstuffed
  B-tree node, broken in half</font></p>

  <p>There are now two nodes, one with Key<sub>0</sub> and
  Key<sub>1</sub>, and one with Key<sub>3</sub> and
  Key<sub>4</sub>, and there's a leftover key, Key<sub>2</sub>.</p>

  <p>And now the trick: If the leaf node's <i>parent</i> has room
  for a new key, we promote Key<sub>2</sub> there. We attach the
  two new half-full nodes as subnodes of the parent, one just to
  the left of Key<sub>2</sub> and one just to the right. Everything
  remains in the correct order.</p>

  <p>If we can do this, we've added a key into a full node without
  making the tree any deeper, by splitting the overfull node into
  two half-full nodes at the same level, and promoting the extra
  key up into the parent node, where there was room.</p>

  <p>What if there wasn't room for Key<sub>2</sub> in the parent
  node? Then we repeat the process. We promote Key<sub>2</sub> into
  the full parent anyway, and then we split the parent node in two
  and promote the middle key from the parent node into the
  grandparent node. This splitting and promoting continues until
  either there's a node somewhere up in one of the ancestors of the
  leaf that does have room, or until we get to the root.</p>

  <p>If the root is full, we split it, and since there's nowhere to
  promote the middle key, it gets promoted into a new root node all
  by itself. This is the exception to the rule that says there
  can't be fewer than B/2 keys in a node; in this case the root
  node has only one key. It's also the only time the tree gets any
  deeper. Since the tree grows from the root up instead of from the
  leaves down, the leaves are all always at the same depth, which
  means that the tree is always balanced and never gets all
  viney.</p>

  <p>Let's see that A-B-C-D-E example again, the one that gave us a
  horrible spindly vine. Only this time let's insert these keys
  into a B-tree, with <i>B=2</i>. This means that nodes are allowed
  to have no more than two keys, and no fewer than one key
  each.</p>

  <p>First we make a new root node for A:</p>

  <p align="center"><img src="images/b_fig9.gif" align="center"
  alt="Figure 9:" border="0" width="41" height="39"></p>

  <p align="center"><font size="-1"><b>Figure 9</b></font></p>

  <p>Since there's room in the root node for B, we add it:</p>

  <p align="center"><img src="images/b_fig10.gif" align="center"
  alt="Figure 10" border="0" width="75" height="45"></p>

  <p align="center"><font size="-1"><b>Figure 10</b></font></p>

  <p>(We use the double box to show that A and B are sharing living
  quarters in the same node.)</p>

  <p>Then we need to insert C into the (only) node. But there's no
  room, so we split the node into two and try to promote the middle
  key of the three, which is B. But there's nowhere to promote to,
  so B gets its own new root node:</p>

  <p align="center"><img src="images/b_fig11.gif" align="center"
  alt="Figure 11" border="0" width="181" height="85"></p>

  <p align="center"><font size="-1"><b>Figure 11</b></font></p>

  <p>Now we need to insert D; it's greater than B, so we move down
  to C's node. We can insert it there because there's room:</p>

  <p align="center"><img src="images/b_fig12.gif" align="center"
  alt="Figure 12" border="0" width="190" height="89"></p>

  <p align="center"><font size="-1"><b>Figure 12</b></font> Now we
  want to insert E. We would have liked to put it into the C-D
  node:</p>

  <p align="center"><img src="images/b_13.gif" width="197" height=
  "96" border="0" alt="Figure 13"></p>

  <p align="center"><font size="-1"><b>Figure 13</b></font> But
  we're out of room, so we split the C-D-E node, and promote D, the
  middle key, into the parent node (B). There is room for D there,
  so we're left with:</p>

  <p align="center"><img src="images/b_fig14.gif" align="center"
  alt="Figure 14" border="0" width="210" height="98"></p>

  <p align="center"><font size="-1"><b>Figure 14</b></font></p>

  <p>Just for kicks, let's see what happens if we get the keys in
  the order B, D, C, A, E, as in the very first binary tree
  example. First B goes into a new root node, and then D joins it.
  Then C wants to join also, but now the (only) node is full, so it
  splits, and C is promoted to a new root node:</p>

  <p align="center"><img src="images/b_fig15.gif" align="center"
  alt="Figure 15" border="0" width="181" height="95"></p>

  <p align="center"><font size="-1"><b>Figure 15</b></font></p>

  <p>Now A goes into B's node and E goes into D's node:</p>

  <p align="center"><img src="images/b_fig16.gif" align="center"
  alt="Figure 16" border="0" width="176" height="85"></p>

  <p align="center"><font size="-1"><b>Figure 16</b></font></p>

  <p>This isn't the same tree as before, but it still has the
  minimum possible depth. Just for fun, let's add F: It wants to go
  in with D and E, but there isn't room. So D-E-F splits, and E is
  promoted one level up, with C:</p>

  <p align="center"><img src="images/b_fig17.gif" align="center"
  alt="Figure 17" border="0" width="200" height="85"></p>

  <p align="center"><font size="-1"><b>Figure 17</b></font></p>

  <p>You might have heard of <i>2-3 trees</i> and <i>red-black
  trees</i>. When B is two, as in the examples, the B-tree is
  called a 2-3 tree because nodes always have either two or three
  subtrees. Red-black trees are 2-3 trees disguised as binary
  trees.</p>

  <h3>A Guided Tour of the Program</h3>

  <p>Now we'll see the implementation. If you'd like to see it all
  at once, you can find the source code at http://tpj.com/programs
  and at http://www.plover.com/~mjd/perl/BTree/BTree.pm. There's
  also a sample test program on the TPJ web site and at
  http://www.plover.com/~mjd/perl/BTree/testbt.pl. The main part of
  the program, which we'll see in detail, is only about forty
  lines.</p>

  <p>BTree.pm defines two classes. The important one is BTree,
  whose objects represent entire trees. BTree objects support
  methods for searching trees for keys, and for inserting new data
  into trees. The file also defines a class that's used internally
  by BTree, called BTree::Node, whose objects are single tree
  nodes. This package includes methods for getting and setting the
  keys and data in a particular node. We'll look at the important
  BTree class first, and at the subsidiary BTree::Node class only
  as it becomes necessary.</p>

  <p>A BTree has only two properties: It has a root node, and it
  has a constant B. We represent a B-Tree as a hash with two keys,
  named B and Root. If <tt>$self</tt> is a BTree object, then
  <tt>$self-&gt;</tt>B returns the B constant and
  <tt>$self-&gt;root</tt> returns the root node, which is a
  BTree::Node object.</p>

  <h3>Moving Down</h3>

  <p>The most important method in BTree is called
  <tt>0B_search()</tt>, which searches a B-Tree for a specified
  key, returns the associated datum if there is one, and possibly
  adds new data to the tree.</p>

  <p>There are several different behaviors that are useful here,
  and it turns out to be simpler to wrap them up into one function
  rather than to write four nearly-identical functions. For
  example, suppose that the search process fails to find your key.
  You might want to add that key with a new datum, or you might
  not. Similarly, if the search succeeds and your key is in the
  tree, you might have been looking for it because you wanted to
  know what data was associated with it, or you might have wanted
  to throw away the data and replace it with a new one.</p>

  <p><tt>B_search()</tt> accepts arguments in "named parameter"
  format, like so:</p>
  <pre>
$btree-&gt;B_search(Key =&gt; $your_key,      # Required 
                Data =&gt; $your_new_data, # Sometimes required 
              Insert =&gt; 1,              # Optional 
             Replace =&gt; 1,              # Optional 
);
</pre>

  <p>The <tt>Key</tt> is always required, and tells
  <tt>B_search()</tt> what key to search for. Whether <tt>Data</tt>
  is required depends on whether <tt>Insert</tt> or
  <tt>Replace</tt> are present.</p>

  <p>If the key is not in the tree, <tt>B_search()</tt> might do
  one of two things. It might simply just return a failure code, or
  it might insert the new key. You can select the latter behavior
  by including the <tt>Insert =&gt; 1</tt> flag in the arguments.
  In this case the Data parameter is required; it is inserted into
  the tree along with the Key as a new KDP.</p>

  <p>If the key is in the tree, <tt>B_search()</tt> might simply
  return its associated data, or it might replace that value with
  new data. You select the latter behavior by including the
  <tt>-Replace =&gt; 1</tt> flag in the arguments. In this case the
  Data parameter is again required, and is used to replace the data
  that is already there.</p>

  <p>If neither insert nor update mode is in effect, we say that
  <tt>B_search()</tt> is in <i>search mode</i>. In search mode you
  may not supply a <tt>Data</tt> parameter - what would it be used
  for, anyway?</p>

  <p>Let's look at <tt>B_search()</tt> in detail. The central idea
  is that the method keeps track of a "current node" with a
  variable called <tt>$cur_node</tt>. The current node starts at
  the root of the tree and moves downward until the key is found or
  until the search terminates at a leaf. In either case, what
  happens next depends on the flags: The method returns or modifies
  the associated data, or returns undef, or inserts the new KDP
  into the tree.</p>
  <pre>
1 sub B_search { 
2     my $self = shift; 
3     my %args = @_; 
4     my $cur_node = $self-&gt;root; 
5     my $k = $args{Key}; 
6     my $d = $args{Data}; 
7     my @path; 
</pre>

  <p>Here we just initialize some important variables.
  <tt>$self</tt> is the tree we're searching; line 4 initializes
  the current node to be the root of that tree. Line 3 loads the
  parameters into a hash, so that we can access them by name, as
  for example on lines 5-6.</p>
  <pre>
9     if ($cur_node-&gt;is_empty) { # Empty root 
10        if ($args{'Insert'}) { 
11            $cur_node-&gt;insert_kdp($k =&gt; $d); 
12            return $d; 
13        } else { 
14            return undef; 
15        } 
16    }
</pre>

  <p>Lines 9-16 handle the special case of a B-Tree which doesn't
  have any keys yet. Line 9 checks to see if the root node is empty
  by calling <tt>$cur_node-&gt;is_empty()</tt>. If the root node is
  entirely empty, the subroutine doesn't have much work to do:
  There are no keys in the tree at all, and the search fails
  immediately. If the subroutine is not in insert mode, it just
  returns undef to indicate failure, in Line 14. In insert mode,
  the subroutine calls (on line 11)
  <tt>$cur_node-&gt;insert_kdp()</tt> to insert the new KDP into
  the root. Normally it would have to worry that it might be
  overfilling the node, but in this case it can be sure that
  there's room, because the node is entirely empty.</p>
  <pre>
18    # Descend tree to leaf 
19    for (;;) { 
20 
</pre>

  <p>With this trivial special case out of the way, the rest of
  <tt>B_search()</tt> is a big endless loop, lines 19-51, in which
  <tt>$cur_node</tt>, the current node, moves down the tree one
  step for each pass through the loop. You can see
  <tt>$cur_node</tt> starting at the root node on line 4. The
  subroutine leaves the loop by returning when the search succeeds
  (line 28) or fails (line 40.)</p>
  <pre>
21       # Didn't hit bottom yet. 
22 
23       my($there, $where) = $cur_node-&gt;locate_key($k);
</pre>

  <p>On each pass through the loop, the subroutine checks to see if
  the desired key is in the current node. It does this on line 23
  by calling <tt>$cur_node-&gt;locate_key()</tt>.</p>

  <p><tt>locate_key()</tt> returns two values, called
  <tt>$there</tt> and <tt>$where</tt>. They are the answers to two
  questions, which are:</p>

  <p>"Is this key in this node?" (<tt>$there</tt>)<br>
  "Where, exactly, is the key?" (<tt>$where</tt>)</p>

  <p><tt>$there</tt> is a boolean value that says whether the key
  is in the node or not. It answers the question "Is it there?", so
  we put the results in the variable <tt>$there</tt> and write if
  (<tt>$there</tt>) ... to mean "if the key was there in the
  current node..." Line 24 checks to see if the key was in the
  current node in exactly this way.</p>
  <pre>
24        if ($there) { # Found it! 
25            if ($args{'Replace'}) { 
26                $cur_node-&gt;kdp($where, $k =&gt; $d); 
27        } 
28        return $cur_node-&gt;data($where); 
29     } 
</pre>

  <p>If <tt>$there</tt> is true, the key is in the current node,
  the search is done because the subroutine found the key that it
  was looking for.</p>

  <p>The key is in the node, but it is one of many such keys, and
  <tt>$where</tt> is an index that identifies which one it is.
  Later on we can use this index in calls to
  <tt>$node-&gt;kdp($where)</tt> to get or replace the key and its
  associated data. Line 25 checks to see if the subroutine is in
  replace mode. If not, line 28 just uses
  <tt>$cur_node-&gt;data($where)</tt> to fetch the
  <tt>$whereth</tt> data item from <tt>$cur_node</tt>, which
  happens to be the one associated with the key, and the subroutine
  returns the data item. In replace mode, line 26, the subroutine
  uses <tt>$cur_node-&gt;kdp($where, $k =&gt; $d)</tt>, which
  replaces the <tt>$whereth KDP</tt> in <tt>$cur_node</tt> with
  <tt>$k</tt> and <tt>$d</tt>. The subroutine then returns the new
  data.</p>
  <pre>
31     # Not here---must be in a subtree. 
32 
33     if ($cur_node-&gt;is_leaf) { # But no subtrees 
34         return undef unless $args{Flags} &amp; $BTREE_INSERT;
35         # Search failed, so stuff it in 
36         $cur_node-&gt;insert_kdp($k =&gt; $d); 
37        if ($self-&gt;node_overfull($cur_node)) { # No room! 
38          $self-&gt;split_and_promote($cur_node, @path); 
39        } 
40        return $d; 
41     }
</pre>

  <p>If the key was not in the node, <tt>$where</tt> identifies
  which of <tt>$cur_node</tt>'s several subtrees contains the key.
  But if <tt>$cur_node</tt> is a leaf, it has no subtrees, and the
  search is finished, since we know that the key isn't anywhere to
  be found. Line 33 uses <tt>$cur_node-&gt;is_leaf()</tt> to check
  to see whether the current node is a leaf.</p>

  <p>If the current node is a leaf, then the search has failed, and
  the key is not in the tree. This part of the program is
  complicated, because this is where we might have to insert new
  keys, split nodes, move up the tree, promote keys to parent
  nodes, and possibly make a new root. We'll come back to it
  later.</p>
  <pre>
43   # There are subtrees, and the key is in one of them.
44 
45   push @path, [$cur_node, $where]; # Record path from root. 
</pre>

  <p>If the current node is <i>not</i> a leaf, control passes to
  line 45. Line 45 is responsible for making a record of the path
  that the search has taken, starting from the root, and making its
  way downwards. It does this so that if we get to the "moving up"
  part of the algorithm, we can remember where we came from and
  where keys should be promoted. The record is maintained in a
  variable called <tt>@path</tt>, which is a list of the nodes that
  the subroutine visited on the way down from the root, and also of
  the <tt>$where</tt> values that the subroutine used to get from
  one node to the next.</p>
  <pre>
47     # Move down to search the subtree 
48     $cur_node = $cur_node-&gt;subnode($where); 
49 
50     # and start over. 
51   }                        # for (;;) ... 
</pre>

  <p>Line 48 then uses <tt>$cur_node-&gt;subnode($where)</tt> to
  get the identity of the <tt>$whereth</tt> subnode of the current
  node. The new node is the one that <tt>locate_key()</tt> claimed
  would contain the search key. <tt>B_search()</tt> sets
  <tt>$cur_node</tt> to be this new node, and then begins the loop
  over again.</p>

  <p>Now, what if the search fails? That's checked on line 33. In
  that case $there was false, so the key wasn't in the current
  node, and we'd like to search in a subnode of the current node.
  But we know that <tt>$cur_node-&gt;is_leaf</tt> was true, which
  means that the current node has no subnodes.</p>
  <pre>
34    return unless $args{'Insert'}; # Search failed
35    # Stuff it in 
36    $cur_node-&gt;insert_kdp($k =&gt; $d); 
37    if ($self-&gt;node_overfull($cur_node)) { # Oops--no room. 
38        $self-&gt;split_and_promote($cur_node, @path); 
39    } 
40    return $d; 
</pre>

  <p>If the subroutine is not in insert mode, it just returns
  <tt>undef</tt> to indicate failure, on line 34.</p>

  <p>In insert mode, the subroutine first inserts the new key and
  data into the appropriate place in the current node on line 36,
  with <tt>$cur_node-&gt;insert_kdp($k =&gt; $d)</tt>. Then it
  checks to see whether the current node is too full with a call to
  the <tt>node_overfull()</tt> method on line 37:
  <tt>$self-&gt;node_overfull($cur_node)</tt>.</p>

  <p>If the node isn't overfull, the subroutine's work is done,
  because <tt>insert_kdp()</tt> already put the key and data into
  the right place in the current node, and so it just returns the
  data associated with the key.</p>

  <p>If the node is overfull, however, control moves into the
  "moving up" part of the algorithm; we have to split the current
  node, promote the middle key, and possibly repeat. For
  convenience and readability, this all happens in a separate
  subroutine, called <tt>split_and_promote()</tt>.</p>

  <h3>Moving Up</h3>
  <pre>
1 sub split_and_promote { 
2     my $self = shift; 
3     my ($cur_node, @path) = @_;
</pre>

  <p><tt>split_and_promote()</tt> takes two arguments. The first is
  the current node, where it starts. The other is <tt>@path</tt>,
  which you'll recall contains a complete record of how we got to
  <tt>$cur_node</tt> in the first place. The last item in @path
  mentions the last node we visited, and that's where
  <tt>split_and_promote()</tt> will have to promote the middle key
  of <tt>$cur_node</tt>. The next-to-last item in <tt>@path</tt>
  mentions the next-to-last node we visited, and if
  <tt>split_and_promote()</tt> has to promote a key up another
  level, the next-to-last node is the one it goes into.</p>
  <pre>
5     for (;;) 
</pre>

  <p><tt>split_and_promote()</tt>, like <tt>B_search()</tt>, is an
  infinite loop (lines 5-21), interrupted a return when it is done.
  It too has a notion of the current node, <tt>$cur_node</tt>,
  which starts out at the leaf node passed from
  <tt>B_search()</tt>, and moves up, one step per pass through the
  loop.</p>
  <pre>
6                 my ($newleft, $newright, $kdp) = 
                            $cur_node-&gt;halves($self-&gt;B / 2); 
</pre>

  <p>The first thing <tt>split_and_promote()</tt> does on each pass
  is to split the current node in two; it does this with the
  <tt>halves()</tt> method. <tt>$cur_node-&gt;halves()</tt> breaks
  the node anywhere we tell it to; by passing it <i>B/2</i>, we
  break the node in the middle, so that key number <i>B/2</i> is
  left over. <tt>halves()</tt> returns three things:
  <tt>$newleft</tt> and <tt>$newright</tt>, which contain the left
  and right halves of the old node, and <tt>$kdp</tt>, which
  contains the leftover key and data that will be promoted. If you
  hark back to Figure 8, <tt>$newleft</tt> is the node on the left,
  with Key<sub>0</sub>, Key<sub>1</sub>, Subtree<sub>0</sub>,
  Subtree<sub>1</sub>, and Subtree<sub>2</sub>. <tt>$newright</tt>
  is the node on the right, with Key<sub>3</sub>, Key<sub>4</sub>,
  Subtree<sub>3</sub>, Subtree<sub>4</sub>, and
  Subtree<sub>5</sub>. <tt>$kdp</tt> is the leftover key and its
  associated data, which Key<sub>2</sub> in the picture.</p>

  <p>After splitting the overfull node,
  <tt>split_and_promote()</tt> determines where to promote the
  leftover key and where to reattach $newleft and $newright. This
  information is in the @path list. Line 7 extracts the last
  element from <tt>@path;</tt> this element mentions <tt>$up</tt>,
  the node above the current one, and <tt>$where</tt>, which says
  that <tt>$cur_node</tt> is the <tt>$whereth</tt> sub-node of
  <tt>$up</tt>.</p>
  <pre>
7     my ($up, $where) = @{pop @path}; 
8     if ($up) { 
</pre>

  <p>If, on line 7, the <tt>@path</tt> array was exhausted, then we
  know that <tt>$cur_node</tt> is the root of the tree, that the
  root was overfull, and that line 6 actually split the root node.
  We test for this possibility on line 8, which checks to see if
  the <tt>$up</tt> node we thought we got from <tt>@path</tt> was
  actually defined.</p>

  <p>If so, <tt>$up</tt> looks like Figure 18.</p>

  <p align="center"><img src="images/b_fig18.gif" align="center"
  alt="Figure 18" border="0" width="532" height="97"></p>

  <p align="center"><font size="-1"><b>Figure 18: <tt>$up</tt>
  before promotion of <tt>$kdp</tt></b></font></p>

  <p><tt>split_and_promote()</tt>'s job then is to make
  <tt>$up</tt> look like Figure 19 instead:</p>

  <p align="center"><img src="images/b_fig19.gif" align="center"
  alt="Figure 19" border="0" width="462" height="79"></p>

  <p align="center"><font size="-1"><b>Figure 19: <tt>$up</tt>
  after promotion of <tt>$kdp</tt></b></font></p>

  <p><tt>split_and_promote()</tt> calls
  <tt>$up-&gt;insert_kdp(@$kdp)</tt> to insert the leftover KDP
  into the appropriate place in <tt>$up</tt>, at line 9 in the
  program. <tt>insert_kdp()</tt> takes care of moving around the
  subnodes that are already there so that they stay in the right
  places. Then, in lines 10-11, <tt>split_and_promote()</tt>
  attaches <tt>$newleft</tt> and <tt>$newright</tt> as subnodes of
  <tt>$up</tt>, adjacent to <tt>$kdp</tt>, by calling
  <tt>$up-&gt;subnode()</tt>.</p>

  <p>Were we paranoid, we could ensure that $kdp was went into $up
  where we expected, by calling $up-&gt;locate_key($kdp-&gt;[0])
  and seeing if $there was true, and if the $where we got back
  matched the one that we got from @path. (The <i>BTree.pm</i>
  module actually does include these checks, but I left them out of
  the article for clarity.)</p>
  <pre>
12     return unless $self-&gt;node_overfull($up); 
13     $cur_node = $up; 
</pre>

  <p>After attaching the new subnodes, <tt>split_and_promote()</tt>
  checks to see if <tt>$up</tt> is overfull, on line 12. If it
  isn't, then <tt>split_and_promote()</tt> is finished, and
  returns. Otherwise, it sets <tt>$cur_node</tt> to <tt>$up</tt>
  (line 13), to move one step up the tree, and it starts the
  infinite loop over again, to split <tt>$up</tt> and promote its
  middle key another step up.</p>

  <p>If the promotion goes all the way to the root, and then even
  the root is overfull, then we have to split the root. When line 7
  tries to get the parent of the root from the <tt>@path</tt>, it
  gets nothing, and control passes to line 14:</p>
  <pre>
14           } else { # We're at the top; make a new root.
15           my $newroot = new BTree::Node ([$kdp-&gt;[0]],
16       [$kdp-&gt;[1]],
17               [$newleft, $newright]); 
18           $self-&gt;root($newroot); 
19           return; 
20       }
</pre>

  <p>Lines 15-17 call new <tt>BTree::Node()</tt> to manufacture a
  new root node with the leftover key and associated data, and with
  <tt>$newleft</tt> and <tt>$newright</tt> as its only subnodes.
  Then line 18 sets the root of the tree to be the new root node,
  and line 19 returns because the whole process is done.</p>

  <h3>Details</h3>

  <p>That's been a long rough journey, but it covers the important
  methods and how they work; everything else is just details. The
  most important detail is the internal structure of a BTree::Node.
  A node needs three things: keys, data associated with those keys,
  and subnodes. In this program, we store these as three lists, so
  that each node will be a reference to a list of three lists: The
  list of keys, the list of data, and the list of subnodes. If
  there are <i>N</i> keys, there are also <i>N</i> data, and
  <i>N+1</i> subnodes. Figure 11 depicts this:</p>

  <p align="center"><img src="images/b_fig20.gif" align="center"
  alt="Figure 20" border="0" width="456" height="105"><br>
  <font size="-1"><b>Figure 20: Internal structure of a
  <tt>Btree::Node</tt></b></font></p>

  <p>Empty nodes are represented by a completely empty list
  <tt>[]</tt>. They only occur as the root nodes of completely
  empty trees.</p>

  <p>The node constructor, <tt>BTree::Node::new()</tt>, accepts
  three parameters, which it installs as the three lists of the new
  node. If you omit the three lists, it installs nothing, and you
  get an empty node:</p>
  <pre>
sub new {
 my $self = shift;
  my $package = ref $self || $self;
   bless [@_] =&gt; $package; 
} 
</pre>

  <p><tt>split_and_promote()</tt> uses the <tt>new()</tt> method
  when it constructs a new root.</p>

  <p>The package contains a lot of simple methods for getting and
  setting keys and subnodes and the like; for example, there's a
  <tt>subnode()</tt> method, which returns the <tt>$nth</tt>
  subnode of the node if you invoke it like this:</p>
  <pre>
         $node-&gt;subnode($n)
</pre>

  <p>It sets and returns the $nth subnode if you invoke it like
  this:</p>
  <pre>
         $node-&gt;subnode($n, $new_subnode);
</pre>

  <p>Here's the subroutine:</p>
  <pre>
sub subnode { 
    my ($self, $n, $newnode) = @_; 
    $self-&gt;[$SUBNODES][$n] = $newnode if defined $newnode;
    $self-&gt;[$SUBNODES][$n]; 
} 
</pre>

  <p><tt>$SUBNODES</tt> is a constant. If <tt>$self</tt> is a
  BTree::Node, it has three lists, and the third of these is the
  list of subnodes of <tt>$self</tt>. <tt>$SUBNODES</tt> is just
  two, so that we can write <tt>$self-&gt;[$SUBNODES]</tt> instead
  of <tt>$self-&gt;[2]</tt> when we want to get the list of
  subnodes, and similarly we can write
  <tt>$self-&gt;[$SUBNODES][$n]</tt> instead of
  <tt>$self-&gt;[2][$n]</tt> to get the <tt>$nth</tt> subnode.
  Analogously, <tt>$KEYS</tt> and <tt>$DATA</tt>, not shown here,
  are constants equal to zero and one.</p>

  <p>The <tt>BTree::Node::locate_key()</tt> method might be
  instructive if you've never seen a binary search before. I won't
  show it, but I will point out a useful software engineering
  tactic: Binary search is notoriously hard to write correctly - it
  has a lot of funny boundary cases - and so for the early versions
  of the module, I didn't bother writing it correctly. I used an
  easy-to-program linear search instead, and I replaced slow linear
  search with quick binary search only once everything else was
  already working.</p>

  <h3>Other Directions</h3>

  <p>The most important point about B-Trees is that it's easy to
  implement a version that saves the tree on disk. The tree nodes
  never need to grow or shrink, so you never have the problem of
  having to move one to a different place in the file when you
  insert a key. For this reason, they are frequently used for disk
  databases where the data have to be accessed by key. I didn't
  show this because the basic algorithm is already complicated
  enough; Our Most Assiduous Reader might like to modify BTree.pm
  so that it stores and maintains its tree structure in a file
  instead of memory, using <tt>tie()</tt>.</p>

  <p>By now you should be thinking of DBM files. A DBM file is a
  database on disk. The data in the file are available to your Perl
  program through a special hash variable, called a "tied"
  variable. The tied variable looks just like a regular hash
  variable, except that when you read from it the data come from
  the disk, and when you store something in it the data are written
  back to the disk. They persist beyond the lifetime of your
  program.</p>

  <p>One DBM package commonly used with Perl is the Berkeley
  DB_File package, which can use a B-Tree structure to store and
  retrieve data by key. Our Most Assiduous Reader might like to add
  a "tied hash" interface to the BTree package presented here. The
  fetching and storing methods are quite simple; fetching is just a
  call to <tt>B_search()</tt> in search mode, and storing is just a
  call in insert-and-replace mode. Only <tt>nextkey()</tt>, which
  is used by the <tt>keys()</tt>, <tt>values()</tt>, and
  <tt>each()</tt> functions, presents any real difficulty.</p>

  <p>When used in DBM files, B-trees have another big advantage
  over binary trees - even balanced binary trees. The binary search
  that occurs in a B-tree node takes about the same amount of CPU
  time as the binary search on the nodes of a binary tree with the
  sane number of keys. But when the tree lives on disk, each node
  must be loaded into memory before it can be examined. In a
  B-tree, you can adjust B so that each entire node can be loaded
  with exactly one disk operation, and then searched quickly in
  memory. In a binary tree, each key resides in its own node, which
  must be loaded from disk separately. A binary tree therefore
  typically requires between <i>B/2</i> and <i>B</i> times as many
  disk accesses as a B-tree of similar size, because it has fewer
  keys per node. When the tree lives on the disk, the time to
  search the tree is dominated by the disk access time, and B-trees
  are therefore much faster than even balanced binary trees.</p>

  <p>DBM files are almost invariably implemented with either
  B-trees or with hash tables. (Hash tables are the method that
  Perl uses for regular in-memory hash variables.) However, B-Trees
  present one enormous advantage over hash tables: The keys are
  stored in sorted order. Why is this important? Suppose you have a
  range, and you want to retrieve all the data for all the keys in
  that range. You can do this efficiently if your database is
  stored using B-trees: Locate the two keys corresponding to the
  upper and lower bounds of the range, and then take all the keys
  in between. (If you did the previous exercise, you can use your
  <tt>nextkey()</tt> function to get the keys in between.) With
  hash tables, the keys are not stored in any particular order, so
  there is no "in between," and to retrieve a range of them, you
  must retrieve all the keys, extract the ones you want, sort them
  into order, and then query the hash once for each key. That's
  vastly less efficient.</p>

  <h3>Bibliography</h3>

  <p><i>Fundamentals of Data Structures in Pascal</i>, Ellis
  Horowitz and Sartaj Sahni, Computer Science Press, 1984, pages
  491-512.</p>

  <h3>Notes from Last Column (Infinite Lists)</h3>

  <p>Rujith S. de Silva pointed out that the <tt>hamming()</tt>
  function from my article about lazy streams could be simplified.
  Gene Hsu and I discussed multi-way merge functions. Also, I posed
  an exercise about the sequence 4,7,10,13,19,22,25,31,... and
  other matters are discussed at <a href=
  "http://www.plover.com/~mjd/perl" target=
  "_blank">http://www.plover.com/~mjd/perl</a>.</p>

  <p>_ _END_ _</p>
  <hr>
  <i>Mark-Jason Dominus is chief programmer for Plover Systems. He
  lives in Philadelphia with his new wife and their five stuffed
  octopuses, and can be reached at <a href=
  "mailto:mjd-tpj@plover.com">mjd-tpj@plover.com</a></i> 
  <!-- end of article -->
   <!-- end of file -->
</body>
</html>
