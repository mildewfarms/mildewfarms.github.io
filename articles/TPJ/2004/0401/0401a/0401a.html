
<html>
<head>
<title>January, 2004: Coverage Testing with Pod::Coverage and Devel::Cover</title>
</head>

<body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000">
<!--Copyright &#169; The Perl Journal-->

<h1>Coverage Testing with Pod::Coverage and Devel::Cover</h1>
<p><i>The Perl Journal</i> January, 2004</p>
<h2></h2>


<h3>By Andy Lester</h3>


<I>Andy manages programmers for Follett Library Resources in McHenry, IL. In his spare time, he works on his CPAN modules and does technical writing and editing. Andy is also the maintainer of Test::Harness and can be contacted at andy@petdance.com.</I>

<hr>





<p>Coverage testing lets you automatically find out what parts of your code are covered by tests or by documentation. It's an extension of automated testing that I've written about before. For someone who's releasing code to CPAN, documentation coverage is important for making sure that you have documented everything.</p>

<p>Code coverage lets you make sure that your test suite actually exercises all the options and paths through which the code can travel. I used it to find some functions that had never been tested because they were never actually used anywhere, much less in the test suite.</p>
<h3>Starting with Documentation Coverage</h3>

<p>The easiest way to think about coverage is by looking at documentation coverage. A simple rule to follow for your code is: "Every subroutine must have a block of POD that describes it." Subroutines that are documented are said to be covered, and those that aren't are uncovered or naked.</p>

<p>The following program, <i>pcover</i>, matches up POD sections to subroutines. It's pretty simple and works well for very regular, nontricky code in a single file.</p>

<blockquote>
<pre>
#!/usr/bin/perl -w

use strict;
my %subs;
my %docs;

while ( &lt;&gt; ) {
    chomp;
    # Assume a =head1, =head2 or =item is the start
    # of some documentation.
    if ( /^=(head[12]|item [\d*]+)\s+([^({]+)/ ) {
        my $item = $2;
        $item =~ /([a-zA-Z0-9_]+)$/ or next;
        $docs{ $1 } = $.;
        next;
    }

    # Find subroutine declarations and stash the line
    # number where it appears.
    if ( /^\s*sub\s+([a-zA-Z0-9_]+)/ ) {
        my $sub = $1;
        $subs{ $sub } = $.;
        next;
    }
} # while

my $nerr = 0;
for my $sub ( sort keys %subs ) {
    if ( !$docs{ $sub } ) {
        print "The following subroutines have no docs:\n"
            if ++$nerr == 1;

        print "$sub, line $subs{$sub}\n";
    } # if
} # for
printf "%d sub%s found without docs.\n", $nerr, $nerr == 1 ? "" : "s";

</pre>
</blockquote>



<p>Now, when I run <i>pcover </i>against <i>WWW::Mechanize</i>,</p>

<blockquote>
<pre>
$ pcover 'perldoc -l WWW::Mechanize'

</pre>
</blockquote>



<p>or</p>

<blockquote>
<pre>
$ pcover /usr/local/lib/perl5/site_perl/5.8.1/WWW/Mechanize.pm

</pre>
</blockquote>



<p>I get the following:</p>

<blockquote>
<pre>
The following subroutines have no docs:
_die, line 1397
_pop_page_stack, line 1350
_warn, line 1390
die, line 1380
res, line 808
warn, line 1370
6 subs found without docs.

</pre>
</blockquote>



<p>(Note: If you haven't seen <i>perldoc -l Module::Name</i> before, start using it now. It prints out the full path of any module, so long as it contains some POD. It will save you much typing and hunting for module files.)</p>

<p>So I have six functions that aren't documented, at least according to my simple program. The first three, with the underscores, are for internal use only, so I don't mind. I have docs for <i>res()</i>, but the heuristic didn't find it. That leaves me only two that I actually need to document.</p>

<p>Aside from the problems described earlier, there's a big, unfixable problem with <i>pcover</i>. The heuristic for finding subroutine names relies on a very rudimentary parsing of Perl and doesn't handle the possibility that documentation for a package might be in a different module. Still, for simple coverage checking of simple modules, <i>pcover</i> may be all you need, and without having to install any new modules.</p>
<h3><i>Pod::Coverage</i> to the Rescue</h3>

<p>For flexibility and accuracy, we turn to <i>Pod::Coverage</i>, which takes a different approach to handling the code. As Tom Christiansen said, "Nothing but Perl can parse Perl," so instead of trying to parse the contents of a source file itself, <i>Pod::Coverage </i>loads up the module into Perl, then takes a peek at the Perl internals. The documentation is still found with a simple set of heuristics, but they're far more flexible than <i>pcover</i>'s.</p>

<p><i>Pod::Coverage </i>was cowritten and is maintained by the wily Richard Clamp, most notable for his <i>File::Find::Rule</i>. Like <i>File::Find::Rule</i>, <i>Pod::Coverage</i> is clever and flexible, with three different ways to use the module. The easiest is right from the command line:</p>

<blockquote>
<pre>
$ perl -MPod::Coverage=WWW::Mechanize -e1

</pre>
</blockquote>



<p>The <i>-M</i> flag tells the Perl executable to load <i>Pod::Coverage</i> as a module, passing <i>MARC::Record</i> as a parameter. The <i>-e1</i> is just a dummy program that does nothing, since <i>Pod::Coverage</i> does all its magic at load time.</p>

<p>When I run that command line, I get output similar to <i>pcover</i>:</p>

<blockquote>
<pre>
WWW::Mechanize has a Pod::Coverage rating of 0.948717948717949
The following are uncovered: die, warn

</pre>
</blockquote>

<p>The coverage rating of 0.948... means that 95 percent of my subroutines are documented. Note that <i>Pod::Coverage</i> took care of the problems that <i>pcover</i> didn't handle: It ignored functions prepended with underscores, and it found the documentation for <i>res()</i>. As an author, I'm glad that <i>Pod::Coverage</i> found these because I realized that their differences from the core <i>die</i> and <i>warn</i> need to be noted.</p>

<p>Note that when we invoke <i>Pod::Coverage</i> this way, it expects that the module has already been installed on your system, and you can't pass a filename. If you've got a module you're working on, but haven't installed it on your system, you'll need to use a different approach. This command-line version also only works with a single module, not multiple modules in a distribution. For this extra flexibility, the <i>pod_cover</i> script, installed for you by <i>Pod::Coverage</i> as of Version 0.13, is a good place to start.</p>

<p><i>pod_cover</i> assumes that you have a <i>lib/</i> directory that contains the modules you want to check, and checks them all for you. When I run this on my working directory for the <i>WWW-Mechanize</i> distribution, I find that at least the other module is covered:</p>

<blockquote>
<pre>
Pod coverage analysis v1.00 (C) by Tels 2001.
Using Pod::Coverage v0.13

Sun Dec 28 22:14:52 2003 Starting analysis:

WWW::Mechanize has a doc coverage of 94.87%.
Uncovered routines are:
 die
 warn

WWW::Mechanize::Link has a doc coverage of 100%.

Summary:
 sub routines total    : 47
 sub routines covered  : 45
 sub routines uncovered: 2
 total coverage        : 95.74%

</pre>
</blockquote>

<p>This is very convenient for a distribution with many modules. Just imagine having to maintain Dave Rolsky's <i>DateTime-TimeZone</i>!</p>
<h3>Modifying the Rules</h3>

<p>If the default settings for <i>pod_cover</i> don't fit your needs, you can quickly whip up a customized script. As part of the Phalanx project (http://qa.perl.org/phalanx/), I'm checking coverage of <i>Test::Reporter</i>, which has a few quirks. The documentation for it is kept in a .pod file, and there are a number of constant functions that need not be documented. Fortunately, the constant functions are all named with all capital letters, so it's easy to write a regular expression to match them. This little script gives me the accurate coverage results:</p>

<blockquote>
<pre>
use Pod::Coverage;
use lib 'lib';

my $pc = 
    Pod::Coverage-&gt;new(
        package =&gt; 'Test::Reporter',
        also_private =&gt; [ qr/^[A-Z_]+$/ ],
        pod_from =&gt; 'lib/Test/Reporter.pod',
    );
print "Coverage = ", $pc-&gt;coverage, "\n";
print "Uncovered: ", join( ", ", $pc-&gt;uncovered ), "\n";

</pre>
</blockquote>

<p><i>pod_from</i> tells the constructor where to find the POD for the module, and <i>also_private</i> is a reference to an array of regular expressions that match subroutines that don't need to be documented. I only needed one <i>regex</i> to match the functions in question, but I could have passed as many as necessary.</p>
<h3><i>Devel::Cover</i></h3>

<p>Documentation coverage is helpful to ensure that no undocumented subroutines slip through the cracks. Code coverage is the measure of whether or not your tests are exercising all the parts of the code that they should.</p>

<p>Paul Johnson's <i>Devel::Cover</i> works by installing itself as a debugger hook, running your code, and then saving its metrics to a special database directory, called <i>cover_db</i> by default. Then, when you run the cover program, you'll be given two sets of output: a plain text summary of the coverage stats for each file and a set of HTML files that give in-depth, line-by-line code coverage analysis of your program. Plus, as an added bonus, if you have <i>Pod::Coverage</i> installed, <i>Devel::Cover</i> does documentation coverage analysis and includes it with the code coverage. Such a deal!</p>

<p>Before running your code coverage analysis, it's important to understand the four different types of code coverage that <i>Devel::Cover</i> tracks: subroutine, statement, branch, and condition. To illustrate, let's look at a simple piece of code and the tests for it.</p>

<p>Say I have a module, <i>My::Math</i>, with a subroutine, <i>my_sqrt</i>, that returns the square root of its parameter, but checks that it's not a negative number or undefined. If it is, it warns the user and returns 0:</p>

<blockquote>
<pre>
 1  =head2 my_sqrt( $n )
 2  
 3  Returns the square root of I&lt;$n&gt;.  If I&lt;$n&gt; is not defined,
 4  or is negative, return 0.
 5  
 6  =cut
 7  
 8  sub my_sqrt {
 9      my $n = shift;
10  
11      if ( !defined($n) || ($n &lt; 0) ) {
12          warn "my_sqrt() got an invalid value\n";
13          $n = 0;
14      }
15  
16      return sqrt($n);
17  }

</pre>
</blockquote>

<p>Then, somewhere in my test suite, I have a t/sqrt.t that tests that the module works as advertised:</p>

<blockquote>
<pre>
use Test::More tests=&gt;2;

is( my_sqrt( 25 ), 5 );
is( int(my_sqrt(2) * 1000), 1414 );

</pre>
</blockquote>

<p>Unfortunately, these two tests don't exercise as much of the code as they should. When I run the t/sqrt.t under <i>Devel::Cover</i>, the coverage percentages are pretty low:</p>

<blockquote>
<pre>
File	stmt	branch	cond	sub
--------------------------------	-----	------	------	------
sqrt.pl	60.00	50.00	33.33	100.00

</pre>
</blockquote>

<p>Let's look at each of these different coverage categories.</p>

<p>Subroutine coverage is simple. There's only one subroutine and the tests executed it at least once, so my subroutine coverage is 100 percent.</p>

<p>Statement coverage is the measure of how many of the statements in the code have been run at least once. There are five statements in the example: lines 9, 11, 12, 13, and 16.</p>

<blockquote>
<pre>
 9      my $n = shift;
11      if ( !defined($n) || ($n &lt; 0) ) {
12          warn "my_sqrt() got an invalid value\n";
13          $n = 0;
16      return sqrt($n);

</pre>
</blockquote>



<p>Since I never pass an <i>undef</i> or negative to the subroutine, lines 12 and 13 never get executed in the test. Therefore, the statement coverage is only 3/5, or 60 percent.</p>

<p>Branch coverage measures whether each possible branch has been taken. Any <i>if </i>statement has exactly two possible branches, regardless of how complex the expression being evaluated is. My subroutine only has one branch, and only one of its possible branches gets taken. Therefore, my branch coverage is 1/2, or 50 percent.</p>

<p>Conditional coverage is related to branch coverage, but looks inside the contents of the conditionals for possible combinations of values. This is usually represented as a truth table and takes into account short-circuit Boolean evaluation.</p>

<p>For the expression:</p>

<blockquote>
<pre>
!defined($n) || ($n &lt; 0)

</pre>
</blockquote>



<p>there are three combinations of values:</p>

<blockquote>
<pre>
!defined($n)    $n &lt; 0
------------    -------
     0             0 
     0             1
     1             1

</pre>
</blockquote>

<p>Since my tests only pass positive, defined numbers, the last row in the truth table is the only one that's been exercised. Therefore, my conditional coverage is only 33 percent.</p>
<h3>Improving My Coverage</h3>

<p>Now that we understand the different types of coverage, how can I improve them? I'll start with passing <i>undef</i>:</p>

<blockquote>
<pre>
is( my_sqrt(undef), 0 );

</pre>
</blockquote>



<p>which improves my results:</p>

<blockquote>
<pre>
File	stmt	branch	cond	sub
-------------------------------	-----	------	-----	------
sqrt.pl	100.00	100.00	66.67	100.00

</pre>
</blockquote>

<p>The main branch does get taken, which means that all the statements have now been executed, bringing statement and branch coverage up to 100 percent. However, I've only taken two of the three conditions in the truth table. To get to 100 percent conditional, I need to add a test for the negative number:</p>

<blockquote>
<pre>
is( my_sqrt(-1), 0 );

</pre>
</blockquote>



<p>Now, I have 100 percent coverage of all statements, all branches and all conditions:</p>

<blockquote>
<pre>
File	stmt	branch	cond	sub
------------------------------	-----	------	------	-----
sqrt.pl	100.00	100.00	100.00	100.00

</pre>
</blockquote>
<h3><i>Devel::Cover</i> in the Real World</h3>

<p>Of course, when you use <i>Devel::Cover</i> on your code, the results won't be quite so clear. One thing that will help is to make a script to automate the running of your code and generating the resulting HTML pages. I call mine <i>gocover</i>, and it works on any module because everything is relative to the current directory:</p>

<blockquote>
<pre>
cover -delete
HARNESS_PERL_SWITCHES=-MDevel::Cover make test
cover
open ./cover_db/coverage.html

</pre>
</blockquote>



<p>Note that this script is specifically for coverage testing on a standard module that uses <i>make test</i> to run its test suite. See the <i>Devel::Cover</i> documentation for examples of how to run other sorts of tests. The last line with the <i>open</i> command opens the main HTML file in my browser under Mac OS X. Adjust accordingly for your operating system.</p>

<p>When you run <i>gocover</i>, you'll notice things being significantly slower, taking about five to eight times as long to run because <i>Devel::Cover</i> is watching your program as it runs and collecting information along the way. Fortunately, the <i>cover</i> command runs quickly, generating a set of HTML files.</p>

<p>The first report file, <i>coverage.html</i>, is your thumbnail sketch of the files in your module, with coverage statistics for each of them. You'll notice a number of hyperlinks in the summary: Each filename and each percentage for branch, conditional, and subroutine coverage. Each of these links jumps to a specific subreport. All the reports are color coded&#151;with green meaning something good and red meaning something bad&#151;making it easy to skim the report for hotspots in your code.</p>

<p>The File Coverage page gives a full listing of a given file with metrics for each statement or subroutine as appropriate. The <i>stmt</i> column shows the number of times that the statement was executed, and the <i>sub</i> column shows how many times the subroutine was called. The <i>branch</i> and <i>cond</i> give percentages of coverage for the statement. The <i>time</i> column tells the number of milliseconds spent on each statement, which can help provide rudimentary profiling information.</p>

<p>Each of the Branch, Conditional, and Subroutine reports gives a summary of each branch, conditional, or subroutine, and summarizes the coverage for each. It's the same information as on the full File Coverage report, but condensed for easy skimming. You can also get to each of these summary reports from hyperlinks on  the File Coverage page. Paul has made navigation between these pages very easy and helpful.</p>
<h3>Improving your Coverage</h3>

<p>So you've got a report on your module and you find that your coverage is weak. What do you do? First, remember that <i>Devel::Cover </i>is a tool, not an arbiter of correctness. It's up to you as the author to make the important decisions. That being said, it's a good idea to have all of your code exercised by your tests to make sure that everything works as you expect.</p>

<p>When I first ran coverage reports on <i>WWW::Mechanize</i>, I was disappointed to see how low my coverage numbers were. I'd been proud of <i>WWW::Mechanize</i>'s testing suite, thinking it was fairly comprehensive, but <i>Devel::Cover</i> pointed out all the places I hadn't exercised. Most of the deficiencies fell into three areas.</p>

<p>The first, and the easiest to correct, was documentation coverage. I'd added a number of methods that I hadn't bothered to document, so fixing that was easy. I also found some methods that I considered as internal to my module, but that weren't prepended with underscores, so I renamed them.</p>

<p>Another source of the dreaded red boxes in my coverage reports were under-exercised default values. In a function that accepts default values, like a hypothetical text-writing function:</p>

<blockquote>
<pre>
sub draw_string {
    my $str = shift;
    my $color = shift || "black";
    ...
}

</pre>
</blockquote>

<p>the second statement has two different conditions that need to be tested: when a value for <i>$color</i> is passed in and when it isn't. I found that in all my tests, I'd been taking the default values, but had never exercised the code that overrides them. A few extra tests took care of covering them.</p>

<p>Finally, I never tested my warning conditions to see if they actually generated warnings. For example, <i>Mech</i>'s <i>agent_alias</i> method lets you set your User-Agent string with an easy-to-read string like "Netscape 6," but if the alias isn't recognized, <i>agent_alias</i> emits a warning. Adding tests for this was simple with <i>Test::Warn</i>:</p>

<blockquote>
<pre>
use Test::Warn;
my $m = WWW::Mechanize-&gt;new;
isa_ok( $m, 'WWW::Mechanize' );

warning_is {
    $m-&gt;agent_alias( "Blongo" );
} 'Unknown agent alias "Blongo"', "Unknown alias squawks";

</pre>
</blockquote>

<p>For checking behaviors where your code should die or throw exceptions, check out the <i>Test::Exception</i> module. Both should be in any module author's testing arsenal.</p>

<p><i>Pod::Coverage</i> and <i>Devel::Cover</i> are both handy tools to help maintain your code, whether it's a module for distribution or just a simple web script. Even if you don't make your code run 100 percent under the tools, take the time to try it once. I guarantee you'll find at least one surprising thing in your code.</p>


<p><b></b></p>
<p><b>TPJ</b></p>




</body>
</html>