<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <title>Braille Contractions and Regular Expressions - The Perl Journal, Fall 1999</title>
  <meta name="generator" content=
  "HTML Tidy for Linux/x86 (vers 12 April 2005), see www.w3.org">
  <meta name="vscategory" content="Perl">
  <meta name="vsisbn" content="">
  <meta name="vstitle" content=
  "Braille Contractions and Regular Expressions">
  <meta name="vsauthor" content="Sean M. Burke,Sheri Wells-Jensen">
  <meta name="searchdescription" content=
  "This article is about how I used regular expressions to turn common English text into Braille, correctly using all the possible shorthand-like contractions and abbreviations that Braille provides.">
  <meta name="vsimprint" content="The Perl Journal">
  <meta name="vspublisher" content="Earthweb">
  <meta name="vspubdate" content="Fall 1999">
  <!-- always update the article title and issue -->

</head>

<body bgcolor="#FFFFFF">
  <font face="verdana" size="1">Issue 15, Fall 1999</font>

  <h2 align="center">Braille Contractions and Regular
  Expressions</h2>

  <h4><i>Sean M. Burke with Sheri Wells-Jensen</i></h4>

  <p>This article is about how I used regular expressions to turn
  common English text into Braille, correctly using all the
  possible shorthand-like contractions and abbreviations that
  Braille provides. This is basically a case study in how a messy
  problem got solved straightaway with Perl - but along the way
  I'll mention some of the new features to be found in Perl 5.005's
  regular expressions, which I used along the way; and in the end,
  I find a surprising commonality between regexes and natural
  language writing systems.</p>

  <div align="center">
    <img src="images/burke-fig1.gif" width="350" height="223"
    border="0" alt="alphabet blocks for braille">
  </div>

  <h3>Braille, and Braille Contractions</h3>

  <p>When I was a little kid, I had a children's book about Helen
  Keller. I don't remember reading it; I just remember the back
  cover, which had the Braille alphabet printed on it - well,
  embossed, actually. They had the Roman letter "a" in ink, and
  then below that the embossed dot pattern for Braille "a", and so
  on up to "z". So I got the idea that Braille printing is just
  like a letter-for-letter substitution cipher for the Roman
  alphabet.</p>

  <p>Then I started noticing on men's room doors that below "MEN"
  in big Roman letters, there'd be the same word in Braille - but
  sometimes the word would have three Braille characters, and
  sometimes just two. And that I found perplexing. I couldn't
  imagine how the word "men" could end up only two characters
  long.</p>

  <p>So I asked my friend Sheri, who's been reading and writing
  Braille since she was a kid, how "men" could be just two
  characters long. She explained that Braille has contractions: the
  first character in "men" is "m", and the second character is a
  contraction for "en". (For the rest of this article, I'll use
  wedges to denote contractions, so "&lt;en&gt;" will mean the
  <i>single</i> Braille character that is a contraction for the two
  Roman letters "en".)(Braille readers typically use the term
  "sign" to mean a Braille character.)</p>

  <p>Moreover, some contractions are context-specific - there's a
  contraction for "com", but it can apply only at the start of
  words, as in "computer". These shorthand-like contractions make
  reading Braille faster, and they make books in Braille less
  expensive and less bulky.</p>

  <p>There are contractions for "en", "st", "ea", "er", "the" (the
  letter sequence, not just the word "the"), and lots more. It
  occurred to me that there were cases where I could imagine more
  than one way to apply contractions. Consider the two ways to
  encode the word "leather":</p>
  <pre>
 l e a t h e r
 . \_/ \_/ \_/     -  contract "ther" as "&lt;th&gt;&lt;er&gt;"
</pre>

  <p>or</p>
  <pre>
  l e a t h e r
  . \_/ \___/ .     -  contract "ther" as "&lt;the&gt;r"
</pre>

  <p>In each case, you end up with a word four letters long, so
  brevity can't be a tie-breaker. I asked Sheri whether both were
  acceptable spellings and she said no; the second spelling, with
  "&lt;the&gt;r", is the only correct way to encode "leather". This
  reminded me of English hyphenation. For example, you <i>could</i>
  hyphenate "boggling" as "bogg-ling" (sort of like "gos-ling",
  maybe), but you could also hyphenate it as "bog-gling", and that
  seems the <i>best</i> way to do it, so that gets to be the
  <i>correct</i> way.</p>

  <p>So I was curious how this would be implemented as an encoding
  algorithm. Sheri explained that programs do exist for taking
  conventional English text, and applying all the contractions
  possible, in the right places - what I'll just call "Braille
  encoding." Braille encoding programs can be embedded in tactile
  displays for computers, so that when I send Sheri email
  (unencoded), it shows on her display in encoded Braille. Or a
  Braille encoder can be a program that encodes a whole file at a
  time, typically for preparing an unencoded text file for sending
  to a Braille embosser, a kind of impact printer.</p>

  <p>One encoder program is from the National Federation of the
  Blind, and is called NFBTRANS. NFBTRANS is by no means the only
  such program around. Another widely used program is DBT, Duxbury
  Braille Translator. DBT, however, is a commercial product, with
  no source available. NFBTRANS is free, and comes with source
  code.</p>

  <p>I hunted down a copy of NFBTRANS, and looked at the source
  code that came with it, and discovered that it was not just a
  Braille encoder, but more a typesetting system like troff. It was
  about seven thousand lines of C, and in the guts of it, I did
  manage to find the encoding routines - and I couldn't make heads
  or tails of them. NFBTRANS reads the list of contractions from an
  external data file that come with the program, but I couldn't
  figure out exactly how the rules were applied - namely, in what
  order or priority.</p>

  <p>In other words, the file had rules like:</p>
  <pre>
  "the" contracts in any context
  "er"  contracts in any context
  "th"  contracts in any context
</pre>

  <p>...but how or why would NFBTRANS manage to always contract the
  end of the word "leather" to "&lt;the&gt;r" and not
  "&lt;th&gt;&lt;er&gt;"? Were there other "-ther-" words that
  could get "&lt;th&gt;&lt;er&gt;" instead of "&lt;the&gt;r"?</p>

  <p>To fill in the blanks in my understanding of Braille, and to
  try my hand at modeling a linguistic system in Perl, I decided to
  try to develop an algorithm in Perl to correctly apply these
  rules, and to check them against NFBTRANS's output.</p>

  <h3>Kinds of Linguistic Rule Systems</h3>

  <p>I'd had some experience with formal linguistic models of the
  subsystems that make up natural languages. Every time I'd seen a
  linguist create a formal model of a subsystem of a language
  (whether English phonology, or Hindi syntax, or something less
  abstract, like hyphenation), the rules that model the system have
  been in one of the two kinds of frameworks I'll explain below -
  either the kind I call a "generativity system," or the kind I
  call an "optimality system". So I expected Braille encoding to be
  one of these two sorts of rule systems, and the first task was to
  figure out which it was.</p>

  <h3>Generativity Systems</h3>In a generativity system, there's a
  list of rules, to be applied in a particular order.

  <p>Linguists often use this kind of rule system to model
  phonology, the study of the way the sounds of language are
  represented in the brain. Phonological models assume that words
  are stored in a somewhat simplified, abstracted form, and that to
  work out the details of how these are to be pronounced, we apply
  a series of rules.</p>

  <p>For example, a phonological model of my dialect of American
  English would assume that the "long i" sound is always stored as
  simply that. But I, like most Americans, pronounce it differently
  in "kite" than in "fly". To account for this difference,
  phonological models say that this sound starts out as just itself
  (here written "/aj/"), but that rules may apply to change it in
  some contexts. This isn't just about vowels - the two
  different-sounding t's in "write" and in "writing" supposedly
  both start out as just /t/, but a rule happens to change the
  latter one to sound like a /d/.</p>

  <p>The rules describing these two phonological changes could look
  like:</p>

  <ul>
    <li>the diphthong /aj/ (as in "fly") changes to /Uj/ (as in
    "kite") when it's before /p/, /t/, or /k/.</li>

    <li>the consonant /t/ changes to /d/ when it's between two
    vowels.</li>
  </ul>

  <p>These rules, when applied in that order, are supposed to take
  words in a representation that doesn't have these finer
  distinctions (like the difference between /aj/ and /Uj/), and
  change those representations to flesh them out with those
  distinctions.</p>

  <p>Now, translating rules like these into regular expressions
  used to be hard, but now, with Perl 5.005 regexes, it's a snap,
  with "lookbehind" and "lookahead":</p>
  <pre>
s/aj         # target : the vowel /aj/
  (?=[ptk])  # following context : /[ptk]/
 /Uj/gx  &amp;&amp; print "R1 applies.  Output: $_\n";
&#13;s/(?&lt;=[aeiouIUj])   # preceding context : any vowel
  t                # target : /t/
  (?=[aeiouIUj])    # following context : any vowel
 /d/gx   &amp;&amp; print "Output of system: $_\n";
</pre>

  <p>What this gets you over <tt>/aj[ptk]/</tt> or
  <tt>/[aeiouIUj]t[aeiouIUJ]/</tt> is that with lookbehind (as in
  (<tt>?&lt;=[aeiouIUj]</tt>)) or lookahead (as in
  (<tt>?=[aeiouIUj]</tt>)), the text matching the lookahead and
  lookbehind parts of the regex aren't part of what gets matched by
  the regex as a whole.</p>

  <p>That is, text that matches the lookbehind expression is free
  to precede the "cursor" (the part of the regex mechanism that pos
  reports the position of), and text matching the lookahead
  expression doesn't move the cursor forward, as normal matching
  does. (Also, the lookbehind text doesn't end up in
  <tt>$&amp;</tt>, which you probably know as the "what matched?"
  regex variable, but which you can better think of as "now that
  we've matched something, what was between where the point
  started, and where it ended up?")</p>

  <p>Now, the above phonetic rules are greatly simplified for the
  sake of discussion, but you can see their application to "write +
  ing", starting from its simplified abstract form /rajt + IN/:</p>
  <pre>
  $_ = 'rajtIN';
  print "Input to system: $_\n";
    
  s/aj
    (?=[ptk])
   /Uj/gx  &amp;&amp; print "R1 applies. Output: $_\n";
    
  s/(?&lt;=[aeiouIUj])
    t
    (?=[aeiouIUj])
    /d/gx   &amp;&amp; print "R2 applies. Output: $_\n";
    
  print "Output of system: $_\n";
</pre>

  <p>This prints:</p>
  <pre>
  Input to system: rajtIN
  R1 applies. Output: rUjtIN
  R2 applies. Output: rUjdIN
  Output of system: rUjdIN
</pre>

  <p>And this gives the correct pronunciation for "writing" in my
  dialect, /rUjdIN/. Change the first line to "rajdIN" ("riding"),
  and neither rule applies, and you get "rajdIN" out. (So, yes,
  when I speak, "writing" and "riding" sound different.) And,
  importantly, if you swap the rules so that R2 applies before R1,
  you get:</p>
  <pre>
  Input to system: rajtIN
  R2 applies. Output: rajdIN
  Output of system: rajdIN
</pre>

  <p>(So, if <i>your</i> dialect has "writing" and "riding"
  sounding the same, it might be that rule-ordering is the only
  difference between your dialect and mine.)</p>

  <p>The ordering of the rules in generativity systems is crucial;
  if you have the right rules in the wrong order, you get the wrong
  answer. If Braille encoding were a generativity system, I'd need
  to figure out how to order the rules from the NFBTRANS data
  table.</p>

  <h3>Optimality Systems</h3>If a generativity system is one that
  gives rules that get you from input to correct output, then an
  optimality system is one that takes all kinds of even remotely
  conceivable possible output, and ranks them in order of
  desirability ("optimality"). The highest ranked one is the
  "correct form" and becomes the output of the system. (And if it
  seems to you that generativity is like imperative programming,
  and optimality is like logical programming - &aacute; la Prolog -
  then you're basically right.)

  <p>The algorithms I've seen that implement English hyphenation
  are basically optimality systems. I encourage interested readers
  to look at the hyphenation algorithm in TeX (which you can see
  reiterated in Perl in CPAN's TeX::Hyphen), but for sake of
  discussion, suppose you can model English hyphenation with these
  rules for ranking candidate forms:</p>

  <ul>
    <li>Hyphenating between consonant letters is good. (As in
    "gos-ling".)</li>

    <li>Hyphenating between a double consonant is good. (As in
    "bit-ter".)</li>

    <li>Hyphenating between a consonant and a vowel is bad. (As in
    "gosl-ing".)</li>

    <li>If hyphenating leaves a word fragment of just consonants,
    that's <i>really</i> bad. (As in "g-osling" or
    "gosli-ng".)</li>
  </ul>

  <p>In Perl, you could implement this as:</p>
  <pre>
  use strict;
  my $in = 'boggling';
  my $best = $in;
  my $best_score = 0;
&#13;  my $Cons = 'bcdfghjklmnpqrstvwxz';
  my $Vowel = 'aeiouy';
&#13;  foreach my $i (1 .. (length($in) - 1)) {
      $_ = $in;
      my $score = 0;
      substr($_, $i, 0) = '-';
&#13;      ++$score if /[$Cons]-[$Cons]/oi;
      ++$score if /([$Cons])-\1/oi;
      --$score if /[$Cons]-[$Vowel]/oi;
      $score -= 10 if /^[$Cons]+-/oi || /-[$Cons]+$/oi;
&#13;      print " \"$_\" : score: $score\n";
      if($score &gt; $best_score) {
         $best_score = $score;
         $best = $_;
      }
  }
  print "Best: \"$best\" with score of $best_score\n";
</pre>

  <p>The output of this is:</p>
  <pre>
   "b-oggling" : score: -11
   "bo-ggling" : score: 0
   "bog-gling" : score: 2
   "bogg-ling" : score: 1
   "boggl-ing" : score: -1
   "boggli-ng" : score: -10
   "bogglin-g" : score: -9
    Best: "bog-gling" with score of 2
</pre>

  <p>...so these rules seem to work right - the highest-ranked form
  ("bog-gling") is the best; and incidentally, the second best
  ("bogg-ling") is not too bad, and from there on out it's all
  quite bad ("bo-ggling", "boggli-ng", etc.).</p>

  <p>Note that it doesn't matter here what <i>order</i> you apply
  the rules in; it just matters what <i>weight</i> gets attached to
  each rule. In the above example, I've kept it simple, but suppose
  we now add a rule that means "the closer to the middle of the
  word you hyphenate, the better", such as:</p>
  <pre>
  $score += .5 * (length($in) - abs($i - length($in) / 2));
</pre>

  <p>If we leave that weighting constant at 0.5, you still get
  "bog-gling" coming out on top. Change it to a 1, and we have a
  tie between "bog-gling" and "bogg-ling", since the point that
  "bog-gling" gets for hyphenating between a double consonant is
  offset by the point that it loses out on for the hyphen not being
  at the exact middle of the word. And if we change the constant to
  1.5, we get "bogg-ling" coming out on top.</p>

  <p>If NFBTRANS's rules somehow interacted with an optimality
  system with ranking-rules like "give K points for every letter
  this contraction saves", or possibly "give (or subtract?) L
  points if this word ends up with contractions next to each other"
  or "subtract a half-point if the word ends in a contraction",
  then I'd need to first puzzle out what these ranking-rules were,
  and then figure out what their values for K and L were.</p>

  <h3>Regex Replacement as a First Hack</h3>I intuitively felt that
  Braille encoding somehow had a lot in common with hyphenation
  (except that it was about contracting letters instead of sticking
  hyphens in between them), suggesting that optimality was at least
  part of the system. On the other hand, optimality systems often
  have some generative component to them (since you need to
  <i>generate</i> some candidates to apply the ranking-rules), so I
  figured that whether the real answer would eventually be in a
  generativity system or an optimality system, I'd probably have to
  work up something generativity-based.

  <p>So I decided to take the rules from NFBTRANS's rules file,
  cook them up into a regular expression, and use that to perform
  all the substitutions, in a one-pass regex like
  <tt>s/($re)/&amp;lookup($1)/eg</tt>, an approach I borrowed from
  Kevin Lenzo's article on converting text to speech in <a href=
  "../vol3_4/ewtoc.html">TPJ #12</a>. I figured that this approach
  would by no means behave correctly, but that the cases where it
  didn't behave correctly would give me some kind of hint as to
  whether a generativity system or an optimality system was called
  for, and from there I could start worrying about the ordering or
  weighting of rules.</p>

  <p>Granted, next to either generativity systems or optimality
  systems, a big one-pass regular expression replacement seems
  pretty strange, but Perl makes regexes so easy that it seemed the
  path of least resistance for a first hack.</p>

  <h3>Contexts in Regular Expressions</h3>Suppose the rule file
  consists of:
  <pre>
  "the" contracts to "&lt;the&gt;" in any context
  "er"  contracts to "&lt;er&gt;" in any context
  "th"  contracts to "&lt;th&gt;" in any context
  "ea"  contracts to "&lt;ea&gt;" only in the middle of words
  "ar"  contracts to "&lt;ar&gt;" in any context
  "ear" contracts to "e&lt;ar&gt;" in any context
</pre>

  <p>Now, a regex for "'the' in any context" would be a simple
  <tt>&lt;the&gt;</tt>. But how to express "<tt>&lt;ea&gt;</tt>
  only in the middle of words"? You could do it with something like
  <tt>/(?&lt;=\w)ea(?=\w)/</tt> to assert that there be a word
  character before and after the 'ea', but Perl already provides a
  metacharacter for matching a word boundary (<tt>\b</tt>), or the
  absence of one (<tt>\B</tt>). In other words, what's needed here
  is the absence of word boundaries before and after the 'ea', and
  you can do that with simply <tt>/\Bea\B/</tt>. Translating the
  above mini-list of Braille contraction rules into a regex
  gives:</p>
  <pre>
  %contraction_for = (
   'the' =&gt; '&lt;the&gt;',
     # Remember: I'm using "&lt;the&gt;" here
     # in place of the Braille ASCII, or Unicode,
     # code for the single Braille character
     # for that contracts "the"
   'er' =&gt;  '&lt;er&gt;',
   'th' =&gt;  '&lt;th&gt;',
   'ea' =&gt;  '&lt;ea&gt;',
   'ar' =&gt;  '&lt;ar&gt;',
   'ear' =&gt; 'e&lt;ar&gt;',
  );
  s/(the|ear|ar|\Bea|er|th)/$contraction_for($1)/eg;
</pre>

  <p>Now, notice that I moved the longer strings to the start of
  the regex. This is a crucial point in understanding Perl's
  implementation of regular expressions: given alternates, Perl
  will match the first one it can match, regardless of whether
  there may be later alternates that are longer. So if
  "<tt>th</tt>" came before "<tt>the</tt>" in that regex, the
  "<tt>th</tt>" would always match, never letting "the" match.
  Moreover, if there were a "<tt>\Bea\B</tt>" and an "<tt>ea</tt>"
  in the regex, if the "<tt>ea</tt>" came first, it would block the
  "<tt>\Bea\B</tt>" from ever matching. So, in producing this
  regular expression, I had to make sure that the alternates
  started out with the longest strings, in the most specific
  contexts (like "<tt>\Bfoo\B</tt>"), and worked their way down to
  the shortest match strings, in the most general contexts (like
  just plain "<tt>foo</tt>"). This was a simple matter of a
  Schwartzian transform, where the sorter function looked like:</p>
  <pre>
  ...
  sort {
    length($b-&gt;[0]) &lt;=&gt; length($a-&gt;[0])
      # sort first by length of the literal
    or $b-&gt;[1] &lt;=&gt; $a-&gt;[1]
      # then by context "precedence"
      # where "\B_" gets a higher "precedence"
      # score than "_"
  }
  ...
</pre>

  <p>By this time, I had 180 lines of code for reading the
  contraction rules file and transforming it into a regex. Only
  about 20 lines were necessary to perform the contractions, and
  they were basically a wrapper around this:</p>
  <pre>
  $word =~ s/($my_re)/$contraction_for{$1}/oeg;
</pre>

  <h3>Embedding Code in Regular Expressions</h3>I'd forgotten about
  one thing - there could be rules that say something like:
  <pre>
  "foo" contracts to "&lt;X&gt;" at word-start
  "foo" contracts to "&lt;Y&gt;" elsewhere
</pre>

  <p>Now, you could model this pair of (fictitious!) rules with a
  regex that contains (<tt>...|\bfoo|foo|...</tt>), but then
  whether "<tt>\bfoo</tt>" or "<tt>foo</tt>" matches, you end with
  simply with <tt>$1</tt> holding "<tt>foo</tt>". In other words,
  while you can use "<tt>\b</tt>" or real lookbehind/lookahead to
  select for certain contexts, you don't end up knowing which
  alternative actually matched.</p>

  <p>However, a new feature in Perl 5.005 is exactly what I needed
  here. The feature is still somewhat experimental, and a full
  discussion of it would require an article of its own; but to make
  a long story short, having (<tt>?{ <i>CODE</i> }</tt>) in a
  regular expression will cause <i>CODE</i> (any Perl code) to be
  evaluated whenever the regular expression engine hits that point
  in trying to match the regular expression. So, to differentiate
  between "<tt>\bfoo</tt>" and "<tt>foo</tt>" matching, I add to
  the regex a bit of code to be executed at the end of each:</p>
  <pre>
$word =~
   s/
     (
      |  \bfoo  (?{ $x=1 })
      |    foo  (?{ $x=2 })
     )
    /$contract[$x]{$1}/eg; 
</pre>

  <p>Here, if <tt>\bfoo</tt> is the bit of the regex that matches,
  the last thing that the match does is to execute <tt>$x=1</tt>,
  so then the string that got matched (say, the "foo" in "foolish")
  gets replaced with the value of <tt>$contract[1]{'foo'}</tt>. But
  if it's the second bit of the regex ("<tt>foo</tt>") that matches
  (as in the "foo" in "buffoon"), <tt>$x=2</tt> will get executed,
  and so "foo" will get replaced with the value of
  <tt>$contract[2]{'foo'}</tt>. This array-of-hashes
  <tt>@contract</tt> (which is accessed like
  <tt>$contract[context_flag_numeric]{string_to_be_replaced}</tt>)
  will have been filled by the same part of the program that read
  the rules in and created the regular expression.</p>

  <h3>Rules as Exceptions</h3>Most linguistic models deal with
  exceptional cases (like, say, irregular verbs) by exempting
  certain forms from the rules. However, NFBTRANS's rules table
  knows only rules and more rules, where more specific rules stop
  more general rules from applying. For example, given:
  <pre>
  "the" contracts to "&lt;the&gt;" in any context
  "er"  contracts to "&lt;er&gt;" in any context
  "th"  contracts to "&lt;th&gt;" in any context
  "ea"  contracts to "&lt;ea&gt;" in the middle of words
  "ar"  contracts to "&lt;ar&gt;" in any context
  "ear" contracts to "e&lt;ar&gt;" in any context
</pre>

  <p>the rule that replaces "the" with the single character
  "&lt;the&gt;" blocks the more general rule of replacing "th" with
  "&lt;th&gt;" from applying. Likewise, the rule that targets "ear"
  blocks the rule that targets "ea" from applying - which is why
  "heart" contracts to "he&lt;ar&gt;t", not "h&lt;ea&gt;rt".</p>

  <p>Now, for some reason, it's incorrect to contract the "ear" in
  "tearoom" at all. This <i>could</i> be modelled by saying that
  "tearoom" is on a list of exception words that are exempt from
  contractions, but then you have <i>two</i> kinds of data in the
  system - the rules table, and the list of exceptions. The way
  NFBTRANS models this is to simply add another rule:</p>
  <pre>
  "tearoom" contracts to "tearoom" in any context
</pre>

  <p>A rule that replaces a word with itself seems entirely
  pointless, but the point of it is to block the more general
  rules. (Actually, the rule says "replace 'tearo' with 'tearo' in
  any context", not specifying the whole word - but I think the
  people who thought up that rule thought of "tearoom" as the only
  word it could apply to, and were not aware of the rarer "-tearo-"
  words: "Aotearoa" or "stearolactone".)</p>

  <p>The NFBTRANS rules file basically consists of:</p>

  <ul>
    <li>a few dozen general rules that implement the regular
    contractions, like "ea".</li>

    <li>a few dozen more rules that implement more specific (yet
    still pretty general) contractions like "ear",</li>

    <li>about a hundred rules for whole word abbreviations like
    "qk" for "quick", and then</li>

    <li>about a <i>thousand</i> rules that are there simply to
    block the more general rules.</li>
  </ul>

  <p>The above "tearoom" rule is an example that happens to block
  <i>all</i> contractions for that word, but the average rule is
  meant to stop only <i>some</i> of the contractions from applying.
  For example, applying the normal contraction rules to "pineapple"
  would contract it as "p&lt;in&gt;&lt;ea&gt;pple". However, this
  spelling is considered incorrect, so there's a rule specifically
  to fix this with the correct spelling:</p>
  <pre>
  "pineapple" contracts to "p&lt;in&gt;eapple" in any context
</pre>

  <p>And so on for "phoenix" (to block the "en" from contracting),
  "coworker" (to block the "ow" from contracting, lest they become
  cow orkers), and all the way up to the longest rule, which
  replaces "psychedelic" with "psy&lt;ch&gt;edelic" (blocking the
  "&lt;ed&gt;").</p>

  <p>Incidentally, as with exceptions in hyphenation, most of these
  exceptions to the normal Braille contraction rules are motivated
  by wanting to not contract (or wanting to hyphenate between)
  letters that belong to different syllables or to different
  morphemes (roots, prefixes, or suffixes, like "tea-room",
  "co-worker", etc.). But the "ea" in "create" <i>does</i> contract
  to the single "&lt;ea&gt;" character, even though it's clearly
  across two syllables. Since the conventions for Braille
  contractions evolved naturally - just as general English spelling
  did - it's full of patterns, and messy exceptions, and messy
  exceptions to the messy exceptions.</p>

  <h3>Testing It</h3>When I wrote the code that generated the big
  regular expression to match everything that could be contracted,
  I initially fed it just a few rules, then a few dozen, and when I
  did feed it the whole rule file, it ended up making a single
  regular expression 14KB long. The longest regex I'd ever heard of
  was the 6.5KB regex for matching RFC822-valid email addresses (in
  Appendix B of Jeffrey Friedl's <i>Mastering Regular
  Expressions</i>), and this was more than twice as long -
  worrisomely long. I anticipated a screaming "OUT OF MEMORY"
  error, or that the regex would take two minutes of swapping to
  compile. But it compiled imperceptibly fast, and without errors.

  <p>I took the "Unix wordlist" (a motley wordlist of 25,000
  English words, one per line), and encoded it with a copy of
  NFBTRANS, so that I could compare it to my algorithm's output. I
  wrote a small program to use my algorithm to encode the wordlist,
  print all cases where my algorithm's output disagreed with the
  output of the inscrutable NFBTRANS algorithm, and then report my
  algorithm's accuracy.</p>

  <p>Guessing wildly, I expected no better than 50% similarity
  between the output of my algorithm, and the output of
  NFBTRANS.</p>

  <h3>It's Alive - Alive!</h3>My first-hack one-pass regex
  algorithm turned out to agree with NFBTRANS 99.59% of the time. I
  was boggled that it was over 50%, much less over 99%.

  <p>Most of the cases of disagreement were words like "R&amp;D" or
  "O'Leary" - since this was a first hack, I had not bothered to
  properly deal with words with internal punctuation or complex
  capitalization, which require somewhat special treatment in
  Braille encoding. The remaining dozen words where my algorithm
  encoded differently than NFBTRANS were because I'd misimplemented
  the regex context for one of the more obscure rules. (And
  incidentally, I've only implemented my encoder for words <i>in
  isolation</i> - in encoding of actual sentences, there's
  punctuation to deal with; and a few Braille contractions in words
  are sensitive to the context of the word, like whether there's
  punctuation after the word, which makes things a bit
  messier.)</p>

  <table border="1" cellspacing="0" cellpadding="5">
    <tr>
      <td><a href="tpj0403-0003a.html">Listing 1</a>: Sample Text
      in Braille</td>
    </tr>
  </table>

  <p>This one-pass regex approach was just a stab in the dark, and
  I expected to use the list of its failures to refine the
  algorithm - say, developing a generativity system that would make
  one pass to handle word-initial contractions, then another to
  handle word-final contractions, then a final pass for everything
  leftover in between. Or maybe the answer would lie in an
  optimality system to consider all <i>possible</i> ways to
  contract a word, and select the one that had the fewest
  characters, or maybe the fewest dots total, or maybe the most
  contractions closest to the beginning or end of the word.</p>

  <p>But it was nothing so complicated - this big regex, in one
  pass, did the whole job. Not only did this seem much too easy
  (although this is a not unfamiliar sensation in programming
  Perl), but it was quite unprecedented - I'd never heard of a
  phenomenon in natural language that could be treated with a
  regular expression.</p>

  <p>I'd always considered regular expressions to be essentially
  abstract and mathematical. After all, the formalism of regular
  expressions was devised just this century, coming out of the work
  of mathematician Stephen Kleene; and the workings of the regex
  engine (as in Mark-Jason Dominus's article in <a href=
  "../vol3_1/ewtoc.html">TPJ #9</a>) are explained in terms of
  automata. And whatever an automaton is (a big scary robot?), it
  sure doesn't sound like anything to do with something that people
  do unconsciously when they write Braille. (Incidentally, people
  have been been writing English in Braille this way for decades
  longer than regexes have been around.)</p>

  <p>But in spite of the very formalist origins of regular
  expressions, I think that the basic mechanism underlying regex
  replacement - scanning left to right, matching as much as you
  can, context permitting - is not so unnatural and abstract.
  That's what we do when we use systems of contraction or
  abbreviation, whether in Braille, Gregg shorthand, or our own
  idiosyncratic abbreviations: we start at the beginning of the
  word (as opposed to inking in the end, and working backwards from
  there), and we abbreviate as much, and as early, as possible.</p>

  <p>Granted, Perl regexes have plenty of features that have no
  parallel in this process of Braille contractions (like
  backtracking, notably). But there's the commonality in that
  what's called "greedy matching" for regexes is effectively the
  same as what we do when we abbreviate/contract, because of a mix
  of economy (wanting to save space) and laziness (not having to
  operate on the whole word at a time, or to consider lots of
  alternatives, but just contracting in one pass, as you write,
  starting at the beginning of the word). Perl programmers know
  from experience that regexes are immensely useful, and my
  experience with Braille encoding is just another case of that.
  But the fact that regexes have a basic commonality with a
  linguistic phenomenon like Braille encoding suggests that not
  only are regexes a useful tool, but that they're also
  linguistically natural and, hopefully, more learnable and
  valuable because of it.</p>

  <p>__END__</p>
  <hr>
  <i>Sean M. Burke (<a href=
  "mailto:sburke@netadventure.net">sburke@netadventure.net</a>)
  likes making linguists think he's a programmer, and programmers
  think he's a linguist.</i>

  <p><i>Sheri Wells-Jensen (<a href=
  "mailto:sheri@sg.inter.edu">sheri@sg.inter.edu</a>) is a linguist
  who used to be a programmer, way back when everyone thought FORTH
  was a pretty neat idea.</i></p>

  <p><i>(Sean adds: thanks to Tack-Tiles (<a href=
  "http://tack-tiles.com" target=
  "resource window">tack-tiles.com</a>) for lending me a set of
  their Braille blocks, and thanks to David Ondrik for taking the
  picture of them. And I'd also like to thank the conferees at this
  year's YAPC for their encouraging response to my talk on Braille
  encoding with regular expressions.)</i></p>

  <p>The final Braille-encoding code is available, along with some
  other Braille links, at <a href=
  "http://www.netadventure.net/~sburke/bounce.cgi/braille" target=
  "resource window">http://www.netadventure.net/~sburke/bounce.cgi/braille</a>.
  <!-- end of file --></p>
</body>
</html>
