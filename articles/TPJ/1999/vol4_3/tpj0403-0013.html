<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
  <title>A Web Spider in One Line? - The Perl Journal, Fall 1999</title>
  <meta name="generator" content=
  "HTML Tidy for Linux/x86 (vers 12 April 2005), see www.w3.org">
  <meta name="vscategory" content="Perl">
  <meta name="vsisbn" content="">
  <meta name="vstitle" content="A Web Spider in One Line?">
  <meta name="vsauthor" content="Tkil">
  <meta name="searchdescription" content=
  "A Perl-based web spider is probably not an ideal project for a novice Perl programmer. Work your way up to it.">
  <meta name="vsimprint" content="The Perl Journal">
  <meta name="vspublisher" content="Earthweb">
  <meta name="vspubdate" content="Fall 1999">
  <!-- always update the article title and issue -->

</head>

<body>
  <font face="verdana" size="1">Issue 15, Fall 1999</font>

  <h2 align="center">A Web Spider in One Line?</h2>

  <h4><i>Tkil</i></h4><!-- packages described, if necessary -->

  <div align="center">
    <table border="1" cellspacing="0" cellpadding="5">
      <tr>
        <td align="center" bgcolor="#CCCC99"><b>URLs</b></td>
      </tr>

      <tr>
        <td>
          <p>libwww-perl
          (LWP):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://www.linpro.no/lwp/"
          target=
          "resource window">http://www.linpro.no/lwp/</a><br>
          Web spiders
          (robots):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://info.webcrawler.com/mak/projects/robots/robots.html"
          target=
          "resource window">http://info.webcrawler.com/mak/projects/robots/robots.html</a></p>
        </td>
      </tr>
    </table>
  </div>

  <p>Today, someone on the IRC #perl channel was asking some
  confused questions. We finally managed to figure out that he was
  trying to write a web robot, or "spider", in Perl. Which is a
  grand idea, except that:</p>

  <ol>
    <li>Perfectly good spiders have already been written and are
    freely available at <a href=
    "http://info.webcrawler.com/mak/%20projects/robots/robots.html"
    target="resource window">http://info.webcrawler.com/mak/
    projects/robots/robots.html</a>.</li>

    <li>A Perl-based web spider is probably not an ideal project
    for a novice Perl programmer. Work your way up to it.</li>
  </ol>

  <p>Having said that, I immediately pictured a one-line Perl
  robot. It wouldn't do much, but it would be amusing. After a few
  abortive attempts, I ended up with this monster, which requires
  Perl 5.005. I've split it onto separate lines for easier
  reading.</p>
  <pre>
perl -MLWP::UserAgent -MHTML::LinkExtor -MURI::URL -lwe '
    $ua = LWP::UserAgent-&gt;new; 
    while (my $link = shift @ARGV) { 
        print STDERR "working on $link"; 
        HTML::LinkExtor-&gt;new( 
          sub { 
            my ($t, %a) = @_; 
            my @links = map { url($_, $link)-&gt;abs() } 
                       grep { defined } @a{qw/href img/}; 
            print STDERR "+ $_" foreach @links;
            push @ARGV, @links;
          } ) -&gt; parse( 
           do { 
               my $r = $ua-&gt;simple_request 
                 (HTTP::Request-&gt;new("GET", $link)); 
               $r-&gt;content_type eq "text/html" ? $r-&gt;content : ""; 
           } 
         ) 
     }' http://slinky.scrye.com/~tkil/ 
</pre>

  <p>I actually edited this on a single line; I use shell-mode
  inside of Emacs, so it wasn't that much of a terror. Here's the
  one-line version.</p>
  <pre>
perl -MLWP::UserAgent -MHTML::LinkExtor -MURI::URL -lwe 
'$ua = LWP::UserAgent-&gt;new; while (my $link = shift @ARGV) { 
print STDERR "working on $link";HTML::LinkExtor-&gt;new( sub
{ my ($t, %a) = @_; my @links = map { url($_, $link)-&gt;abs()
} grep { defined } @a{qw/href img/}; print STDERR "+ $_"
foreach @links; push @ARGV, @links} )-&gt;parse(do { my $r =
$ua-&gt;simple_request (HTTP::Request-&gt;new("GET", $link)); 
$r-&gt;content_type eq "text/html" ? $r-&gt; content : ""; } )
}' http://slinky.scrye.com/~tkil/ 
</pre>

  <p>After getting an ego-raising chorus of groans from the hapless
  onlookers in #perl, I thought I'd try to identify some cute
  things I did with this code that might actually be instructive to
  TPJ readers.</p>

  <h3>Callbacks and Closures</h3>Many modules are designed to do
  grunt work. In this case, <tt>HTML::LinkExtor</tt> (a specialized
  version of <tt>HTML::Parser</tt>) knows how to look through an
  HTML document and find links. Once it finds them, however, it
  needs to know what to do with them.

  <p>This is where "callbacks" come in. They're well-known in GUI
  circles, since interfaces need to know what to do when one
  presses a button or selects a menu item. Here,
  <tt>HTML::LinkExtor</tt> needs to know what to do with links (all
  tags, actually) when it finds them.</p>

  <p>My callback is an anonymous subroutine reference:</p>
  <pre>
      sub { 
          my ($t, %a) = @_; 
          my @links = map { url($_, $link)-&gt;abs() } 
                        grep { defined } @a{qw/href img/}; 
          print STDERR "+ $_" foreach @links;
          push @ARGV, @links;
      } 
</pre>

  <p>I didn't notice until later that <tt>$link</tt> is actually
  scoped just outside of this subroutine (in the while loop),
  making this subroutine look almost like a closure. It's not a
  classical closure - it doesn't define its own storage - but it
  does use a lexical value far away from where it is defined.
  (Enough justification for a section title!)</p>

  <h3>Cascading Arrows</h3>It's amusing to note that, aside from
  debugging output, the while loop consists of a single statement.
  The arrow operator (-&gt;) only cares about the value of the left
  hand side; this is the heart of the Perl/Tk idiom:
  <pre>
    my $button = $main-&gt;Button( ... )-&gt;pack(); 
</pre>

  <p>We use a similar approach, except we don't keep a copy of the
  created reference (which is stored in <tt>$button</tt>
  above):</p>
  <pre>
    HTML::LinkExtor-&gt;new(...)-&gt;parse(...); 
</pre>

  <p>This is a nice shortcut to use whenever you want to create an
  object for a single use.</p>

  <h3>Using Modules with One-Liners</h3>From my first thought of
  this one-liner, I knew I'd be using modules from the libwww-perl
  (LWP) library. The first few iterations of this "one-liner" used
  LWP::Simple, which explicitly states that it should be ideal for
  one-liners. The <tt>-M</tt> flag is easy to use, and makes many
  things very easy. LWP::Simple fetched the files just fine. I used
  something like:
  <pre>
        HTML::LinkExtor-&gt;new(...)-&gt;parse( get $link ); 
</pre>

  <p>Where <tt>get()</tt> is a function provided by LWP::Simple; it
  returns the contents of a given URL.</p>

  <p>Unfortunately, I needed to check the Content-Type of the
  returned data. The first version merrily tried to parse
  <tt>.tar.gz</tt> files and got confused:</p>
  <pre>
working on ./dist/irchat/irchat-3.03.tar.gz
Use of uninitialized value at
    /usr/lib/perl5/site_perl/5.005/LWP/Protocol.pm line 104.
Use of uninitialized value at 
    /usr/lib/perl5/site_perl/5.005/LWP/Protocol.pm line 107.
Use of uninitialized value at 
    /usr/lib/perl5/site_perl/5.005/LWP/Protocol.pm line 82. 
</pre>

  <p>Ooops.</p>

  <p>Switching to the "industrial strength" LWP::UserAgent module
  allowed me to check the Content-Type of the fetched page. Using
  this information, together with the HTTP::Response module and a
  quick ?: construct, I could parse either the HTML content or an
  empty string.</p>

  <h3>The End</h3>Whenever I write a one-liner, I find it
  interesting to think about it in different ways. While I was
  writing it, I was mostly thinking from the bottom up; some of the
  complex nesting is a result of this. For example, the callback
  routine is fairly hairy, but once I had it written, I could
  change the data source from <tt>LWP::Simple::get()</tt> to
  <tt>LWP::UserAgent</tt> and <tt>HTTP::Request::content()</tt>
  quite easily.

  <p>Obviously, this spider does nothing more than visit HTML pages
  and try to grab all the links off of each one. It could be more
  polite (but see the LWP::RobotUA module for some of that) and it
  could be smarter about which links to visit. In particular,
  there's no sense of which pages have already been visited; a tied
  DBM of visited pages would solve that nicely.</p>

  <p>Even with these limitations, I'm impressed at the power
  expressed by that "one" line. Kudos for that go to Gisle Aas (the
  author of LWP) and to Larry Wall, for making a language that does
  all the boring stuff for us. Thanks Gisle and Larry!</p>

  <p>__END__</p>
  <hr>
  <i>Tkil can be found at <a href=
  "mailto:tkil@scrye.com">tkil@scrye.com</a> He lives in Fort
  Collins, Colorado, with a small pod of computers, a wall full of
  CDs, some neglected juggling toys, a closetful of neuroses,
  bunches of books, and a string of Christmas lights for
  illumination. He enjoys playing with Perl, C++, and Unix, and
  sometimes even manages to get paid for it. The rest of his time
  is wasted on IRC EFNet's #perl channel.</i> <!-- end of file -->
</body>
</html>
