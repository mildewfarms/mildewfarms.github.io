<html>
<head>
<title>October, 2004: State Space Searching</title>
</head>

<body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000">
<!--Copyright &#169; C/C++ Users Journal-->

<p><i>C/C++ Users Journal</i> October, 2004</p>
<h1>State Space Searching</h1>
<h2>  A policy-based approach to problem solving</h2>


<h3>By David Theese</h3>


<I>David Theese works at Siebel Systems. He can be contacted at <a href="mailto:dtheese@yahoo.com">dtheese@yahoo.com</a>.</I>

<hr>



<a href="0410theeses1.html" TARGET="_BLANK">Suppressing Repeated State Generation</a><br>


<hr>





<p>The need for state space search occurs in many problem domains, including network routing (and route finding in general), parsing, VLSI design, and game playing. This wide range of usefulness motivated me to develop a generic library for performing state space searches. In this article, I provide an overview of state space search, describe how to use my library, and touch on a couple of implementation details.</p>

<p>In designing the library, I used a policy-based approach [1]. This allows easy configuration of the library by the client and, since policy-based design is a template-based technique, the benefits of type safety are realized while still achieving the desired type (problem domain) independence. Although the library is implemented purely in Standard C++, some compilers might have a problem with it due to heavy template usage. Complete source code for the library is at <a href="http://www.cuj.com/code/">http://www.cuj.com/code/</a>. In addition, I've included a sample client that solves the toy sliding tile problem [2]. The library is implemented in the self-contained files search.h and search.inl, respectively.</p>
<h3>State Space  Search Overview </h3>

<p>State space search is used for problem solving. A state space is the set of all discrete configurations (that is, states) that might be encountered while trying to solve a problem. A state space search entails systematically exploring these states in an effort to find a solution to the problem. Sometimes, any solution will do. But frequently, a solution that can be reached with least possible cost (an optimal solution) is desired.</p>

<p>Consider, for example, the sliding tile problem. A solution to this problem is an ordered list of moves that, when applied to the initial state, results in the tiles being in the desired order. Depending on the search algorithm used, the solution may or may not be optimal.</p>

<p>To search a state space, you need to be able to move between states. This is done via the application of operators. (In the context of the sliding tile problem, an operator is a command directing the movement of a specific tile.) This takes you from some state to some other adjacent state. The search proceeds by systematically generating all operators that may be applied to the initial state, applying those operators to expand the initial state into its child states, repeating the process on those states, and so on. This continues until you either succeed (that is, find a goal state) or exhaustively check the entire state space and find that no goal state exists (be wary of infinite state spaces that may not contain a goal state!).</p>

<p>While searching a state space, you will likely encounter the problem of states being repeatedly generated. This can introduce extreme inefficiency to the search, as it causes you to explore fruitless paths multiple times. Several possibilities for dealing with this problem (from least to most effective) are suggested on page 82 of [3]:</p>

<ol>
  <li>Don't return to a state's parent state.</li>
  <li>Don't return to any of a state's ancestors.</li>
  <li>Don't return to any state ever previously generated.</li>
</ol>



<p>There are many different algorithms for searching a state space, and the primary difference between those presented here lies in the order in which states are expanded. One way to categorize these algorithms is by whether a heuristic [4] is used in determining which state to expand next. Since a heuristic uses problem-specific knowledge, algorithms that employ a heuristic are referred to as "informed." Those that don't are referred to as "uninformed." For more details, see Chapters 3 and 4 of [3].</p>
<h3>Uninformed Search</h3>

<p>The library I present implements five uninformed search algorithms:</p>



<ul>
  <li><b>Breadth-first</b>, in which all of a state's children are expanded before any of their children are expanded. </li>
  <li><b>Depth-first</b>, in which children are recursively expanded before their siblings.</li>
  <li><b>Depth-limited</b>, depth-first that is prohibited from considering states beyond a specified depth limit.</li>
  <li><b>Iterative deepening</b>, a repeated depth limited performed with a depth limit of 1, then with a depth limit of 2, and so on, up to a specified depth limit. The iteration continues until a goal state is found or the depth limit is reached.</li>
  <li><b>Uniform cost</b>, in which states are expanded in increasing order of the cost incurred to reach them.</li>
</ul>

<p>These algorithms offer different trade-offs with regard to time/space requirements, whether they are guaranteed to find an optimal solution, or whether they are even guaranteed to find a solution at all (if one exists). In short, the following hold if a solution exists: Depth-first is not guaranteed to find a solution at all (allowing no repeated state generation will fix this if the state space is finite; but even then, the solution may not be optimal); depth-limited is guaranteed to find a solution as long as the depth limit is at least that of the shallowest solution, but it may not be optimal (see the sidebar entitled "Suppressing Repeated State Generation"); in all other cases, an optimal solution is guaranteed to be found.</p>
<h3>Informed Search</h3>

<p>The library implements two informed search algorithms:</p>



<ul>
  <li><b>Greedy</b> search, in which states are expanded in increasing order of their estimated cost (as judged by the heuristic function) to reach the nearest goal state.</li>
  <li><b>A*</b>, which is the most effective search algorithm of those presented here. It is a combination of <b>uniform cost</b> and <b>greedy</b> search. For every state <b>S</b> being considered for expansion, it adds the estimated cost (as judged by the heuristic function) from <b>S</b> to the goal to the actual cost to get from the initial state to <b>S</b>. This is an estimate of the cost to get from the initial state to the goal state via <b>S</b>. States are expanded in increasing order of this estimated cost.</li>
</ul>



<p>In short, the following hold if a solution exists: Though <b>greedy</b> search does have a tendency to find solutions quickly, it is not guaranteed to find a solution at all (allowing no repeated state generation will fix this if the state space is finite; but even then, the solution may not be optimal). In contrast, <b>A*</b> is guaranteed to find an optimal solution so long as one condition is met. The heuristic employed must be admissible&#151;it must never overestimate the cost to reach the nearest goal state.</p>
<h3>Using the Library</h3>

<p>To use the library, clients must instantiate <b>search_engine_t</b>, whose declaration is:</p>

<pre>
template
&lt;
  class STATE_T, class OP_T,
  class OP_GEN_T, class OP_APPLY_T,
  class GOAL_TEST_T,
  class REPEATED_STATE_CHECKER_T,
  class HEURISTIC_T = null_heuristic_t
&gt; class search_engine_t;

</pre>

<p><b>STATE_T</b> is a user-defined type representing a state. <b>OP_T</b> is a user-defined type representing an operator. They must:</p>



<ul>
  <li>Be default constructible.</li>
  <li>Be copy constructible.</li>
  <li>Be assignable.</li>
  <li>Be destructible.</li>
  <li>Implement <b>operator&lt;()</b>.</li>
</ul>



<p><b>OP_GEN_T</b>, <b>OP_APPLY_T</b>, and <b>GOAL_TEST_T</b> are user-defined policy classes that must provide nonprivate member functions with the following semantics and signatures:</p>

<pre>
OP_GEN_T:
// Return all operators that may
// legally be applied to a state
std::set&lt;OP_T&gt;
gen_ops(const STATE_T &amp;);

OP_APPLY_T:
// Return the resulting state and
// cost of application of an
// operator to a state
std::pair&lt;STATE_T, double&gt;
apply_op(const STATE_T &amp;,
         const OP_T &amp;);
GOAL_TEST_T:
// Check whether a given state is a
// goal state
bool
is_goal(const STATE_T &amp;);

</pre>

<p><b>REPEATED_STATE_CHECKER_T</b> should be substituted with one of the five library-supplied full specializations of class template <b>repeated_state_checker_t&lt;&gt;</b>. The five choices are:</p>



<ul>
  <li><b>repeated_state_checker_t&lt;0&gt;</b>. No repeated state checking (generally ill-advised).</li>
  <li><b>repeated_state_checker_t&lt;1&gt;</b>. Option 1 described earlier.</li>
  <li><b>repeated_state_checker_t&lt;2&gt;</b>. Option 2 described earlier.</li>
  <li><b>repeated_state_checker_t&lt;3&gt;</b>. Option 3 described earlier.</li>
  <li><b>repeated_state_checker_t&lt;4, CHECK_T&gt;</b>. Use a user-defined repeated state checking policy <b>CHECK_T</b>.</li>
</ul>



<p>If specialization #4 is used, <b>CHECK_T</b> must be supplied (it may be omitted otherwise due to the presence of a default template argument). It must provide nonprivate member functions with the following semantics and signatures:</p>

<pre>
// Clear all internally stored
// states, if any
void clear_states();

// Check if a given state has been
// seen before
bool seen_before(const STATE_T &amp;);

</pre>

<p>Clients would commonly want to use specialization #4 if they have developed a hashing scheme for their <b>STATE_T</b> type (allowing constant lookup time). Specialization #3 provides full repeated state checking, but it does so using an <b>std:set&lt;&gt;</b>, which provides logarithmic lookup time.</p>

<p><b>HEURISTIC_T</b> need only be supplied if one of the informed search algorithms (<b>Greedy</b> search or <b>A*</b>) is used (it may be omitted otherwise due to the presence of a default template argument). If supplied, it must provide a nonprivate member function with the following semantics and signature:</p>

<pre>
// For a given state, return the
// estimated cost from that state
// to the nearest goal state.
double
apply_heuristic(const STATE_T &amp;);

</pre>

<p>Once <b>search_engine_t&lt;&gt;</b> has been instantiated, the member function corresponding to the desired search algorithm should be invoked. Each member function takes an initial state from which to start the search. Where applicable, some member functions take a depth limit and, in all cases except <b>iterative_deepening()</b>, it is possible to pass a flag indicating that all solutions, rather than just the first found, are to be returned [5]. Each of these member functions returns an <b>std::set&lt;&gt;</b> of solution structures. Each structure contains a goal state reached, the cost to get to it, and the operator sequence leading to it. See <a href="0410theesel1.html" target="_BLANK">Listing 1</a> for the relevant declarations. <a href="0410theesel2.html" target="_BLANK">Listing 2</a> provides a brief demonstration of use of the library.</p>

<p>The library neither generates nor traps exceptions. Any exceptions that propagate out of the library will have originated from either the Standard Library or user-supplied code.</p>
<h3>Storage of the Search Tree</h3>

<p>During library implementation, I found myself needing to create an arbitrary <b>n</b>-ary tree to store the search tree that is built up as states are expanded, and I sought to find a way to store it that did not involve explicit memory management (and the associated maintenance problems it tends to spawn).</p>

<p>My solution was to store the vertices of the tree as elements in an <b>std::list&lt;&gt;</b>. A vertex's parent/child pointers simply point to other elements in the list. The list is never used as such&#151;it is not traversed, sorted, spliced, and so on. It is just a place to store vertices and a mechanism to ensure they get deallocated automatically. When the list is destroyed, the entire tree is also automatically destroyed in one fell swoop.</p>

<p>I chose <b>std::list&lt;&gt;</b> for a specific reason: The insertion of new elements will not invalidate pointers to other elements. A vertex can always be assured its parent/child pointers will remain valid. In addition, the insertion of new elements occurs in constant time.</p>
<h3>One Search Function  Underlying all Algorithms</h3>

<p>Again, the primary difference between the search algorithms is the order in which states are expanded. For depth-first, depth-limited, and iterative deepening, new states can be pushed onto an <b>std::stack&lt;&gt;</b>. For breadth-first, new states can be inserted into an <b>std::queue&lt;&gt;</b>. For the remaining algorithms, new states can be inserted into an <b>std::priority_queue&lt;&gt;</b> created with an appropriate ordering criterion.</p>

<p>It is obviously desirable to have one search function underlying each of the algorithms (and this was accomplished). Providing, as a function template argument, one of the three container types aforementioned as the data structure to store the states-to-be-expanded in almost allows this. All three support <b>push()</b>, <b>pop()</b>, and <b>empty()</b>, but only <b>std::stack&lt;&gt;</b> and <b>std::priority_queue&lt;&gt;</b> support <b>top()</b>. The equivalent in <b>std::queue&lt;&gt;</b> has a different name&#151;<b>front()</b>. Since these three class templates don't have a consistent interface, I couldn't quite get away with just using the needed member functions directly. Oh, so close! I was forced to deal with the <b>top()</b> versus <b>front()</b> issue.</p>

<p>It is tempting to use <b>push()</b>, <b>pop()</b>, and <b>empty()</b> directly and to supply a pointer-to-member to either <b>top()</b> or <b>front()</b>. However, this approach is problematic. To declare a pointer-to-member, an exact member function signature must be known. Believe it or not, the signatures for <b>top()</b> and <b>front()</b> are not precisely specified in the C++ Standard! We know these member functions return a reference to an element and that they should be called with no arguments. But we don't know that they take no arguments&#151;it is possible they have arguments, all of which have a default value. This provision is specifically spelled out in the C++ Standard [6].</p>

<p>My solution was to supply the container type as a function template argument, use <b>push()</b>, <b>pop()</b>, and <b>empty()</b> directly, and then deal with <b>top()</b> versus <b>front()</b> as follows: I created a <b>get_next_node_to_expand()</b> member function, taking a reference to <b>std::queue&lt;&gt;</b>. This member function is just a pass-through to <b>front()</b>. I also created a templated <b>get_next_node_to_expand()</b> member function, taking a reference to any container type. This member function is just a pass-through to <b>top()</b>. A simple call to <b>get_next_node_to_ expand()</b> is made, passing in a reference to the container (whatever its type), and overload resolution solves the problem for us. Voil&agrave;!</p>
<h3>Acknowledgments</h3>

<p>Thanks to Ryan Stephens, Bret Carruthers, and John Ericson for providing peer reviews of the article text and source code.</p>
<h3>References</h3>

  <p>[1]	Alexandrescu, Andrei. <i>Modern C++ Design</i>, Addison-Wesley, 2001.
  <p>[2]	In this well-known problem, movable square tiles are placed within a constraining square frame. One space is left empty, and tiles adjacent to this empty space may slide into it. By sliding tiles in this manner, you try to get the tiles into some particular arrangement. An interesting fact about this problem is that its state space is split evenly into two disjoint sets. A randomly chosen instance of this problem has exactly a 50 percent chance of being solvable!
  <p>[3]	Russell, Stuart and Peter Norvig. <i>Artificial Intelligence: A Modern Approach</i>, Prentice-Hall, 1995.
  <p>[4]	In this context, a heuristic is a function that, given a state, will make an estimate of the cost to get from that state to the nearest goal state.
  <p>[5]	If the client desires to find paths to all goal states (of which there may be any number), this is done by recording the existence, and path to, any goal state found, then continuing the search in a normal manner. This continues until the entire state space has been searched (this makes the choice of search algorithm irrelevant when searching for all solutions). For obvious reasons, this should not be attempted with problems that have an infinite state space! You should also be sure to completely suppress the generation of repeated states when exhaustively searching a state space.
  <p>	  When using iterative deepening, it does not make sense to search for all goal states, and so this is not supported. By definition, this algorithm searches only until the first goal state is encountered.
  <p>	  In this article, the assumption is made that the client desires only a path to one goal state. For most problems, the state space will simply be too large to search exhaustively.
  <p>[6]	Sutter, Herb. Guru of the Week #64 (<a href="http://www.gotw.ca/gotw/064.htm">http://www.gotw.ca/gotw/064.htm</a>). 





</body>
</html>