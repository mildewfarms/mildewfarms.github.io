<HTML>   
     <HEAD>
<TITLE>March 2002 C++ Experts Forum/The (B)Leading Edge</TITLE></HEAD>
<BODY BACKGROUND="" BGCOLOR="#FFFFFF" TEXT="#000000">
<H2><A HREF="../../20.03/tocmar.htm"></A><FONT COLOR="#FF0000">   C++ Experts Forum</FONT></H2>

<HR>

<H2 ALIGN="center"><FONT COLOR="#800000">The (B)Leading Edge: Building an Indexed File Class Using XDR_Stream</FONT></H2>
<H3 ALIGN="center"><FONT COLOR="#800000">by Jack W. Reeves</FONT></H3>

<HR>
<BLOCKQUOTE>

<p>I want to kick off this column like I have many others with a little historical perspective. Early in my C++ career, I got involved in an effort to build a medical imaging workstation using an ordinary personal computer &#151; in this case an Apple MacIntosh IIfx. The images were stored in individual files on the largest hard disk that could be installed in the machine. The images were then indexed by several different criteria such as patient name, type of study, etc. I ended up being responsible for building this index. Eventually, it was intended that the system have a real database behind it, but for an initial prototype it was decided to build the index using a commercial ISAM file product. </p>
<p>Partially because I was part of the &quot;a DBMS is overkill for this&quot; crowd, I got stuck developing the index using the ISAM library. Actually, if you think of the hard disk as an image database, with the full path name of an image being its primary key, then I was building a number of secondary indexes. In any case, the project turned out to be relatively straightforward with the commercial ISAM product providing more than enough capability. Even now, nine years later, I am still impressed by the performance that was achieved on the hardware that we were working with. I also remain impressed by the quality of the design and the code that was produced. The development team was one of the most talented I have ever been associated with.</p> 
<p>The only problem, from my perspective, was that the ISAM product was completely C based, whereas the rest of the project was object-oriented C++ . Naturally, I hid the C-based code behind a C++ interface, but I wanted to go even further and create a C++ wrapper for the C-based API of the ISAM mechanism. Unfortunately, I realized from the beginning that what I really needed was some type of template, and the compiler we were using did not yet support templates. Even if it had, I wasn't sure that I had enough insight at the time to come up with a good C++ ISAM API. As a result, the idea went into the &quot;someday&quot; file in the back of my brain.</p>
<p>A couple of years later, I was introduced to an early version of the STL (Standard Template Library). I quickly realized that the associative containers, especially <b>map</b> and <b>multimap</b>, had almost precisely the interface that I needed for a C++ class representing an indexed file. In fact, the internal class that implements the red-black tree usually used as the underlying implementation of all associative containers in the STL provided the most inspiration. </p>
<p>This class is a template that takes four arguments <b>Key</b>, <b>Item</b>, <b>Compare</b>, and <b>KeyFromItem</b> (ignoring the <b>Allocator</b> for now). The first two are data types, and the second two are function object types. The red-black tree store <b>Item</b>s. The <b>KeyFromItem</b> functor is used to extract the key portion of an item so that it can be compared using the <b>Compare</b> functor. When used to implement a set, the <b>Item</b> and <b>Key</b> are the same type, and <b>KeyFromItem</b> is an identify function. When used to implement a <b>map</b>, the <b>Item</b> is a <b>pair&lt;const Key, Value&gt;</b> and the <b>KeyFromItem</b> functor returns the first element of the pair. I realized that this was a perfect generalization of a database that stored <b>Item</b>s that were indexed by <b>Key</b>s <a href="#1">[1]</a>.</p> 
<p>I still had one problem however. Consider trying to build an <b>IndexedFile</b> with a key of type <b>std::string</b>. You would expect this to be quite common. While it is easy enough to write a string object to a file, it is a waste of time since the actual string data is not typically stored in the string object itself. In order to correctly store a string in a file, you have to do more than just store the object. Furthermore, strings can vary in length. I rejected outright any idea that an <b>IndexedFile</b> class could only be built using data types that were fixed size and stored all their data internally. Being able to use a <b>std::string</b> as a key is simply one example of a capability too useful to ignore. Many classes in C++ store their data on the free store and only hold pointers in the object itself. In addition, I wanted this to be a true object-oriented facility that could handle storing items that were actually objects from derived classes in a hierarchy. Taken together, this all meant that <b>IndexedFile</b> itself could not be expected to know how to store and retrieve the actual data it was working with; some help would have to be provided by the user.</p>
<p>Right after I encountered the STL, I had to do some work on a project that was using XDR. When exposed to XDR as a presentation-layer communications protocol, I was not overly impressed; it seemed too simplistic and tightly coupled to its applications. On the other hand, I quickly realized that those very traits made it a reasonable protocol for persisting objects in a stream. XDR even comes reasonably close to supporting the storage of derived data types with its concept of a discriminated union. </p> 
<p>With XDR as a platform-independent object storage mechanism, I now had all the pieces I needed to design and implement a C++ <b>IndexedFile</b> class template that could store arbitrary <b>Item</b>s &#151; or at least I thought I had all the pieces. When I sat down to actually do it however, I found there were a challenging number of details to be addressed. On the chance that you may find some of those details interesting, I intend to describe my resulting <b>IndexedFile</b> class and its associated <b>BtreeIndex</b> class in this column. The next column will get inside the implementation.</p> 
<p>Before I begin, let me get some caveats and qualifications out of the way. I am not trying to build a database engine with <b>IndexedFile</b>. The underlying metaphor is still that of an ordinary &quot;file,&quot; more specifically the underlying metaphor is that of an <b>XDRStream</b>, which is in turn modeled after IOStreams from the Standard C++ library. The intent is to add a layer of additional organization to an ordinary file to make it more useful under certain circumstances. As such, the intended usage is basically the same as any other <b>XDRStream</b> or IOStream.</p> 
<p>In particular, there is no provision in <b>IndexedFile</b> for record locking, so the concept of multiple simultaneous users of an <b>IndexedFile</b> is a little foreign &#151; at least if any of them is doing updates. The implementation depends upon whatever locking is provided by the underlying <b>XDRStream</b> mechanism, which basically means whatever is provided by the underlying OS file system. I will admit that it might be nice if <b>IndexedFile</b> was more robust in this area, but I am a firm believer in keeping solutions as simple as the problem will allow. <b>IndexedFile</b> is intended for use by single applications that need to be able to access external data by index. If your needs are more sophisticated, then you will have to build them yourself. Maybe you could use <b>IndexedFile</b> (or something similar) as a starting point, or maybe you should just use a DBMS. </p> 

<H3><FONT COLOR="#000080">Class IndexedFile</FONT></H3>
<H4><FONT COLOR="#000080">Template Arguments</FONT></H4>

<p><a href="list1.htm">Listing 1</a> contains the public interface of class <b>IndexedFile</b>. Let me describe certain parts of it in detail. First, you will note that it is a template with several arguments. While <b>IndexedFile</b>'s public interface is modeled after an associative container (<b>multimap</b> to be precise), it requires considerably more help from the user than the typical associative container. The class declaration is as follows:</p> 

<pre>
template&lt;typename Key,
    typename Item,
    typename Compare = std::less&lt;Key&gt;,
    typename KeyTraits = XDR_Traits&lt;Key&gt;,
    typename ItemTraits = XDR_Traits&lt;Item&gt;,
    size_t PageSize = 4096&gt;

class IndexedFile;
</pre>

<p>The first two template arguments are the <b>Key</b> used for the indexing and the actual data <b>Item</b> to be stored. The third template argument is the type of a function object to be used to compare the <b>Key</b> values. As is usually the case, if no <b>Compare</b> argument is supplied, it defaults to the standard <b>less&lt;Key&gt;</b> functor.</p> 
<p>Right off the bat, you will notice that there is no <b>KeyFromItem</b> argument. After some thought, I decided to forgo the idea of insisting that the <b>Item</b> contain the <b>Key</b>. My experience with the medical imaging database was a key factor in my decision. In that case, the actual <i>items</i> being stored were simply filenames that did not contain the key information &#151; the key information had to be supplied externally. I decided it was simpler in the long run to have clients supply both the key and the item as part of an <b>insert</b> rather than having to supply a <b>KeyFromItem</b> functor. If the <i>item</i> does contain the key, the client can simply extract it before calling <b>insert</b>. In essence, I require the client to do whatever <b>KeyFromItem</b> would have done. After I made this decision, I realized that it eliminates the problem of trying to allow the user to update an <b>Item</b> without forcing them to remove it and re-insert it just to make sure the key portion doesn't change without a corresponding update of the index. When design decisions make things simpler for both the implementation and the client, that is usually a sign that they are the right decisions.</p>
<p>Up to this point, the template arguments are the same as for <b>multimap </b>(or <b>map)</b> and the requirements on the types are pretty similar. Unfortunately, there are some additional requirements imposed by <b>IndexedFile</b> on <b>Key</b> and <b>Item</b> types. </p> 
<p>The most obvious is that it must be possible to encode and decode both a <b>Key</b> and an <b>Item</b> to/from an <b>XDRStream</b>. The next two template arguments are concerned with supplying this capability. In order to store <b>Key</b>s and <b>Item</b>s in the external file, <b>IndexedFile</b> has to have functions like <b>operator&lt;&lt;</b> and <b>operator&gt;&gt;</b> for those types. Originally, I thought about just using those operators and requiring that they be available. This is a little restrictive, however, so I decided I had to do better. Rather than add four additional template arguments for the functions, I decided to incorporate a <i>traits</i> type &#151; in this case an <b>XDR_Traits</b> type. As with other traits types, the <b>XDR_Traits</b> type is a <b>struct</b> that must supply certain <b>typedefs</b> and static functions that in turn provide information and operations on the underlying type. For <b>IndexedFile</b>, the requirements for <b>XDR_Traits</b> are that it supply the following:</p> 

<UL><LI><b>X::xio_type</b> &#151; an <b>XDR_Stream</b> type that can read/write to an external file. The type must supply the same public interface as <b>std::fstream</b>.</LI> 
<LI><b>X::encode</b> &#151; a static function that has the same signature as the <b>operator&lt;&lt;</b> function for the underlying type.</LI> 
<LI><b>X::decode</b> &#151; a static function that has the same signature as the <b>operator&gt;&gt;</b> function for the underlying type.</LI> 
</UL>

<p>The header file provides a template <b>XDR_Traits</b> that supplies a default <b>xio_type</b> from the <b>XIO.h</b> header and on the standard <b>operator&lt;&lt;</b> and <b>operator&gt;&gt;</b> functions. The <b>XIOFileStream</b> type uses an <b>XIOFileBuf</b> type that is based on the <b>std::filebuf</b> type in the Standard C++ library. Clients are free to provide their own version of the <b>xio_type</b>. It might be especially useful to provide an <b>xio_type</b> that is more directly connected to the underlying file system.</p> 
<p>In addition to being able to store <b>Key</b> and <b>Item</b> types in an <b>XDRStream</b>, the encoding/decoding of different objects must be order independent. It should be obvious with an <b>IndexedFile</b> that <b>Key</b>/<b>Item</b>s can be inserted and then retrieved in random order. Most of the time this should pose no problems, but recall that one of my goals is to store different object types from a class hierarchy by just being able to encode/decode a base class reference. In my previous column, I discussed how an encoder could store a type id with the object, and a decoder could recover the type id and then create the correct derived object type. The mechanism I described then was based on assigning unique type id's sequentially on an as-needed basis. The first time an id was used, a user assigned type name was also stored with the id. That would work for a sequential object store, but not for <b>IndexedFile</b>. For <b>IndexedFile</b>, the association between the type name and the id has to be made externally. In retrospect, I think this is probably a better idea anyway. I will discuss this more when I talk about support for polymorphic class hierarchies below. For now, just note that a requirement of the <b>Key</b> and <b>Item</b> encoders and decoders is that each operation must be independent of all previous operations.</p> 
<p>Finally, <b>Key</b> and <b>Item</b> types must also be able to handle their own memory management. Originally, I had hoped to be able to allow any type that could be encoded into an <b>XDRStream</b> to be used as the <b>Key</b> or <b>Item</b> type. If you have followed previous columns, you will recall that if I have a hierarchy of types derived from a class <b>Base</b> that I wish to be able to encode and decode in an <b>XDRStream</b>, I typically create the following functions:</p> 

<pre>
operator&lt;&lt;(oXDR_Stream&amp;, const Base*);
operator&gt;&gt;(iXDR_Stream&amp;, Base*&amp;);
</pre>

<p>The first function puts the actual type information in the <b>XDRStream</b> (a type discriminant) and then dispatches to a member function to write the object itself into the stream. The second function is responsible for reading the type information back, creating the correct derived type object, and then dispatching to a member function to actually read the object from the stream. I use a pointer in the <b>operator&lt;&lt;</b> function to emphasize the fact said function handles a hierarchy of types, rather than just the <b>Base</b> type. The <b>operator&gt;&gt;</b> function has to take a reference to a pointer since it must create the object after it figures out what type it should be. In the latter case, the function acts as a <b>Factory</b>, creates the correct type of object, and then turns ownership of the object over to the client. It is up to the client to make sure that the object is destroyed later.</p>
<p>As I said, I had hoped to be able to use such types with <b>IndexedFile</b>, as in:</p>

<pre>
IndexedFile&lt;std::string, Base*&gt;
</pre>

<p>In this case, the <b>Item</b> type is &quot;pointer to <b>Base</b>.&quot; Assuming I have the functions described above (encapsulated in an <b>XDR_Traits</b> type), then originally I thought that everything should work. Unfortunately it doesn't &#151; or at least it might not. I immediately realized that it was not possible to use something like <b>Base*</b> as the <b>Key</b> type, and after some thought, I decided it is probably not a good idea even for the <b>Item</b> type. For a <b>Key</b> type, the <b>IndexedFile</b> will have to decode keys from the external index as part of searching. These keys will never be seen outside of <b>IndexedFile</b>, but <b>IndexedFile</b> does not know that they might have to be explicitly deleted after being decoded. Using a pointer for <b>Key</b> is guaranteed to leak memory. For the <b>Item</b> type, the situation is a little more ambiguous. <b>Item</b>s are only decoded from external storage when explicitly requested by a user (by dereferencing an iterator). Therefore it seemed theoretically possible to still have the user be responsible for deleting the object created by the decode operation. It may be, but I decided to make no promises that would limit my implementation options. In particular, I wanted to allow the possibility of caching. All this means that it must be possible for <b>IndexedFile</b> to decode both <b>Key</b>s and <b>Item</b>s from external storage without worrying about whether they need to be passed to a client to be deleted. </p> 
<p>In order to have <b>Key</b>s or <b>Item</b>s that represent hierarchies of object types, you must either be using a real garbage collector, or the actual types used to specialize the <b>IndexedFile</b> template must be smart pointers that do reference-counted memory management. I don't see a class hierarchy being used as a <b>Key</b> type very often (if ever), but I expect it to be quite common as an <b>Item</b> type. Fortunately, reference-counted pointer types are easily obtained. See <a href="#2">[2]</a> or &lt;www.boost.org&gt;.</p> 
<p>The final template argument is the page size to be used in the <b>BtreeIndex</b> implementation. This parameter will be discussed in more detail when I describe the <b>BtreeIndex</b> class.</p> 

<H4><FONT COLOR="#000080">Operations</FONT></H4>

<p>The actual interface for <b>IndexedFile</b> is similar to the interface of the Standard C++ library's <b>multimap</b> container. This involved another decision that took me a long time to make. I do not claim to be a database expert, but I know enough about relational data modeling to know that every table should have a unique key. Therefore, my original idea was that <b>IndexedFile</b> would support only unique keys (i.e., it should look like a <b>map</b>). </p> 
<p>Again, my experience with the medical imaging application provided a different perspective. As I noted in the beginning, the idea was to index images by things like patient name. Obviously, a given patient was likely to have multiple images in the database. The more I thought about it, the more I realized that support for non-unique keys was essential. Furthermore, I realized that it wasn't really any harder to implement. So, I decided that <b>IndexedFile</b> would be patterned after <b>multimap</b> instead of <b>map</b>. I am still a little ambivalent about this since it means that clients that want only unique keys will have to handle the elimination of duplicates themselves. While I am a firm believer in minimal interfaces whenever possible, I am also a firm believer in providing for common situations, even if it does bloat the interface somewhat. I am still thinking about this, but for now, <b>IndexedFile</b> looks very much like a persistent <b>multimap</b>. There are some differences, however. </p> 
<p>First, since <b>IndexedFile</b> is a <i>file</i>, there are almost no <b>const</b> operations. The underlying file can be opened for input only, but the actual <b>IndexedFile</b> object is not a <b>const</b> object. As a result there are no <b>const_iterator</b>s.</p>
<p>Another important thing to note is that dereferencing an <b>Iterator</b> does not return a reference to the <b>value_type</b>. Technically speaking, this probably means that an <b>IndexedFile::Iterator</b> does not meet the Standard's requirements for an iterator (although they are probably close enough for most purposes). Unlike a typical iterator that mimics a pointer, the <b>IndexedFile Iterator</b> is more like a <b>Proxy</b> object. It contains enough information to allow the <b>Key</b>/<b>Item</b> pair to be decoded from the external <b>XDRStream</b> when needed. Since the <b>Key</b>/<b>Item</b> pair is not stored directly as part of the <b>IndexedFile</b> object, the <b>Iterator</b> cannot return a reference to it. </p> 
<p>Originally, when an <b>Iterator</b> was dereferenced, I just decoded the key (which was probably already cached in memory) and the <b>Item</b> and returned the resulting pair. But this left me with no way to actually update an item while keeping the same key. The alternative was to remove the existing item and then insert the new item. This seemed like an inefficient way to do things, especially for an external <b>Btree</b> index. I figured this was an important enough capability that I actually added a member function to handle it. The function (named <b>replace</b>) took an iterator and a new <b>Item</b> value. Then I realized that I really needed an <b>IndexedFile::Iterator</b> to have correct iterator semantics, and there was a way I could provide them.</p> 
<p>Now, when an <b>Iterator</b> is dereferenced, instead of returning a <b>value_type</b> object directly, it returns <b>std::pair&lt;const Key, ItemProxy&gt;</b>. The <b>ItemProxy</b> class provides two operators, one that converts the <b>ItemProxy</b> into an <b>Item</b>. <b>ItemProxy</b> also provides an assignment operator that takes a new <b>Item</b> and stores it in the <b>IndexedFile</b> with the existing <b>Key</b> value.</p> 
<p>There are a couple of special operations that are more a part of the <i>file</i> interface than part of the <b>multimap</b> interface. One of these is the <b>compact</b> function. This function is a minor exposure of the underlying implementation, and this seems like a good point to at least outline that implementation. <b>IndexedFile</b> actually is implemented as two XDR file-based streams. One of these contains the keys, and the other contains the items. Because items are not required to be the same size (they are not even required to be the same type), the items are simply written sequentially into the data file as they are inserted. When an item is removed, or a new item replaces an existing one, the old item remains in the file, but without a key to access it. No attempt is made to reclaim this space. As a result, the data file part of <b>IndexedFile</b> can grow indefinitely large. The <b>compact</b> function is there to deal with this. When invoked, it creates a new data file and then steps through the index and copies every valid item from the old data file into the new one. It updates the index to reference the new file in the process. When done, the new <i>compacted</i> data file replaces the old one.</p> 
<p>This is another of those little design decisions that often seem to make the difference between really good class design, and just so-so. Besides providing the <b>compact</b> function so clients can explicitly compact the <b>IndexedFile</b>, I also thought about making it something that happened automatically when the file was closed. I quickly rejected this idea since compacting a file that doesn't need to be compacted would be a real waste of time. I then thought about adding a <i>compact</i> parameter to the <b>close</b> function with the default being no-compaction. In the end, I just stuck with the explicit function call. Unfortunately, the current design does not provide any way to determine the amount of wasted space in an <b>IndexedFile</b>, so it is practically impossible to know when compaction is needed or when it would be a waste of time. This is one design area that I am still working on.</p> 
<p>The other utility function is the <b>read</b> function. This is deliberately there to allow external indexes to read the data portion of an <b>IndexedFile</b>. Again, it might be nice to be able to create multiple indices all within the same <b>IndexedFile</b> object, but I am not trying to build a database engine. For now, it seems sufficient to just be able to read the data <b>Item</b>s. </p> 
<p>Finally, I need to comment on supporting the storage of polymorphic objects in an <b>IndexedFile</b>. In one sense, it is totally up to the XDR <b>encode</b>/<b>decode</b> functions to handle any polymorphic objects. The simplest approach is to treat polymorphic objects like a discriminated union of all the types in the hierarchy. An enumerated type could be created to map a discriminate value into the actual type of the object. The encoder would determine the actual object type, write out the discriminate for that type, and then write out the actual object value. The latter would probably be done via a virtual function call. The decoder would read the discriminate, create a new object of the corresponding type, and read the value into the new object. Again, the last step would probably involve a virtual function call. The prior step would probably be done with a switch statement. Whenever a new derived class was added to the hierarchy, the enumeration would have to be updated, and the encoder and decoder changed to handle the update. For hierarchies that do not change very often, this is probably acceptable. On the other hand, it is not what most of us consider good object-oriented programming style. </p> 
<p>For this reason I originally added some support to <b>iXDR_Stream</b> and <b>oXDR_Stream</b> to provide a more general solution. <b>iXDR_Stream</b> provides an object of type <b>IdToTypeMap</b>. It is suppose to map unique ids into strings that represent type names. The strings are then expected to be used by the decoder function to create new objects of the requested type. This still might be done with the equivalent of a switch statement, or it might use something like the <b>FactoryCollection</b> I described in a previous column, or a Factory pattern based upon a <b>Prototype</b>. The point is that the <b>IdToTypeMap</b>, as well as the corresponding <b>TypeToIdMap</b> in the <b>oXDR_Stream</b> class, were intended to allow data initialization to replace programming. (This is also the point of the <b>FactoryCollection</b> class.) </p> 
<p>Using this capability with <b>IndexedFile</b> means being able to initialize the maps in the <b>XDR_Stream</b> so that they will be available to the <b>encode</b>/<b>decode</b> functions. For this reason, I provide two accessor functions. <b>index</b> returns a reference to the <b>IndexedFile</b>'s <b>BtreeIndex</b>. The <b>XDR_Stream</b> used for <b>Key</b>s can be obtained from this. <b>xdrstream</b> returns a reference to the <b>XDR_Stream</b> used for the <b>Item</b>s. With access to the underlying <b>XDRStream</b> classes, the user can initialize the <b>TypeToIdMap</b> with the appropriate type names and corresponding ids (likewise for the <b>IdToTypeMap</b>). </p> 
<p>I must note that I added an additional function to the <b>TypeToIdMap</b> class in the <b>XDRStream</b> header. Before, inserting a type name would just assign the next available id. While this capability still exists, I added a function that allows a specific id to be assigned to a type name. This way, users can ensure that the same id is assigned to the same type every time. This is essential for <b>IndexedFile</b>. No checks are made to ensure that the same id is not assigned to more than one type name, and in fact, it is not unreasonable that the same ids can be used for classes in different hierarchies. The only real requirement is that every class in a hierarchy has a unique id within the hierarchy. </p> 

<H3><FONT COLOR="#000080">Class BtreeIndex</FONT></H3>

<p>While the ability to create <b>IndexedFile</b>s, essentially a persistent <b>multimap</b>, is what I set out to do, the heart of <b>IndexedFile</b> is its Btree index. Naturally, I created this as a class in its own right, and since it turns out to be useful by itself, I made it a public class. The class <b>BtreeIndex</b> has an interface that is almost identical to that of <b>IndexedFile</b>, so I will limit myself to pointing out the important differences.</p> 
<p>First, <b>BtreeIndex</b> is a template, but it only stores <b>Key</b>s, so it does not have the <b>Item</b> and <b>ItemTraits</b> template arguments. </p>
<p>The <b>PageSize</b> template argument is of special interest to <b>BtreeIndex</b>. A Btree implementation stores keys in external <i>pages</i>, which are fixed sized. It is assumed that retrieving pages from external storage will completely swamp other performance aspects, even if the keys are processed linearly within a page. Therefore, the intent of a Btree implementation is to minimize the number of external page fetches (also called probes) that it has to do. Note that it is not so much the number of keys per page that determines the number of probes, but the depth of the search tree. Obviously the more keys per page, the shallower the tree will be, but equally obvious are the practical limits to how large a page can be. Typically a page should be able to hold &quot;many&quot; keys. A good number seems to be at least 100. </p> 
<p>Note that since <b>BtreeIndex</b> allows variable length keys, <b>PageSize</b> is specified in raw characters rather than as the number of keys per page. Again, the page size is typically specified as some multiple of the actual virtual-memory page size of the machine, which is usually some power of two. The default of 4,096 is based on the assumption that if a string is used as the <b>Key</b>, and the average length is 32 characters, then a 4,096-character page could typically store 128 keys. </p> 
<p>Another thing to note is that <b>PageSize</b> is actually used only when a new <b>BtreeIndex</b> is first created. When an existing <b>BtreeIndex</b> is opened, the <b>PageSize</b> of the existing index is retrieved and checked against that of the class. If the existing page size is not the same as the argument, an exception is thrown. This is perhaps not the best approach. I would like to get rid of the template argument, but some way must be provided for the user to specify the parameter. I considered making it an argument to the <b>open</b> function (and the corresponding constructor), but decided it was more fundamental than that -- likewise for making it something that could be set/retrieved. The jury is still out on this, and I intend to re-examine it after I gain some experience using the class.</p> 
<p>Moving on, the <b>value_type</b> of <b>BtreeIndex</b> is <b>std::pair&lt;const Key, size_t &gt;</b>. The second field is actually the stream position of a file. I decided not to use <b>std::streampos</b> since it is potentially too <i>heavy</i> a class for what I need. The idea of <b>BtreeIndex</b> is that a key value references an offset in some file where the actual data can be retrieved. It is up to the client to make the connection between the index and the data file being indexed. For <b>IndexedFile</b>, the position field refers to an <b>XDR_Stream</b>, and the value is in terms of <b>XDR_Char</b>s. Other types of indexes are obviously possible; <b>BtreeIndex</b> doesn't care. </p> 
<p>One obvious use for a <b>BtreeIndex</b> separate from <b>IndexedFile</b> is when the entire object to be stored is the key itself or can be reasonably treated as such. In such a case, the second field of <b>value_type</b> can be set to zero (or any value). A special version of the <b>insert</b> method supports this use by simply taking a <b>Key</b> value to be inserted. </p>
<p>Like <b>IndexedFile</b>, when <b>BtreeIndex::Iterator</b> is dereferenced, it does not return a reference to the <b>value_type</b>. Instead it returns a <b>std::pair&lt;const Key, StreamposProxy&gt;</b>. The later class is similar to the <b>ItemProxy</b> in <b>IndexedFile</b> &#151; primarily it provides an assignment operator that updates the stream position value for the specific key. </p> 
<p>Finally, there are three utility functions: <b>reindex</b>, <b>set_delete_strategy</b>, and <b>set_update_strategy</b>. The first function is similar in concept to the <b>compact</b> function in <b>IndexedFile</b>, but it requires a little more explanation, which starts with the second function. One of the key characteristics of a Btree is that all pages, except the root, are at least half full at all times. When the Btree is first built, this happens automatically as new keys are inserted; when a new key needs to be inserted into a full page, the page is split and the new key inserted into one of the new pages. The resulting two pages are both at least half full. The problem happens when keys are removed.</p> 
<p>If a key is removed from a page that was just half full, there are three possibilities (that I could see anyway). First is just to do nothing. (Obviously, when a page gets to be completely empty, the page itself will have to be removed.) In this case, the Btree is no longer technically correct, but it may not matter very much. The second possibility is to see if either of the page's siblings is also half full or less. This would allow two pages to be consolidated into one page that was more than half full. Finally, assuming that no consolidation was possible, the theoretically correct approach would be to transfer a key from a sibling page to keep the current page at least half full. Unfortunately, shuffling keys and consolidating pages could be a lot of unnecessary work &#151; and a significant performance penalty &#151; for many applications.</p> 
<p>The theoretician in me wanted to implement the last option, but the pragmatist in me wondered what was the point. This is not just an idle question asked out of laziness. The most important characteristic of a Btree is its depth. This determines the number of external probes that are typically necessary in a search. Once a Btree has grown to a certain depth, nothing is going to affect performance until enough keys have been removed to shrink the tree's depth. Of course, the problem is how do you determine when you can shrink the tree unless you actually try to do the consolidation. I decided to pass this buck back to the user.</p> 
<p>There is an enumeration type <b>DeleteStrategy</b> that provides three values corresponding to the three cases mentioned above: <b>None</b> (do nothing), <b>Compact</b> (consolidate pages together if possible), and <b>Shuffle</b> (move keys from one page to another to keep pages at least half full). Note that <b>Shuffle</b> implies <b>Compact</b>. The default is <b>Compact</b>. This seemed to me like a reasonable compromise between performance and letting pages get too empty. The user can change it if desired. One thing a user might want to do is change the delete strategy to <b>None</b> to increase performance when a lot of deletes occur. This could leave the Btree with a lot of mostly empty pages. To allow a Btree to be restored to its proper state in such a case, I provide the <b>reindex</b> method. This walks through the existing Btree and rebuilds the index. Note that re-indexing is only useful if <b>None</b> or <b>Compact</b> have been the delete strategies when keys are removed. If <b>Shuffle</b> is always the delete strategy, then no re-indexing is necessary. </p> 
<p>I will describe the utility function <b>set_update_strategy</b> when I discuss the implementation in the next column. For now, simply note that the default update strategy is <b>MostlySafe</b>.

<H3><FONT COLOR="#000080">Final Thoughts</FONT></H3>

<p>That pretty much covers the interface to <b>IndexedFile</b> and <b>BtreeIndex</b>. It really doesn't look like there is very much there &#151; which is good. On the other hand, I think it should be sufficient for a lot of different applications. I want to reiterate what I said at the beginning about this not being intended to substitute for a full-fledged database engine. Let me give one simple example to illustrate both points. </p> 
<p>One obvious use for a stand-alone <b>BtreeIndex</b> is as a secondary index for an existing <b>IndexedFile</b>. Let's assume we have a <b>IndexedFile</b> of <b>Part</b>s, keyed by <b>PartNo</b>, and we want to build a secondary index based an a common name for the part. Further, lets assume that the name is a field of a <b>Part</b>. Assume we have the following:</p> 

<pre>
typedef IndexedFile&lt;PartNo, Part&gt;   Parts;
Parts parts;
</pre>

<p>Our secondary index creation might look something like this:</p>

<pre>
typedef BtreeIndex&lt;string&gt;       PartNames;
PartNames names;

parts.open(&quot;Parts&quot;, std::ios_base::in);
names.open(&quot;Names&quot;);

Parts::Iterator it;

for (it = parts.begin(); it != parts.end(); ++it) {
    Part p = (*it).second;
    names.insert( PartNames::value_type(p.name,
        (*it.base()).second)); 
}
</pre>

<p>This steps through all the records in the parts file and inserts the name and the stream position into the secondary index. The stream index is obtained by calling the <b>base</b> function of the <b>Iterator</b>. This returns the underlying <b>BtreeIndex::Iterator</b>. Dereferencing that provides the key and the stream position. </p> 
<p>The point is that this is not too difficult. The use of iterators and the typical STL-like interface make it straightforward to write. On the other hand, it is not automatic. For example, the application has to keep track of what the secondary index refers to. This is what I mean by not trying to duplicate a database. </p> 
<p>Next time, I will walk through the implementation. </p>

<H3><FONT COLOR="#000080">Notes and References</FONT></H3>

<p><a name="1"></a>[1] My actual <b>IndexedFile</b> class did not end up with the same interface as the <b>rBtree</b>.</p>
<p><a name="2"></a>[2] Jack Reeves. &quot;The (B)Leading Edge: Simple Memory Management  Classes,&quot; <i>C++ Report</i>, July 2000.</p>


<H3><FONT COLOR="#000080">About the Author</FONT></H3>
<p><i><B>Jack W. Reeves</b> is an engineer and consultant specializing in object-oriented software design and implementation. His background includes Space Shuttle simulators, military CCCI systems, medical imaging systems, financial data systems, and numerous middleware and low-level libraries. He currently is living and working in Europe and can be contacted via <b>jack_reeves@bleading-edge.com</b>.</i></p>

<h4><a href="../../../source/2002/mar02/reeves.zip"></a></h4>

</BLOCKQUOTE></body></html>

