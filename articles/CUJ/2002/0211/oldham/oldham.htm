<HTML>   
     <HEAD>
<TITLE>November 2002/Scientific Computing Using POOMA</TITLE></HEAD>
<BODY BACKGROUND="" BGCOLOR="#FFFFFF" TEXT="#000000">
<H2><A HREF="../tocnov.htm"></A><FONT COLOR="#FF0000">   Scientific Programming</FONT></H2>

<HR>

<h2 align="center"><font color="800000">Scientific Computing Using POOMA</font></h2>
<h3 align="center"><font color="800000"><b>Jeffrey D. Oldham</b> </font></h3>

<BLOCKQUOTE>
<p>A very effective, MP-capable library for mathematical computation. If it works for Los Alamos, it'll work for you.</p>
</BLOCKQUOTE>

<HR>
<BLOCKQUOTE>
<p>Scientists and programmers convert science to algorithms, which are then implemented 
  as programs. The science and algorithms are of interest to scientists, but the 
  implementation of algorithms as programs is much less interesting to scientists, 
  who want to obtain correct, efficient, flexible implementations as quickly as 
  possible. 
<p> The POOMA (Parallel Object-Oriented Methods and Applications) Toolkit, developed 
  at Los Alamos National Laboratory, provides high-level C++ tools to rapidly 
  implement many scientific algorithms as C++ programs. The toolkit makes scientific 
  tools (e.g., arrays, fields, and data-parallel expressions) available while 
  hiding the underlying computer science.
<p> In this article, I will describe the POOMA Toolkit and show how POOMA eases 
  the task of translating scientific algorithms into programs. Then, I will illustrate 
  how to use POOMA by implementing a two-dimensional diffusion algorithm. A few 
  changes convert the program to run on a computer with thousands of processors. 
  I conclude by describing how the open-source POOMA Toolkit can make scientific 
  programming easier and more efficient. 

<h3><font color="000080">Easy Translation from Algorithms to Programs </font></h3>
<p> POOMA&#146;s concepts and syntax mimic notation used to describe scientific 
  algorithms, so scientific programs written using POOMA are: 
<ul>
  <li> Easier to write.</li>
  <li>Significantly shorter.</li>
  <li>Easier to debug.</li>
  <li>More likely to be correct.</li>
</ul>
<p> For example, a mathematical formula <i>x = 3sin((v&#150;w)/</i><FONT FACE="Symbol">p</FONT><i>) &#150; 
  4.2cos(w</i><SUP>2</SUP><i>)</i> can be directly converted to C++ code:
<p> 
<pre>
x = 3.0 * sin((v - w) / M_PI)
    - 4.2 cos(w * w)</pre>
<p> where <b>v</b>, <b>w</b>, and <b>x</b> are scalar values or vectors or matrices 
  or tensors or even containers of values. Error-prone memory allocation and deallocation 
  is eliminated because POOMA containers automatically allocate and deallocate 
  memory to store data. Furthermore, containers are first-class objects, so they 
  can be used as function arguments and copied as simply as if they were built-in 
  scalar values. 
<p> Because the toolkit automatically supplies all interprocessor communication, 
  programmers familiar with writing sequential programs can easily write POOMA 
  programs that run on thousands of processors. Since the same executable can 
  run on any number of processors, many POOMA programs are developed and debugged 
  on uniprocessor workstations and then run on multiprocessor computers without 
  any need for additional debugging.
<p> All these benefits together speed the process of converting algorithms into 
  programs so scientists can spend their time on what is important: the science. 
  For example, a team of four physicists at Los Alamos National Laboratory recently 
  used POOMA to implement an extensive set of physics simulations, averaging just 
  two days to translate each scientific paper into a program. 

<h3><font color="000080">POOMA Concepts </font></h3>
<p> Three concepts you&#146;ll need to understand in order to work with POOMA 
  are: 
<ul>
  <li> Containers: POOMA containers support data access and storage. POOMA <b>Array</b>s 
    extend the functionality of C++ arrays by supporting multiple dimensions and 
    data-parallel expressions. Other POOMA containers include <b>Field</b>s (which 
    support field-based scientific computations where values are located at positions 
    within grid cells), <b>Vector</b>s, <b>Matrix</b>es, and <b>Tensor</b>s.</li>
  <li>Computation modes: computation modes describe the syntax used to perform 
    computations on data stored in containers. C and C++ programmers are familiar 
    with element-wise computation mode, where each container value (a.k.a. element) 
    is individually accessed. Many familiar mathematical operations require an 
    alternative data-parallel mode, where multiple values are simultaneously accessed 
    (see sidebar, &#147;<a href="side1.htm">POOMA Data-Parallel 
    Syntax</a>&#148;). Other computation modes include stencils (illustrated in 
    the program below) and relational computations. Relational computation implements 
    lazy evaluation, where one container&#146;s values depend on several other 
    containers&#146; values.</li>
  <li>Computation environment: the computation environment indicates the machine 
    and operating system that will run a program. Sequential computation using 
    just one thread of execution is familiar to most programmers. POOMA also supports 
    distributed programming using the SPMD (single-program, multiple-data) model, 
    which is particularly appropriate for scientific programs. Any number of processors 
    execute the same program, each using different data.</li>
</ul>

<h3><font color="000080">The POOMA Toolkit </font></h3>
<p> The POOMA Toolkit is a general-purpose library designed to implement scientific 
  and technical programs. It has been used to simulate advection equations used 
  in modeling weather, simulate diffusion processes such as the neutron diffusion 
  program (available for download at &lt;www.cuj.com/code&gt;) described in this 
  article, and solve systems of linear equations. It could be used to model oil 
  reservoirs or predict the values of financial options. It has even been used 
  to implement Conway&#146;s Game of Life. These programs have been run on single-processor 
  desktop computers and on massively parallel computers with thousands of processors. 
<p> The POOMA Toolkit provides a wide variety of tools. To store groups of values, 
  it provides single- and multi-dimensional array and field containers. As anyone 
  who writes scientific or technical programs knows, arrays (or grids) of values 
  form the heart of these programs. The <b>Field</b> container extends this concept 
  to three-dimensional space, so values are not only stored but the distances 
  between them can be computed. Values within containers can be individually manipulated, 
  but data-parallel operations operate collectively on the values in ways analogous 
  to Fortran 90. Stencils support local computations such as in Conway&#146;s 
  Game of Life where the life or death of a cell depends on its neighboring values. 
  The toolkit provides vector, matrix, and tensor classes and mathematical operations. 
  It has been built to support multiprocessor computation and communication with 
  a minimum of fuss. Programmers need only specify how each container&#146;s data 
  should be distributed among the processors, and POOMA automatically ensures 
  all necessary interprocessor communication occurs. Thus, the same oil reservoir 
  simulation program might simulate a small field using a desktop computer and 
  simulate an elephant field using a cluster of computers. 

<h3><font color="000080">Neutron Diffusion Algorithm </font></h3>
<p> POOMA eases the translation of scientific algorithms into programs, and I 
  illustrate this with a two-dimensional diffusion simulation. Diffusion problems 
  occur frequently in science, and I present one based on 1943 lectures at the 
  newly created Los Alamos National Laboratory, which developed the POOMA Toolkit 
  fifty years later. 
<p>To introduce the problem of making an atomic bomb to 
  the incoming scientists and engineers, Robert Serber described the neutron diffusion 
  process that powers an atomic bomb <a href="#1">[1]</a>. The rate of increase 
  of free neutron density <i>N</i> in a supercritical nuclear mass is modeled 
  by the diffusion equation: 
<p><img src="eq1.gif" width="300" height="81">
<p> 
<p> where <FONT FACE="Symbol">n</FONT>, <FONT FACE="Symbol">t</FONT>, <img src="ltxt.gif">, and <FONT FACE="Symbol">u</FONT> are constants.
<p> To simulate the diffusion, time and two-dimensional space are discretized, 
  yielding: 
<p><img src="eq2.gif" width="460" height="80">
<p> 
<p> where <img src="ntxt.gif" width="30" height="30"> indicates the number 
  of neutrons at time <i>t</i> at grid position <i>(i,j)</i>, <FONT FACE="Symbol">a</FONT> is a diffusion 
  constant in the range <i>(0,0.5)</i>, and <FONT FACE="Symbol">b</FONT> indicates the number of neutrons 
  created by each fission. In words, the equation indicates that the number of 
  the neutrons at grid position <i>(i,j)</i> at time step <i>t + 1</i> is dependent 
  on the number of neutrons at time step <i>t</i> at grid position <i>(i,j)</i> 
  and its neighboring cells. 
<p> The recurrence equation, as presented, could easily be implemented, but its 
  local nature facilitates use of a stencil, which is used by many scientific 
  algorithms. A stencil is a rectangular tile that, when applied to a grid, yields 
  a value. (For more information on stencils, see the sidebar, &#147;<a href="side2.htm">Stencils</a>.&#148;) 
  Figures <a href="fig1.htm">1</a> and <a href="fig2.htm">2</a> 
  illustrate how a stencil is applied to a grid. A stencil contains coefficients 
  for a particular cell (indicated by solid lines in <a href="fig1.htm">Figure 
  1</a>) and neighboring cells. When applying the stencil to a grid position, 
  the stencil&#146;s coefficients are multiplied by corresponding grid values 
  and then combined (e.g., added). <a href="fig2.htm">Figure 
  2</a> indicates the same stencil can be applied to various grid positions even 
  if the stencil applications overlap. 
<p> Rewriting the recurrence equation in terms of the stencil in <a href="fig1.htm">Figure 
  1</a> yields: 
<p><img src="eq3.gif" width="192" height="45"> 
<p> 
<p> meaning the new neutron density <i>N</i> equals the application of the stencil 
  at grid position <i>(i,j)</i>.
<p> Free neutrons at the edge of the mass escape without causing fission, so the 
  neutron density on the edges of our mass is zero, yielding a boundary condition. 
  To ease notation, the program will simulate a square mass, rather than a circular 
  mass. Initially the simulation will have no free neutrons present except at 
  the center of the mass.
<p> <a href="algo1.htm">Algorithm 1</a> summarizes the simulation. 
  After establishing initial conditions, a series of time steps are simulated. 
  During each time step, all free neutron densities are updated using the stencil, 
  boundary conditions are again applied, and the current simulation values are 
  inspected if desired. 
<h3><font color="000080">Uniprocessor Program </font></h3>
<p> Now that the algorithm is decided, I will translate it to a C++ program using 
  the POOMA Toolkit (i.e., a &#147;POOMA program&#148;). POOMA supports stencils 
  so the translation will be easy. The free neutron density will be represented 
  by a two-dimensional array <i>N</i> holding floating-point numbers. To declare 
  a <i>n x n</i> grid use: 
<p> 
<pre>
Array&lt;2&gt; N(n,n);</pre>
<p> The declaration creates a two-dimensional array object, as the template parameter 
  <b>2</b> indicates. POOMA <b>Array</b>s are first-class objects, automatically 
  handling necessary memory allocation and deallocation, negating any need for 
  explicit destruction. 
<p> Two statements implement the two initial conditions:
<p> 
<pre>
N = 0.0;
N(n/2,n/2) = 1.0e+7;</pre>
<p> The first, data-parallel statement assigns <b>0.0</b> to all values in <b>N</b>, 
  which knows its domain size so it can iterate through all its values. The second 
  statement assigns a nonzero neutron density to the central grid position. Note 
  parentheses, not brackets, surround <b>Array</b> indices. 
<p> To create the stencil, a POOMA <b>Stencil</b> is instantiated with a function 
  object. <a href="list1.htm">Listing 1</a> shows the <b>Fisher</b> function object class. (&#147;Fish&#148; 
  is a historical word for &#147;fission.&#148;) A POOMA <b>Stencil</b> function 
  object must have three member functions: two indicating the stencil&#146;s size 
  and one computing a value. As illustrated in <a href="fig1.htm">Figure 
  1</a>, the stencil extends one cell to the left of the stencil&#146;s central 
  position and one cell below. Thus, the function object&#146;s <b>lowerExtent</b>, 
  taking a dimension argument, returns the number of cells to the left (or below) 
  the central position. <b>upperExtent</b> indicates the number of cells to the 
  right (or above) the central position. 
<p> The stencil&#146;s <b>operator()</b> computes the value from applying it to 
  a particular grid position. Given three parameters that indicate an <b>Array</b> 
  or other container <b>C</b> and a two-dimensional position (<b>i,j)</b>, it 
  reads container values and computes a value. Since the stencil in <a href="fig1.htm">Figure 1</a> has five nonzero values, the computation reads five values. For example, 
  <b>C.read(i,j)</b> reads the value corresponding to the stencil&#146;s central 
  point. Using the container&#146;s <b>read</b> member function rather than syntax 
  like <b>C(i,j)</b> tells the compiler the value will be read and not changed, 
  perhaps permitting better optimization. Each value is weighted by the appropriate 
  value and then added to yield the function&#146;s return value. 
<p> The <b>Fisher</b> function object depends on its <FONT FACE="Symbol">a</FONT> and <FONT FACE="Symbol">b</FONT> parameters, which 
  are supplied as constructor arguments. To create the stencil <b>stencil</b>, 
  a <b>Fisher</b> object storing a and b is supplied:
<p> 
<pre>
Fisher fisher(alpha, beta);
Stencil&lt;Fisher&gt; stencil(fisher);</pre>
<p> Applying the stencil to all grid positions is simple: 
<p> 
<pre>
N = stencil(N);</pre>
<p> <b>stencil</b> is applied to every position in the two-dimensional array <b>N</b>. 
  Applying a stencil to a cell on the edge of the grid causes the stencil to try 
  to read non-existent container values, so the stencil should only be applied 
  to interior cells. <b>interiorDomain</b>, declared as:
<p> 
<pre>
Interval&lt;2&gt; interiorDomain
  (Interval&lt;1&gt;(1,n-2),
   Interval&lt;1&gt;(1,n-2));</pre>
<p> indicates these cells. The statement: 
<p> 
<pre>
N(interiorDomain) =
  stencil(N, interiorDomain);</pre>
<p> applies the stencil to only the interior cells of <b>N</b>, assigning the 
  computed values to those same interior cells. 
<p> Unfortunately, this data-parallel POOMA statement is not correct. The statement 
  is implemented one grid position at a time without storing any intermediate 
  values. Thus, the statement has a read-write race condition. For example, both 
  the values of <b>N(3,3)</b> and <b>N(3,2)</b> at time step <i>t + 1</i> depend 
  on <b>N(3,3)</b> and <b>N(3,2)</b> at time step <i>t</i>. Neither new value 
  can be computed and assigned before the other. Doubling the number of arrays 
  avoids the problem:
<p> 
<pre>
Na(interiorDomain) =
  stencil(Nb, interiorDomain);
Nb(interiorDomain) =
  stencil(Na, interiorDomain);</pre>
<p> Since each array is either read or written in each statement, the read-write 
  race condition is avoided. The declaration of <b>N</b> is correspondingly changed 
  to declare two <b>Array</b>s <b>Na</b> and <b>Nb</b>. 
<p> Since only interior cells of <b>Na</b> and <b>Nb</b> are assigned values, 
  the boundary cells&#146; values remain unchanged at <b>0.0</b>, so the boundary 
  condition is maintained, and no explicit code needs to be written.
<p> The <b>stencil</b> application is contained with a loop counting the desired 
  number of iterations. During any loop iteration, the neutron densities can be 
  inspected. For example, use:
<p> 
<pre>
std::cout &lt;&lt; N &lt;&lt; std::endl;</pre>
<p> to print all the values in <b>N</b>. When the program finishes, it prints 
  the central neutron density. 
<p> To support using the POOMA Toolkit, <b>Pooma::initialize</b> and <b>Pooma::finalize</b> 
  must be called before and after, respectively, using any POOMA code.
<p> <a href="list2.htm">Listing 2</a> summarizes the sequential program. I encourage you to compare it 
  with <a href="algo1.htm">Algorithm 1</a>. To run the program 
  <b>neutron-sequential</b>, use a command like <b>neutron-sequential 10 5 0.2</b>. 
  This execution has 10 grid points along each of its two dimensions, performs 
  five time steps, and uses an a value of <b>0.2</b>. <FONT FACE="Symbol">a</FONT> is constrained to the 
  range <i>(0.0, 0.5)</i>. 
<h3><font color="000080">Multiprocessor Program </font></h3>
<p> A key advantage of the POOMA Toolkit is that the same executable can run on 
  one or thousands of processors. Thus, a scientist can use a uniprocessor workstation 
  to design, program, and debug a program and then port to a multiprocessor with 
  no code changes or need for more debugging. 
<p> To convert a program designed for sequential execution to one designed to 
  run on multiple processors, one must: 
<ol>
  <li> Modify the declaration of containers.</li>
  <li>Modify program input and output.</li>
  <li>Add guard statements before accesses to individual container values.</li>
</ol>
<p> Almost all computations and program control flow remain unchanged. There is 
  no need to add explicit communication commands. Thus, almost all of the program 
  remains unchanged. 

<h3><font color="000080">SPMD Model </font></h3>
<p> POOMA implements a SPMD programming model. Thus, each processor runs the same 
  program, but containers&#146; data can be distributed across the processors. 
  Each processor runs the same statements but is restricted to assignments for 
  data it owns. If an assignment requires data from other processors, the toolkit 
  automatically issues the required communication commands to obtain the data 
  from these processors. No programmer-specified communication syntax is required, 
  but the program must specify how each container&#146;s data is distributed across 
  processors. 
<p> <a href="fig3.htm">Figure 3</a> illustrates how a <i>6 
  x 6</i> grid might be partitioned among four processors. Grid cells, outlined 
  with solid lines, are split into four equally sized patches, each <i>3 x 3</i>. 
  Each processor stores its patch of data and performs the computations to assign 
  values to this data. 
<p> Computing a grid value using the stencil requires knowing its neighboring 
  values. For grid values on an &#147;interior&#148; edge of a patch, this requires 
  using the values from neighboring patches. These values could be communicated 
  from adjacent patches, but each value might be read many times before it is 
  changed. Thus, the values can be cached on each processor requiring their use. 
  A guard cell is a read-only cell duplicating a value from an adjacent patch. 
  The dashed cells in <a href="fig3.htm">Figure 3</a> indicate 
  these cells. Arrows illustrate the source locations for a few guard cells. The 
  POOMA Toolkit automatically ensures the guard cells&#146; values equal their 
  source grid values. The boundary conditions require the outermost cells have 
  zero values, and they are not computed, so no &#147;external&#148; guard cells 
  are needed. 
<p> (The careful reader may have noticed that each guard cell value is used only 
  once before its source value is changed, so the use of guard cells in this program 
  does not necessarily lead to a more efficient program. If, for example, the 
  stencil computation involved all the stencils&#146; neighboring values rather 
  than just those in the shape of a cross, using guard cells would reduce the 
  necessary communication. For this program, using guard cells does not hurt the 
  program&#146;s efficiency since the values are used once.) 

<h3><font color="000080">Container Declarations </font></h3>
<p> For a multiprocessor program, the declarations of <b>Array</b>s <b>Na</b> 
  and <b>Nb</b> need to be modified to indicate how the data should be partitioned 
  and how it should be mapped to processors. A partition describes how a domain 
  should be split into pieces. The <b>UniformGridPartition</b> splits a domain 
  into pieces of the same size: 
<p> 
<pre>
UniformGridPartition&lt;2&gt;
  partition(Loc&lt;2&gt;(nuProcessors,
                   nuProcessors),
                   GuardLayers&lt;2&gt;(1),
                   GuardLayers&lt;2&gt;(0));</pre>
<p> The first argument indicates that applying partition to a two-dimensional 
  domain will split each dimension into <b>nuProcessors</b> equally sized pieces. 
  The second and third arguments indicate the desired number of internal and external 
  guard cells, respectively. The template argument <b>2</b> indicates a two-dimensional 
  partition. A <b>UniformGridPartition</b> partition requires that each dimension 
  of the domain be evenly divisible into the desired number of pieces. For this 
  reason the number <b>n</b> of grid points is rounded up to the nearest multiple 
  of <b>nuProcessors</b>: 
<p> 
<pre>
n = ((n+nuProcessors-1) / nuProcessors)
    * nuProcessors;</pre>
<p> Applying a partition to a domain yields a set of patches, which must be mapped 
  to processors. For the diffusion program, the patches should be distributed 
  among the available processors. The layout specifies this one-to-one mapping: 
<p> 
<pre>
UniformGridLayout&lt;2&gt;
  layout(vertDomain, partition,
         DistributedTag());</pre>
<p> The domain <b>vertDomain</b> to partition is declared as the cross product 
  of two intervals: 
<p> 
<pre>
Interval&lt;2&gt;(Interval&lt;1&gt;(0, n-1),
            Interval&lt;1&gt;(0, n-1))</pre>
<p> The second and third arguments specify the partition and the one-to-one mapping. 
<p> Finally, the <b>Array</b>s are declared using <b>layout</b> as the constructor 
  argument:
<p> 
<pre>
Array&lt;2, double,
      MultiPatch&lt;UniformTag, Remote&lt;Brick&gt; &gt; &gt;
  Na(layout);
Array&lt;2, double,
      MultiPatch&lt;UniformTag, Remote&lt;Brick&gt; &gt; &gt;
  Nb(layout);</pre>
<p> The sequential declaration for <b>Na</b> has only one template argument because 
  <b>Array</b>&#146;s two other default arguments of <b>double</b> and <b>Brick</b> 
  suffice. <b>double</b> indicates the type of values stored in <b>Array</b>, 
  and <b>Brick</b> indicated how the data will be stored (i.e., each value should 
  be explicitly stored). (The ability to specify data storage independent of its 
  use, which is what the container type indicates, permits optimizations based 
  on programmer knowledge. For example, if all the stored data frequently has 
  the same value, a <b>CompressibleBrick</b> rather than a <b>Brick</b> can be 
  used.) 
<p> <b>Na</b>&#146;s <b>MultiPatch&lt;UniformTag, Remote&lt;Brick&gt; &gt;</b> 
  declaration has four pieces: 
<ul>
  <li> <b>MultiPatch</b>: the container&#146;s data is distributed among multiple 
    patches.</li>
  <li><b>UniformTag</b>: the patches all have the same size.</li>
  <li><b>Remote&lt;Brick&gt;</b>: a patch may reside on any processor in the computer.</li>
  <li><b>Brick</b>: each patch, on a particular processor, should explicitly store 
    all its data.</li>
</ul>
<p>Just like High Performance Fortran <a href="#2">[2]</a>, 
  POOMA supports a wide variety of data distributions, but the programmer must 
  explicitly declare how each container&#146;s data is to be distributed. The 
  optimal distribution depends on how the containers are used. It would be nice 
  if POOMA automatically determined optimal distributions, but doing so remains 
  an unsolved computer science problem. 
<h3><font color="000080">Input and Output </font></h3>
<p> In the SPMD model, many processors run the same executable on different data, 
  so each executable instance might have its own standard input and standard output. 
  Thus, one use of <b>std::cout</b> in a SPMD program may produce many statements 
  on a terminal, up to one per processor. To avoid this flood of data, POOMA provides 
  the <b>Inform</b> output stream class, which works like a <b>std::ostream</b> 
  class in a multiprocessor environment. Writing to an <b>Inform</b> object, for 
  example: 
<p> 
<pre>
output &lt;&lt; Na(n/2,n/2) &lt;&lt; std::endl;</pre>
<p> produces only one output regardless of the number of processors. 
<p> Declaring such an object is simple:
<p> 
<pre>
Inform output;</pre>
<p> Thus, all calls to <b>std::ostream</b> in the sequential program should be 
  changed to use an <b>Inform</b> stream. <b>Inform</b> streams also work for 
  sequential programs, so POOMA programmers frequently use them rather than <b>std::cout</b> 
  and <b>std::cerr</b>. 
<p> To avoid difficulties with program input when each processor might have its 
  own <b>std::cin</b>, POOMA programs frequently use command-line arguments to 
  pass input data. Since the sequential program already uses command-line arguments, 
  it does not need to be modified for its multiprocessor version except that the 
  number of processors must also be specified. 

<h3><font color="000080">Avoiding Race Conditions </font></h3>
<p> The POOMA Toolkit automatically prevents race conditions in multiprocessor 
  programs except for one case: accessing an individual container value immediately 
  after performing a data-parallel statement. Almost all computation in POOMA 
  programs can be expressed using data-parallel syntax, so accesses to individual 
  <b>Array</b> values are rare. When a data-parallel statement precedes accessing 
  an individual value, a <b>Pooma::blockAndEvaluate()</b> statement should occur 
  before accessing the individual value. For example, the initial conditions are 
  specified as: 
<p> 
<pre>
Na = Nb = 0.0;
Pooma::blockAndEvaluate();
Nb(n/2,n/2) = 1.0e+7;</pre>
<p> <b>blockAndEvaluate</b> ensures all processors have completed their assignments 
  of zero before the central grid value is assigned. This prevents a race condition 
  where the <b>0.0</b> assignments are intermixed with the assignment to the central 
  grid position. 
<p> The <b>blockAndEvaluate</b> statement is only necessary for multiprocessor 
  execution. But since POOMA programs are so easily and frequently ported to multiprocessor 
  computers, it is good POOMA programming practice to include these statements 
  even when writing sequential programs, where these statements have no effect. 

<h3><font color="000080">Running the Program </font></h3>
<p> The command to run a multiprocessor POOMA program depends on the computer&#146;s 
  operating system and messaging library. If using a MPI Library <a href="#3">[3]</a>, 
  the command: 
<p> 
<pre>
mpiexec -n 9 neutron -mpi 3 18 5 0.2</pre>
<p> runs <b>neutron</b> on nine processors. <b>mpiexec -n 9 cmd</b> is an MPI 
  command to run <b>cmd</b> on nine processors. (<b>mpiexec</b> is not available 
  with all MPI implementations. Check your MPI manual for the appropriate command.) 
  <b>neutron -mpi 3 18 5 0.2</b> is similar to running the sequential program 
  except POOMA uses the <b>-mpi</b> option to determine the type of the communication 
  library, and <b>3</b> is the number of processors along one dimension. <b>Pooma::initialize</b> 
  strips the <b>-mpi</b> option from the command-line arguments before the diffusion 
  program parses them. 
<p> MPI, the POOMA Toolkit, and the computer automatically determine which nine 
  processors to use, how to communicate among these processors, and how to run 
  the programs on these processors. This information need not be encoded in a 
  POOMA program in any way. 

<h3><font color="000080">Summary </font></h3>
<p> Converting the uniprocessor neutron diffusion program to the multiprocessor 
  version in <a href="list3.htm">Listing 3</a> requires specifying how each container&#146;s data is distributed 
  among all the processors, ensuring the program uses command-line arguments for 
  input and <b>Inform</b> objects for output, and using <b>blockAndEvaluate</b> 
  to avoid race conditions before accessing individual container values. Since 
  POOMA programmers naturally do the latter two even when writing sequential programs, 
  the difference between a sequential and multiprocessor program is usually only 
  a few container declarations. The vast majority of a program, including all 
  its computation (except <b>blockAndEvaluate</b>, which I assume has already 
  been added) is the same. The sequential thought processes and control flow logic 
  in which most programmers are trained can be used to produce POOMA programs 
  that run on one or thousands of processors. 

<h3><font color="000080">Efficiency </font></h3>
<p> The POOMA Toolkit provides high-level scientific syntax without sacrificing 
  efficiency. Efficiency is measured in a variety of ways: 
<ul>
  <li> Programmer time: the time to write and debug the initial version of a program.</li>
  <li>Maintenance time: the time to maintain a program, fixing errors and adding 
    features.</li>
  <li>Run time: the time to run a program.</li>
  <li>Software cost: the cost of software to support the program (e.g., compilers 
    and libraries).</li>
</ul>
<p> POOMA programs are usually up to an order of magnitude shorter than comparable 
  C or Fortran programs because they use POOMA&#146;s high-level scientific syntax, 
  and there is no explicit interprocessor communication syntax. Since the time 
  to write and debug a program usually depends superlinearly on its length, the 
  time savings can be significant. Furthermore, scientific programmers using POOMA 
  need not take the time to learn computer-science skills unimportant to their 
  science (e.g., interprocessor communication protocols, how to avoid &#151; or 
  detect &#151; race conditions, and how to implement lazy evaluation).
<p> POOMA extensively uses template technology to produce code comparable to hand-written 
  C code. For example, each data-parallel statement is translated into one loop 
  regardless of the number of operands. The POOMA statement involving <b>sin</b> 
  and <b>cos</b> listed above is translated into code equivalent to:
<p> 
<pre>
for (unsigned index = 0;
     index &lt; x.size();
     ++index)
  x[index] = 3.0 *
    sin((v[index] - w[index]) / M_PI)
    - 4.2 * cos(w[index] * w[index]);</pre>
<p>This expression-template technology used in POOMA is so powerful it is also separately 
  available as the PETE Library <a href="#4">[4]</a>. Using POOMA does rely heavily 
  on good compiler optimization, but many current C++ compilers (e.g., g++ <a href="#5">[5]</a> 
  and the defunct KCC <a href="#6">[6]</a>) provide it. 
<p> POOMA programs can be slightly slower than hand-coded C or Fortran programs, 
  but the ease of writing, debugging, and maintaining these significantly shorter 
  programs usually outweighs the slight increase in running time. Profiling can 
  reveal the most time-critical portions of a POOMA program, which can be rewritten 
  to run more quickly. 

<h3><font color="000080">Conclusions </font></h3>
<p> POOMA uses sophisticated C++ to ease writing scientific programs. Containers 
  appropriate for scientific programs, a wide variety of computation syntax, and 
  easy support for writing multiprocessor programs ease translating scientific 
  algorithms into programs, as illustrated with the neutron diffusion algorithm. 
  These programs are easier to write and debug, require significantly fewer lines, 
  and are easier to maintain than comparable hand-coded programs. 
<p> The POOMA Toolkit is open-source software that can be freely used, is available 
  without payment, and can be extended to support additional specific syntax or 
  domains. 
<p> The POOMA Toolkit and portions of a user manual are available at the CodeSourcery 
  website (&lt;www.codesourcery.com/pooma/pooma/&gt;). 
  For those wanting to know more about POOMA, Addison-Wesley will soon publish 
  my book <i>Scientific Computing Using Sophisticated C++</i>, describing how 
  using POOMA eases writing scientific programs. 

<h3><font color="000080">Bibliography </font></h3>
<p> <a name="1"></a>[1] Robert Serber. <i>The Los Alamos Primer</i> (University 
  of California Press, 1992). </p>
<p> <a name="2"></a>[2] Charles H. Koelbel, David B. Loveman, and Robert S. Schreiber. 
  <i>The High Performance Fortran Handbook</i> (MIT Press, 1996). </p>
<p> <a name="3"></a>[3] The Message Passing Interface (MPI) Standard,&lt;www-unix.mcs.anl.gov/mpi/&gt;. </p>
<p> <a name="4"></a>[4] Scott Haney, James Crotinger, Steve Karmesin, and Stephen 
  Smith. &#147;The Portable Expression Template Engine,&#148; <i>Dr. Dobbs Journal</i>, 
  October 1999, &lt;www.acl.lanl.gov/pete&gt;. </p>
<p> <a name="5"></a>[5] GNU Compiler Collection, &lt;http://gcc.gnu.org/&gt;. </p>
<p> <a name="6"></a>[6] KAI C++ Compiler, &lt;http://developer.intel.com/software/products/kcc/&gt;. </p>

<h4><a href="../../../source/2002/nov02/oldham.zip"></a></h4>

<p><i><b>Jeffrey D. Oldham</b> worked with the POOMA developers on POOMA v2.4. He 
  received a Ph.D. in computer science from Stanford University and has taught 
  at the university level. He currently works for CodeSourcery, LLC, developing 
  software tools for scientific computing and working on compilers. </i></p>
</BODY>
</HTML>
