<HTML>   
     <HEAD>
<TITLE>June 2002/Keyword Correction from a Dictionary</TITLE></HEAD>
<BODY BACKGROUND="" BGCOLOR="#FFFFFF" TEXT="#000000">
<H2><A HREF="../tocjun.htm"></A><FONT COLOR="#FF0000">   Algorithms</FONT></H2>

<HR>

<H2 ALIGN="center"><FONT COLOR="#800000">Keyword Correction from a Dictionary</FONT></H2>
<H3 ALIGN="center"><FONT COLOR="#800000">Larry Andrews</FONT></H3>

<BLOCKQUOTE>
<p>Have your computer understand what you mean, not just what you say, with this effective string matching algorithm.</p>
</BLOCKQUOTE>

<HR>
<BLOCKQUOTE>

<H3><FONT COLOR="#000080">Introduction</FONT></H3>

<p>I typed into my computer:</p>

<pre>
coyp a b
</pre>

<p>and the computer replied:</p>

<pre>
bad command or file name
</pre>

<p>Isn&#146;t that the way it always is? Stupid computer, you say, and you retype the offending command. Sometimes you even type it correctly the next time. Any human would be able to figure out the intention; why can&#146;t these great machines? Why in this day of spelling and grammar checkers, ever faster and ever more capable computers, can&#146;t they do something simple like figure out what I mean rather than what I say. The common response (or so beginners are told) is that computers are simple and that they just do what they are told; they can&#146;t figure out what you meant. Well, that shouldn&#146;t mean that you have to be so limited. Even if you don&#146;t put artificial intelligence into your systems, it doesn&#146;t mean that you have to tolerate artificial stupidity everywhere.</p>
<p>This article describes an algorithm you can use to make your programs smarter about correcting typographical errors. You can&#146;t fix everything, but at least keywords that aren&#146;t too far from correct can be corrected automatically. I&#146;ve hooked two algorithms together so they can at least correct some of the kinds of common errors. And the algorithm is compact enough to embed in other programs.</p>
<p>The code below uses a dictionary, a nearest neighbor search <a href="#1">[1]</a>, and a simple routine to give a distance measure for how different two strings are. Here&#146;s an example using the 300 most common words in English (plus a couple of their contractions) and a misquote from The Rolling Stones. If I type:</p>

<pre>
yo caint alwys ge wha yu wan
</pre>

<p>The algorithm replies:</p>

<pre>
you can&#146;t always get what you want
</pre>

<p>Not bad, but you will be able to get more from it by the time you are through. The code developed is not a complete system, but an easily modified toolkit for attaching to your applications. A simple command processor can easily be written to go in front of the system shell and correct misspelled commands.</p>

<H3><FONT COLOR="#000080">Distance between Strings</FONT></H3>

<p>There&#146;s substantial literature on string matching. For my purpose, I needed approximate string matching, and I needed a metric for how different the strings are. For use with the nearest neighbor algorithm, the metric needs to obey the triangle inequality. The triangle inequality simply expresses the fact that the length of one side of a triangle can exceed the sum of the lengths of the other two sides. Many algorithms exist for comparing strings <a href="#2">[2]</a>, but a common one is the Levenstein edit distance <a href="#3">[3]</a>. It finds the minimum number of insertions, deletions, and replacements to convert one string into another. The three operations can be given weights to change their relative importance.</p>
<p>Levenstein edit distance computation is implemented by dynamic programming, and it has a computational complexity of <I>O(n</I>2<I>)</I> to <I>O(n</I>3<I>)</I>. I have chosen a simpler, less general algorithm that has complexity <I>O(n)</I> <a href="#4">[4]</a>. (These measures are for nearly equal string lengths.) Like Levenstein, this algorithm obeys the triangle inequality.</p>
<p>The SD (string difference) algorithm that I&#146;ve used has complexity <I>O(n)</I>. It doesn&#146;t compute full edit distances, but it robustly compares strings and gives a bounded distance measure that obeys the triangle inequality. Matches are computed by a pair of passes through the strings, one in the forward direction and then one in the reverse direction. Information on matching characters is accumulated on each pass. In each direction, matches are scored as having a value equal to the string length for the first character examined, one less for the next, and so on down to the last character, which gets a match weight of one. If the corresponding characters do not match, then the match score is increased if the character found in the first string has occurred in the second string more often than it has in the first; this allows some weight for misplaced characters. The match weight given in this latter case is the length of the string still remaining in the first string. The same logic is also applied to the other string.</p>
<p>The other part of the SD algorithm is the computation of the normalizing factor. The match metric is divided by the sum of the maximum possible metric values of the forward and reverse passes (summed for each string). These are determined by summing the character position in the pass times the weighting factor for the particular character.</p>
<p>All of the match values calculated are weighted by factors that can be different for the forward and reverse passes, and the values can be specified for each particular character. In this way, the vowels, for instance, could be down weighted relative to the consonants; this would reflect their secondary importance in English. The whole SD algorithm has been cast as a C++ template so that other string containers (such as wide-character strings) or locales can be easily implemented.</p>

<H3><FONT COLOR="#000080">Examples of Distances between Strings</FONT></H3>

<p>Here are some results from string matching, starting with a simple string. All characters are given equal weight.</p>

<pre>
String     Distance from xxx
 xxx               0.00
 xxy               0.33
 xyx               0.33
 yxx               0.33
 xyy               0.67
 yxy               0.67
 yyx               0.67
 yyy               1.00
</pre>

<p>The fairly intuitive result is that <B>xxx</B> is about 0.33 from <B>xxy</B> and twice as far from <B>xyy</B>. The value of 0.33 for comparing <B>xxx</B> to <B>xxy</B> certainly corresponds to our intuition that they differ by 1/3. If no characters are common to the two strings, then the normalized distance is 1.00 (the maximum distance).</p>
<p>Next, you do the same set again, but now you make the reverse weight 0.8 times the weight for the forward pass. Here are the results for matching the string <B>xxx</B> to several other strings.</p>

<pre>
String     Distance from xxx
 xxx               0.00
 xxy               0.32
 xyx               0.33
 yxx               0.35
 xyy               0.65
 yxy               0.67
 yyx               0.69
 yyy               1.00
</pre>

<p>Because the weight for the forward scan is larger than the weight for the reverse direction, matches at the front of the strings are more important than those at the rear. So <B>xxx</B> matches <B>xyy</B> better than it matches <B>yxy</B> or <B>yyx</B>. This weighting corresponds somewhat better to how you look at words and misspellings (in English) than it corresponds to equal weights.</p>
<p>So now let&#146;s look at some strings that differ in length. Using the same 1.0/0.8 weights, compare <B>x</B> to several other strings of <B>x</B>s.</p>

<pre>
 x         0
 xx        0.25
 xxx       0.43
 xyx       0.43
 xxxx      0.55
 xxxxx     0.63
</pre>

<p><B>x</B> is most similar to <B>xx</B>, which makes a certain sense. The single <B>x</B> matches the first character in both the forward and reverse scans, and only one other character is left over. For <B>xxx</B> there are two characters left over, etc. Surprising at first, the comparison of <B>x</B> to <B>xxx</B> and to <B>xyx</B> give the same values.</p>
<p>Here are some comparisons to <B>xx</B>:</p>

<pre>
 xx          0.00
 xxx         0.11
 xxxx        0.23
 x           0.25
</pre>

<p>Again you see a reasonable ordering of the matches where <B>xx</B> matches <B>xxx</B> better than it matches <B>xxxx</B>. All this makes a lot of sense, and it inspires confidence that searching can be reasonable. What does reasonable mean? Well, nearly matching words will have a lot of characters in common, and the more they are in the same order, the better the match will be. Will you get some bad matches? Probably. Will you get some of the howlers that Microsoft Word produces? Probably not.</p>

<H3><FONT COLOR="#000080">A Class to Implement String Distance</FONT></H3>

<p>Two obvious ways to implement the SD algorithm present themselves: a C-style function to return a value or a C++ class. Since there is persistent data associated with the algorithm (the weights for matches in each direction), a class is the obvious solution. I have chosen to create a template, <B>CThetaMatch</B>, so that locales and different string times might be used without changing the code (not yet tested). <a href="list1.htm">Listing 1</a> shows the implementation of the most important parts of the template, and the complete code is available for download at &lt;www.cuj.com/code&gt;. The string distance is returned by the function call operator (<B>operator()</B>) so that a function object is available to the nearest neighbor search. The use of function objects in this type of application was discussed earlier in <I>CUJ</I> <a href="#5">[5]</a>.</p>
<p>I included three constructors in the source code. A default constructor allows 256 characters with reverse weights equal to 0.8 times the forward weights. This constructor is ideal for use with the ASCII character set. A second constructor uses the same weights, but allows the number of characters in the character set to be specified. And finally, another constructor allows two <B>valarray</B>s of type <B>double</B> to be input; they should contain the weights for the forward and reverse directions, and they should be the same size as the character set to be examined.</p>
<p>The other important item in the SD class is, of course, <B>operator()</B>. It returns the string distance between two input strings, calculated using the weights specified in the constructor. Also included in <B>CThetaMatch</B> are some routines for setting weights for the forward and reverse comparison passes. A function, <B>m_fnSetEnglishFrequencies</B>, sets the forward and reverse weights so that the most common letters in English are the most important in matches, and the least are less important. Also, there are routines for allowing some &#147;compensation&#148; for missing characters, but that makes <B>CThetaMatch</B> violate the triangle inequality, and it turned off by default.</p>

<H3><FONT COLOR="#000080">Nearest Neighbor Search</FONT></H3>

<p>An implementation of the nearest neighbor search has already appeared in <I>CUJ</I> <a href="#1">[1]</a>. Since the distance measure was being replaced, the older version needed to be modified to use a function object to return the string distance. This necessitated the addition of the function object&#146;s class to the template parameters. Only minor modifications were needed, principally passing the function object into the tree builder, the nearest neighbor function, and the search within a sphere function where it would be needed.</p>

<H3><FONT COLOR="#000080">Dictionary Lookup &#151; Multiple Matches vs. Best Match</FONT></H3>

<p><a href="list2.htm">Listing 2</a> lists the heart of a small program (<B>main2.cpp</B> available at &lt;www.cuj.com/code&gt;) to search for best matches and nearly best matches in a dictionary that has been loaded into a <B>NearTree</B> (&#147;Tree&#148; in the example). If the string being tested is found in the dictionary, then there usually isn&#146;t any reason to search any further. But if it is not found, then searching with some radius larger than the distance between the input string and the nearest in the dictionary gives a list of possible candidates. If the closest is significantly nearer than the next nearest, then the closest is probably the correct one.</p>

<H3><FONT COLOR="#000080">Other Implementation Issues and Limitations</FONT></H3>

<p>Obvious improvements could be made in the source code. Changing locales and character sets might require some fine tuning of the templates. The storage for counting found characters and for weights is stored in <B>valarray</B>s. For large character sets, sparse array storage methods could reduce memory requirements. Another alternative would be to simply use two scalars for the forward and reverse weights and not to allow the weights to be assigned character by character. Also not implemented here is upper/lower-case independent matching.</p>
<p>While fast enough for modest dictionaries, some improvements in search speed might be made by changing the character representation from strings to <B>char*</B> (but computers do just keep getting faster).</p>

<H3><FONT COLOR="#000080">References</FONT></H3>

<p><a name="1"></a>[1]  Larry Andrews. &#147;A Template for the Nearest Neighbor Problem,&#148; <I>C/C++ Users Journal</I>, November 2001.</p>
<p><a name="2"></a>[2]  Steven Skiena. <I>The Algorithm Design Manual</I> (SpringerVerlag, 1997).</p>
<p><a name="3"></a>[3]  Zvika Ben-Haim. &lt;www.codeguru.com/cpp_mfc/EditDist.shtml&gt;.</p>
<p><a name="4"></a>[4]  Unknown. Article in <I>Electronics</I>, 1980.</p>
<p><a name="5"></a>[5]  Qiang Liu. &#147;Implementing Reusable Mathematical Procedures Using C++,&#148; <I>C/C++ Users Journal</I>, June 2001. </p>

<p><i><B>Larry Andrews</B> has a Ph.D. in chemistry from the University of Washington in Seattle. He has been a software developer and software QA manager for a number of years. He may be reached at <B>andrewsL@ix.netcom.com</B>.</i></p>

<h4><a href="../../../source/2002/jun02/andrews.zip"></a></h4>

</blockquote></body></html>
