<HTML>   
     <HEAD>
<TITLE>April 2001/C++ Made Easier</TITLE></HEAD>
<BODY BACKGROUND="" BGCOLOR="#FFFFFF" TEXT="#000000">
<H2><A HREF="../tocapr.htm"></A><FONT COLOR="#FF0000">    C/C++ Contributing Editors</FONT></H2>

<HR>

<H2 ALIGN="center"><FONT COLOR="#800000">C++ Made Easier: How Vectors Grow</FONT></H2>
<H3 ALIGN="center"><FONT COLOR="#800000">Andrew Koenig and Barbara E. Moo</FONT></H3>

<BLOCKQUOTE>
<p>The Standard C++ library delivers reasonable performance by default. If you&#146;ve ever wondered how, or what is implied in the word &#147;reasonable,&#148; read on.</p>
</BLOCKQUOTE>

<HR>
<BLOCKQUOTE>

<H3><FONT COLOR="#000080">Introduction</FONT></H3>
<p>Suppose we want to read a bunch of values of type <B>double</B> from a file into a data structure that will allow us to get at the values efficiently. The usual way to do so is something like this:</p>

<pre>
vector&lt;double&gt; values;
double x;

while (cin &gt;&gt; x)
   values.push_back(x);
</pre>

<p>When this loop completes, <B>values</B> will hold all the values, and we will be able to access any of those values efficiently by writing <B>values[i]</B> with a suitable value for <B>i</B>.</p>
<p>Intuitively, the standard-library <B>vector</B> class is like a built-in array: we can think of it as holding its elements in a single block of contiguous memory. Indeed, although the C++ Standard does not explicitly require that the elements of a <B>vector</B> occupy contiguous memory, the standards committee decided in its October, 2000 meeting that this requirement was missing due to an oversight, and voted to include the requirement as part of its Technical Corrigendum. This delayed imposition was not a particular hardship, because every existing implementation already worked that way.</p>
<p>If the elements of a vector are in contiguous memory, it is easy to see how the implementaiton can access an individual element efficiently &#151; it simply uses the same mechanism as the built-in arrays use. What is not so easy to see is how an implementation can arrange for a <B>vector</B> to grow efficiently, when growth must inevitably involve copying elements from one area of memory to another. Although modern processors are often particularly good at copying contiguous blocks of data from one part of memory to another, such copies are not free. Therefore, it is useful to think about how a standard-library implementation might be able to arrange for a <B>vector</B> to grow incrementally without consuming inordinate amounts of time or space.</p>
<p>The rest of this article will discuss a simple, efficient strategy for managing such growth.</p>

<H3><FONT COLOR="#000080">Size and Capacity</FONT></H3>
<p>The first thing to realize about how the <B>vector</B> class works is that a <B>vector</B> is more than just a block of memory. Instead, every <B>vector</B> has not one but two sizes associated with it. One, called its size, is the number of elements that it contains. The other, called its capacity, is the total amount of memory that is available for storing elements. If <B>v</B> is a <B>vector</B>, then <B>v.size()</B> and <B>v.capacity()</B> return <B>v</B>&#146;s size and capacity, respectively. You might imagine a vector looking like this:</p>

<p>&nbsp;</p>
<IMG SRC="fig1.gif" width=289>
<p>&nbsp;</p>

<p>The point of having this extra memory at the end of the <B>vector</B>, of course, is to let <B>push_back</B> append an element to the <B>vector</B> without having to allocate more memory. If the memory that happens to be adjacent to the end of the <B>vector</B> is presently unoccupied, it might be possible to make the <B>vector</B> grow simply by annexing that memory to the <B>vector</B>. However, such luck is rare: most of the time, it will be necessary to allocate new memory, copy all of the <B>vector</B>&#146;s present elements into that memory, destroy those elements, and deallocate the memory that the elements formerly occupied. The advantage of having extra memory in a <B>vector</B> is that such reallocation, which is likely to be expensive, doesn&#146;t happen every time one tries to append an element to a <B>vector</B>.</p>
<p>How expensive is reallocation? It involves four steps:</p>

<OL><LI>Allocate enough memory for the desired new capacity;</LI>
<LI>Copy the elements from the old memory to the new;</LI>
<LI>Destroy the elements in the old memory; and</LI>
<LI>Deallocate the old memory.</LI>
</OL>

<p>If there are <I>n</I> elements, we know that steps (2) and (3) each take <I>O(n)</I> time. Unless the price of allocating or deallocating a block of memory grows more quickly than <I>O(n),</I> these steps will dominate the overall execution time. Therefore, we can conclude that reallocating a <B>vector</B> with a size of <I>n</I> takes <I>O(n)</I> time &#151; regardless of the capacity that we use for the reallocation.</p>
<p>This conclusion suggests a tradeoff. If when we reallocate, we ask for a lot of extra memory, we will not have to reallocate again for quite a while, so reallocations will consume relatively less time. The cost of this strategy will be a lot of wasted space. On the other hand, we can ask for only a little extra memory. Doing so will conserve space, but only by spending time in extra reallocations. In other words, we have a classic opportunity to trade time for space, and vice versa.</p>

<H3><FONT COLOR="#000080">Reallocation Strategy</FONT></H3>

<p>As an example of one extreme, let&#146;s assume that every time we fill the <B>vector</B>, we increase its capacity by one. This strategy wastes as little space as possible, but reallocates the entire <B>vector</B> each time we append an element. We said that reallocating an <I>n</I>-element <B>vector</B> takes <I>O(n)</I> time, so if we start with an empty <B>vector</B> and grow it to <I>k</I> elements, the total time will be <I>O(1+2+...+k),</I> or <I>O(k</I>2<I>).</I> That&#146;s terrible! Can we do better?</p>
<p>Suppose, for example, that instead of increasing the <B>vector</B>&#146;s capacity by one, we increase it by a constant <I>C.</I> It should be clear that this strategy will reduce the number of reallocations by a factor of <I>C,</I> so it is certainly an improvement. But how much of an improvement?</p>
<p>One way to understand the improvement is to realize that with this new strategy, a reallocation happens for every chunk of <I>C</I> elements. Suppose, then, that we allocate <I>K</I> chunks, for a total of <I>K</I>x<I>C</I> elements. Then the first reallocation will copy <I>C</I> elements, the second will copy 2x<I>C</I> elements, and so on. Big-O notation ignores constant factors, so we can divide out all the factors of <I>C</I> to obtain a total time of <I>O(1+2+...+K),</I> or <I>O(K</I>2<I>).</I> In other words, the time is still quadratic in the number of elements, but with a much smaller factor.</p>
<p>Despite the smaller factor, quadratic behavior is still bad, even with a fast processor. In fact, it is especially bad with a fast processor, because fast processors usually come with lots of memory. Programmers with access to fast processors with lots of memory usually try to use all that memory sooner or later, and a programmer who does so is apt to discover that the processor speed is to no avail if there is a quadratic algorithm around.</p>
<p>We have just shown that an implementation that wants to be able to allocate large <B>vector</B>s in less than quadratic time cannot use a strategy of increasing the <B>vector</B>&#146;s capacity by a constant each time it fills up. Instead, the amount of additional memory allocated must grow each time the <B>vector</B> grows. This fact suggests a simple strategy: how about starting the <B>vector</B> out with a single element, and then doubling its capacity each time we reallocate? Remarkably, it turns out that this strategy allows us to build up an <I>n</I>-element <B>vector</B> in <I>O(n)</I> time.</p>
<p>To understand how such efficiency is possible, consider the state of a <B>vector</B> when we have completely filled it up and are about to reallocate it:</p>

<p>&nbsp;</p>
<IMG SRC="fig2.gif" width=454>
<p>&nbsp;</p>

<p>Half of the elements were appended to the <B>vector</B> since the last reallocation, so they have never been copied. Of the ones that have been copied, half of those have been copied exactly once, half of the remainder have been copied twice, and so on.</p>
<p>In other words, <I>n/2</I> elements have been copied one or more times, <I>n/4</I> elements have been copied two or more times, and so on. Therefore, the total number of copies that have been made up to this point is <I>n/2 + n/4 +...,</I> which is approximately <I>n.</I> (This approximation becomes more accurate as <I>n</I> increases.) In addition to the copies, <I>n</I> elements have been appended to the <B>vector</B>, but the total number of operations is still <I>O(n),</I> not <I>O(n</I>2<I>).</I></p>

<H3><FONT COLOR="#000080">Discussion</FONT></H3>

<p>The C++ Standard does not mandate that the <B>vector</B> class manage its memory in any particular way. What it does is to require that creating an <I>n</I>-element <B>vector</B> through repeated calls to <B>push_back</B> take no longer than <I>O(n)</I> time. The strategy that we have been discussing is probably the most straightforward that is capable of meeting that requirement.</p>
<p>Because <B>vector</B>s have good time performance for such operations, there is no reason to avoid loops such as</p>

<pre>
vector&lt;double&gt; values;
double x;
while (cin &gt;&gt; x)
   values.push_back(x);
</pre>

</B>Yes, the implementation will reallocate the <B>vector</B>&#146;s elements as it grows, but this reallocation will take no more than a constant factor longer than it would have taken if we had been able to predict the ultimate size of the <B>vector</B> in advance.</p>

<H3><FONT COLOR="#000080">Exercises</FONT></H3>

<p>1.  Suppose we tried to make our little loop faster by writing it this way:</p>

<pre>
while (cin &gt;&gt; x) {
   if (values.size() == 
       values.capacity())
       values.reserve(values.size() + 
          1000);
   values.push_back(x); }
</pre>

<p>What would be the effect? The <B>reserve</B> member function does a reallocation, thereby changing the <B>vector</B>&#146;s capacity to be greater than or equal to its argument.</p>
<p>2.  Suppose that instead of doubling the size of the <B>vector</B> each time, we tripled it. What would be the effect on performance? In particular, would the execution time still be <I>O(n)</I> for creating an <I>n</I>-element <B>vector</B>?</p>
<p>3.  Suppose you know how many elements your <B>vector</B> is ultimately going to have. In that case, you can call <B>reserve</B> to preallocate the right amount of memory before you begin filling it. Experiment with your local implementation to find out how much of a difference calling <B>reserve</B> makes in your programs&#146; execution time.</p>

<p><i><B>Andrew Koenig</B> is a member of the Large-Scale Programming Research Department at AT&amp;T&#146;s Shannon Laboratory, and the Project Editor of the C++ standards committee. A programmer for more than 30 years, 15 of them in C++, he has published more than 150 articles about C++ and speaks on the topic worldwide. He is the author of <I>C Traps and Pitfalls</I> and co-author of <I>Ruminations on C++</I>.</i></p>
<p><i><B>Barbara E. Moo</B> is an independent consultant with 20 years&#146; experience in the software field. During her nearly 15 years at AT&amp;T, she worked on one of the first commercial projects ever written in C++, managed the company&#146;s first C++ compiler project, and directed the development of AT&amp;T&#146;s award-winning WorldNet Internet service business. She is co-author of <I>Ruminations on C++</I> and lectures worldwide.</i></p>

</blockquote></body></html>
