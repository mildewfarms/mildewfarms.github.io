


<html>
<head>
<title>August, 2005: Extensible  Data Processing Without Inheritance</title>
</head>

<body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000">
<!--Copyright &#169; C/C++ Users Journal-->

<h1>Extensible  Data Processing Without Inheritance</h1>
<p><i>C/C++ Users Journal</i> August, 2005</p>
<h2>Processor objects don't need to be related through class hierarchies </h2>


<h3>By Geoffrey C. Wedig and Stephen Gross</h3>


<I>Geoffrey Wedig is a senior developer at Case Western Reserve University, designing statistical modeling software for genetic research. He can be contacted at wedig@darwin.epbi.cwru.edu. Stephen Gross also works at CWRU. He can be contacted at sgross@darwin.epbi.cwru.edu.</I>

<hr>





<p>Statistical Analysis for Genetic Epidemiology, or S.A.G.E., is a suite of software tools for researchers in the field of Genetic Epidemiology (http://darwin.cwru.edu/). These tools provide statistical analysis of genetic data with the goal of identifying the genes underlying complex diseases. At present, S.A.G.E. includes a dozen different programs, each of which can perform one or several different analyses upon their data, but are built on a common set of libraries and tools. </p>

<p>A standard way to provide analysis definitions to the programs is provided through parameter files. These files are text based and consist of a list of analysis configurations to be performed. Each analysis type is identified by a name ("foo_analysis," "bar_analysis," and so on) and contains the analysis-specific settings. When a program in the suite executes, it parses each of the parameter file's analysis configurations according to analysis-specific syntax rules. Each S.A.G.E. program recognizes a different set of analysis configurations.</p>

<p>Traditionally, each program was required to create its own custom structures for the parsing and containment of the data and analysis configurations associated with the run. This is simplified by having a common base class that stores data common to all programs from which applications derive and add any specific features unique to their particular needs. Even so, a lot of effort was required from each individual program to customize the parsing routines. This led to a great deal of redundant code that, because it was specific to the analysis type, could not be easily generalized. This was particularly troubling for writing component tests, each of which would need to have component-specific versions of the same routines.</p>

<p>We wanted to create a new library for parsing and containing analysis definitions, requiring a minimal effort from the application using the library. At most, we wanted the application to have to define the specific analysis and its parameters and how to parse it (the parsing itself is also generalized, but is not the subject of this article). We didn't want to require a lot of boilerplate code to make it work.</p>

<p>The requirements of the new system were:</p>



<ul>
  <li>Provide a methodology for specifying new analysis configurations and the parsing rules thereof.</li>
  <li>Be able to add these new configurations when needed, without extensive coding of derived types.</li>
  <li>Have the system classify each analysis configuration it encounters and process it correctly using the appropriate passing rules.</li>
    <li>If the list of allowable analysis configurations was fixed, this would not be a difficult problem. We could write a parser for each analysis type, and then in some <b>ParsingManager</b> class, iterate across the contents of the input file and use a switch to choose which fooParser to use on a particular analysis configuration. Unfortunately, the requirement that we be able to add new analysis types at need makes things more difficult.</li>
  <li>Our first solution was to consider an inherited parser schema, with a <b>BaseParser</b> class containing a virtual <b>processInput()</b> function that could be overridden. These derived parsers could be registered with the primary processor, which would do the classification of each analysis and pass it to the appropriate parser. This didn't have the same level of boilerplate that inheritance of the processor itself would, but it still required a fixed layout and was therefore hard to extend should unforeseen parsing needs emerge. We'd prefer a system whereby the parsing routines were only required to support a single member function, one that takes the argument to be processed and returns an object of the correct analysis type. But how could we make the processor accept a number of parsers that do not share a familial relationship through inheritance? To make our problem even more complex, we wanted this to be general, able to be used in a variety of circumstances, essentially whenever we have an iteratable list of data elements, each of which must be processed based upon some sorting criteria.</li>
</ul>
<h3>The Solution</h3>

<p>Our solution required an interesting mix of templates and function pointers. To begin, consider a simple, nonclass-based solution to the requirement that processor objects need not be derived from a common base. What if we write processing logic in standalone functions, then store pointers to those functions? Each function must follow a predefined signature and correspond to a name-based set of input. The <b>ProcessorMgr</b> (available at http://www.cuj.com/code/) then stores a map of strings to function pointers; see <a href="0508grossl1.html" target="_BLANK">Listing 1</a>.</p>

<p>This certainly works, although we've eliminated all the advantages of object-oriented design from our solution. If we could store member function pointers in the <b>ProcessorMgr</b>, we could let users write complete processor classes rather than standalone processor functions. Unfortunately, member function pointers are bound to specific classes, and there is no way to store a container of member functions that are bound to a mixture of classes. What if we require that the processing member function have a specific name instead? That works, but we need a way to store the processors internally. Because they share no ancestry, the only thing we can store is a <b>void*</b>. We'd like the code to look something like <a href="0508grossl2.html" target="_BLANK">Listing 2</a>. </p>

<p><a href="0508grossl2.html" target="_BLANK">Listing 2</a> is a nice idea, but it is missing crucial information to make it work, namely the types of the processors. Could we, perhaps, templatize <b>processInput()</b> so that it knows how to cast the void pointer it finds (<a href="0508grossl3.html" target="_BLANK">Listing 3</a>)?</p>

<p>That would certainly work, but it places the burden of determining which processor to use on users, rather than have <b>ProcessingManager</b> figure it out, which makes you wonder why the object is there at all. We have to make the <b>ProcessorManager</b> figure out what type to cast the <b>void*</b> to. What if we had a function of the <b>ProcessorManager</b> templatized on the processor type that could do this cast for us? How would we make sure it was the right version of this templatized proxy function? Merging the previous examples shows us how. Because the <b>ProcessorMgr</b> knows its own type, it can store function pointers to itself along with the processor to be cast (<a href="0508grossl4.html" target="_BLANK">Listing 4</a>).</p>

<p>Now, the <b>addProcessor()</b> function is properly templatized on the processor type. When a processor is added, it is still stored as a <b>void*</b>, but in addition, a pointer to the <b>proxyFunc()</b> member function is stored as well. This is a function that is templatized on the processor type, and therefore, can correctly cast a void pointer back to its original PROCESSOR_TYPE, and then invoke the <b>operator()</b> on that object. When an <b>InputObj</b> is processed using <b>processInput()</b>, the function locates the <b>ProcessorInfo</b> corresponding to the given input category name and invokes the correctly templatized proxy function, which recasts our processor. Using function pointers, we have effectively templatized the correct function call in advance of its invocation. You are now able to write your own processor object in whatever manner is needed. As long as that class has an <b>operator()</b> function with the correct signature, the processor works.</p>

<p>There are still a few problems, however. First, the <b>processInput()</b> function must have the classification fed to it from an external source. We'd like <b>ProcessorMgr</b> to determine which processor to use. And we'd like the processor to not be restricted to strings as a classification method either. <a href="0508grossl5.html" target="_BLANK">Listing 5</a> shows something like what we want, using an arbitrary classification schema, and not telling the process manager what to do with a specific <b>InputObj</b>.</p>

<p>To make this work, we templatize <b>ProcessorMgr</b> on a CLASSIFIER_TYPE&#151;a functor that takes an <b>InputObj</b> and returns that <b>InputObj</b>'s category as a CLASSIFIER_TYPE::return_type. Then, in <b>processInput()</b>, we search for the correct <b>ProcessorInfo</b> based on the classification of the input type (<a href="0508grossl6.html" target="_BLANK">Listing 6</a>).</p>

<p>So far, we have been using <b>InputObj</b> as the standard input type to a processor object. Again, making things general, we modify the code so that <b>ProcessorMgr</b> is templatized on the input type. Also, we provide a default classifier object that simply returns the input type, so we can process any sortable types without having to define a new function (<a href="0508grossl7.html" target="_BLANK">Listing 7</a>).</p>

<p>At this point, the majority of the system is in place. We can take any input, classify that input based upon a function, and process it, requiring only minimal restrictions to interface and implementation concerns. All that is left to do is some cleanup. We added default processing for unclassified types, replaced the processor points in the <b>addProcess()</b> function with a functor-style interface, and so on. Internally, we use shared pointers to void to clean up our memory management. The result was an easily extensible method for classifying data and processing it based upon that classification.</p>
<h3>Acknowledgment</h3>

<p>S.A.G.E. (Statistical Analysis for Genetic Epidemiology) is supported by a U.S. Public Health Service Resource Grant (RR03655) from the National Center for Research Resources. </p>





</body>
</html>