


<html>
<head>
<title>November, 2005: C++/CLI Threading: Part II</title>
</head>

<body BGCOLOR="#ffffff" LINK="#0000ff" VLINK="#330066" ALINK="#ff0000" TEXT="#000000">
<!--Copyright &#169; C/C++ Users Journal-->

<h1>C++/CLI Threading: Part II</h1>
<p><i>C/C++ Users Journal</i> November, 2005</p>
<h2>Providing persistent privacy with ThreadStatic</h2>


<h3>By Rex Jaeschke</h3>


<I>Rex Jaeschke is an independent consultant, author, and seminar leader. He serves as editor of the Standards for C++/CLI, CLI, and C#. Rex can be reached at http://www.RexJaeschke.com/.</I>

<hr>





<p>C++/CLI supports the ability to create multiple threads of execution within a single program. Last month, we saw how threads are created and synchronized. This month, we'll see how shared variables can be guarded against compromise during concurrent operations, learn about thread-local storage, and we'll look at interlocked operations.</p>
<h3>Other Forms of Synchronization</h3>

<p>We can control synchronization of threads directly by using a number of functions in classes <b>Monitor</b> and <b>Thread</b>. <a href="0511jaeschkel1.html" target="_BLANK">Listing 1</a> contains an example.</p>

<p>In case 1, a shared buffer of type <b>MessageBuffer</b> is created. In cases 2a, 2b, and 2c, a thread is created and started such that it processes each message placed in that buffer. Cases 3a, 3b, and 3c create and start a thread that causes a series of five messages to be put into the shared buffer for processing. The two threads are synchronized such that the processor can't process the buffer until the creator has put something there, and the creator can't put another message there until the previous one has been processed. In case 4, we wait until the creator thread has completed its work.</p>

<p>By the time case 5 executes, the processor thread should have processed all of the messages the creator put there, so we tell it to stop work by interrupting it using <b>Thread::Interrupt</b>. We then wait on that thread in case 6 by calling <b>Thread::Join</b>, which allows the calling thread to block itself until some other thread terminates. (Instead of waiting indefinitely, a thread can specify a maximum time that it will wait.)</p>

<p>The <b>CreateMessages</b> thread is quite straightforward. It writes five messages to the shared message buffer, waiting two seconds between each one. To suspend a thread for a given amount of time (in milliseconds), we call <b>Thread::Sleep</b>. A sleeping thread is resumed by the runtime environment rather than by another thread.</p>

<p>The <b>ProcessMessages</b> thread is even simpler because it has the <b>MessageBuffer</b> class do all its work. Class <b>MessageBuffer</b>'s functions are synchronized because only one of them at a time can have access to the shared buffer. </p>

<p>The main program starts the processor thread first. As such, that thread starts executing <b>ProcessMessages</b>, which causes the parent object's synchronization lock to be obtained. However, it immediately runs into a call to <b>Wait</b> in case 10, which causes it to wait until it is told to continue; however, it also gives up its hold on the synchronization lock in the meantime, allowing the creator thread to obtain the synchronization lock and to execute <b>SetMessage</b>. Once that function has put the new message in the shared buffer, it calls <b>Pulse</b> in case 8, which allows any one thread waiting on that lock to wake up and resume operation. However, this cannot happen until <b>SetMessage</b> completes execution because it doesn't give up its hold on the lock until that function returns. Once that happens, the processor thread regains the lock, the wait is satisfied, and execution resumes beyond case 10. A thread can wait indefinitely or until a specified amount of time has lapsed. For completeness, the output is shown in <a href="0511jaeschkef1.html" target="_BLANK">Figure 1</a>.</p>

<p>Note carefully that the processor thread was started before the creator thread. If they were started in the opposite order, the first message would be added, yet no processor thread would be waiting, so no processor thread is woken up. By the time the processor thread gets to its first call to <b>Wait</b>, it will have missed the first message and will only be woken up when the second one has been stored.</p>
<h3>Managing Threads</h3>

<p>By default, a thread is a foreground thread that executes until its entry-point function terminates, regardless of the life span of its parent. On the other hand, a background thread automatically terminates when its parent terminates. We configure a thread as being a background thread by setting <b>Thread</b>'s property <b>IsBackground</b>. A background thread can also be made a foreground thread by the same approach.</p>

<p>Once a thread has been started, it is alive. We can test for this by inspecting <b>Thread</b>'s property <b>IsAlive</b>. A thread can give up the rest of its CPU time slice by calling <b>Wait</b> with a time of zero milliseconds. A thread can get at its own <b>Thread</b> object via the property <b>CurrentThread::Thread::CurrentThread</b>.</p>

<p>Each thread has a priority level associated with it and this is used by the runtime environment to schedule the execution of threads. A thread's priority can be set or tested via the property <b>Thread::Priority</b>. Priorities range from <b>ThreadPriority::Lowest</b> to <b>ThreadPriority::Highest</b>. By default, a thread has priority <b>ThreadPriority::Normal</b>. Because thread scheduling varies from one implementation to another, we should not rely too heavily on priority levels as a means of controlling threads.</p>
<h3>Volatile Fields</h3>

<p>The type qualifier <b>volatile</b> tells the compiler that no single thread controls all aspects of the object to which it is applied; specifically, one or more other threads might be reading from and/or writing to this variable asynchronously. Essentially, this qualifier forces the compiler to be less aggressive when performing optimization. </p>

<p>Consider the code fragment in <a href="0511jaeschkel2.html" target="_BLANK">Listing 2</a>. In the absence of <b>volatile</b>, case 1 could safely be ignored because we immediately overwrite the value of <b>i</b> in case 2; however, given the volatile qualifier, the compiler must perform both store operations. </p>

<p>In case 3, the compiler must generate code to fetch the value of <b>i</b> twice; however, its value might change between fetches. To make sure we are testing the same value, we have to write something like case 4 instead. By storing a snapshot of <b>i</b> in the nonvolatile variable <b>copy</b>, we can safely use the value of <b>copy</b> multiple times, knowing that its value cannot be changing "behind the scenes." By using <b>volatile</b>, we can avoid explicit synchronization for certain kinds of variable access.</p>
<h3>Thread-Local Storage</h3>

<p>When writing a multithreaded application, it can be useful to have variables that are specific to a particular thread. For example, consider the program in <a href="0511jaeschkel3.html" target="_BLANK">Listing 3</a>.</p>

<p><b>m1</b> is an instance field, so each instance of type <b>ThreadX</b> has its own copy, and that exists for the life of its parent object. On the other hand, <b>m2</b> is a class field, so there is only one occurrence of it for the class, regardless of the number of instances of that class. In theory, this field exists until the application terminates. Neither of these fields is specific to a thread. With the appropriate constructs, both kinds of fields can be accessed by multiple threads.</p>

<p>Simply stated, thread-local storage is memory that is owned by a particular thread, and that memory is allocated when a new thread is created, and deallocated when that thread terminates. It combines the privacy of local variables with the persistence of static variables. A field is marked as being thread-local by attaching to it the attribute <b>ThreadStatic</b>, as shown in case 3 of <a href="0511jaeschkel3.html" target="_BLANK">Listing 3</a>. Being a static field, <b>m3</b> can have an initializer.</p>

<p>Function <b>TMain</b> is the entry point for new threads. This function simply increments the three fields <b>m1</b>, <b>m2</b>, and <b>m3</b>, five times each, and prints their current value. The lock block in case 4 makes sure that no other thread can concurrently access these fields while their values are being incremented or printed.</p>

<p>The primary thread sets its own name to <b>t0</b> in case 5, and then creates and starts two threads. It also calls <b>TMain</b> directly, as a regular function rather than as part of thread creation and startup. One example of the output that can result is shown in <a href="0511jaeschkef2.html" target="_BLANK">Figure 2</a>. (The only difference between the possible outputs is the order in which the threads do their incrementing and printing.)</p>

<p>Each of the three threads has its own instance of <b>m1</b>, which is initialized to 10, so it is no surprise that each has the value 15 after being incremented five times. In the case of <b>m2</b>, all three threads share the same variable, so that one variable is incremented 15 times.</p>

<p>The threads <b>t1</b> and <b>t2</b> go through the thread-creation process, each getting its own version of <b>m3</b>. However, these thread-local variables take on their default value zero, rather than the initializer 30 shown in the source code. Beware! After being incremented five times, each has the value 5. Thread <b>t0</b> exhibits different behavior. As we can see, this thread was not created by the same machinery as the other two threads. As a result, its <b>m3</b> does take on the explicit initial value, 30. Also note that in case 6, <b>TMain</b> is being called as a regular function, not as part of the creation of a new thread.</p>
<h3>Atomicity and Interlocked Operations</h3>

<p>Consider the following scenario: An application has multiple threads executing in parallel, with each thread having write access to some shared integer variable. Each thread simply increments that variable by 1, using <b>++value</b>. That looks harmless enough; after all, this looks like an atomic operation, and on many systems, it is&#151;at least from the point of view of a machine instruction. However, C++/CLI's execution environment does not universally guarantee this for all integer types.</p>

<p>To demonstrate this, the program in <a href="0511jaeschkel4.html" target="_BLANK">Listing 4</a> has three threads, each concurrently incrementing a shared 64-bit integer variable 10 million times. It then displays that variable's final value, which, in theory, should be 30 million. The resulting application can be run in one of two modes: the default mode is unsynchronized and uses the <b>++</b> operator; the alternate mode, indicated by using a command-line argument of <b>Y</b> or <b>y</b>, uses a synchronized library increment function instead.</p>

<p>When the standard <b>++</b> operator is used, five consecutive executions of the application resulted in the output shown in <a href="0511jaeschkef3.html" target="_BLANK">Figure 3</a>. As we can see, the reported total falls far short of the correct answer. Simply stated, between 17 and 50 percent of the increments went unreported. When the same program was run in synchronized mode&#151;that is, using <b>Interlocked</b>'s <b>Increment</b> instead, all 30 million increments are done and reported correctly.</p>

<p>Class <b>Interlocked</b> also has a <b>Decrement</b> function.</p>
<h3>Exercises</h3>

<p>To reinforce the material we've covered, perform the following activities:</p>



<ol>
  <li>In <a href="0511jaeschkel4.html" target="_BLANK">Listing 4</a>, change the type of the shared variable, <b>value</b>, and run the application with and without synchronization.</li>
  <li>In your implementation's documentation, carefully read the description of the <b>Increment</b> and <b>Decrement</b> functions in class <b>Interlocked</b>. Note that there are two sets, one for <b>int</b> and one for <b>long long</b>. Note also that there is no support for arguments of type <b>unsigned int</b> or <b>unsigned long long</b>.</li>
  <li>Carefully read the description of the other functions in <b>Interlocked</b>, especially <b>Add</b>, <b>Exchange</b>, and <b>CompareExchange</b>.</li>
  <li>The class <b>Queue</b> in Listing 5 (available online at http://www.cuj .com/code/) implements a queue of strings. Modify this class so that it is thread safe; that is, provide support for multiple threads adding and/or removing nodes from the same queue at the same time. The class has two public functions:</li>

<pre>
     void AddNode(String^ s);
     String^ RemoveNode();

</pre>


  <li>	    <b>RemoveNode</b> must not return to its caller until it has something to return; that is, it must wait indefinitely, if necessary, for a node to be added.</li>
  <li>	    In some other assembly, write a <b>Main</b> that creates three threads that each adds some fixed number of nodes, and one thread that removes nodes, all running asynchronously. Once all the adder threads have finished, have the main thread add one last string with the value "END" and wait for the remover thread to shut itself down, which it does when it sees this node. Hint: You will need to use the <b>Wait</b>, <b>Pulse</b>, and <b>Join</b> functions, and you might find it useful to use <b>Sleep</b> as well, to stagger the adder threads' actions.</li></ol>

<h5>CUJ</h5>





</body>
</html>