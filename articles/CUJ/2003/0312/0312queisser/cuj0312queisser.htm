<html>
<head>
<title>Computing the Hough Transform</title>
</head>

<body>
<h2>Computing the Hough Transform</h2>

<h3>By Andrew Queisser</h3>


<p>The Hough Transform (HT) is an algorithm for finding shapes in images or sets of data points. Unlike regression, algorithms that find one line or curve, the HT can be used to find several lines in one set of data points. Although well known in the field of image processing, HT was originally published in 1962 as part of a patent for a device to track high-energy particles [1]. In this article, I introduce the HT for line and circle detection, and discusses implementation details.</p>
<p>Imagine you have a set of <i><i>x-y </i></i>data points that represent several lines. Traditional regression algorithms can only give you one line that best fits the data points. If the data points are edge pixels from an image, then it is likely that you want to find several lines at once. HT is well suited for edge searches like this because it is a global transform, which considers all likely edge pixels. The HT does not require any a priori information other than the edge shape (line, circle, ellipse, or the like) to be found.</p>



<h3>Line Detection</h3>


<p>A straight line in <i>x-y</i> space is often written as<i> y=mx+b</i>, but can also be written in the normal form:</p>


<pre>
<IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10">= x*cos(<IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10">)+y*sin(<IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10">),
</pre>

<p>where <IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> is the angle of the normal vector and <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"> is the distance of the line to the origin. <A HREF="0312queisserf1.htm" target="_BLANK">Figure 1</A> illustrates values <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"> and <IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> for a line <i><i>L1</i></i> going through two points <i><i>P1</i></i> and <i><i>P2</i></i>. The normal form is more suitable for the HT because it avoids the problem of the slope <i><i>m</i></i> becoming infinite for lines parallel to the <i><i>y</i></i>-axis. </p>


<p>Inserting coordinates <i>(x1,y1)</i> of a specific edge pixel <i>P1</i> into the normal form yields a curve <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"><i>=f(</i><IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"><i>),</i> which describes all possible straight lines through <i>P1</i>. In <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10">-<IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> coordinates, also known as "Hough space," <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"> is a sinusoidal curve. A point in <i><i>x-y</i></i> space maps to a sinusoidal curve in Hough space, while a line in <i><i>x-y</i></i> maps to a point in Hough space. <A HREF="0312queisserf2.htm" target="_BLANK">Figure 2</A> shows the two sinusoidal curves corresponding to points <i><i>P1</i></i> and <i><i>P2</i></i> in <A HREF="0312queisserf1.htm" target="_BLANK">Figure 1</A>. The two curves intersect at the <IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> and <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"> for line <i><i>L1</i></i>.</p>

<p>The basic idea of the HT is to calculate the curves that represent all possible lines through each edge pixel and to accumulate the results in Hough space. Each edge pixel contributes one curve through the Hough space accumulator; and each accumulator cell through which the curve passes gets incremented. If each of <i><i>N</i></i> accumulated edge pixels lies on a perfect line <i>L1</i>, the Hough cell corresponding to <i><i>L1</i></i> ends up with a value of <i><i>N</i></i>. In most real images, the points will be close to &#151; but not perfectly on &#151; <i>L1</i>, and the Hough cell for <i><i>L1</i></i> will contain a local maximum smaller than <i><i>N</i></i>. The cells around the maximum cell drop down to smaller values. When the accumulation for all edge pixels in the image is finished, the Hough accumulator contains a peak for each line in the image. A peak selection algorithm, (in the simplest case, just a search for the maximum value) finds the strongest line in the image.</p>



<h3>Implementation</h3>


<p>A naive implementation of HT would simply loop through all values of <IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> from 0 to <i><i>PI</i></i> (the range of <i><i>PI</i></i> to <i><i>2*PI</i></i> would accumulate the same lines again), calculate the <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"> value, and increment the cell in question. <A HREF="0312queisserl1.htm" target="_BLANK">Listing 1</A>, which shows the loop required to calculate the Hough accumulator, illustrates some important implementation choices:</p>


<ul>

  <li>The angle resolution is determined by the value of <b>numAngleCells</b>. A resolution of half a degree requires a value of <b>numAngleCells=360</b>.

  <li>The value of<b> rhoMax </b>is<b> sqrt(dx^2+dy^2)</b>, where <b>dx</b> and <b>dy</b> are the maximum coordinates of the image. In effect, <b>rhoMax</b> is the length of the diagonal of the original image. The full range for <b>rho</b> is <b>[-rhoMax,rhoMax]</b> so the accumulator has to be large enough to hold <b>numAngleCells*2*rhoMax</b> values unless the resolution of <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"> is scaled down to a lower resolution


</ul>

<p>For a typical image with<b> dx=640</b>,<b> dy=480 </b>and an angular resolution of 0.5 degrees, the accumulator has to be at least<b> [360][sqrt(640*640 + 480*480) * 2] </b>or<b> [360][1600].</b> As you can see, the angular resolution and the distance resolution is quite different &#151; dividing the <b>rhoValue</b> by two results in a more balanced overall resolution with 360 <IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> values and +/-400 <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"> values. In general, a suitable <b>rhoDivisor</b> value should be chosen, but a division by two is efficient because it can be accomplished by a right-shift of one.</p>

<p>Many implementations of the Hough Transform use the approach in <A HREF="0312queisserl1.htm" target="_BLANK">Listing 1</A> more or less directly. Unfortunately, the loop as shown only increments one cell per <IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> value instead of all cells through which the sinusoidal curve passes. To get complete coverage of all cells, you need to consider parts of the curve where the curve passes through several <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"> cells for one value of <IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10">. To get complete coverage, a nested loop that fills in the skipped cells is needed. <A HREF="0312queisserl2.htm" target="_BLANK">Listing 2</A> is the complete accumulation loop.</p>



<h3>Optimization</h3>


<p>The first optimization that speeds up the accumulation is to replace the calls to <i>cos(</i><IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"><i><i>)</i></i> and <i>sin(</i><IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"><i><i>) </i></i>with lookup tables. The <IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> values can be precalculated because they depend only on the step size. The second optimization is moving the origin to the center of the image by subtracting<b> dx/2,dy/2 </b>from each point. Centering the origin halves the size of the accumulator because <b>rhoMax</b> is now only half as large as before. The accumulation loop can be rewritten, as in <A HREF="0312queisserl3.htm" target="_BLANK">Listing 3</A>. (For clarity, I have omitted the nested loop that fills in the skipped cells.)</p>


<p>The lookup tables <b>cosTable</b> and <b>sinTable</b> have been precalculated once when the size of the original image is known. Further optimization is possible by replacing <b>cosTable</b> and <b>sinTable</b> with scaled integer values by scaling up the sine and cosine from the original [-1,1] range to [-1024,1024] and dividing the end result by 1024, which is a right-shift by 10 bits.</p>

<p>With the <b>sine</b> and <b>cosine</b> functions replaced by a lookup table, it is tempting to go one step further and replace the <b>multiplications</b><i></i> <b>x*cosTable[a] </b>and <b>y*sinTable[a]</b> with two-dimensional lookup tables <b>xTable</b> and <b>yTable</b>. However, the big lookup tables did not speed-up the algorithm in my tests, presumably because the accesses over large memory areas are slower than smaller lookups combined with multiplications. </p>

<p><A HREF="0312queissert1.htm" target="_BLANK">Table 1</A> lists some times measured on a not-so-fast PC for a 640&times;480 image with 13,801 edge pixel candidates. These times will vary significantly depending on processor type and available cache memory.</p>



<h3>An HT Accumulator Class</h3>


<p><A HREF="0312queisserl4.htm" target="_BLANK">Listing 4</A> is the class definition of an HT accumulator base class <b>HoughAccum</b>, which encapsulates the management of the accumulator memory. I use <b>std::vector&lt;int&gt;</b> for the accumulator. There is no appreciable performance penalty for using <b>vector</b> instead of a plain array because the <b>vector</b> is presized during initialization. If the maximum values for <b>dx</b> and <b>dy</b> are known beforehand, <b>m_accum</b> can be defined as a true two-dimensional array or a <b>boost::multi_array</b>. Using a two-dimensional array makes the implementation of <b>GetCell/SetCell</b> simpler and would also simplify further analysis of the accumulator. For now, the <b>std::vector</b> is enough.</p>


<p>The <b>AddPoint</b> function is implemented as a template method [2]. The nonvirtual public <b>AddPoint</b> function checks the bounds of <i><i>x</i></i> and <i><i>y</i></i> and calls the virtual <b>DoAddPoint</b> function, which has to be defined by the derived class for the specific accumulator class.</p>

<p>The <b>GetCell/SetCell</b> and other accessor functions for the accumulator array are also nonvirtual. For these frequently called functions, the overhead of a virtual function is best avoided.</p>

<p>The motivation behind creating an abstract base class is that the HT can be used for shapes other than straight lines. <b>HoughAccum</b> itself can not be instantiated, so I define a derived class <b>LineHoughAccum</b>, which defines the functionality for the line detection. <b>LineHoughAccum</b> adds the lookup tables for <b>sine</b> and <b>cosine</b> and defines the necessary <b>Init</b> and <b>DoAddPoint</b> overrides. <b>LineHoughAccum</b> uses the row index for the angle <IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> and the column index for the distance <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10">. <A HREF="0312queisserl4.htm" target="_BLANK">Listing 4</A> is the definition of <b>LineHoughAccum</b>. To use the <b>LineHoughAccum</b> class, follow these steps:</p>

<ol>

<li>Create a <b>LineHoughAccum</b> object with the desired angle resolution.<p></p>

<li>Initialize the accumulator with the size of the image.<p></p>

<li>Call the <b>AddPoint</b> function with the coordinates for each of the points in the image that might be an edge point.<p></p>

<li>Analyze the accumulator for cells with values that are high enough to be significant using the <b>GetCell</b> function.<p></p>

<li>Call <b>Clear()</b> and repeat steps 2 and 3 for additional images with the same size, or start at step 1 if the image size changes.<p></p>
</ol>


<p>Step 3 deserves special attention because the interpretation of the Hough accumulator is not trivial.</p>



<h3>Peak Detection Algorithms</h3>


<p>The simplest peak detection algorithm simply searches for the cell with the maximum value in the accumulator and calculates the angle and distance values from the cell index. Here's how to calculate the angle and distance for the cell at<b> row,col</b> (avoid integer division by multiplying with <i><i>PI</i></i> first):</p>


<pre>
<IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> = (PI * row)/numRows
<IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"> = col-numCols/2

</pre>

<p>where <b>numRows</b> and <b>numCols</b> was obtained from the call to <b>HoughAccumulator::GetAccumSize()</b>.</p>


<p>Usually, an image contains more than one line, though. You will need a way of successively finding peaks that are far enough away from previous peaks. To make things more challenging, each peak in the Hough accumulator is spread across several cells because the edge pixels in a typical image will not be on perfectly straight lines. An iterative peak detection algorithm looks like this:</p>


<p>1.	Find the maximum cell in the accumulator.</p>

<p>2.	Find the area around the maximum cell that belongs to the same line.</p>

<p>3.	Mark or zero out the area.</p>

<p>4.	Continue at step 1 until all cells are below some preselected sensitivity threshold.</p>


<p>Step 2 is the tricky part. How can you determine how many neighboring cells belong to the same maximum? You have to choose which range of <IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> and <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"> values should be merged with the maximum line. The extreme cases include the following:</p>

<ul>

  <li>The detection of a single polygonal shape requires a peak detection that finds local maxima and doesn't return multiple lines that are clustered close to each other. The minimum values of <IMG SRC="theta14.gif" WIDTH="5" HEIGHT="10"> and <IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"> that separate two peaks in the accumulator can be directly determined from the polygon.

  <li>The interpretation of natural scenes requires a detection algorithm that returns many lines, which are then further interpreted. In natural scenes, several lines may actually lie close to each other and shouldn't be lumped together.


</ul>

<p>The source code for this article, available at <a href="http://www.cuj.com/code">http://www.cuj.com/code/</a>, includes examples of peak detection algorithms.</p>



<h3>Experimental Results</h3>


<p><A HREF="0312queisserf3.htm" target="_BLANK">Figure 3</A> shows an example image of two brackets. The image was processed with a Sobel edge detection filter and made binary. <A HREF="0312queisserf4.htm" target="_BLANK">Figure 4</A> shows the lines extracted with the HT overlayed with the original image. Only peaks with accumulator cells greater than 50 were extracted. Lines within +/- five degrees were merged into one line.</p>




<h3>Further Refinements</h3>


<p>The HT can be used for shapes other than straight lines. The basic idea of accumulating votes in a parameter space can be applied to any shape that can be represented by a small number of parameters. A circle of known radius <b><IMG SRC="rho14.gif" WIDTH="6" HEIGHT="10"></b> can be represented by two parameters: The two coordinates <b>xc,yc</b> of the center point. If you accumulate votes along a circle with radius <b>r</b> around each edge pixel, you will accumulate a maximum at <b>xc,yc</b>. In some ways, the HT for circles is easier than for lines because the Hough space for circle detection is actually the image space itself. If the accumulator results are viewed as an image, you will see bright spots at the center points of circles in the source image.</p>


<p>For grayscale images, several ways to make the Hough Transform more efficient or robust have been proposed:</p>


<ul>
  <li>The basic Hough Transform ignores information about edge direction that can be extracted from the grayscale source images. Each edge pixel contributes a complete curve through the accumulator. The approximate edge direction can be estimated from the image so it is sufficient to accumulate only the portion of the curve around the parameter estimated from the image.
  <li>The edge strength of the edge pixel can be used to make the HT more robust. Instead of simply giving each edge pixel one vote, the edge strength is added to the accumulator. Strong edges contribute more to the accumulator than weak edges, which helps reduce noise effects.


  <li>The Hough Transform has also been expanded to detect shapes other than circles and lines. The "Generalized Hough Transform" can be used to detect arbitrary shapes although the accumulation becomes much more involved than the simple schemes introduced here. The machine-vision literature discusses many other ways of applying the HT [3].

</ul>

<h3>References</h3>


<p>[1]	Hough, P.V.C (1962). Method and means for recognizing complex patterns. U.S. Patent 3069654.</p>

<p>[2]	Gamma, Erich, et al.<i><i> Design Patterns: Elements of Reusable Object-</i>oriented Software</i>. Addison-Wesley, 1995.</p>

<p>[3] Davies, E.R. <i><i>Machine Vision: Theory, Algorithms, Practicalities, </i></i>Second Edition. Academic Press, 1997. </p>

<hr><I>
<b>Andrew</b> is a software engineer for Hewlett-Packard. He can be contacted at <a href="mailto:andrew.queisser@hp.com">andrew.queisser@hp.com</a>.</I>

<hr>

</body>
</html>
