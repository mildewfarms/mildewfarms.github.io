<HTML>
<HEAD>
<TITLE>Threading from Managed C++</TITLE>
</HEAD><BODY>
<h2>Threading from Managed C++</h2>
<h3>Rex Jaeschke</h3>

<P>The .NET Framework supports the ability to create multiple threads of execution within a single program. As such, this facility is available to all languages executing in that environment. In this article, I&#146;ll show how threads are created and synchronized. (It is important to note that Managed C++ does not support synchronization of threads in different applications.) I&#146;ll also show how shared variables can be guarded against compromise during concurrent operations.<P>

<h3>Creating Threads</h3>
<P>In <a href="cuj0310jaeschke_l1.htm">Listing 1</a>, the primary thread creates two other threads, and the three threads run in parallel without synchronization. No data is shared between the threads and the process terminates when the last thread terminates.<P>

<P>Let&#146;s begin by looking at the first executable statement in <a href="cuj0310jaeschke_l1.htm">Listing 1</a>, in case 3a. Here I create an object having the user-defined type <B>Th01</B>. <B>Th01</B> has a constructor, an instance function, and three fields. I call the constructor passing it a start and end count and an increment amount, which it stores for later use in controlling a loop.<P>

<P>In case 3b, I create an object of the library type <B>Thread</B>, which is from the namespace <B>System::Threading</B>. A new thread is created using such an object. However, before a thread can do useful work, it must know where to start execution. I indicate this by passing to <B>Thread</B>&#146;s constructor a delegate of type <B>ThreadStart</B>, which supports any function taking no arguments and returning no value. (Being a delegate, it could encapsulate multiple functions. However, in my examples, I&#146;ll specify only one.) In this case, I identify that the thread is to begin by executing instance function <B>ThreadEntryPoint</B> on object <B>o1</B>. Once started, this thread will execute until this function terminates. Finally, in case 3c, an arbitrary name is given to this thread by setting its <B>Name</B> property.<P>

<P>In cases 4a, 4b, and 4c, I do the same thing for a second thread, giving it a different set of loop control data and a different name.<P>

<P>At this stage, two thread objects have been constructed. However, no new threads have yet been created. At this stage, these threads are &#147;inactive.&#148; To make a thread &#147;active,&#148; you must call <B>Thread</B>&#146;s function <B>Start</B>, as shown in cases 5 and 6. This function starts a new thread executing by calling its entry-point function.<P>

<P>The two new threads each display their names and then proceed to loop and display their progress periodically. Since each of these threads is executing its own instance function, each has its own set of instance data members.<P>

<P>All three threads write to standard output, and, as you can see from the following, the output from the threads is intertwined:<P>

<pre>
Primary thread terminating
t1: i =         0
t1: i =    200000
t2: i =  -1000000
t2: i =   -800000
t1: i =    400000
t1: i =    600000
t1: i =    800000
t1: i =   1000000
t1 thread terminating
t2: i =   -600000
t2: i =   -400000
t2: i =   -200000
t2: i =         0
t2 thread terminating
</pre>

<P>Of course, the output might be ordered differently on subsequent executions.<P>

<P>In this output, the primary thread terminated before either of the other two started running. This demonstrates that although the primary thread was the parent of the other threads, the lifetimes of all three threads are unrelated. (You can make the life of a child thread be dependent on that of its parent by making the child a &#147;background&#148; thread.)<P>

<P>Although the entry-point function used in this example is trivial, that function can call any other function to which it has access.<P>

<P>If you want different threads to start execution with different entry-point functions, you simply define those functions in the same or different classes, as you see fit.<P>

<h3>Synchronized Statements</h3>

<P>In <a href="cuj0310jaeschke_l2.htm">Listing 2</a>, I have two threads accessing the same <B>Point</B>. One of them continually sets the <B>Point</B>&#146;s x- and y-coordinates to some new values while the other retrieves these values and displays them.<P>

<P>Even though both threads start executing the same entry-point function, you can make each thread behave differently by passing a value to their constructors. The function <B>Sleep</B> suspends the calling thread for the given number of milliseconds.<P>

<P>The potential for conflict arises from the fact that one thread can be calling <B>Move</B> in case 3 while the other is (implicitly) calling <B>ToString</B> in case 4. Since both access the same <B>Point</B>, without synchronization <B>Move</B> might update the x-coordinate, but before it can update the corresponding y-coordinate, <B>ToString</B> could run and display a mismatched coordinate pair. When the appropriate blocks of code are synchronized, as shown in cases 1 and 2, the coordinate pairs always match.<P>

<P>Since <B>Move</B> and <B>ToString</B> are instance functions, when they are called on the same <B>Point</B>, they share a common lock for that <B>Point</B>. To get exclusive access to an object&#146;s lock, you call <B>Monitor::Enter</B>, giving it a pointer to that lock. Then if <B>Move</B> is called to operate on the same <B>Point</B> as <B>ToString</B>, <B>Move</B> is blocked until <B>ToString</B> is completed, and vice versa. As a result, the functions spend time waiting on each other whereas without synchronization, they both run as fast as possible. For the sake of discussion, groups of statements that are used for synchronization will be referred to as &#147;lock blocks.&#148;<P>

<P>Once control of an object&#146;s lock is obtained, you are guaranteed that only one instance function from that class can have its critical code be executed on that object at any one time. Of course, an instance function in that class that uses no lock pays no mind to what any of its synchronized siblings are doing, so you must be careful to use locks as appropriate. Instance functions&#146; lock blocks that are operating on different objects do not wait on each other. A lock is released when the code associated with a lock block terminates normally or an exception is thrown from within it. Therefore, the lock is in place while code within a lock block calls any and all other functions.<P>

<P>It is the programmer&#146;s responsibility to avoid a deadlock, that situation when thread <B>A</B> is waiting on thread <B>B</B>, and vice versa.<P>

<P>Consider <a href="cuj0310jaeschke_l3.htm">Listing 3</a>. When the lock block begins execution in case 2, the lock for the array pointed to by <B>array</B> is engaged thereby blocking all other code that also needs to synchronize on that array, such as case 3 when both functions are called to operate on the same array.<P>

<P>A lock block can contain another lock block for the same object since it already has a lock on that object. In this case, the lock count is simply increased; it must decrease to zero before that object can be operated on by another synchronized statement in another thread. A lock block can also contain a lock block for a different object, in which case, it will be blocked until that second object becomes available. Here&#146;s an example:<P>

<pre>
  static void CopyArrays(int list1 __gc[],
                         int list2 __gc[])
  {
/*4*/    Monitor::Enter(list1);
/*5*/      Monitor::Enter(list2);
        Array::Copy(list1, list2,
          list1.Length);
      Monitor::Exit(list2);
    Monitor::Exit(list1);
  }
};
</pre>

<P>The obvious thing to do with a lock block is to use the instance object for the parent function. However, you can invent lock objects and synchronize on them without actually having those objects contain any information (see <a href="cuj0310jaeschke_l4.htm">Listing 4</a>).<P>

<P>In <a href="cuj0310jaeschke_l4.htm">Listing 4</a>, class <B>Th04</B> has a lock object called <B>fileLock</B> that contains no data and is never initialized or used in any context except a lock block. Functions <B>M1</B> and <B>M2</B> each contain a statement that must be blocked while the other runs, and vice versa.<P>

<P>If a class function (rather than an instance function) needs synchronizing, the lock object is obtained by using the <B>__typeof</B> operator. There is one lock object for each class (as well as one for each instance of that class). A lock on a class means that only one class function&#146;s lock block for that class can execute at a time as shown in <a href="cuj0310jaeschke_l5.htm">Listing 5</a>).<P>

<h3>Other Forms of Synchronization</h3>

<P>You can control synchronization of threads directly by using a number of functions in classes <B>Monitor</B> and <B>Thread</B>. For example, consider a buffer into which one thread writes and another thread reads. The two threads are synchronized such that you can&#146;t process the contents of the buffer until the creator has put something there, and the creator can&#146;t put another message there until the previous one has been processed.<P>

<P>Although space limitations prohibit me from showing an example, the functions involved in such an arrangement are <B>Monitor::Pulse</B> and <B>Monitor::Wait</B>. Basically, the writer thread gets ownership of the buffer, writes to it, and then calls <B>Pulse</B> and releases its hold on the buffer&#146;s lock. Some thread waiting (via <B>Wait</B>) for that lock to become available then gets ownership, reads from the buffer, and then releases its lock. Calling <B>PulseAll</B> allows all waiting threads to continue, rather than just one of them.<P>

<P>The function <B>Thread::Sleep</B> can also be useful, as it allows a thread to be suspended for a given number of milliseconds.<P>

<h3><b>volatile</b> Fields</h3>

<P>The field modifier <B>volatile</B> tells the compiler that no one thread controls all aspects of this field. Specifically, one or more other threads might be reading from and/or writing to this variable asynchronously. Essentially, this modifier forces the compiler to be less aggressive when performing optimization. Consider the following:<P>

<pre>
  volatile int i = 0;

/*1*/  i = 10;
/*2*/  i = 20;

/*3*/  if (i &lt; 5 || i &gt; 10) {
    // ...
  }

  int copy = i;

/*4*/  if (copy &lt; 5 || copy &gt; 10) {
    // ...
  }
</pre>

<P>In the absence of <B>volatile</B>, case 1 could safely be ignored, since you immediately overwrite the value of <B>i</B> in case 2. However, given the <B>volatile</B> modifier, the compiler must perform both store operations.<P>

<P>In case 3, the compiler must generate code to fetch the value of <B>i</B> twice. However, its value might change between fetches. To make sure you are testing the same value, you have to write something like case 4 instead. By storing a snapshot of <B>i</B> in the non-volatile variable copy, you can safely use the value of <B>copy</B> multiple times knowing that its value cannot be changing &#147;behind the scenes.&#148;<P>

<P>By using <B>volatile</B>, you can avoid explicit synchronization for certain kinds of variable access.<P>

<h3>Thread-Local Storage</h3>
<P>When writing a multithreaded application, it can be useful to have variables that are specific to a particular thread. Although this is not a standard feature of C++, Managed C++ supports it via an attribute that allows &#147;Thread-Local Storage.&#148; For example, consider the following program:<P>

<pre>
#using &lt;mscorlib.dll&gt;
using namespace System;
using namespace System::Threading;

__gc class Th07
{
/*1*/  int f1;
/*2*/  static int f2 = 20;
/*3*/  [ThreadStatic] static int f3 = 30;
</pre>

<P><b>f1</b> is an instance field, so each instance of type <B>Th07</B> has its own copy, and that exists for the life of its parent object. On the other hand, <B>f2</B> is a class field, so there is only one occurrence of it for the class, regardless of the number of instances of that class. In theory, this field exists until the applications terminate. Neither of these fields is specific to a thread. With the appropriate constructs, both kinds of fields can be accessed by multiple threads.<P>

<P>Simply stated, thread-local storage is memory that is owned by a particular thread, and that memory is allocated when a new thread is created and deallocated when that thread terminates. It combines the privacy of local variables with the persistence of static variables. A field is marked as being thread-local by attaching to it the attribute <B>ThreadStatic</B>, as shown above in case 3. Like a local or static field, a thread-local static field can have an initializer.<P>

<pre>
public:
  Th07()
  {
    f1 = 10;
  }

  void TMain()
  {
    String *threadName =
      Thread::CurrentThread-&gt;Name;
    
/*4a*/    ++f1; ++f1; ++f1; ++f1; ++f1;

/*4b*/    Monitor::Enter(__typeof(Th07));
    ++f2; ++f2; ++f2; ++f2; ++f2;
    int f2LocalCopy = f2;
    Monitor::Exit(__typeof(Th07));

/*4c*/    ++f3; ++f3; ++f3; ++f3; ++f3;

    Console::WriteLine(S"Thread {0}: f1 = {1},
      f2 = {2}, f3 = {3}", threadName,
      f1.ToString(), f2LocalCopy.ToString(),
      f3.ToString());
  }
};
</pre>

<P>Function <B>TMain</B> is the entry point for new threads. This function simply increments the three fields, <B>f1</B>, <B>f2</B>, and <B>f3</B>, five times each and prints their current value. The lock block starting in case 4 makes sure that no other thread can concurrently access the shared variable <B>f2</B> while its value is being incremented or printed.<P>

<pre>
int main()
{
/*5*/  Thread::CurrentThread-&gt;Name = S"t0";

  Thread *t1 = new Thread
    (new ThreadStart(new Th07(),
    &amp;Th07::TMain));
  t1-&gt;Name = S"t1";

  Thread *t2 = new Thread
    (new ThreadStart(new Th07(),
    &amp;Th07::TMain));
  t2-&gt;Name = S"t2";

  t1-&gt;Start();
/*6*/  (new Th07())-&gt;TMain();
  t2-&gt;Start();
}
</pre>

<P>The primary thread sets its own name to <B>t0</B> in case 5 and then creates and starts two threads. It also calls <B>TMain</B> directly, as a regular function rather than as part of thread creation and startup. Here are several possible examples of the output that can result. (The only difference between the possible outputs is the order in which the threads do their incrementing and printing.)<P>

<pre>
Thread t0: f1 = 15, f2 = 25, f3 = 35
Thread t1: f1 = 15, f2 = 30, f3 = 5
Thread t2: f1 = 15, f2 = 35, f3 = 5

Thread t1: f1 = 15, f2 = 25, f3 = 5
Thread t0: f1 = 15, f2 = 30, f3 = 35
Thread t2: f1 = 15, f2 = 35, f3 = 5
</pre>

<P>Each of the three threads has its own instance of <B>f1</B>, which is initialized to <B>10</B>, so it is no surprise that each has the value <B>15</B> after being incremented five times. In the case of <B>f2</B>, all three threads share the same variable, so that one variable is incremented 15 times.<P>

<P>The threads <B>t1</B> and <B>t2</B> go through the thread-creation process, each getting its own version of <B>f3</B>. However, these thread-local variables take on their default value zero, rather than the initializer <B>30</B> shown in the source code. Beware! Then after being incremented five times, each has the value <B>5</B>. Thread <B>t0</B> exhibits different behavior. As you can see, this thread was not created by the same machinery as the other two threads. As a result, its <B>f3</B> <I>does</I> take on the explicit initial value, <B>30</B>. Also note that in case 6, <B>TMain</B> is being called as a regular function, not as part of the creation of a new thread.<P>

<h3>Atomicity and Interlocked Operations</h3>
<P>Consider the following scenario: an application has multiple threads executing in parallel with each thread having write access to some shared integer variable. Each thread simply increments that variable by one as follows:<P>

<pre>
++value;
</pre>

<P>Well that looks harmless enough. After all, this looks like an atomic operation, and on many systems, it is, at least from the point of view of a machine instruction. However, Managed C++&#146;s execution environment does not universally guarantee this.<P>

<P>To demonstrate this, <a href="cuj0310jaeschke_l6.htm">Listing 6</a> has three threads, each concurrently incrementing such a shared variable ten million times. It then displays that variable&#146;s final value, which, in theory, should be thirty million. The resulting application can be run in one of two modes: the default mode is unsynchronized and uses the <B>++</B> operator; the alternate mode, indicated by using a command-line argument of <B>Y</B> or <B>y</B>, uses a synchronized library increment function instead.<P>

<P>When the standard <B>++</B> operator is used, five consecutive executions of the application resulted in the following output (when run on an Intel Pentium-based system):<P>

<pre>
After 30000000 operations, value = 20672006
After 30000000 operations, value = 19852180
After 30000000 operations, value = 27631609
After 30000000 operations, value = 25205827
After 30000000 operations, value = 25429970
</pre>

<P>and as you can see, the reported total falls far short of the correct answer. Simply stated, between 20 and 30 percent of the increments went unreported. When the same program runs in synchronized mode &#151; that is, using <B>Interlocked</B>&#146;s <B>Increment</B> instead &#151; all thirty million increments are done and reported correctly, as follows:<P>

<pre>
After 30000000 operations, value = 30000000
</pre>

<P>Class <B>Interlocked</B> also has a <B>Decrement</B> function. <P>
<hr>
<i><B>Rex Jaeschke</B> is an independent consultant and developer and leader of 
seminars, specializing in programming languages and environments, including .NET. 
He serves as editor of the C# standard. Rex can be reached at <a href="mailto:rex@RexJaeschke.com">rex@RexJaeschke.com</a>.</i>
</HTML>
